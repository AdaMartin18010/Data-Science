# çŸ¥è¯†æ¨ç†ä¸å½’çº³ç†è®ºï¼šä»ç¬¦å·æ¨ç†åˆ°ç¥ç»æ¨ç†

> **åˆ›å»ºæ—¥æœŸ**ï¼š2025-01-15
> **æœ€åæ›´æ–°**ï¼š2025-01-15
> **ç‰ˆæœ¬**ï¼šv1.0
> **çŠ¶æ€**ï¼šå®æ–½ä¸­

---

## ğŸ“‹ ç›®å½•

- [çŸ¥è¯†æ¨ç†ä¸å½’çº³ç†è®ºï¼šä»ç¬¦å·æ¨ç†åˆ°ç¥ç»æ¨ç†](#çŸ¥è¯†æ¨ç†ä¸å½’çº³ç†è®ºä»ç¬¦å·æ¨ç†åˆ°ç¥ç»æ¨ç†)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1. æ¨ç†ç±»å‹åˆ†ç±»](#11-æ¨ç†ç±»å‹åˆ†ç±»)
    - [1.2. æ¨ç†æ–¹æ³•é€‰æ‹©å†³ç­–æ ‘](#12-æ¨ç†æ–¹æ³•é€‰æ‹©å†³ç­–æ ‘)
  - [2. ç¬¦å·æ¨ç†](#2-ç¬¦å·æ¨ç†)
    - [2.1. è§„åˆ™æ¨ç†](#21-è§„åˆ™æ¨ç†)
    - [2.2. é€»è¾‘æ¨ç†](#22-é€»è¾‘æ¨ç†)
    - [2.3. æœ¬ä½“æ¨ç†](#23-æœ¬ä½“æ¨ç†)
  - [3. ç»Ÿè®¡æ¨ç†](#3-ç»Ÿè®¡æ¨ç†)
    - [3.1. æ¦‚ç‡æ¨ç†](#31-æ¦‚ç‡æ¨ç†)
    - [3.2. é“¾æ¥é¢„æµ‹](#32-é“¾æ¥é¢„æµ‹)
  - [4. ç¥ç»æ¨ç†](#4-ç¥ç»æ¨ç†)
    - [4.1. çŸ¥è¯†å›¾è°±åµŒå…¥ï¼ˆKGEï¼‰](#41-çŸ¥è¯†å›¾è°±åµŒå…¥kge)
    - [4.2. å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰æ¨ç†](#42-å›¾ç¥ç»ç½‘ç»œgnnæ¨ç†)
    - [4.3. çŸ¥è¯†å›¾è°±åµŒå…¥å­˜å‚¨](#43-çŸ¥è¯†å›¾è°±åµŒå…¥å­˜å‚¨)
  - [5. çŸ¥è¯†å½’çº³](#5-çŸ¥è¯†å½’çº³)
    - [5.1. è§„åˆ™å½’çº³](#51-è§„åˆ™å½’çº³)
    - [5.2. æ¨¡å¼å½’çº³](#52-æ¨¡å¼å½’çº³)
    - [5.3. æ¦‚å¿µå½’çº³](#53-æ¦‚å¿µå½’çº³)
  - [6. æ··åˆæ¨ç†æ¡†æ¶](#6-æ··åˆæ¨ç†æ¡†æ¶)
    - [6.1. ç¬¦å·+ç¥ç»æ··åˆæ¨ç†](#61-ç¬¦å·ç¥ç»æ··åˆæ¨ç†)
  - [7. æ¨ç†ç³»ç»Ÿè®¾è®¡](#7-æ¨ç†ç³»ç»Ÿè®¾è®¡)
    - [7.1. æ¨ç†å¼•æ“æ¶æ„](#71-æ¨ç†å¼•æ“æ¶æ„)
    - [7.2. æ¨ç†æ€§èƒ½ä¼˜åŒ–](#72-æ¨ç†æ€§èƒ½ä¼˜åŒ–)
  - [8. å‚è€ƒèµ„æ–™](#8-å‚è€ƒèµ„æ–™)

---

## 1. æ¦‚è¿°

çŸ¥è¯†æ¨ç†æ˜¯ä»å·²çŸ¥çŸ¥è¯†æ¨å¯¼å‡ºæ–°çŸ¥è¯†çš„è¿‡ç¨‹ï¼ŒçŸ¥è¯†å½’çº³æ˜¯ä»å…·ä½“å®ä¾‹æŠ½è±¡å‡ºä¸€èˆ¬è§„å¾‹çš„è¿‡ç¨‹ã€‚

### 1.1. æ¨ç†ç±»å‹åˆ†ç±»

```mermaid
mindmap
  root((çŸ¥è¯†æ¨ç†))
    ç¬¦å·æ¨ç†
      è§„åˆ™æ¨ç†
      é€»è¾‘æ¨ç†
      æœ¬ä½“æ¨ç†
    ç»Ÿè®¡æ¨ç†
      æ¦‚ç‡æ¨ç†
      è´å¶æ–¯æ¨ç†
      é©¬å°”å¯å¤«æ¨ç†
    ç¥ç»æ¨ç†
      å›¾ç¥ç»ç½‘ç»œ
      çŸ¥è¯†å›¾è°±åµŒå…¥
      ç«¯åˆ°ç«¯å­¦ä¹ 
    æ··åˆæ¨ç†
      ç¬¦å·+ç¥ç»
      è§„åˆ™+å­¦ä¹ 
      å¤šé˜¶æ®µæ¨ç†
```

### 1.2. æ¨ç†æ–¹æ³•é€‰æ‹©å†³ç­–æ ‘

```mermaid
flowchart TD
    A[é€‰æ‹©æ¨ç†æ–¹æ³•] --> B{çŸ¥è¯†ç±»å‹}

    B -->|ç»“æ„åŒ–è§„åˆ™| C[ç¬¦å·æ¨ç†]
    B -->|æ¦‚ç‡çŸ¥è¯†| D[ç»Ÿè®¡æ¨ç†]
    B -->|å¤§è§„æ¨¡æ•°æ®| E[ç¥ç»æ¨ç†]
    B -->|æ··åˆçŸ¥è¯†| F[æ··åˆæ¨ç†]

    C --> G[è§„åˆ™å¼•æ“]
    D --> H[æ¦‚ç‡æ¨¡å‹]
    E --> I[ç¥ç»ç½‘ç»œ]
    F --> J[æ··åˆæ¡†æ¶]
```

---

## 2. ç¬¦å·æ¨ç†

### 2.1. è§„åˆ™æ¨ç†

**æ¨ç†è§„åˆ™å®šä¹‰**ï¼š

```text
è§„åˆ™å½¢å¼ï¼šIF å‰æ THEN ç»“è®º

ç¤ºä¾‹è§„åˆ™ï¼š
  R1: IF (X, parentOf, Y) AND (Y, parentOf, Z)
      THEN (X, grandparentOf, Z)

  R2: IF (X, type, Person) AND (X, age, A) AND A > 18
      THEN (X, type, Adult)
```

**è§„åˆ™æ¨ç†å®ç°**ï¼š

```sql
-- è§„åˆ™å­˜å‚¨è¡¨
CREATE TABLE knowledge_rules (
    rule_id SERIAL PRIMARY KEY,
    rule_name VARCHAR(100) NOT NULL,
    premise_pattern TEXT NOT NULL,  -- SPARQLæ¨¡å¼æˆ–Cypheræ¨¡å¼
    conclusion_pattern TEXT NOT NULL,
    rule_type VARCHAR(50) NOT NULL,  -- TRANSITIVE, SYMMETRIC, INVERSE, CUSTOM
    confidence DECIMAL(3,2) DEFAULT 1.0,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ä¸‰å…ƒç»„è¡¨ï¼ˆçŸ¥è¯†å›¾è°±å­˜å‚¨ï¼‰
CREATE TABLE knowledge_triples (
    triple_id BIGSERIAL PRIMARY KEY,
    subject VARCHAR(200) NOT NULL,
    predicate VARCHAR(200) NOT NULL,
    object VARCHAR(200) NOT NULL,
    confidence DECIMAL(3,2) DEFAULT 1.0,
    source VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(subject, predicate, object)
);

CREATE INDEX idx_triples_subject ON knowledge_triples(subject);
CREATE INDEX idx_triples_predicate ON knowledge_triples(predicate);
CREATE INDEX idx_triples_object ON knowledge_triples(object);
CREATE INDEX idx_triples_spo ON knowledge_triples(subject, predicate, object);

-- ä¼ é€’æ€§æ¨ç†å‡½æ•°
CREATE OR REPLACE FUNCTION transitive_reasoning(
    p_predicate VARCHAR(200),
    p_max_depth INTEGER DEFAULT 5
)
RETURNS TABLE (
    subject VARCHAR(200),
    predicate VARCHAR(200),
    object VARCHAR(200),
    depth INTEGER
) AS $$
WITH RECURSIVE transitive_closure AS (
    -- åŸºç¡€æƒ…å†µï¼šç›´æ¥å…³ç³»
    SELECT
        subject,
        predicate,
        object,
        1 AS depth
    FROM knowledge_triples
    WHERE predicate = p_predicate

    UNION

    -- é€’å½’æƒ…å†µï¼šä¼ é€’å…³ç³»
    SELECT
        tc.subject,
        tc.predicate,
        t.object,
        tc.depth + 1
    FROM transitive_closure tc
    JOIN knowledge_triples t ON tc.object = t.subject
    WHERE t.predicate = p_predicate
      AND tc.depth < p_max_depth
)
SELECT * FROM transitive_closure;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ç¤ºä¾‹ï¼šæŸ¥æ‰¾æ‰€æœ‰ç¥–å…ˆå…³ç³»
SELECT * FROM transitive_reasoning('parentOf', 10);
```

### 2.2. é€»è¾‘æ¨ç†

**ä¸€é˜¶é€»è¾‘æ¨ç†**ï¼š

```text
é€»è¾‘è§„åˆ™ï¼š
  âˆ€x, y, z: parentOf(x, y) âˆ§ parentOf(y, z) â†’ grandparentOf(x, z)

æ¨ç†è¿‡ç¨‹ï¼š
  1. å·²çŸ¥ï¼šparentOf(Alice, Bob)
  2. å·²çŸ¥ï¼šparentOf(Bob, Charlie)
  3. åº”ç”¨è§„åˆ™ï¼šgrandparentOf(Alice, Charlie)
```

**é€»è¾‘æ¨ç†å®ç°**ï¼š

```sql
-- é€»è¾‘è§„åˆ™è¡¨
CREATE TABLE logic_rules (
    rule_id SERIAL PRIMARY KEY,
    rule_formula TEXT NOT NULL,  -- ä¸€é˜¶é€»è¾‘å…¬å¼
    rule_type VARCHAR(50),  -- IMPLICATION, EQUIVALENCE, NEGATION
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- é€»è¾‘æ¨ç†å¼•æ“ï¼ˆç®€åŒ–ç‰ˆï¼‰
CREATE OR REPLACE FUNCTION logical_reasoning(
    p_goal_predicate VARCHAR(200),
    p_goal_subject VARCHAR(200),
    p_goal_object VARCHAR(200)
)
RETURNS BOOLEAN AS $$
DECLARE
    v_rule RECORD;
    v_result BOOLEAN := FALSE;
BEGIN
    -- æ£€æŸ¥ç›´æ¥äº‹å®
    SELECT EXISTS(
        SELECT 1 FROM knowledge_triples
        WHERE subject = p_goal_subject
          AND predicate = p_goal_predicate
          AND object = p_goal_object
    ) INTO v_result;

    IF v_result THEN
        RETURN TRUE;
    END IF;

    -- åº”ç”¨è§„åˆ™æ¨ç†
    FOR v_rule IN
        SELECT * FROM logic_rules WHERE is_active = TRUE
    LOOP
        -- è¿™é‡Œéœ€è¦å®ç°è§„åˆ™åŒ¹é…å’Œæ¨ç†é€»è¾‘
        -- ç®€åŒ–ç¤ºä¾‹ï¼šä¼ é€’æ€§è§„åˆ™
        IF v_rule.rule_type = 'TRANSITIVE' THEN
            -- æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¸­é—´å®ä½“
            SELECT EXISTS(
                SELECT 1 FROM knowledge_triples t1
                JOIN knowledge_triples t2 ON t1.object = t2.subject
                WHERE t1.subject = p_goal_subject
                  AND t1.predicate = p_goal_predicate
                  AND t2.predicate = p_goal_predicate
                  AND t2.object = p_goal_object
            ) INTO v_result;

            IF v_result THEN
                RETURN TRUE;
            END IF;
        END IF;
    END LOOP;

    RETURN FALSE;
END;
$$ LANGUAGE plpgsql;
```

### 2.3. æœ¬ä½“æ¨ç†

**OWLæœ¬ä½“æ¨ç†**ï¼š

```text
æœ¬ä½“å…¬ç†ç¤ºä¾‹ï¼š
  SubClassOf(Person, Animal)
  SubClassOf(Student, Person)

æ¨ç†ç»“æœï¼š
  SubClassOf(Student, Animal)  -- ä¼ é€’æ€§
```

**æœ¬ä½“æ¨ç†å®ç°**ï¼š

```sql
-- æœ¬ä½“ç±»å±‚æ¬¡è¡¨
CREATE TABLE ontology_classes (
    class_id SERIAL PRIMARY KEY,
    class_uri VARCHAR(500) UNIQUE NOT NULL,
    class_name VARCHAR(200) NOT NULL,
    parent_class_uri VARCHAR(500),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_ontology_classes_parent ON ontology_classes(parent_class_uri);

-- ç±»å±‚æ¬¡æ¨ç†ï¼ˆä¼ é€’é—­åŒ…ï¼‰
CREATE OR REPLACE FUNCTION get_all_subclasses(
    p_class_uri VARCHAR(500)
)
RETURNS TABLE (
    subclass_uri VARCHAR(500),
    depth INTEGER
) AS $$
WITH RECURSIVE subclass_hierarchy AS (
    -- åŸºç¡€ï¼šç›´æ¥å­ç±»
    SELECT
        class_uri,
        1 AS depth
    FROM ontology_classes
    WHERE parent_class_uri = p_class_uri

    UNION

    -- é€’å½’ï¼šé—´æ¥å­ç±»
    SELECT
        oc.class_uri,
        sh.depth + 1
    FROM subclass_hierarchy sh
    JOIN ontology_classes oc ON oc.parent_class_uri = sh.class_uri
)
SELECT class_uri AS subclass_uri, depth FROM subclass_hierarchy;
$$ LANGUAGE plpgsql;

-- å®ä¾‹ç±»å‹æ¨ç†
CREATE TABLE entity_types (
    entity_id BIGINT NOT NULL,
    type_uri VARCHAR(500) NOT NULL,
    PRIMARY KEY (entity_id, type_uri)
);

-- æ¨ç†æ‰€æœ‰ç±»å‹ï¼ˆåŒ…æ‹¬ç»§æ‰¿çš„ç±»å‹ï¼‰
CREATE OR REPLACE FUNCTION infer_all_types(
    p_entity_id BIGINT
)
RETURNS TABLE (type_uri VARCHAR(500)) AS $$
BEGIN
    RETURN QUERY
    WITH direct_types AS (
        SELECT type_uri FROM entity_types WHERE entity_id = p_entity_id
    ),
    inherited_types AS (
        SELECT DISTINCT parent.class_uri AS type_uri
        FROM entity_types et
        JOIN ontology_classes child ON et.type_uri = child.class_uri
        JOIN get_all_subclasses(child.class_uri) parent ON TRUE
        WHERE et.entity_id = p_entity_id
    )
    SELECT type_uri FROM direct_types
    UNION
    SELECT type_uri FROM inherited_types;
END;
$$ LANGUAGE plpgsql;
```

---

## 3. ç»Ÿè®¡æ¨ç†

### 3.1. æ¦‚ç‡æ¨ç†

**è´å¶æ–¯æ¨ç†**ï¼š

```text
è´å¶æ–¯è§„åˆ™ï¼š
  P(H|E) = P(E|H) Ã— P(H) / P(E)

å…¶ä¸­ï¼š
  H: å‡è®¾ï¼ˆå¦‚ï¼šå®ä½“é—´å­˜åœ¨å…³ç³»ï¼‰
  E: è¯æ®ï¼ˆå¦‚ï¼šå…±ç°ã€æ–‡æœ¬ç›¸ä¼¼åº¦ç­‰ï¼‰
```

**æ¦‚ç‡æ¨ç†å®ç°**ï¼š

```sql
-- å…³ç³»æ¦‚ç‡è¡¨
CREATE TABLE relation_probabilities (
    relation_id SERIAL PRIMARY KEY,
    subject_type VARCHAR(200) NOT NULL,
    predicate VARCHAR(200) NOT NULL,
    object_type VARCHAR(200) NOT NULL,
    prior_probability DECIMAL(5,4) NOT NULL,  -- P(predicate | subject_type, object_type)
    evidence_count BIGINT DEFAULT 0,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(subject_type, predicate, object_type)
);

-- è¯æ®è¡¨
CREATE TABLE relation_evidence (
    evidence_id BIGSERIAL PRIMARY KEY,
    subject VARCHAR(200) NOT NULL,
    predicate VARCHAR(200) NOT NULL,
    object VARCHAR(200) NOT NULL,
    evidence_type VARCHAR(50) NOT NULL,  -- COOCCURRENCE, TEXT_SIMILARITY, PATTERN
    evidence_strength DECIMAL(5,4) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- è´å¶æ–¯æ¨ç†å‡½æ•°
CREATE OR REPLACE FUNCTION bayesian_reasoning(
    p_subject VARCHAR(200),
    p_predicate VARCHAR(200),
    p_object VARCHAR(200)
)
RETURNS DECIMAL AS $$
DECLARE
    v_subject_type VARCHAR(200);
    v_object_type VARCHAR(200);
    v_prior DECIMAL(5,4);
    v_likelihood DECIMAL(5,4);
    v_evidence DECIMAL(5,4);
    v_posterior DECIMAL(5,4);
BEGIN
    -- è·å–å®ä½“ç±»å‹
    SELECT type_uri INTO v_subject_type
    FROM entity_types
    WHERE entity_id = (SELECT entity_id FROM entities WHERE uri = p_subject)
    LIMIT 1;

    SELECT type_uri INTO v_object_type
    FROM entity_types
    WHERE entity_id = (SELECT entity_id FROM entities WHERE uri = p_object)
    LIMIT 1;

    -- è·å–å…ˆéªŒæ¦‚ç‡
    SELECT prior_probability INTO v_prior
    FROM relation_probabilities
    WHERE subject_type = v_subject_type
      AND predicate = p_predicate
      AND object_type = v_object_type;

    IF v_prior IS NULL THEN
        v_prior := 0.01;  -- é»˜è®¤å…ˆéªŒ
    END IF;

    -- è®¡ç®—è¯æ®å¼ºåº¦
    SELECT AVG(evidence_strength) INTO v_evidence
    FROM relation_evidence
    WHERE subject = p_subject
      AND predicate = p_predicate
      AND object = p_object;

    IF v_evidence IS NULL THEN
        v_evidence := 0.5;  -- é»˜è®¤è¯æ®å¼ºåº¦
    END IF;

    -- è´å¶æ–¯æ›´æ–°
    v_likelihood := v_evidence;
    v_posterior := (v_likelihood * v_prior) /
                   (v_likelihood * v_prior + (1 - v_likelihood) * (1 - v_prior));

    RETURN v_posterior;
END;
$$ LANGUAGE plpgsql;
```

### 3.2. é“¾æ¥é¢„æµ‹

**åŸºäºç»Ÿè®¡çš„é“¾æ¥é¢„æµ‹**ï¼š

```sql
-- é“¾æ¥é¢„æµ‹ç»“æœè¡¨
CREATE TABLE link_predictions (
    prediction_id BIGSERIAL PRIMARY KEY,
    subject VARCHAR(200) NOT NULL,
    predicate VARCHAR(200) NOT NULL,
    object VARCHAR(200) NOT NULL,
    prediction_score DECIMAL(5,4) NOT NULL,
    prediction_method VARCHAR(50) NOT NULL,  -- STATISTICAL, EMBEDDING, HYBRID
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(subject, predicate, object, prediction_method)
);

-- åŸºäºå…±ç°çš„é“¾æ¥é¢„æµ‹
CREATE OR REPLACE FUNCTION cooccurrence_link_prediction(
    p_subject VARCHAR(200),
    p_predicate VARCHAR(200),
    p_top_k INTEGER DEFAULT 10
)
RETURNS TABLE (
    object VARCHAR(200),
    score DECIMAL(5,4)
) AS $$
BEGIN
    RETURN QUERY
    WITH subject_neighbors AS (
        SELECT object AS neighbor
        FROM knowledge_triples
        WHERE subject = p_subject
    ),
    neighbor_objects AS (
        SELECT
            t.object,
            COUNT(*) AS cooccurrence_count
        FROM knowledge_triples t
        JOIN subject_neighbors sn ON t.subject = sn.neighbor
        WHERE t.predicate = p_predicate
          AND t.object NOT IN (
              SELECT object FROM knowledge_triples
              WHERE subject = p_subject AND predicate = p_predicate
          )
        GROUP BY t.object
    ),
    max_count AS (
        SELECT MAX(cooccurrence_count) AS max_val FROM neighbor_objects
    )
    SELECT
        no.object,
        no.cooccurrence_count::DECIMAL / NULLIF(mc.max_val, 0) AS score
    FROM neighbor_objects no
    CROSS JOIN max_count mc
    ORDER BY score DESC
    LIMIT p_top_k;
END;
$$ LANGUAGE plpgsql;
```

---

## 4. ç¥ç»æ¨ç†

### 4.1. çŸ¥è¯†å›¾è°±åµŒå…¥ï¼ˆKGEï¼‰

**TransEæ¨¡å‹**ï¼š

```text
TransEæ ¸å¿ƒæ€æƒ³ï¼š
  å¯¹äºä¸‰å…ƒç»„ (h, r, t)ï¼Œæ»¡è¶³ï¼š
    h + r â‰ˆ t

  æŸå¤±å‡½æ•°ï¼š
    L = ||h + r - t||â‚‚
```

**KGEå®ç°ï¼ˆPythonç¤ºä¾‹ï¼‰**ï¼š

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader

class TransE(nn.Module):
    def __init__(self, num_entities, num_relations, embedding_dim=100):
        super(TransE, self).__init__()
        self.num_entities = num_entities
        self.num_relations = num_relations
        self.embedding_dim = embedding_dim

        # å®ä½“åµŒå…¥
        self.entity_embeddings = nn.Embedding(num_entities, embedding_dim)
        # å…³ç³»åµŒå…¥
        self.relation_embeddings = nn.Embedding(num_relations, embedding_dim)

        # åˆå§‹åŒ–
        nn.init.xavier_uniform_(self.entity_embeddings.weight.data)
        nn.init.xavier_uniform_(self.relation_embeddings.weight.data)

        # L2å½’ä¸€åŒ–
        self.entity_embeddings.weight.data = \
            nn.functional.normalize(self.entity_embeddings.weight.data, p=2, dim=1)

    def forward(self, heads, relations, tails, neg_heads=None, neg_tails=None):
        """
        å‰å‘ä¼ æ’­
        heads: [batch_size] å¤´å®ä½“ID
        relations: [batch_size] å…³ç³»ID
        tails: [batch_size] å°¾å®ä½“ID
        """
        h = self.entity_embeddings(heads)
        r = self.relation_embeddings(relations)
        t = self.entity_embeddings(tails)

        # TransEå¾—åˆ†ï¼š||h + r - t||
        score = torch.norm(h + r - t, p=2, dim=1)

        # è´Ÿé‡‡æ ·æŸå¤±
        if neg_heads is not None and neg_tails is not None:
            neg_h = self.entity_embeddings(neg_heads)
            neg_t = self.entity_embeddings(neg_tails)
            neg_score = torch.norm(neg_h + r - neg_t, p=2, dim=1)
            # è¾¹é™…æŸå¤±
            loss = torch.relu(score - neg_score + 1.0).mean()
            return loss, score

        return score

    def predict(self, heads, relations, candidates=None):
        """
        é¢„æµ‹å°¾å®ä½“
        """
        h = self.entity_embeddings(heads)
        r = self.relation_embeddings(relations)

        if candidates is None:
            # å¯¹æ‰€æœ‰å®ä½“è®¡ç®—å¾—åˆ†
            all_entities = torch.arange(self.num_entities).to(heads.device)
            t_candidates = self.entity_embeddings(all_entities)
        else:
            t_candidates = self.entity_embeddings(candidates)

        # è®¡ç®—å¾—åˆ†
        scores = torch.norm(
            h.unsqueeze(1) + r.unsqueeze(1) - t_candidates.unsqueeze(0),
            p=2, dim=2
        )

        return scores

# è®­ç»ƒç¤ºä¾‹
def train_transe(model, train_data, num_epochs=100, batch_size=128):
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(num_epochs):
        total_loss = 0
        for batch in DataLoader(train_data, batch_size=batch_size, shuffle=True):
            heads, relations, tails = batch

            # è´Ÿé‡‡æ ·
            neg_heads = torch.randint(0, model.num_entities, (batch_size,))
            neg_tails = torch.randint(0, model.num_entities, (batch_size,))

            optimizer.zero_grad()
            loss, _ = model(heads, relations, tails, neg_heads, neg_tails)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        print(f"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_data)}")
```

### 4.2. å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰æ¨ç†

**GCNï¼ˆGraph Convolutional Networkï¼‰å®ç°**ï¼š

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv

class KGCN(nn.Module):
    """
    çŸ¥è¯†å›¾è°±å·ç§¯ç½‘ç»œ
    """
    def __init__(self, num_entities, num_relations, embedding_dim=100, hidden_dim=200):
        super(KGCN, self).__init__()
        self.num_entities = num_entities
        self.num_relations = num_relations

        # å®ä½“åµŒå…¥
        self.entity_embedding = nn.Embedding(num_entities, embedding_dim)
        # å…³ç³»åµŒå…¥
        self.relation_embedding = nn.Embedding(num_relations, embedding_dim)

        # GCNå±‚
        self.conv1 = GCNConv(embedding_dim, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, embedding_dim)

        # é“¾æ¥é¢„æµ‹å¤´
        self.link_predictor = nn.Linear(embedding_dim * 3, 1)

    def forward(self, x, edge_index, edge_type, heads, relations, tails):
        """
        x: èŠ‚ç‚¹ç‰¹å¾ [num_nodes, embedding_dim]
        edge_index: è¾¹ç´¢å¼• [2, num_edges]
        edge_type: è¾¹ç±»å‹ï¼ˆå…³ç³»ï¼‰[num_edges]
        """
        # GCNä¼ æ’­
        x = F.relu(self.conv1(x, edge_index))
        x = self.conv2(x, edge_index)

        # è·å–å®ä½“åµŒå…¥
        h_emb = x[heads]
        r_emb = self.relation_embedding(relations)
        t_emb = x[tails]

        # é“¾æ¥é¢„æµ‹
        combined = torch.cat([h_emb, r_emb, t_emb], dim=1)
        score = torch.sigmoid(self.link_predictor(combined))

        return score
```

### 4.3. çŸ¥è¯†å›¾è°±åµŒå…¥å­˜å‚¨

**åœ¨æ•°æ®åº“ä¸­å­˜å‚¨åµŒå…¥å‘é‡**ï¼š

```sql
-- å®ä½“åµŒå…¥è¡¨
CREATE TABLE entity_embeddings (
    entity_id BIGINT PRIMARY KEY,
    embedding vector(100) NOT NULL,  -- TransEåµŒå…¥å‘é‡
    model_name VARCHAR(100) NOT NULL,
    model_version VARCHAR(50) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_entity_embeddings_vector
ON entity_embeddings
USING hnsw (embedding vector_cosine_ops);

-- å…³ç³»åµŒå…¥è¡¨
CREATE TABLE relation_embeddings (
    relation_id INTEGER PRIMARY KEY,
    relation_uri VARCHAR(500) UNIQUE NOT NULL,
    embedding vector(100) NOT NULL,
    model_name VARCHAR(100) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- åŸºäºåµŒå…¥çš„é“¾æ¥é¢„æµ‹
CREATE OR REPLACE FUNCTION embedding_link_prediction(
    p_head_entity_id BIGINT,
    p_relation_id INTEGER,
    p_top_k INTEGER DEFAULT 10
)
RETURNS TABLE (
    tail_entity_id BIGINT,
    score DECIMAL(5,4)
) AS $$
DECLARE
    v_head_embedding vector(100);
    v_relation_embedding vector(100);
BEGIN
    -- è·å–å¤´å®ä½“å’Œå…³ç³»åµŒå…¥
    SELECT embedding INTO v_head_embedding
    FROM entity_embeddings
    WHERE entity_id = p_head_entity_id;

    SELECT embedding INTO v_relation_embedding
    FROM relation_embeddings
    WHERE relation_id = p_relation_id;

    -- è®¡ç®—ç›®æ ‡åµŒå…¥ï¼šhead + relation
    -- é¢„æµ‹å°¾å®ä½“ï¼šæ‰¾åˆ°æœ€æ¥è¿‘çš„å®ä½“åµŒå…¥
    RETURN QUERY
    SELECT
        ee.entity_id,
        1 - (ee.embedding <=> (v_head_embedding + v_relation_embedding)) AS score
    FROM entity_embeddings ee
    ORDER BY ee.embedding <=> (v_head_embedding + v_relation_embedding)
    LIMIT p_top_k;
END;
$$ LANGUAGE plpgsql;
```

---

## 5. çŸ¥è¯†å½’çº³

### 5.1. è§„åˆ™å½’çº³

**ä»å®ä¾‹å½’çº³è§„åˆ™**ï¼š

```text
å½’çº³è¿‡ç¨‹ï¼š
  è¾“å…¥ï¼šå¤šä¸ªä¸‰å…ƒç»„å®ä¾‹
    (Alice, parentOf, Bob)
    (Bob, parentOf, Charlie)
    (David, parentOf, Eve)
    (Eve, parentOf, Frank)

  å½’çº³è§„åˆ™ï¼š
    IF (X, parentOf, Y) AND (Y, parentOf, Z)
    THEN (X, grandparentOf, Z)
```

**è§„åˆ™å½’çº³å®ç°**ï¼š

```sql
-- è§„åˆ™æ¨¡å¼è¡¨
CREATE TABLE rule_patterns (
    pattern_id SERIAL PRIMARY KEY,
    pattern_type VARCHAR(50) NOT NULL,  -- TRANSITIVE, SYMMETRIC, INVERSE
    premise_pattern TEXT NOT NULL,
    conclusion_pattern TEXT NOT NULL,
    support_count INTEGER DEFAULT 0,  -- æ”¯æŒè¯¥è§„åˆ™çš„å®ä¾‹æ•°
    confidence DECIMAL(5,4),  -- ç½®ä¿¡åº¦
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- è§„åˆ™å½’çº³å‡½æ•°ï¼ˆä¼ é€’æ€§è§„åˆ™ï¼‰
CREATE OR REPLACE FUNCTION induce_transitive_rule(
    p_predicate VARCHAR(200),
    p_min_support INTEGER DEFAULT 10,
    p_min_confidence DECIMAL DEFAULT 0.8
)
RETURNS TABLE (
    rule_id INTEGER,
    support_count BIGINT,
    confidence DECIMAL
) AS $$
BEGIN
    RETURN QUERY
    WITH transitive_instances AS (
        SELECT
            t1.subject,
            t1.predicate,
            t2.object,
            COUNT(*) AS instance_count
        FROM knowledge_triples t1
        JOIN knowledge_triples t2
            ON t1.object = t2.subject
            AND t1.predicate = t2.predicate
        WHERE t1.predicate = p_predicate
        GROUP BY t1.subject, t1.predicate, t2.object
    ),
    rule_stats AS (
        SELECT
            ti.subject,
            ti.predicate,
            ti.object,
            ti.instance_count,
            CASE
                WHEN EXISTS(
                    SELECT 1 FROM knowledge_triples kt
                    WHERE kt.subject = ti.subject
                      AND kt.predicate = ti.predicate
                      AND kt.object = ti.object
                ) THEN 1
                ELSE 0
            END AS direct_exists
        FROM transitive_instances ti
    )
    SELECT
        ROW_NUMBER() OVER ()::INTEGER AS rule_id,
        SUM(instance_count)::BIGINT AS support_count,
        AVG(direct_exists::DECIMAL) AS confidence
    FROM rule_stats
    GROUP BY predicate
    HAVING SUM(instance_count) >= p_min_support
       AND AVG(direct_exists) >= p_min_confidence;
END;
$$ LANGUAGE plpgsql;
```

### 5.2. æ¨¡å¼å½’çº³

**å›¾æ¨¡å¼å½’çº³**ï¼š

```sql
-- å›¾æ¨¡å¼è¡¨
CREATE TABLE graph_patterns (
    pattern_id SERIAL PRIMARY KEY,
    pattern_name VARCHAR(200) NOT NULL,
    pattern_graph JSONB NOT NULL,  -- å›¾ç»“æ„æè¿°
    frequency INTEGER DEFAULT 0,
    significance_score DECIMAL(5,4),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ¨¡å¼åŒ¹é…å‡½æ•°
CREATE OR REPLACE FUNCTION match_graph_pattern(
    p_pattern_graph JSONB
)
RETURNS TABLE (
    match_id BIGINT,
    matched_entities JSONB
) AS $$
DECLARE
    v_pattern_nodes JSONB;
    v_pattern_edges JSONB;
BEGIN
    -- è§£ææ¨¡å¼å›¾
    v_pattern_nodes := p_pattern_graph->'nodes';
    v_pattern_edges := p_pattern_graph->'edges';

    -- å®ç°å›¾æ¨¡å¼åŒ¹é…ç®—æ³•
    -- è¿™é‡Œç®€åŒ–ç¤ºä¾‹ï¼Œå®é™…éœ€è¦å®ç°å­å›¾åŒæ„ç®—æ³•

    RETURN QUERY
    SELECT
        ROW_NUMBER() OVER ()::BIGINT AS match_id,
        '{}'::JSONB AS matched_entities;  -- ç®€åŒ–ç¤ºä¾‹
END;
$$ LANGUAGE plpgsql;
```

### 5.3. æ¦‚å¿µå½’çº³

**ä»å®ä¾‹å½’çº³æ¦‚å¿µ**ï¼š

```sql
-- æ¦‚å¿µå½’çº³è¡¨
CREATE TABLE concept_inductions (
    concept_id SERIAL PRIMARY KEY,
    concept_name VARCHAR(200) NOT NULL,
    parent_concept_id INTEGER REFERENCES concept_inductions(concept_id),
    defining_properties JSONB,  -- å®šä¹‰è¯¥æ¦‚å¿µçš„å±æ€§
    instance_count INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ¦‚å¿µå½’çº³å‡½æ•°ï¼ˆåŸºäºå…±åŒå±æ€§ï¼‰
CREATE OR REPLACE FUNCTION induce_concept(
    p_min_instances INTEGER DEFAULT 5,
    p_min_common_properties INTEGER DEFAULT 3
)
RETURNS TABLE (
    concept_id INTEGER,
    concept_name VARCHAR(200),
    common_properties JSONB,
    instance_count BIGINT
) AS $$
BEGIN
    RETURN QUERY
    WITH entity_properties AS (
        SELECT
            e.entity_id,
            jsonb_object_agg(p.predicate, p.object) AS properties
        FROM entities e
        JOIN knowledge_triples p ON e.entity_id = p.subject
        GROUP BY e.entity_id
    ),
    property_groups AS (
        SELECT
            properties,
            COUNT(*) AS instance_count,
            array_agg(entity_id) AS entity_ids
        FROM entity_properties
        GROUP BY properties
        HAVING COUNT(*) >= p_min_instances
    )
    SELECT
        ROW_NUMBER() OVER ()::INTEGER AS concept_id,
        'Concept_' || ROW_NUMBER() OVER ()::TEXT AS concept_name,
        pg.properties AS common_properties,
        pg.instance_count::BIGINT
    FROM property_groups pg
    WHERE jsonb_object_keys(pg.properties)::INTEGER >= p_min_common_properties;
END;
$$ LANGUAGE plpgsql;
```

---

## 6. æ··åˆæ¨ç†æ¡†æ¶

### 6.1. ç¬¦å·+ç¥ç»æ··åˆæ¨ç†

**æ··åˆæ¨ç†æ¶æ„**ï¼š

```mermaid
flowchart TD
    A[æŸ¥è¯¢] --> B[ç¬¦å·æ¨ç†å±‚]
    B --> C{æ‰¾åˆ°ç­”æ¡ˆ?}

    C -->|æ˜¯| D[è¿”å›ç»“æœ]
    C -->|å¦| E[ç¥ç»æ¨ç†å±‚]

    E --> F[åµŒå…¥æ£€ç´¢]
    F --> G[é“¾æ¥é¢„æµ‹]

    G --> H{ç½®ä¿¡åº¦é«˜?}
    H -->|æ˜¯| I[éªŒè¯å¹¶è¿”å›]
    H -->|å¦| J[æ··åˆè¯„åˆ†]

    J --> K[æœ€ç»ˆç»“æœ]
```

**æ··åˆæ¨ç†å®ç°**ï¼š

```sql
-- æ··åˆæ¨ç†ç»“æœè¡¨
CREATE TABLE hybrid_reasoning_results (
    result_id BIGSERIAL PRIMARY KEY,
    query_subject VARCHAR(200),
    query_predicate VARCHAR(200),
    query_object VARCHAR(200),
    symbolic_score DECIMAL(5,4),
    neural_score DECIMAL(5,4),
    combined_score DECIMAL(5,4),
    reasoning_path TEXT,  -- æ¨ç†è·¯å¾„
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ··åˆæ¨ç†å‡½æ•°
CREATE OR REPLACE FUNCTION hybrid_reasoning(
    p_subject VARCHAR(200),
    p_predicate VARCHAR(200),
    p_object VARCHAR(200),
    p_symbolic_weight DECIMAL DEFAULT 0.6,
    p_neural_weight DECIMAL DEFAULT 0.4
)
RETURNS DECIMAL AS $$
DECLARE
    v_symbolic_score DECIMAL(5,4);
    v_neural_score DECIMAL(5,4);
    v_combined_score DECIMAL(5,4);
BEGIN
    -- ç¬¦å·æ¨ç†å¾—åˆ†
    SELECT CASE
        WHEN EXISTS(
            SELECT 1 FROM knowledge_triples
            WHERE subject = p_subject
              AND predicate = p_predicate
              AND object = p_object
        ) THEN 1.0
        ELSE 0.0
    END INTO v_symbolic_score;

    -- ç¥ç»æ¨ç†å¾—åˆ†ï¼ˆåŸºäºåµŒå…¥ï¼‰
    SELECT embedding_link_prediction_score(
        (SELECT entity_id FROM entities WHERE uri = p_subject),
        (SELECT relation_id FROM relations WHERE uri = p_predicate),
        (SELECT entity_id FROM entities WHERE uri = p_object)
    ) INTO v_neural_score;

    -- ç»„åˆå¾—åˆ†
    v_combined_score :=
        p_symbolic_weight * v_symbolic_score +
        p_neural_weight * v_neural_score;

    -- è®°å½•ç»“æœ
    INSERT INTO hybrid_reasoning_results
    (query_subject, query_predicate, query_object,
     symbolic_score, neural_score, combined_score)
    VALUES (p_subject, p_predicate, p_object,
            v_symbolic_score, v_neural_score, v_combined_score);

    RETURN v_combined_score;
END;
$$ LANGUAGE plpgsql;
```

---

## 7. æ¨ç†ç³»ç»Ÿè®¾è®¡

### 7.1. æ¨ç†å¼•æ“æ¶æ„

**å®Œæ•´æ¨ç†ç³»ç»ŸSchema**ï¼š

```sql
CREATE SCHEMA reasoning_engine;

-- æ¨ç†ä»»åŠ¡è¡¨
CREATE TABLE reasoning_engine.reasoning_tasks (
    task_id BIGSERIAL PRIMARY KEY,
    task_type VARCHAR(50) NOT NULL,  -- LINK_PREDICTION, QUERY_ANSWERING, RULE_INDUCTION
    query_pattern TEXT NOT NULL,
    reasoning_method VARCHAR(50) NOT NULL,  -- SYMBOLIC, NEURAL, HYBRID
    status VARCHAR(20) DEFAULT 'pending',  -- pending, processing, completed, failed
    result JSONB,
    execution_time_ms INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP
);

CREATE INDEX idx_reasoning_tasks_status ON reasoning_engine.reasoning_tasks(status);
CREATE INDEX idx_reasoning_tasks_created ON reasoning_engine.reasoning_tasks(created_at DESC);

-- æ¨ç†è§„åˆ™åº“
CREATE TABLE reasoning_engine.rule_library (
    rule_id SERIAL PRIMARY KEY,
    rule_name VARCHAR(200) NOT NULL,
    rule_category VARCHAR(50),  -- TRANSITIVE, SYMMETRIC, INVERSE, CUSTOM
    rule_definition TEXT NOT NULL,
    rule_confidence DECIMAL(5,4) DEFAULT 1.0,
    usage_count INTEGER DEFAULT 0,
    success_count INTEGER DEFAULT 0,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ¨ç†å†å²è¡¨
CREATE TABLE reasoning_engine.reasoning_history (
    history_id BIGSERIAL PRIMARY KEY,
    task_id BIGINT REFERENCES reasoning_engine.reasoning_tasks(task_id),
    step_order INTEGER NOT NULL,
    step_type VARCHAR(50),  -- RULE_APPLICATION, EMBEDDING_SEARCH, PATTERN_MATCH
    input_data JSONB,
    output_data JSONB,
    execution_time_ms INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_reasoning_history_task ON reasoning_engine.reasoning_history(task_id, step_order);
```

### 7.2. æ¨ç†æ€§èƒ½ä¼˜åŒ–

**æ¨ç†ç¼“å­˜**ï¼š

```sql
-- æ¨ç†ç»“æœç¼“å­˜
CREATE TABLE reasoning_engine.reasoning_cache (
    cache_id BIGSERIAL PRIMARY KEY,
    query_hash VARCHAR(64) UNIQUE NOT NULL,
    query_pattern TEXT NOT NULL,
    result JSONB NOT NULL,
    result_score DECIMAL(5,4),
    cache_hit_count INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_accessed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_reasoning_cache_hash ON reasoning_engine.reasoning_cache(query_hash);

-- ç¼“å­˜æŸ¥è¯¢å‡½æ•°
CREATE OR REPLACE FUNCTION get_cached_reasoning_result(
    p_query_pattern TEXT
)
RETURNS JSONB AS $$
DECLARE
    v_query_hash VARCHAR(64);
    v_cached_result JSONB;
BEGIN
    -- è®¡ç®—æŸ¥è¯¢å“ˆå¸Œ
    v_query_hash := md5(p_query_pattern);

    -- æŸ¥æ‰¾ç¼“å­˜
    SELECT result INTO v_cached_result
    FROM reasoning_engine.reasoning_cache
    WHERE query_hash = v_query_hash;

    -- æ›´æ–°è®¿é—®æ—¶é—´
    IF v_cached_result IS NOT NULL THEN
        UPDATE reasoning_engine.reasoning_cache
        SET cache_hit_count = cache_hit_count + 1,
            last_accessed_at = CURRENT_TIMESTAMP
        WHERE query_hash = v_query_hash;
    END IF;

    RETURN v_cached_result;
END;
$$ LANGUAGE plpgsql;
```

---

## 8. å‚è€ƒèµ„æ–™

- [çŸ¥è¯†å›¾è°±ç†è®º](./01.04-çŸ¥è¯†å›¾è°±ç†è®º.md)
- [å›¾ç¥ç»ç½‘ç»œè®ºæ–‡](https://arxiv.org/abs/2003.00911)
- [çŸ¥è¯†å›¾è°±åµŒå…¥ç»¼è¿°](https://arxiv.org/abs/2003.00911)

---

**æœ€åæ›´æ–°**ï¼š2025-01-15
**ç»´æŠ¤è€…**ï¼šData-Science Team
**çŠ¶æ€**ï¼šå®æ–½ä¸­
