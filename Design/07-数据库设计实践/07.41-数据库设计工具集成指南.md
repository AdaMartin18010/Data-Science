# æ•°æ®åº“è®¾è®¡å·¥å…·é›†æˆæŒ‡å—ï¼šå·¥å…·å¯¹æ¯”ä¸è‡ªåŠ¨åŒ–å®è·µ

> **åˆ›å»ºæ—¥æœŸ**ï¼š2025-01-16
> **æœ€åæ›´æ–°**ï¼š2025-01-16
> **ç‰ˆæœ¬**ï¼šv1.0
> **çŠ¶æ€**ï¼šå·²å®Œæˆ âœ…
> **ä¼˜å…ˆçº§**ï¼šP0

---

## ğŸ“‹ ç›®å½•

- [æ•°æ®åº“è®¾è®¡å·¥å…·é›†æˆæŒ‡å—ï¼šå·¥å…·å¯¹æ¯”ä¸è‡ªåŠ¨åŒ–å®è·µ](#æ•°æ®åº“è®¾è®¡å·¥å…·é›†æˆæŒ‡å—å·¥å…·å¯¹æ¯”ä¸è‡ªåŠ¨åŒ–å®è·µ)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1. å·¥å…·åˆ†ç±»](#11-å·¥å…·åˆ†ç±»)
    - [1.2. å·¥å…·é€‰æ‹©æ€ç»´å¯¼å›¾](#12-å·¥å…·é€‰æ‹©æ€ç»´å¯¼å›¾)
  - [2. æ•°æ®åº“è®¾è®¡å·¥å…·å¯¹æ¯”](#2-æ•°æ®åº“è®¾è®¡å·¥å…·å¯¹æ¯”)
    - [2.1. å¯è§†åŒ–è®¾è®¡å·¥å…·](#21-å¯è§†åŒ–è®¾è®¡å·¥å…·)
    - [2.2. ä»£ç ç”Ÿæˆå·¥å…·](#22-ä»£ç ç”Ÿæˆå·¥å…·)
    - [2.3. ç‰ˆæœ¬æ§åˆ¶å·¥å…·](#23-ç‰ˆæœ¬æ§åˆ¶å·¥å…·)
    - [2.4. å·¥å…·å¯¹æ¯”çŸ©é˜µ](#24-å·¥å…·å¯¹æ¯”çŸ©é˜µ)
    - [2.5. å·¥å…·é€‰æ‹©å†³ç­–æ ‘](#25-å·¥å…·é€‰æ‹©å†³ç­–æ ‘)
  - [3. è‡ªåŠ¨åŒ–è„šæœ¬åº“](#3-è‡ªåŠ¨åŒ–è„šæœ¬åº“)
    - [3.1. Schemaç”Ÿæˆè„šæœ¬](#31-schemaç”Ÿæˆè„šæœ¬)
    - [3.2. ç´¢å¼•ä¼˜åŒ–è„šæœ¬](#32-ç´¢å¼•ä¼˜åŒ–è„šæœ¬)
    - [3.3. æ€§èƒ½åˆ†æè„šæœ¬](#33-æ€§èƒ½åˆ†æè„šæœ¬)
    - [3.4. åæ¨¡å¼æ£€æµ‹è„šæœ¬](#34-åæ¨¡å¼æ£€æµ‹è„šæœ¬)
    - [3.5. æ–‡æ¡£ç”Ÿæˆè„šæœ¬](#35-æ–‡æ¡£ç”Ÿæˆè„šæœ¬)
  - [4. CI/CDé›†æˆ](#4-cicdé›†æˆ)
    - [4.1. GitHub Actionsé›†æˆ](#41-github-actionsé›†æˆ)
    - [4.2. GitLab CIé›†æˆ](#42-gitlab-cié›†æˆ)
    - [4.3. Jenkinsé›†æˆ](#43-jenkinsé›†æˆ)
  - [5. å®é™…æ¡ˆä¾‹](#5-å®é™…æ¡ˆä¾‹)
    - [5.1. æ¡ˆä¾‹1ï¼šè‡ªåŠ¨åŒ–Schemaç”Ÿæˆ](#51-æ¡ˆä¾‹1è‡ªåŠ¨åŒ–schemaç”Ÿæˆ)
    - [5.2. æ¡ˆä¾‹2ï¼šè‡ªåŠ¨åŒ–æ€§èƒ½ä¼˜åŒ–](#52-æ¡ˆä¾‹2è‡ªåŠ¨åŒ–æ€§èƒ½ä¼˜åŒ–)
    - [5.3. æ¡ˆä¾‹3ï¼šè‡ªåŠ¨åŒ–æ–‡æ¡£ç”Ÿæˆ](#53-æ¡ˆä¾‹3è‡ªåŠ¨åŒ–æ–‡æ¡£ç”Ÿæˆ)
  - [6. æœ€ä½³å®è·µæ€»ç»“](#6-æœ€ä½³å®è·µæ€»ç»“)
    - [6.1. å·¥å…·é€‰æ‹©åŸåˆ™](#61-å·¥å…·é€‰æ‹©åŸåˆ™)
    - [6.2. è‡ªåŠ¨åŒ–åŸåˆ™](#62-è‡ªåŠ¨åŒ–åŸåˆ™)
  - [7. å‚è€ƒèµ„æ–™](#7-å‚è€ƒèµ„æ–™)
    - [7.1. å·¥å…·èµ„æº](#71-å·¥å…·èµ„æº)
    - [7.2. ç›¸å…³æ–‡æ¡£](#72-ç›¸å…³æ–‡æ¡£)

---

## 1. æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›æ•°æ®åº“è®¾è®¡å·¥å…·çš„å…¨é¢å¯¹æ¯”å’Œè‡ªåŠ¨åŒ–å®è·µæŒ‡å—ï¼Œå¸®åŠ©å›¢é˜Ÿé€‰æ‹©åˆé€‚å·¥å…·å¹¶å®ç°è‡ªåŠ¨åŒ–å·¥ä½œæµã€‚

### 1.1. å·¥å…·åˆ†ç±»

**å·¥å…·åˆ†ç±»**ï¼š

1. **å¯è§†åŒ–è®¾è®¡å·¥å…·**ï¼šERå›¾è®¾è®¡ã€Schemaå¯è§†åŒ–
2. **ä»£ç ç”Ÿæˆå·¥å…·**ï¼šä»è®¾è®¡ç”ŸæˆDDLã€ä»DDLç”Ÿæˆæ¨¡å‹ä»£ç 
3. **ç‰ˆæœ¬æ§åˆ¶å·¥å…·**ï¼šSchemaç‰ˆæœ¬ç®¡ç†ã€è¿ç§»ç®¡ç†
4. **æ€§èƒ½åˆ†æå·¥å…·**ï¼šæŸ¥è¯¢åˆ†æã€ç´¢å¼•åˆ†æ
5. **æ–‡æ¡£ç”Ÿæˆå·¥å…·**ï¼šè‡ªåŠ¨ç”Ÿæˆæ•°æ®åº“æ–‡æ¡£

### 1.2. å·¥å…·é€‰æ‹©æ€ç»´å¯¼å›¾

```mermaid
mindmap
  root((æ•°æ®åº“è®¾è®¡å·¥å…·))
    å¯è§†åŒ–å·¥å…·
      ERå›¾è®¾è®¡
        dbdiagram.io
        Draw.io
        Lucidchart
      Schemaå¯è§†åŒ–
        pgAdmin
        DBeaver
        DataGrip
    ä»£ç ç”Ÿæˆ
      DDLç”Ÿæˆ
        SQLAlchemy
        TypeORM
        Prisma
      æ¨¡å‹ç”Ÿæˆ
        Django ORM
        Rails ActiveRecord
    ç‰ˆæœ¬æ§åˆ¶
      è¿ç§»å·¥å…·
        Flyway
        Liquibase
        Alembic
      Schemaç‰ˆæœ¬
        Git
        Schema Registry
    æ€§èƒ½åˆ†æ
      æŸ¥è¯¢åˆ†æ
        pg_stat_statements
        EXPLAIN ANALYZE
      ç´¢å¼•åˆ†æ
        pg_indexes
        Index Advisor
    æ–‡æ¡£ç”Ÿæˆ
      è‡ªåŠ¨æ–‡æ¡£
        SchemaSpy
        dbdocs
        Data Dictionary
```

---

## 2. æ•°æ®åº“è®¾è®¡å·¥å…·å¯¹æ¯”

### 2.1. å¯è§†åŒ–è®¾è®¡å·¥å…·

**å·¥å…·å¯¹æ¯”**ï¼š

| å·¥å…· | ç±»å‹ | åŠŸèƒ½ | ä»·æ ¼ | æ˜“ç”¨æ€§ | æ¨èåº¦ |
|------|------|------|------|--------|--------|
| **dbdiagram.io** | åœ¨çº¿ | ERå›¾è®¾è®¡ã€DDLç”Ÿæˆ | å…è´¹/ä»˜è´¹ | â­â­â­â­â­ | â­â­â­â­â­ |
| **Draw.io** | æ¡Œé¢/åœ¨çº¿ | é€šç”¨å›¾è¡¨è®¾è®¡ | å…è´¹ | â­â­â­â­ | â­â­â­â­ |
| **Lucidchart** | åœ¨çº¿ | ä¸“ä¸šå›¾è¡¨è®¾è®¡ | ä»˜è´¹ | â­â­â­â­â­ | â­â­â­â­ |
| **pgAdmin** | æ¡Œé¢ | PostgreSQLç®¡ç† | å…è´¹ | â­â­â­â­ | â­â­â­â­ |
| **DBeaver** | æ¡Œé¢ | é€šç”¨æ•°æ®åº“å·¥å…· | å…è´¹/ä»˜è´¹ | â­â­â­â­â­ | â­â­â­â­â­ |
| **DataGrip** | IDE | æ•°æ®åº“IDE | ä»˜è´¹ | â­â­â­â­â­ | â­â­â­â­â­ |

**dbdiagram.ioç¤ºä¾‹**ï¼š

```dbml
// dbdiagram.ioè¯­æ³•ç¤ºä¾‹
Table users {
  id uuid [primary key]
  username varchar(50) [unique, not null]
  email varchar(100) [unique, not null]
  created_at timestamp [default: `now()`]
}

Table orders {
  id uuid [primary key]
  user_id uuid [ref: > users.id]
  total_amount decimal(10,2) [not null]
  created_at timestamp [default: `now()`]
}

Ref: orders.user_id > users.id [delete: cascade]
```

### 2.2. ä»£ç ç”Ÿæˆå·¥å…·

**å·¥å…·å¯¹æ¯”**ï¼š

| å·¥å…· | è¯­è¨€ | åŠŸèƒ½ | æ˜“ç”¨æ€§ | æ¨èåº¦ |
|------|------|------|--------|--------|
| **SQLAlchemy** | Python | ORMã€DDLç”Ÿæˆ | â­â­â­â­ | â­â­â­â­â­ |
| **TypeORM** | TypeScript | ORMã€è¿ç§» | â­â­â­â­ | â­â­â­â­â­ |
| **Prisma** | TypeScript | ORMã€è¿ç§» | â­â­â­â­â­ | â­â­â­â­â­ |
| **Django ORM** | Python | ORMã€è¿ç§» | â­â­â­â­â­ | â­â­â­â­â­ |
| **Rails ActiveRecord** | Ruby | ORMã€è¿ç§» | â­â­â­â­â­ | â­â­â­â­â­ |

**Prismaç¤ºä¾‹**ï¼š

```prisma
// schema.prisma
model User {
  id        String   @id @default(uuid())
  username  String   @unique
  email     String   @unique
  orders    Order[]
  createdAt DateTime @default(now())
}

model Order {
  id          String   @id @default(uuid())
  userId      String
  user        User     @relation(fields: [userId], references: [id])
  totalAmount Decimal  @db.Decimal(10, 2)
  createdAt   DateTime @default(now())
}
```

### 2.3. ç‰ˆæœ¬æ§åˆ¶å·¥å…·

**å·¥å…·å¯¹æ¯”**ï¼ˆè§è¿ç§»æ–‡æ¡£7.1èŠ‚ï¼‰

### 2.4. å·¥å…·å¯¹æ¯”çŸ©é˜µ

| å·¥å…·ç±»åˆ« | æœ€ä½³å·¥å…· | é€‚ç”¨åœºæ™¯ | æ¨èåº¦ |
|---------|---------|---------|--------|
| **å¯è§†åŒ–è®¾è®¡** | dbdiagram.io | ERå›¾è®¾è®¡ã€å¿«é€ŸåŸå‹ | â­â­â­â­â­ |
| **æ•°æ®åº“ç®¡ç†** | DBeaver | é€šç”¨æ•°æ®åº“ç®¡ç† | â­â­â­â­â­ |
| **ä»£ç ç”Ÿæˆ** | Prisma | TypeScripté¡¹ç›® | â­â­â­â­â­ |
| **ç‰ˆæœ¬æ§åˆ¶** | Flyway/Liquibase | Javaé¡¹ç›® | â­â­â­â­â­ |
| **æ€§èƒ½åˆ†æ** | pg_stat_statements | PostgreSQLæ€§èƒ½åˆ†æ | â­â­â­â­â­ |

### 2.5. å·¥å…·é€‰æ‹©å†³ç­–æ ‘

```mermaid
flowchart TD
    A[é€‰æ‹©æ•°æ®åº“è®¾è®¡å·¥å…·] --> B{ä½¿ç”¨åœºæ™¯}

    B -->|ERå›¾è®¾è®¡| C[å¯è§†åŒ–å·¥å…·]
    B -->|ä»£ç ç”Ÿæˆ| D[ORMå·¥å…·]
    B -->|ç‰ˆæœ¬ç®¡ç†| E[è¿ç§»å·¥å…·]
    B -->|æ€§èƒ½åˆ†æ| F[åˆ†æå·¥å…·]

    C --> C1{é¢„ç®—}
    C1 -->|å…è´¹| C2[dbdiagram.io]
    C1 -->|ä»˜è´¹| C3[Lucidchart]

    D --> D1{å¼€å‘è¯­è¨€}
    D1 -->|Python| D2[Django/SQLAlchemy]
    D1 -->|TypeScript| D3[Prisma/TypeORM]
    D1 -->|Ruby| D4[Rails]

    E --> E1{é¡¹ç›®ç±»å‹}
    E1 -->|Java| E2[Flyway/Liquibase]
    E1 -->|Python| E3[Alembic]
    E1 -->|é€šç”¨| E4[Sqitch]

    F --> F1{æ•°æ®åº“ç±»å‹}
    F1 -->|PostgreSQL| F2[pg_stat_statements]
    F1 -->|é€šç”¨| F3[é€šç”¨ç›‘æ§å·¥å…·]
```

---

## 3. è‡ªåŠ¨åŒ–è„šæœ¬åº“

### 3.1. Schemaç”Ÿæˆè„šæœ¬

**Python Schemaç”Ÿæˆå™¨**ï¼š

```python
# schema_generator.py
from typing import Dict, List
import psycopg2

class SchemaGenerator:
    def __init__(self, connection_string: str):
        self.conn = psycopg2.connect(connection_string)

    def generate_table_ddl(self, table_def: Dict) -> str:
        """ç”Ÿæˆè¡¨DDL"""
        ddl = f"CREATE TABLE {table_def['name']} (\n"

        columns = []
        for col in table_def['columns']:
            col_def = f"    {col['name']} {col['type']}"
            if col.get('not_null'):
                col_def += " NOT NULL"
            if col.get('default'):
                col_def += f" DEFAULT {col['default']}"
            columns.append(col_def)

        ddl += ",\n".join(columns)

        if table_def.get('primary_key'):
            ddl += f",\n    PRIMARY KEY ({', '.join(table_def['primary_key'])})"

        ddl += "\n);"
        return ddl

    def generate_index_ddl(self, index_def: Dict) -> str:
        """ç”Ÿæˆç´¢å¼•DDL"""
        unique = "UNIQUE " if index_def.get('unique') else ""
        ddl = f"CREATE {unique}INDEX {index_def['name']} ON {index_def['table']}"

        if index_def.get('method'):
            ddl += f" USING {index_def['method']}"

        ddl += f" ({', '.join(index_def['columns'])});"
        return ddl

    def generate_foreign_key_ddl(self, fk_def: Dict) -> str:
        """ç”Ÿæˆå¤–é”®DDL"""
        ddl = f"ALTER TABLE {fk_def['table']}\n"
        ddl += f"    ADD CONSTRAINT {fk_def['name']}\n"
        ddl += f"    FOREIGN KEY ({fk_def['column']})\n"
        ddl += f"    REFERENCES {fk_def['referenced_table']}({fk_def['referenced_column']})"

        if fk_def.get('on_delete'):
            ddl += f"\n    ON DELETE {fk_def['on_delete']}"
        if fk_def.get('on_update'):
            ddl += f"\n    ON UPDATE {fk_def['on_update']}"

        ddl += ";"
        return ddl
```

### 3.2. ç´¢å¼•ä¼˜åŒ–è„šæœ¬

**ç´¢å¼•ä¼˜åŒ–è„šæœ¬**ï¼š

```python
# index_optimizer.py
import psycopg2
from typing import List, Dict

class IndexOptimizer:
    def __init__(self, connection_string: str):
        self.conn = psycopg2.connect(connection_string)

    def analyze_index_usage(self) -> List[Dict]:
        """åˆ†æç´¢å¼•ä½¿ç”¨æƒ…å†µ"""
        query = """
        SELECT
            schemaname,
            tablename,
            indexname,
            idx_scan,
            idx_tup_read,
            idx_tup_fetch
        FROM pg_stat_user_indexes
        WHERE idx_scan = 0
        ORDER BY idx_tup_read DESC;
        """
        cursor = self.conn.cursor()
        cursor.execute(query)
        return [{
            'schema': row[0],
            'table': row[1],
            'index': row[2],
            'scans': row[3],
            'reads': row[4],
            'fetches': row[5]
        } for row in cursor.fetchall()]

    def suggest_indexes(self, table_name: str) -> List[Dict]:
        """å»ºè®®ç´¢å¼•"""
        query = """
        SELECT
            schemaname,
            tablename,
            seq_scan,
            seq_tup_read,
            idx_scan,
            seq_scan - idx_scan AS too_many_seq_scans
        FROM pg_stat_user_tables
        WHERE tablename = %s
        AND seq_scan > idx_scan + 1000;
        """
        cursor = self.conn.cursor()
        cursor.execute(query, (table_name,))
        results = cursor.fetchall()

        suggestions = []
        for row in results:
            if row[5] > 10000:  # å¤ªå¤šé¡ºåºæ‰«æ
                suggestions.append({
                    'table': row[1],
                    'issue': 'too_many_seq_scans',
                    'suggestion': f'Consider adding indexes on frequently queried columns'
                })

        return suggestions
```

### 3.3. æ€§èƒ½åˆ†æè„šæœ¬

**æ€§èƒ½åˆ†æè„šæœ¬**ï¼š

```python
# performance_analyzer.py
import psycopg2
from typing import List, Dict

class PerformanceAnalyzer:
    def __init__(self, connection_string: str):
        self.conn = psycopg2.connect(connection_string)

    def get_slow_queries(self, threshold_ms: int = 1000) -> List[Dict]:
        """è·å–æ…¢æŸ¥è¯¢"""
        query = """
        SELECT
            query,
            calls,
            total_exec_time,
            mean_exec_time,
            max_exec_time
        FROM pg_stat_statements
        WHERE mean_exec_time > %s
        ORDER BY mean_exec_time DESC
        LIMIT 20;
        """
        cursor = self.conn.cursor()
        cursor.execute(query, (threshold_ms,))
        return [{
            'query': row[0][:100],  # æˆªæ–­é•¿æŸ¥è¯¢
            'calls': row[1],
            'total_time': row[2],
            'mean_time': row[3],
            'max_time': row[4]
        } for row in cursor.fetchall()]

    def analyze_table_statistics(self) -> List[Dict]:
        """åˆ†æè¡¨ç»Ÿè®¡ä¿¡æ¯"""
        query = """
        SELECT
            schemaname,
            tablename,
            n_live_tup,
            n_dead_tup,
            last_vacuum,
            last_autovacuum
        FROM pg_stat_user_tables
        ORDER BY n_dead_tup DESC;
        """
        cursor = self.conn.cursor()
        cursor.execute(query)
        return [{
            'schema': row[0],
            'table': row[1],
            'live_tuples': row[2],
            'dead_tuples': row[3],
            'last_vacuum': row[4],
            'last_autovacuum': row[5]
        } for row in cursor.fetchall()]
```

### 3.4. åæ¨¡å¼æ£€æµ‹è„šæœ¬

**åæ¨¡å¼æ£€æµ‹è„šæœ¬**ï¼ˆè§åæ¨¡å¼æ–‡æ¡£8.3èŠ‚ï¼‰

### 3.5. æ–‡æ¡£ç”Ÿæˆè„šæœ¬

**æ–‡æ¡£ç”Ÿæˆè„šæœ¬**ï¼š

```python
# doc_generator.py
import psycopg2
from typing import Dict, List
import json

class DocGenerator:
    def __init__(self, connection_string: str):
        self.conn = psycopg2.connect(connection_string)

    def generate_schema_doc(self) -> str:
        """ç”ŸæˆSchemaæ–‡æ¡£"""
        tables = self.get_tables()

        doc = "# Database Schema Documentation\n\n"
        doc += f"Generated on: {datetime.now()}\n\n"

        for table in tables:
            doc += f"## Table: {table['name']}\n\n"
            doc += f"**Description**: {table.get('comment', 'N/A')}\n\n"

            doc += "### Columns\n\n"
            doc += "| Column | Type | Nullable | Default | Description |\n"
            doc += "|--------|------|----------|---------|-------------|\n"

            for col in table['columns']:
                doc += f"| {col['name']} | {col['type']} | "
                doc += f"{'Yes' if col['nullable'] else 'No'} | "
                doc += f"{col.get('default', 'N/A')} | {col.get('comment', '')} |\n"

            doc += "\n"

        return doc

    def get_tables(self) -> List[Dict]:
        """è·å–æ‰€æœ‰è¡¨ä¿¡æ¯"""
        query = """
        SELECT
            t.table_name,
            obj_description(c.oid) as table_comment
        FROM information_schema.tables t
        JOIN pg_class c ON c.relname = t.table_name
        WHERE t.table_schema = 'public'
        AND t.table_type = 'BASE TABLE'
        ORDER BY t.table_name;
        """
        cursor = self.conn.cursor()
        cursor.execute(query)

        tables = []
        for row in cursor.fetchall():
            table = {
                'name': row[0],
                'comment': row[1],
                'columns': self.get_columns(row[0])
            }
            tables.append(table)

        return tables

    def get_columns(self, table_name: str) -> List[Dict]:
        """è·å–è¡¨åˆ—ä¿¡æ¯"""
        query = """
        SELECT
            column_name,
            data_type,
            is_nullable,
            column_default,
            col_description(c.oid, a.attnum) as column_comment
        FROM information_schema.columns c
        JOIN pg_class cl ON cl.relname = %s
        JOIN pg_attribute a ON a.attrelid = cl.oid AND a.attname = c.column_name
        WHERE table_name = %s
        ORDER BY ordinal_position;
        """
        cursor = self.conn.cursor()
        cursor.execute(query, (table_name, table_name))

        return [{
            'name': row[0],
            'type': row[1],
            'nullable': row[2] == 'YES',
            'default': row[3],
            'comment': row[4]
        } for row in cursor.fetchall()]
```

---

## 4. CI/CDé›†æˆ

### 4.1. GitHub Actionsé›†æˆ

**GitHub Actionså·¥ä½œæµ**ï¼š

```yaml
# .github/workflows/db-migration.yml
name: Database Migration

on:
  push:
    branches: [ main ]
    paths:
      - 'migrations/**'

jobs:
  migrate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2

      - name: Setup PostgreSQL
        uses: harmon758/postgresql-action@v1
        with:
          postgresql version: '14'
          postgresql db: 'test_db'
          postgresql user: 'postgres'
          postgresql password: 'postgres'

      - name: Run Migrations
        run: |
          flyway migrate \
            -url=jdbc:postgresql://localhost:5432/test_db \
            -user=postgres \
            -password=postgres \
            -locations=filesystem:migrations

      - name: Run Tests
        run: |
          pytest tests/
```

### 4.2. GitLab CIé›†æˆ

**GitLab CIé…ç½®**ï¼š

```yaml
# .gitlab-ci.yml
stages:
  - migrate
  - test

migrate:
  stage: migrate
  image: postgres:14
  services:
    - postgres:14
  variables:
    POSTGRES_DB: test_db
    POSTGRES_USER: postgres
    POSTGRES_PASSWORD: postgres
  script:
    - flyway migrate
      -url=jdbc:postgresql://postgres:5432/test_db
      -user=postgres
      -password=postgres
      -locations=filesystem:migrations

test:
  stage: test
  image: python:3.9
  script:
    - pip install -r requirements.txt
    - pytest tests/
```

### 4.3. Jenkinsé›†æˆ

**Jenkins Pipeline**ï¼š

```groovy
// Jenkinsfile
pipeline {
    agent any

    stages {
        stage('Migrate') {
            steps {
                sh '''
                    flyway migrate \
                        -url=jdbc:postgresql://localhost:5432/test_db \
                        -user=postgres \
                        -password=postgres \
                        -locations=filesystem:migrations
                '''
            }
        }

        stage('Test') {
            steps {
                sh 'pytest tests/'
            }
        }
    }
}
```

---

## 5. å®é™…æ¡ˆä¾‹

### 5.1. æ¡ˆä¾‹1ï¼šè‡ªåŠ¨åŒ–Schemaç”Ÿæˆ

**åœºæ™¯**ï¼šä»YAMLå®šä¹‰è‡ªåŠ¨ç”ŸæˆPostgreSQL Schema

**å®ç°**ï¼š

```python
# ä½¿ç”¨Schemaç”Ÿæˆå™¨
generator = SchemaGenerator(connection_string)

table_def = {
    'name': 'users',
    'columns': [
        {'name': 'id', 'type': 'UUID', 'not_null': True, 'default': 'gen_random_uuid()'},
        {'name': 'username', 'type': 'VARCHAR(50)', 'not_null': True},
        {'name': 'email', 'type': 'VARCHAR(100)', 'not_null': True}
    ],
    'primary_key': ['id']
}

ddl = generator.generate_table_ddl(table_def)
print(ddl)
```

### 5.2. æ¡ˆä¾‹2ï¼šè‡ªåŠ¨åŒ–æ€§èƒ½ä¼˜åŒ–

**åœºæ™¯**ï¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä¼˜åŒ–æ…¢æŸ¥è¯¢

**å®ç°**ï¼š

```python
# ä½¿ç”¨æ€§èƒ½åˆ†æå™¨
analyzer = PerformanceAnalyzer(connection_string)

# è·å–æ…¢æŸ¥è¯¢
slow_queries = analyzer.get_slow_queries(threshold_ms=1000)

# è‡ªåŠ¨ä¼˜åŒ–
for query in slow_queries:
    suggestions = optimizer.suggest_indexes(query['table'])
    print(f"Query: {query['query']}")
    print(f"Suggestions: {suggestions}")
```

### 5.3. æ¡ˆä¾‹3ï¼šè‡ªåŠ¨åŒ–æ–‡æ¡£ç”Ÿæˆ

**åœºæ™¯**ï¼šè‡ªåŠ¨ç”Ÿæˆæ•°æ®åº“æ–‡æ¡£

**å®ç°**ï¼š

```python
# ä½¿ç”¨æ–‡æ¡£ç”Ÿæˆå™¨
generator = DocGenerator(connection_string)

# ç”Ÿæˆæ–‡æ¡£
doc = generator.generate_schema_doc()

# ä¿å­˜åˆ°æ–‡ä»¶
with open('schema_doc.md', 'w') as f:
    f.write(doc)
```

---

## 6. æœ€ä½³å®è·µæ€»ç»“

### 6.1. å·¥å…·é€‰æ‹©åŸåˆ™

1. **éœ€æ±‚é©±åŠ¨**ï¼šæ ¹æ®å®é™…éœ€æ±‚é€‰æ‹©å·¥å…·
2. **å›¢é˜Ÿç†Ÿæ‚‰åº¦**ï¼šé€‰æ‹©å›¢é˜Ÿç†Ÿæ‚‰çš„å·¥å…·
3. **æˆæœ¬è€ƒè™‘**ï¼šå¹³è¡¡åŠŸèƒ½å’Œæˆæœ¬
4. **å¯æ‰©å±•æ€§**ï¼šè€ƒè™‘æœªæ¥æ‰©å±•éœ€æ±‚

### 6.2. è‡ªåŠ¨åŒ–åŸåˆ™

1. **é€æ­¥è‡ªåŠ¨åŒ–**ï¼šä»ç®€å•ä»»åŠ¡å¼€å§‹
2. **æµ‹è¯•å……åˆ†**ï¼šè‡ªåŠ¨åŒ–è„šæœ¬è¦å……åˆ†æµ‹è¯•
3. **æ–‡æ¡£å®Œå–„**ï¼šè®°å½•è‡ªåŠ¨åŒ–æµç¨‹
4. **æŒç»­æ”¹è¿›**ï¼šæ ¹æ®åé¦ˆæŒç»­æ”¹è¿›

---

## 7. å‚è€ƒèµ„æ–™

### 7.1. å·¥å…·èµ„æº

- [dbdiagram.io](https://dbdiagram.io/)
- [Prismaæ–‡æ¡£](https://www.prisma.io/docs)
- [Flywayæ–‡æ¡£](https://flywaydb.org/)
- [DBeaveræ–‡æ¡£](https://dbeaver.io/)

### 7.2. ç›¸å…³æ–‡æ¡£

- [æ•°æ®åº“è®¾è®¡å·¥å…·ä¸æ¨¡æ¿åº“](./07.15-æ•°æ®åº“è®¾è®¡å·¥å…·ä¸æ¨¡æ¿åº“.md)
- [æ•°æ®åº“è¿ç§»ä¸ç‰ˆæœ¬ç®¡ç†](./07.07-æ•°æ®åº“è¿ç§»ä¸ç‰ˆæœ¬ç®¡ç†.md)
- [æ•°æ®åº“æ€§èƒ½è°ƒä¼˜å®æˆ˜](./07.08-æ•°æ®åº“æ€§èƒ½è°ƒä¼˜å®æˆ˜.md)

---

**åˆ›å»ºæ—¥æœŸ**ï¼š2025-01-16
**æœ€åæ›´æ–°**ï¼š2025-01-16
**ç‰ˆæœ¬**ï¼šv1.0
**çŠ¶æ€**ï¼šå·²å®Œæˆ âœ…
**ç»´æŠ¤è€…**ï¼šData-Science Team
