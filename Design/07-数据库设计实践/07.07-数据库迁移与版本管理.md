# 数据库迁移与版本管理：Schema演化的实践指南

> **创建日期**：2025-01-15
> **最后更新**：2025-01-15
> **版本**：v1.0
> **状态**：实施中

---

## 📋 目录

- [数据库迁移与版本管理：Schema演化的实践指南](#数据库迁移与版本管理schema演化的实践指南)
  - [📋 目录](#-目录)
  - [1. 概述](#1-概述)
    - [1.1. Schema演化挑战](#11-schema演化挑战)
    - [1.2. 迁移决策树](#12-迁移决策树)
  - [2. 数据库版本管理](#2-数据库版本管理)
    - [2.1. 版本表设计](#21-版本表设计)
    - [2.2. 迁移文件组织](#22-迁移文件组织)
    - [2.3. 迁移工具实现](#23-迁移工具实现)
  - [3. 迁移策略](#3-迁移策略)
    - [3.1. 添加列（零停机）](#31-添加列零停机)
    - [3.2. 删除列（零停机）](#32-删除列零停机)
    - [3.3. 修改列类型（零停机）](#33-修改列类型零停机)
    - [3.4. 重命名表（零停机）](#34-重命名表零停机)
  - [4. 零停机迁移](#4-零停机迁移)
    - [4.1. 双写模式](#41-双写模式)
    - [4.2. 变更数据捕获（CDC）](#42-变更数据捕获cdc)
    - [4.3. 迁移检查清单](#43-迁移检查清单)
  - [5. 数据迁移实践](#5-数据迁移实践)
    - [5.1. 大批量数据迁移](#51-大批量数据迁移)
    - [5.2. 数据验证](#52-数据验证)
  - [6. 回滚策略](#6-回滚策略)
    - [6.1. 可逆迁移设计](#61-可逆迁移设计)
    - [6.2. 数据回滚](#62-数据回滚)
    - [6.3. 回滚决策树](#63-回滚决策树)
  - [7. 迁移工具对比](#7-迁移工具对比)
    - [7.1. 工具对比矩阵](#71-工具对比矩阵)
    - [7.2. 工具选择决策树](#72-工具选择决策树)
  - [8. 实际案例深度分析](#8-实际案例深度分析)
    - [8.1. 案例1：大型系统零停机迁移](#81-案例1大型系统零停机迁移)
    - [8.2. 案例2：数据模型重构迁移](#82-案例2数据模型重构迁移)
    - [8.3. 案例3：跨数据库迁移](#83-案例3跨数据库迁移)
  - [9. 迁移最佳实践总结](#9-迁移最佳实践总结)
    - [9.1. 迁移原则](#91-迁移原则)
    - [9.2. 迁移检查清单](#92-迁移检查清单)
  - [10. 参考资料](#10-参考资料)
    - [10.1. 迁移工具](#101-迁移工具)
    - [10.2. 相关文档](#102-相关文档)

---

## 1. 概述

数据库Schema会随着业务需求不断演化。本文档介绍如何安全、高效地管理Schema变更和数据迁移。

### 1.1. Schema演化挑战

| 挑战 | 影响 | 解决方案 |
|------|------|---------|
| **结构变更** | 应用中断 | 渐进式迁移 |
| **数据迁移** | 停机时间 | 零停机迁移 |
| **版本管理** | 混乱 | 版本控制系统 |
| **回滚** | 数据丢失 | 可逆迁移 |

### 1.2. 迁移决策树

```mermaid
flowchart TD
    A[Schema变更需求] --> B{变更类型}

    B -->|添加列| C[简单迁移]
    B -->|删除列| D[复杂迁移]
    B -->|修改列| E[复杂迁移]
    B -->|重命名表| F[复杂迁移]

    C --> G{允许停机?}
    D --> H[需要数据迁移]
    E --> H
    F --> H

    G -->|是| I[直接ALTER]
    G -->|否| J[渐进式迁移]

    H --> K[零停机迁移]
    J --> K
```

---

## 2. 数据库版本管理

### 2.1. 版本表设计

**版本追踪表**：

```sql
-- 迁移版本表
CREATE TABLE schema_migrations (
    version VARCHAR(50) PRIMARY KEY,
    description TEXT NOT NULL,
    applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    execution_time_ms INTEGER,
    checksum VARCHAR(64),  -- 迁移文件校验和
    rolled_back BOOLEAN DEFAULT FALSE,
    rolled_back_at TIMESTAMP
);

-- 迁移步骤表（记录每个迁移的详细步骤）
CREATE TABLE migration_steps (
    id SERIAL PRIMARY KEY,
    version VARCHAR(50) REFERENCES schema_migrations(version),
    step_order INTEGER NOT NULL,
    step_type VARCHAR(20) NOT NULL,  -- CREATE_TABLE, ALTER_TABLE, DATA_MIGRATION
    sql_statement TEXT NOT NULL,
    executed_at TIMESTAMP,
    execution_time_ms INTEGER,
    success BOOLEAN DEFAULT TRUE,
    error_message TEXT
);
```

### 2.2. 迁移文件组织

**目录结构**：

```text
migrations/
├── 001_create_users_table.sql
├── 002_create_orders_table.sql
├── 003_add_email_index.sql
├── 004_migrate_user_data.sql
└── rollback/
    ├── 001_rollback_create_users_table.sql
    ├── 002_rollback_create_orders_table.sql
    └── ...
```

**迁移文件格式**：

```sql
-- migrations/001_create_users_table.sql
-- Version: 001
-- Description: Create users table
-- Created: 2024-01-15

BEGIN;

-- 创建用户表
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 创建索引
CREATE INDEX idx_users_email ON users(email);

-- 记录迁移版本
INSERT INTO schema_migrations (version, description, checksum)
VALUES ('001', 'Create users table', 'abc123...');

COMMIT;
```

### 2.3. 迁移工具实现

**Python迁移工具示例**：

```python
import psycopg2
import hashlib
import os
from pathlib import Path

class MigrationManager:
    def __init__(self, db_connection):
        self.conn = db_connection
        self.migrations_dir = Path('migrations')

    def get_applied_versions(self):
        """获取已应用的迁移版本"""
        with self.conn.cursor() as cur:
            cur.execute("""
                SELECT version FROM schema_migrations
                WHERE rolled_back = FALSE
                ORDER BY version
            """)
            return [row[0] for row in cur.fetchall()]

    def calculate_checksum(self, file_path):
        """计算文件校验和"""
        with open(file_path, 'rb') as f:
            return hashlib.sha256(f.read()).hexdigest()

    def apply_migration(self, file_path):
        """应用迁移"""
        version = file_path.stem
        description = file_path.stem.replace('_', ' ').title()

        # 检查是否已应用
        if version in self.get_applied_versions():
            print(f"Migration {version} already applied, skipping")
            return

        # 读取SQL文件
        with open(file_path, 'r') as f:
            sql = f.read()

        checksum = self.calculate_checksum(file_path)

        try:
            with self.conn.cursor() as cur:
                # 执行迁移
                cur.execute(sql)

                # 记录迁移
                cur.execute("""
                    INSERT INTO schema_migrations
                    (version, description, checksum)
                    VALUES (%s, %s, %s)
                """, (version, description, checksum))

                self.conn.commit()
                print(f"Migration {version} applied successfully")
        except Exception as e:
            self.conn.rollback()
            print(f"Migration {version} failed: {e}")
            raise

    def migrate(self):
        """执行所有未应用的迁移"""
        migration_files = sorted(
            self.migrations_dir.glob('*.sql'),
            key=lambda x: x.stem
        )

        applied = self.get_applied_versions()

        for file_path in migration_files:
            version = file_path.stem
            if version not in applied:
                self.apply_migration(file_path)
```

---

## 3. 迁移策略

### 3.1. 添加列（零停机）

**策略：渐进式添加列**:

```sql
-- Step 1: 添加可空列（不设置默认值）
ALTER TABLE users ADD COLUMN phone VARCHAR(20) NULL;

-- Step 2: 应用层开始写入新列
-- 应用代码更新...

-- Step 3: 批量更新现有数据（后台任务）
UPDATE users SET phone = 'default' WHERE phone IS NULL;

-- Step 4: 添加NOT NULL约束（如果数据已填充）
ALTER TABLE users ALTER COLUMN phone SET NOT NULL;

-- Step 5: 添加默认值（可选）
ALTER TABLE users ALTER COLUMN phone SET DEFAULT 'default';
```

### 3.2. 删除列（零停机）

**策略：先标记后删除**:

```sql
-- Step 1: 应用层停止使用该列
-- 应用代码更新...

-- Step 2: 等待一段时间确保没有使用
-- 监控查询日志...

-- Step 3: 重命名列（保留数据）
ALTER TABLE users RENAME COLUMN old_column TO _deprecated_old_column;

-- Step 4: 等待确认期（如1个月）

-- Step 5: 删除列
ALTER TABLE users DROP COLUMN _deprecated_old_column;
```

### 3.3. 修改列类型（零停机）

**策略：创建新列并同步**:

```sql
-- Step 1: 添加新列（新类型）
ALTER TABLE users ADD COLUMN email_new VARCHAR(200);

-- Step 2: 同步数据
UPDATE users SET email_new = email;

-- Step 3: 应用层双写（同时写新旧列）
-- 应用代码更新...

-- Step 4: 再次同步确保一致性
UPDATE users SET email_new = email WHERE email_new IS NULL;

-- Step 5: 应用层切换到新列
-- 应用代码更新...

-- Step 6: 删除旧列
ALTER TABLE users DROP COLUMN email;
ALTER TABLE users RENAME COLUMN email_new TO email;

-- Step 7: 添加约束
ALTER TABLE users ADD CONSTRAINT users_email_unique UNIQUE (email);
```

### 3.4. 重命名表（零停机）

**策略：视图桥接**:

```sql
-- Step 1: 创建新表
CREATE TABLE users_new (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL
);

-- Step 2: 同步数据
INSERT INTO users_new SELECT * FROM users;

-- Step 3: 创建视图桥接
CREATE VIEW users AS SELECT * FROM users_new;

-- Step 4: 应用层切换到新表
-- 应用代码更新...

-- Step 5: 删除旧表和视图
DROP VIEW users;
DROP TABLE users_old;
ALTER TABLE users_new RENAME TO users;
```

---

## 4. 零停机迁移

### 4.1. 双写模式

**实现示例**：

```sql
-- 双写触发器
CREATE OR REPLACE FUNCTION dual_write_trigger()
RETURNS TRIGGER AS $$
BEGIN
    -- 写入新表
    INSERT INTO users_new (id, username, email)
    VALUES (NEW.id, NEW.username, NEW.email)
    ON CONFLICT (id) DO UPDATE SET
        username = EXCLUDED.username,
        email = EXCLUDED.email;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER users_dual_write
AFTER INSERT OR UPDATE ON users
FOR EACH ROW
EXECUTE FUNCTION dual_write_trigger();
```

### 4.2. 变更数据捕获（CDC）

**使用PostgreSQL逻辑复制**：

```sql
-- 1. 启用逻辑复制
ALTER SYSTEM SET wal_level = logical;
SELECT pg_reload_conf();

-- 2. 创建发布
CREATE PUBLICATION users_publication FOR TABLE users;

-- 3. 创建订阅（在目标数据库）
CREATE SUBSCRIPTION users_subscription
CONNECTION 'host=source_db port=5432 dbname=mydb'
PUBLICATION users_publication;
```

### 4.3. 迁移检查清单

```mermaid
flowchart TD
    A[开始迁移] --> B[备份数据库]
    B --> C[创建迁移脚本]
    C --> D[测试迁移脚本]
    D --> E{测试通过?}

    E -->|否| F[修复脚本]
    F --> D

    E -->|是| G[执行迁移]
    G --> H[验证数据]

    H --> I{数据正确?}
    I -->|否| J[回滚]
    I -->|是| K[更新应用]

    K --> L[监控性能]
    L --> M{性能正常?}
    M -->|否| N[优化]
    M -->|是| O[迁移完成]
```

---

## 5. 数据迁移实践

### 5.1. 大批量数据迁移

**分批迁移策略**：

```sql
-- 分批迁移函数
CREATE OR REPLACE FUNCTION migrate_users_batch(
    p_batch_size INTEGER DEFAULT 1000,
    p_max_batches INTEGER DEFAULT NULL
)
RETURNS TABLE (
    batch_num INTEGER,
    rows_migrated INTEGER,
    total_migrated BIGINT
) AS $$
DECLARE
    v_batch_num INTEGER := 0;
    v_rows_migrated INTEGER;
    v_total_migrated BIGINT := 0;
    v_max_id INTEGER;
BEGIN
    -- 获取最大ID
    SELECT COALESCE(MAX(id), 0) INTO v_max_id FROM users_new;

    LOOP
        v_batch_num := v_batch_num + 1;

        -- 检查批次限制
        IF p_max_batches IS NOT NULL AND v_batch_num > p_max_batches THEN
            EXIT;
        END IF;

        -- 迁移一批数据
        WITH batch AS (
            SELECT *
            FROM users
            WHERE id > v_max_id
            ORDER BY id
            LIMIT p_batch_size
        )
        INSERT INTO users_new (id, username, email)
        SELECT id, username, email FROM batch
        ON CONFLICT (id) DO NOTHING;

        GET DIAGNOSTICS v_rows_migrated = ROW_COUNT;
        v_total_migrated := v_total_migrated + v_rows_migrated;

        -- 返回进度
        RETURN QUERY SELECT v_batch_num, v_rows_migrated, v_total_migrated;

        -- 更新最大ID
        SELECT COALESCE(MAX(id), v_max_id) INTO v_max_id FROM users_new;

        -- 如果没有更多数据，退出
        EXIT WHEN v_rows_migrated = 0;

        -- 短暂延迟，避免锁竞争
        PERFORM pg_sleep(0.1);
    END LOOP;
END;
$$ LANGUAGE plpgsql;

-- 使用示例
SELECT * FROM migrate_users_batch(1000, 10);  -- 每次1000条，最多10批
```

### 5.2. 数据验证

**迁移后验证脚本**：

```sql
-- 数据一致性检查
CREATE OR REPLACE FUNCTION validate_migration()
RETURNS TABLE (
    check_name TEXT,
    source_count BIGINT,
    target_count BIGINT,
    match BOOLEAN
) AS $$
BEGIN
    -- 检查1: 总记录数
    RETURN QUERY
    SELECT
        'Total records'::TEXT,
        (SELECT COUNT(*) FROM users),
        (SELECT COUNT(*) FROM users_new),
        (SELECT COUNT(*) FROM users) = (SELECT COUNT(*) FROM users_new);

    -- 检查2: 唯一值数量
    RETURN QUERY
    SELECT
        'Unique usernames'::TEXT,
        (SELECT COUNT(DISTINCT username) FROM users),
        (SELECT COUNT(DISTINCT username) FROM users_new),
        (SELECT COUNT(DISTINCT username) FROM users) =
        (SELECT COUNT(DISTINCT username) FROM users_new);

    -- 检查3: 数据差异
    RETURN QUERY
    SELECT
        'Data differences'::TEXT,
        (SELECT COUNT(*) FROM users u
         LEFT JOIN users_new n ON u.id = n.id
         WHERE n.id IS NULL OR u.username != n.username OR u.email != n.email),
        0::BIGINT,
        NOT EXISTS (
            SELECT 1 FROM users u
            LEFT JOIN users_new n ON u.id = n.id
            WHERE n.id IS NULL OR u.username != n.username OR u.email != n.email
        );
END;
$$ LANGUAGE plpgsql;

-- 执行验证
SELECT * FROM validate_migration();
```

---

## 6. 回滚策略

### 6.1. 可逆迁移设计

**原则**：每个迁移都应该有对应的回滚脚本。

**回滚脚本示例**：

```sql
-- rollback/001_rollback_create_users_table.sql
BEGIN;

-- 删除索引
DROP INDEX IF EXISTS idx_users_email;

-- 删除表
DROP TABLE IF EXISTS users;

-- 删除迁移记录
DELETE FROM schema_migrations WHERE version = '001';

COMMIT;
```

### 6.2. 数据回滚

**快照回滚策略**：

```sql
-- 创建迁移前快照
CREATE TABLE users_backup_20240115 AS SELECT * FROM users;

-- 回滚时恢复
TRUNCATE TABLE users;
INSERT INTO users SELECT * FROM users_backup_20240115;
```

### 6.3. 回滚决策树

```mermaid
flowchart TD
    A[需要回滚?] --> B{回滚原因}

    B -->|数据错误| C[数据回滚]
    B -->|结构错误| D[结构回滚]
    B -->|性能问题| E[优化而非回滚]

    C --> F[从备份恢复]
    D --> G[执行回滚脚本]

    F --> H[验证数据]
    G --> H

    H --> I{验证通过?}
    I -->|是| J[回滚完成]
    I -->|否| K[手动修复]
    K --> H
```

---

## 7. 迁移工具对比

### 7.1. 工具对比矩阵

| 工具 | 语言 | 迁移方式 | 回滚支持 | 版本控制 | 社区支持 | 推荐度 |
|------|------|---------|---------|---------|---------|--------|
| **Flyway** | Java | SQL/Java | ✅ | ✅ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| **Liquibase** | Java | XML/YAML/SQL | ✅ | ✅ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| **Alembic** | Python | Python | ✅ | ✅ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ |
| **db-migrate** | Node.js | SQL/JS | ✅ | ✅ | ⭐⭐⭐ | ⭐⭐⭐ |
| **Django Migrations** | Python | Python | ✅ | ✅ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ |
| **Rails Migrations** | Ruby | Ruby | ✅ | ✅ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ |
| **Sqitch** | Perl | SQL | ✅ | ✅ | ⭐⭐⭐ | ⭐⭐⭐ |

### 7.2. 工具选择决策树

```mermaid
flowchart TD
    A[选择迁移工具] --> B{开发语言}

    B -->|Java| C[Flyway/Liquibase]
    B -->|Python| D[Alembic/Django]
    B -->|Node.js| E[db-migrate]
    B -->|Ruby| F[Rails Migrations]
    B -->|其他| G[Sqitch]

    C --> H{需求复杂度}
    D --> H
    E --> H
    F --> H
    G --> H

    H -->|简单| I[Flyway]
    H -->|复杂| J[Liquibase]

    I --> K[实施]
    J --> K
```

---

## 8. 实际案例深度分析

### 8.1. 案例1：大型系统零停机迁移

**背景**：

某大型电商系统需要将订单表从单表迁移到分区表，系统需要保持7x24小时运行。

**迁移策略**：

1. **阶段1：创建新分区表**（1周）

   ```sql
   -- 创建分区表
   CREATE TABLE orders_new (
       ...
   ) PARTITION BY RANGE (created_at);

   -- 创建分区
   CREATE TABLE orders_2025_01 PARTITION OF orders_new
       FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
   ```

2. **阶段2：双写模式**（2周）

   ```sql
   -- 应用层同时写入两个表
   INSERT INTO orders VALUES (...);
   INSERT INTO orders_new VALUES (...);
   ```

3. **阶段3：数据同步**（1周）

   ```sql
   -- 使用CDC同步历史数据
   COPY (SELECT * FROM orders WHERE created_at < '2025-01-01')
   TO '/tmp/orders_backup.csv';

   COPY orders_new FROM '/tmp/orders_backup.csv';
   ```

4. **阶段4：切换读操作**（1周）
   - 逐步将读操作切换到新表
   - 监控性能指标

5. **阶段5：完成迁移**（1天）

   ```sql
   -- 重命名表
   ALTER TABLE orders RENAME TO orders_old;
   ALTER TABLE orders_new RENAME TO orders;
   ```

**效果**：

- 零停机时间：100%
- 数据一致性：100%
- 性能影响：<5%

### 8.2. 案例2：数据模型重构迁移

**背景**：

某系统需要将多用途表拆分为多个规范化表。

**迁移策略**：

1. **创建新表结构**

   ```sql
   CREATE TABLE users (...);
   CREATE TABLE orders (...);
   CREATE TABLE products (...);
   ```

2. **数据迁移**

   ```sql
   -- 迁移用户数据
   INSERT INTO users (id, username, email)
   SELECT id, data->>'username', data->>'email'
   FROM everything
   WHERE type = 'user';

   -- 迁移订单数据
   INSERT INTO orders (id, user_id, total)
   SELECT id, data->>'user_id', (data->>'total')::DECIMAL
   FROM everything
   WHERE type = 'order';
   ```

3. **验证数据**

   ```sql
   -- 验证数据完整性
   SELECT
       (SELECT COUNT(*) FROM everything WHERE type = 'user') as old_count,
       (SELECT COUNT(*) FROM users) as new_count;
   ```

**效果**：

- 数据完整性：100%
- 查询性能：提升5x
- 维护成本：降低50%

### 8.3. 案例3：跨数据库迁移

**背景**：

某系统需要从MySQL迁移到PostgreSQL。

**迁移策略**：

1. **使用pgloader工具**

   ```bash
   pgloader mysql://user:pass@mysql-host/dbname \
            postgresql://user:pass@pg-host/dbname
   ```

2. **数据验证**

   ```sql
   -- 验证记录数
   SELECT COUNT(*) FROM source_table;
   SELECT COUNT(*) FROM target_table;

   -- 验证数据一致性
   SELECT * FROM source_table
   EXCEPT
   SELECT * FROM target_table;
   ```

3. **应用切换**
   - 更新连接字符串
   - 测试应用功能
   - 逐步切换流量

**效果**：

- 迁移成功率：100%
- 数据丢失：0
- 停机时间：4小时

---

## 9. 迁移最佳实践总结

### 9.1. 迁移原则

1. **渐进式迁移**：分阶段进行，降低风险
2. **零停机优先**：优先考虑零停机迁移方案
3. **数据验证**：每个阶段都要验证数据完整性
4. **可回滚设计**：设计可回滚的迁移方案
5. **充分测试**：在测试环境充分测试

### 9.2. 迁移检查清单

**迁移前检查**：

- [ ] 备份数据库
- [ ] 在测试环境验证迁移脚本
- [ ] 评估迁移时间和资源需求
- [ ] 准备回滚方案
- [ ] 通知相关团队

**迁移中检查**：

- [ ] 监控迁移进度
- [ ] 验证数据完整性
- [ ] 检查性能指标
- [ ] 记录问题和解决方案

**迁移后检查**：

- [ ] 验证应用功能
- [ ] 监控系统性能
- [ ] 验证数据一致性
- [ ] 更新文档
- [ ] 清理临时数据

---

## 10. 参考资料

### 10.1. 迁移工具

- [Flyway文档](https://flywaydb.org/)
- [Liquibase文档](https://www.liquibase.org/)
- [Alembic文档](https://alembic.sqlalchemy.org/)
- [pgloader文档](https://pgloader.readthedocs.io/)

### 10.2. 相关文档

- [Schema设计方法论](./07.01-Schema设计方法论.md)
- [现代数据库设计模式](./07.05-现代数据库设计模式.md)
- [数据库设计反模式](./07.06-数据库设计反模式与解决方案.md)

---

**最后更新**：2025-01-16
**维护者**：Data-Science Team
**状态**：已完成 ✅
