# æ•°æ®åº“è¿ç§»ä¸ç‰ˆæœ¬ç®¡ç†ï¼šSchemaæ¼”åŒ–çš„å®è·µæŒ‡å—

> **åˆ›å»ºæ—¥æœŸ**ï¼š2025-01-15
> **æœ€åæ›´æ–°**ï¼š2025-12-01
> **ç‰ˆæœ¬**ï¼šv2.0
> **çŠ¶æ€**ï¼šå·²å®Œæˆ âœ…

---

## ğŸ“‹ ç›®å½•

- [æ•°æ®åº“è¿ç§»ä¸ç‰ˆæœ¬ç®¡ç†ï¼šSchemaæ¼”åŒ–çš„å®è·µæŒ‡å—](#æ•°æ®åº“è¿ç§»ä¸ç‰ˆæœ¬ç®¡ç†schemaæ¼”åŒ–çš„å®è·µæŒ‡å—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1. Schemaæ¼”åŒ–æŒ‘æˆ˜](#11-schemaæ¼”åŒ–æŒ‘æˆ˜)
    - [1.2. è¿ç§»å†³ç­–æ ‘](#12-è¿ç§»å†³ç­–æ ‘)
  - [2. æ•°æ®åº“ç‰ˆæœ¬ç®¡ç†](#2-æ•°æ®åº“ç‰ˆæœ¬ç®¡ç†)
    - [2.1. ç‰ˆæœ¬è¡¨è®¾è®¡](#21-ç‰ˆæœ¬è¡¨è®¾è®¡)
    - [2.2. è¿ç§»æ–‡ä»¶ç»„ç»‡](#22-è¿ç§»æ–‡ä»¶ç»„ç»‡)
    - [2.3. è¿ç§»å·¥å…·å®ç°](#23-è¿ç§»å·¥å…·å®ç°)
  - [3. è¿ç§»ç­–ç•¥](#3-è¿ç§»ç­–ç•¥)
    - [3.1. æ·»åŠ åˆ—ï¼ˆé›¶åœæœºï¼‰](#31-æ·»åŠ åˆ—é›¶åœæœº)
    - [3.2. åˆ é™¤åˆ—ï¼ˆé›¶åœæœºï¼‰](#32-åˆ é™¤åˆ—é›¶åœæœº)
    - [3.3. ä¿®æ”¹åˆ—ç±»å‹ï¼ˆé›¶åœæœºï¼‰](#33-ä¿®æ”¹åˆ—ç±»å‹é›¶åœæœº)
    - [3.4. é‡å‘½åè¡¨ï¼ˆé›¶åœæœºï¼‰](#34-é‡å‘½åè¡¨é›¶åœæœº)
  - [4. é›¶åœæœºè¿ç§»](#4-é›¶åœæœºè¿ç§»)
    - [4.1. åŒå†™æ¨¡å¼](#41-åŒå†™æ¨¡å¼)
    - [4.2. å˜æ›´æ•°æ®æ•è·ï¼ˆCDCï¼‰](#42-å˜æ›´æ•°æ®æ•è·cdc)
    - [4.3. è¿ç§»æ£€æŸ¥æ¸…å•](#43-è¿ç§»æ£€æŸ¥æ¸…å•)
  - [5. æ•°æ®è¿ç§»å®è·µ](#5-æ•°æ®è¿ç§»å®è·µ)
    - [5.1. å¤§æ‰¹é‡æ•°æ®è¿ç§»](#51-å¤§æ‰¹é‡æ•°æ®è¿ç§»)
    - [5.2. æ•°æ®éªŒè¯](#52-æ•°æ®éªŒè¯)
  - [6. å›æ»šç­–ç•¥](#6-å›æ»šç­–ç•¥)
    - [6.1. å¯é€†è¿ç§»è®¾è®¡](#61-å¯é€†è¿ç§»è®¾è®¡)
    - [6.2. æ•°æ®å›æ»š](#62-æ•°æ®å›æ»š)
    - [6.3. å›æ»šå†³ç­–æ ‘](#63-å›æ»šå†³ç­–æ ‘)
  - [7. è¿ç§»å·¥å…·å¯¹æ¯”](#7-è¿ç§»å·¥å…·å¯¹æ¯”)
    - [7.1. å·¥å…·å¯¹æ¯”çŸ©é˜µ](#71-å·¥å…·å¯¹æ¯”çŸ©é˜µ)
    - [7.2. å·¥å…·é€‰æ‹©å†³ç­–æ ‘](#72-å·¥å…·é€‰æ‹©å†³ç­–æ ‘)
  - [8. å®é™…æ¡ˆä¾‹æ·±åº¦åˆ†æ](#8-å®é™…æ¡ˆä¾‹æ·±åº¦åˆ†æ)
    - [8.1. æ¡ˆä¾‹1ï¼šå¤§å‹ç³»ç»Ÿé›¶åœæœºè¿ç§»](#81-æ¡ˆä¾‹1å¤§å‹ç³»ç»Ÿé›¶åœæœºè¿ç§»)
    - [8.2. æ¡ˆä¾‹2ï¼šæ•°æ®æ¨¡å‹é‡æ„è¿ç§»](#82-æ¡ˆä¾‹2æ•°æ®æ¨¡å‹é‡æ„è¿ç§»)
    - [8.3. æ¡ˆä¾‹3ï¼šè·¨æ•°æ®åº“è¿ç§»](#83-æ¡ˆä¾‹3è·¨æ•°æ®åº“è¿ç§»)
  - [9. è¿ç§»æœ€ä½³å®è·µæ€»ç»“](#9-è¿ç§»æœ€ä½³å®è·µæ€»ç»“)
    - [9.1. è¿ç§»åŸåˆ™](#91-è¿ç§»åŸåˆ™)
    - [9.2. è¿ç§»æ£€æŸ¥æ¸…å•](#92-è¿ç§»æ£€æŸ¥æ¸…å•)
  - [10. 2024-2025 æ•°æ®åº“è¿ç§»è¶‹åŠ¿](#10-2024-2025-æ•°æ®åº“è¿ç§»è¶‹åŠ¿)
    - [10.1. è¿ç§»æŠ€æœ¯æ¼”è¿›æ—¶é—´çº¿](#101-è¿ç§»æŠ€æœ¯æ¼”è¿›æ—¶é—´çº¿)
    - [10.2. è¿ç§»å·¥å…·å¯¹æ¯”çŸ©é˜µï¼ˆ2025æ›´æ–°ï¼‰](#102-è¿ç§»å·¥å…·å¯¹æ¯”çŸ©é˜µ2025æ›´æ–°)
    - [10.3. GitOpsæ•°æ®åº“è¿ç§»](#103-gitopsæ•°æ®åº“è¿ç§»)
    - [10.4. å£°æ˜å¼Schemaç®¡ç†ï¼ˆAtlasï¼‰](#104-å£°æ˜å¼schemaç®¡ç†atlas)
    - [10.5. å˜æ›´æ•°æ®æ•è·ï¼ˆCDCï¼‰é«˜çº§å®è·µ](#105-å˜æ›´æ•°æ®æ•è·cdcé«˜çº§å®è·µ)
    - [10.6. AIè¾…åŠ©è¿ç§»åˆ†æ](#106-aiè¾…åŠ©è¿ç§»åˆ†æ)
  - [è¡¨ç»Ÿè®¡ä¿¡æ¯](#è¡¨ç»Ÿè®¡ä¿¡æ¯)
  - [å½“å‰Schema](#å½“å‰schema)
  - [ç›®æ ‡Schema](#ç›®æ ‡schema)
  - [çº¦æŸæ¡ä»¶](#çº¦æŸæ¡ä»¶)
    - [10.7. è¿ç§»å·¥å…·é€‰å‹å†³ç­–æ ‘ï¼ˆ2025ç‰ˆï¼‰](#107-è¿ç§»å·¥å…·é€‰å‹å†³ç­–æ ‘2025ç‰ˆ)
  - [11. å‚è€ƒèµ„æ–™](#11-å‚è€ƒèµ„æ–™)
    - [11.1. è¿ç§»å·¥å…·æ–‡æ¡£](#111-è¿ç§»å·¥å…·æ–‡æ¡£)
    - [11.2. GitOpsä¸CDèµ„æº](#112-gitopsä¸cdèµ„æº)
    - [11.3. ç›¸å…³æ–‡æ¡£](#113-ç›¸å…³æ–‡æ¡£)

---

## 1. æ¦‚è¿°

æ•°æ®åº“Schemaä¼šéšç€ä¸šåŠ¡éœ€æ±‚ä¸æ–­æ¼”åŒ–ã€‚æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•å®‰å…¨ã€é«˜æ•ˆåœ°ç®¡ç†Schemaå˜æ›´å’Œæ•°æ®è¿ç§»ã€‚

### 1.1. Schemaæ¼”åŒ–æŒ‘æˆ˜

| æŒ‘æˆ˜ | å½±å“ | è§£å†³æ–¹æ¡ˆ |
|------|------|---------|
| **ç»“æ„å˜æ›´** | åº”ç”¨ä¸­æ–­ | æ¸è¿›å¼è¿ç§» |
| **æ•°æ®è¿ç§»** | åœæœºæ—¶é—´ | é›¶åœæœºè¿ç§» |
| **ç‰ˆæœ¬ç®¡ç†** | æ··ä¹± | ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ |
| **å›æ»š** | æ•°æ®ä¸¢å¤± | å¯é€†è¿ç§» |

### 1.2. è¿ç§»å†³ç­–æ ‘

```mermaid
flowchart TD
    A[Schemaå˜æ›´éœ€æ±‚] --> B{å˜æ›´ç±»å‹}

    B -->|æ·»åŠ åˆ—| C[ç®€å•è¿ç§»]
    B -->|åˆ é™¤åˆ—| D[å¤æ‚è¿ç§»]
    B -->|ä¿®æ”¹åˆ—| E[å¤æ‚è¿ç§»]
    B -->|é‡å‘½åè¡¨| F[å¤æ‚è¿ç§»]

    C --> G{å…è®¸åœæœº?}
    D --> H[éœ€è¦æ•°æ®è¿ç§»]
    E --> H
    F --> H

    G -->|æ˜¯| I[ç›´æ¥ALTER]
    G -->|å¦| J[æ¸è¿›å¼è¿ç§»]

    H --> K[é›¶åœæœºè¿ç§»]
    J --> K
```

---

## 2. æ•°æ®åº“ç‰ˆæœ¬ç®¡ç†

### 2.1. ç‰ˆæœ¬è¡¨è®¾è®¡

**ç‰ˆæœ¬è¿½è¸ªè¡¨**ï¼š

```sql
-- è¿ç§»ç‰ˆæœ¬è¡¨
CREATE TABLE schema_migrations (
    version VARCHAR(50) PRIMARY KEY,
    description TEXT NOT NULL,
    applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    execution_time_ms INTEGER,
    checksum VARCHAR(64),  -- è¿ç§»æ–‡ä»¶æ ¡éªŒå’Œ
    rolled_back BOOLEAN DEFAULT FALSE,
    rolled_back_at TIMESTAMP
);

-- è¿ç§»æ­¥éª¤è¡¨ï¼ˆè®°å½•æ¯ä¸ªè¿ç§»çš„è¯¦ç»†æ­¥éª¤ï¼‰
CREATE TABLE migration_steps (
    id SERIAL PRIMARY KEY,
    version VARCHAR(50) REFERENCES schema_migrations(version),
    step_order INTEGER NOT NULL,
    step_type VARCHAR(20) NOT NULL,  -- CREATE_TABLE, ALTER_TABLE, DATA_MIGRATION
    sql_statement TEXT NOT NULL,
    executed_at TIMESTAMP,
    execution_time_ms INTEGER,
    success BOOLEAN DEFAULT TRUE,
    error_message TEXT
);
```

### 2.2. è¿ç§»æ–‡ä»¶ç»„ç»‡

**ç›®å½•ç»“æ„**ï¼š

```text
migrations/
â”œâ”€â”€ 001_create_users_table.sql
â”œâ”€â”€ 002_create_orders_table.sql
â”œâ”€â”€ 003_add_email_index.sql
â”œâ”€â”€ 004_migrate_user_data.sql
â””â”€â”€ rollback/
    â”œâ”€â”€ 001_rollback_create_users_table.sql
    â”œâ”€â”€ 002_rollback_create_orders_table.sql
    â””â”€â”€ ...
```

**è¿ç§»æ–‡ä»¶æ ¼å¼**ï¼š

```sql
-- migrations/001_create_users_table.sql
-- Version: 001
-- Description: Create users table
-- Created: 2024-01-15

BEGIN;

-- åˆ›å»ºç”¨æˆ·è¡¨
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_users_email ON users(email);

-- è®°å½•è¿ç§»ç‰ˆæœ¬
INSERT INTO schema_migrations (version, description, checksum)
VALUES ('001', 'Create users table', 'abc123...');

COMMIT;
```

### 2.3. è¿ç§»å·¥å…·å®ç°

**Pythonè¿ç§»å·¥å…·ç¤ºä¾‹**ï¼š

```python
import psycopg2
import hashlib
import os
from pathlib import Path

class MigrationManager:
    def __init__(self, db_connection):
        self.conn = db_connection
        self.migrations_dir = Path('migrations')

    def get_applied_versions(self):
        """è·å–å·²åº”ç”¨çš„è¿ç§»ç‰ˆæœ¬"""
        with self.conn.cursor() as cur:
            cur.execute("""
                SELECT version FROM schema_migrations
                WHERE rolled_back = FALSE
                ORDER BY version
            """)
            return [row[0] for row in cur.fetchall()]

    def calculate_checksum(self, file_path):
        """è®¡ç®—æ–‡ä»¶æ ¡éªŒå’Œ"""
        with open(file_path, 'rb') as f:
            return hashlib.sha256(f.read()).hexdigest()

    def apply_migration(self, file_path):
        """åº”ç”¨è¿ç§»"""
        version = file_path.stem
        description = file_path.stem.replace('_', ' ').title()

        # æ£€æŸ¥æ˜¯å¦å·²åº”ç”¨
        if version in self.get_applied_versions():
            print(f"Migration {version} already applied, skipping")
            return

        # è¯»å–SQLæ–‡ä»¶
        with open(file_path, 'r') as f:
            sql = f.read()

        checksum = self.calculate_checksum(file_path)

        try:
            with self.conn.cursor() as cur:
                # æ‰§è¡Œè¿ç§»
                cur.execute(sql)

                # è®°å½•è¿ç§»
                cur.execute("""
                    INSERT INTO schema_migrations
                    (version, description, checksum)
                    VALUES (%s, %s, %s)
                """, (version, description, checksum))

                self.conn.commit()
                print(f"Migration {version} applied successfully")
        except Exception as e:
            self.conn.rollback()
            print(f"Migration {version} failed: {e}")
            raise

    def migrate(self):
        """æ‰§è¡Œæ‰€æœ‰æœªåº”ç”¨çš„è¿ç§»"""
        migration_files = sorted(
            self.migrations_dir.glob('*.sql'),
            key=lambda x: x.stem
        )

        applied = self.get_applied_versions()

        for file_path in migration_files:
            version = file_path.stem
            if version not in applied:
                self.apply_migration(file_path)
```

---

## 3. è¿ç§»ç­–ç•¥

### 3.1. æ·»åŠ åˆ—ï¼ˆé›¶åœæœºï¼‰

**ç­–ç•¥ï¼šæ¸è¿›å¼æ·»åŠ åˆ—**:

```sql
-- Step 1: æ·»åŠ å¯ç©ºåˆ—ï¼ˆä¸è®¾ç½®é»˜è®¤å€¼ï¼‰
ALTER TABLE users ADD COLUMN phone VARCHAR(20) NULL;

-- Step 2: åº”ç”¨å±‚å¼€å§‹å†™å…¥æ–°åˆ—
-- åº”ç”¨ä»£ç æ›´æ–°...

-- Step 3: æ‰¹é‡æ›´æ–°ç°æœ‰æ•°æ®ï¼ˆåå°ä»»åŠ¡ï¼‰
UPDATE users SET phone = 'default' WHERE phone IS NULL;

-- Step 4: æ·»åŠ NOT NULLçº¦æŸï¼ˆå¦‚æœæ•°æ®å·²å¡«å……ï¼‰
ALTER TABLE users ALTER COLUMN phone SET NOT NULL;

-- Step 5: æ·»åŠ é»˜è®¤å€¼ï¼ˆå¯é€‰ï¼‰
ALTER TABLE users ALTER COLUMN phone SET DEFAULT 'default';
```

### 3.2. åˆ é™¤åˆ—ï¼ˆé›¶åœæœºï¼‰

**ç­–ç•¥ï¼šå…ˆæ ‡è®°ååˆ é™¤**:

```sql
-- Step 1: åº”ç”¨å±‚åœæ­¢ä½¿ç”¨è¯¥åˆ—
-- åº”ç”¨ä»£ç æ›´æ–°...

-- Step 2: ç­‰å¾…ä¸€æ®µæ—¶é—´ç¡®ä¿æ²¡æœ‰ä½¿ç”¨
-- ç›‘æ§æŸ¥è¯¢æ—¥å¿—...

-- Step 3: é‡å‘½ååˆ—ï¼ˆä¿ç•™æ•°æ®ï¼‰
ALTER TABLE users RENAME COLUMN old_column TO _deprecated_old_column;

-- Step 4: ç­‰å¾…ç¡®è®¤æœŸï¼ˆå¦‚1ä¸ªæœˆï¼‰

-- Step 5: åˆ é™¤åˆ—
ALTER TABLE users DROP COLUMN _deprecated_old_column;
```

### 3.3. ä¿®æ”¹åˆ—ç±»å‹ï¼ˆé›¶åœæœºï¼‰

**ç­–ç•¥ï¼šåˆ›å»ºæ–°åˆ—å¹¶åŒæ­¥**:

```sql
-- Step 1: æ·»åŠ æ–°åˆ—ï¼ˆæ–°ç±»å‹ï¼‰
ALTER TABLE users ADD COLUMN email_new VARCHAR(200);

-- Step 2: åŒæ­¥æ•°æ®
UPDATE users SET email_new = email;

-- Step 3: åº”ç”¨å±‚åŒå†™ï¼ˆåŒæ—¶å†™æ–°æ—§åˆ—ï¼‰
-- åº”ç”¨ä»£ç æ›´æ–°...

-- Step 4: å†æ¬¡åŒæ­¥ç¡®ä¿ä¸€è‡´æ€§
UPDATE users SET email_new = email WHERE email_new IS NULL;

-- Step 5: åº”ç”¨å±‚åˆ‡æ¢åˆ°æ–°åˆ—
-- åº”ç”¨ä»£ç æ›´æ–°...

-- Step 6: åˆ é™¤æ—§åˆ—
ALTER TABLE users DROP COLUMN email;
ALTER TABLE users RENAME COLUMN email_new TO email;

-- Step 7: æ·»åŠ çº¦æŸ
ALTER TABLE users ADD CONSTRAINT users_email_unique UNIQUE (email);
```

### 3.4. é‡å‘½åè¡¨ï¼ˆé›¶åœæœºï¼‰

**ç­–ç•¥ï¼šè§†å›¾æ¡¥æ¥**:

```sql
-- Step 1: åˆ›å»ºæ–°è¡¨
CREATE TABLE users_new (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL
);

-- Step 2: åŒæ­¥æ•°æ®
INSERT INTO users_new SELECT * FROM users;

-- Step 3: åˆ›å»ºè§†å›¾æ¡¥æ¥
CREATE VIEW users AS SELECT * FROM users_new;

-- Step 4: åº”ç”¨å±‚åˆ‡æ¢åˆ°æ–°è¡¨
-- åº”ç”¨ä»£ç æ›´æ–°...

-- Step 5: åˆ é™¤æ—§è¡¨å’Œè§†å›¾
DROP VIEW users;
DROP TABLE users_old;
ALTER TABLE users_new RENAME TO users;
```

---

## 4. é›¶åœæœºè¿ç§»

### 4.1. åŒå†™æ¨¡å¼

**å®ç°ç¤ºä¾‹**ï¼š

```sql
-- åŒå†™è§¦å‘å™¨
CREATE OR REPLACE FUNCTION dual_write_trigger()
RETURNS TRIGGER AS $$
BEGIN
    -- å†™å…¥æ–°è¡¨
    INSERT INTO users_new (id, username, email)
    VALUES (NEW.id, NEW.username, NEW.email)
    ON CONFLICT (id) DO UPDATE SET
        username = EXCLUDED.username,
        email = EXCLUDED.email;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER users_dual_write
AFTER INSERT OR UPDATE ON users
FOR EACH ROW
EXECUTE FUNCTION dual_write_trigger();
```

### 4.2. å˜æ›´æ•°æ®æ•è·ï¼ˆCDCï¼‰

**ä½¿ç”¨PostgreSQLé€»è¾‘å¤åˆ¶**ï¼š

```sql
-- 1. å¯ç”¨é€»è¾‘å¤åˆ¶
ALTER SYSTEM SET wal_level = logical;
SELECT pg_reload_conf();

-- 2. åˆ›å»ºå‘å¸ƒ
CREATE PUBLICATION users_publication FOR TABLE users;

-- 3. åˆ›å»ºè®¢é˜…ï¼ˆåœ¨ç›®æ ‡æ•°æ®åº“ï¼‰
CREATE SUBSCRIPTION users_subscription
CONNECTION 'host=source_db port=5432 dbname=mydb'
PUBLICATION users_publication;
```

### 4.3. è¿ç§»æ£€æŸ¥æ¸…å•

```mermaid
flowchart TD
    A[å¼€å§‹è¿ç§»] --> B[å¤‡ä»½æ•°æ®åº“]
    B --> C[åˆ›å»ºè¿ç§»è„šæœ¬]
    C --> D[æµ‹è¯•è¿ç§»è„šæœ¬]
    D --> E{æµ‹è¯•é€šè¿‡?}

    E -->|å¦| F[ä¿®å¤è„šæœ¬]
    F --> D

    E -->|æ˜¯| G[æ‰§è¡Œè¿ç§»]
    G --> H[éªŒè¯æ•°æ®]

    H --> I{æ•°æ®æ­£ç¡®?}
    I -->|å¦| J[å›æ»š]
    I -->|æ˜¯| K[æ›´æ–°åº”ç”¨]

    K --> L[ç›‘æ§æ€§èƒ½]
    L --> M{æ€§èƒ½æ­£å¸¸?}
    M -->|å¦| N[ä¼˜åŒ–]
    M -->|æ˜¯| O[è¿ç§»å®Œæˆ]
```

---

## 5. æ•°æ®è¿ç§»å®è·µ

### 5.1. å¤§æ‰¹é‡æ•°æ®è¿ç§»

**åˆ†æ‰¹è¿ç§»ç­–ç•¥**ï¼š

```sql
-- åˆ†æ‰¹è¿ç§»å‡½æ•°
CREATE OR REPLACE FUNCTION migrate_users_batch(
    p_batch_size INTEGER DEFAULT 1000,
    p_max_batches INTEGER DEFAULT NULL
)
RETURNS TABLE (
    batch_num INTEGER,
    rows_migrated INTEGER,
    total_migrated BIGINT
) AS $$
DECLARE
    v_batch_num INTEGER := 0;
    v_rows_migrated INTEGER;
    v_total_migrated BIGINT := 0;
    v_max_id INTEGER;
BEGIN
    -- è·å–æœ€å¤§ID
    SELECT COALESCE(MAX(id), 0) INTO v_max_id FROM users_new;

    LOOP
        v_batch_num := v_batch_num + 1;

        -- æ£€æŸ¥æ‰¹æ¬¡é™åˆ¶
        IF p_max_batches IS NOT NULL AND v_batch_num > p_max_batches THEN
            EXIT;
        END IF;

        -- è¿ç§»ä¸€æ‰¹æ•°æ®
        WITH batch AS (
            SELECT *
            FROM users
            WHERE id > v_max_id
            ORDER BY id
            LIMIT p_batch_size
        )
        INSERT INTO users_new (id, username, email)
        SELECT id, username, email FROM batch
        ON CONFLICT (id) DO NOTHING;

        GET DIAGNOSTICS v_rows_migrated = ROW_COUNT;
        v_total_migrated := v_total_migrated + v_rows_migrated;

        -- è¿”å›è¿›åº¦
        RETURN QUERY SELECT v_batch_num, v_rows_migrated, v_total_migrated;

        -- æ›´æ–°æœ€å¤§ID
        SELECT COALESCE(MAX(id), v_max_id) INTO v_max_id FROM users_new;

        -- å¦‚æœæ²¡æœ‰æ›´å¤šæ•°æ®ï¼Œé€€å‡º
        EXIT WHEN v_rows_migrated = 0;

        -- çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…é”ç«äº‰
        PERFORM pg_sleep(0.1);
    END LOOP;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ç¤ºä¾‹
SELECT * FROM migrate_users_batch(1000, 10);  -- æ¯æ¬¡1000æ¡ï¼Œæœ€å¤š10æ‰¹
```

### 5.2. æ•°æ®éªŒè¯

**è¿ç§»åéªŒè¯è„šæœ¬**ï¼š

```sql
-- æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
CREATE OR REPLACE FUNCTION validate_migration()
RETURNS TABLE (
    check_name TEXT,
    source_count BIGINT,
    target_count BIGINT,
    match BOOLEAN
) AS $$
BEGIN
    -- æ£€æŸ¥1: æ€»è®°å½•æ•°
    RETURN QUERY
    SELECT
        'Total records'::TEXT,
        (SELECT COUNT(*) FROM users),
        (SELECT COUNT(*) FROM users_new),
        (SELECT COUNT(*) FROM users) = (SELECT COUNT(*) FROM users_new);

    -- æ£€æŸ¥2: å”¯ä¸€å€¼æ•°é‡
    RETURN QUERY
    SELECT
        'Unique usernames'::TEXT,
        (SELECT COUNT(DISTINCT username) FROM users),
        (SELECT COUNT(DISTINCT username) FROM users_new),
        (SELECT COUNT(DISTINCT username) FROM users) =
        (SELECT COUNT(DISTINCT username) FROM users_new);

    -- æ£€æŸ¥3: æ•°æ®å·®å¼‚
    RETURN QUERY
    SELECT
        'Data differences'::TEXT,
        (SELECT COUNT(*) FROM users u
         LEFT JOIN users_new n ON u.id = n.id
         WHERE n.id IS NULL OR u.username != n.username OR u.email != n.email),
        0::BIGINT,
        NOT EXISTS (
            SELECT 1 FROM users u
            LEFT JOIN users_new n ON u.id = n.id
            WHERE n.id IS NULL OR u.username != n.username OR u.email != n.email
        );
END;
$$ LANGUAGE plpgsql;

-- æ‰§è¡ŒéªŒè¯
SELECT * FROM validate_migration();
```

---

## 6. å›æ»šç­–ç•¥

### 6.1. å¯é€†è¿ç§»è®¾è®¡

**åŸåˆ™**ï¼šæ¯ä¸ªè¿ç§»éƒ½åº”è¯¥æœ‰å¯¹åº”çš„å›æ»šè„šæœ¬ã€‚

**å›æ»šè„šæœ¬ç¤ºä¾‹**ï¼š

```sql
-- rollback/001_rollback_create_users_table.sql
BEGIN;

-- åˆ é™¤ç´¢å¼•
DROP INDEX IF EXISTS idx_users_email;

-- åˆ é™¤è¡¨
DROP TABLE IF EXISTS users;

-- åˆ é™¤è¿ç§»è®°å½•
DELETE FROM schema_migrations WHERE version = '001';

COMMIT;
```

### 6.2. æ•°æ®å›æ»š

**å¿«ç…§å›æ»šç­–ç•¥**ï¼š

```sql
-- åˆ›å»ºè¿ç§»å‰å¿«ç…§
CREATE TABLE users_backup_20240115 AS SELECT * FROM users;

-- å›æ»šæ—¶æ¢å¤
TRUNCATE TABLE users;
INSERT INTO users SELECT * FROM users_backup_20240115;
```

### 6.3. å›æ»šå†³ç­–æ ‘

```mermaid
flowchart TD
    A[éœ€è¦å›æ»š?] --> B{å›æ»šåŸå› }

    B -->|æ•°æ®é”™è¯¯| C[æ•°æ®å›æ»š]
    B -->|ç»“æ„é”™è¯¯| D[ç»“æ„å›æ»š]
    B -->|æ€§èƒ½é—®é¢˜| E[ä¼˜åŒ–è€Œéå›æ»š]

    C --> F[ä»å¤‡ä»½æ¢å¤]
    D --> G[æ‰§è¡Œå›æ»šè„šæœ¬]

    F --> H[éªŒè¯æ•°æ®]
    G --> H

    H --> I{éªŒè¯é€šè¿‡?}
    I -->|æ˜¯| J[å›æ»šå®Œæˆ]
    I -->|å¦| K[æ‰‹åŠ¨ä¿®å¤]
    K --> H
```

---

## 7. è¿ç§»å·¥å…·å¯¹æ¯”

### 7.1. å·¥å…·å¯¹æ¯”çŸ©é˜µ

| å·¥å…· | è¯­è¨€ | è¿ç§»æ–¹å¼ | å›æ»šæ”¯æŒ | ç‰ˆæœ¬æ§åˆ¶ | ç¤¾åŒºæ”¯æŒ | æ¨èåº¦ |
|------|------|---------|---------|---------|---------|--------|
| **Flyway** | Java | SQL/Java | âœ… | âœ… | â­â­â­â­ | â­â­â­â­â­ |
| **Liquibase** | Java | XML/YAML/SQL | âœ… | âœ… | â­â­â­â­â­ | â­â­â­â­â­ |
| **Alembic** | Python | Python | âœ… | âœ… | â­â­â­â­ | â­â­â­â­ |
| **db-migrate** | Node.js | SQL/JS | âœ… | âœ… | â­â­â­ | â­â­â­ |
| **Django Migrations** | Python | Python | âœ… | âœ… | â­â­â­â­ | â­â­â­â­ |
| **Rails Migrations** | Ruby | Ruby | âœ… | âœ… | â­â­â­â­ | â­â­â­â­ |
| **Sqitch** | Perl | SQL | âœ… | âœ… | â­â­â­ | â­â­â­ |

### 7.2. å·¥å…·é€‰æ‹©å†³ç­–æ ‘

```mermaid
flowchart TD
    A[é€‰æ‹©è¿ç§»å·¥å…·] --> B{å¼€å‘è¯­è¨€}

    B -->|Java| C[Flyway/Liquibase]
    B -->|Python| D[Alembic/Django]
    B -->|Node.js| E[db-migrate]
    B -->|Ruby| F[Rails Migrations]
    B -->|å…¶ä»–| G[Sqitch]

    C --> H{éœ€æ±‚å¤æ‚åº¦}
    D --> H
    E --> H
    F --> H
    G --> H

    H -->|ç®€å•| I[Flyway]
    H -->|å¤æ‚| J[Liquibase]

    I --> K[å®æ–½]
    J --> K
```

---

## 8. å®é™…æ¡ˆä¾‹æ·±åº¦åˆ†æ

### 8.1. æ¡ˆä¾‹1ï¼šå¤§å‹ç³»ç»Ÿé›¶åœæœºè¿ç§»

**èƒŒæ™¯**ï¼š

æŸå¤§å‹ç”µå•†ç³»ç»Ÿéœ€è¦å°†è®¢å•è¡¨ä»å•è¡¨è¿ç§»åˆ°åˆ†åŒºè¡¨ï¼Œç³»ç»Ÿéœ€è¦ä¿æŒ7x24å°æ—¶è¿è¡Œã€‚

**è¿ç§»ç­–ç•¥**ï¼š

1. **é˜¶æ®µ1ï¼šåˆ›å»ºæ–°åˆ†åŒºè¡¨**ï¼ˆ1å‘¨ï¼‰

   ```sql
   -- åˆ›å»ºåˆ†åŒºè¡¨
   CREATE TABLE orders_new (
       ...
   ) PARTITION BY RANGE (created_at);

   -- åˆ›å»ºåˆ†åŒº
   CREATE TABLE orders_2025_01 PARTITION OF orders_new
       FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
   ```

2. **é˜¶æ®µ2ï¼šåŒå†™æ¨¡å¼**ï¼ˆ2å‘¨ï¼‰

   ```sql
   -- åº”ç”¨å±‚åŒæ—¶å†™å…¥ä¸¤ä¸ªè¡¨
   INSERT INTO orders VALUES (...);
   INSERT INTO orders_new VALUES (...);
   ```

3. **é˜¶æ®µ3ï¼šæ•°æ®åŒæ­¥**ï¼ˆ1å‘¨ï¼‰

   ```sql
   -- ä½¿ç”¨CDCåŒæ­¥å†å²æ•°æ®
   COPY (SELECT * FROM orders WHERE created_at < '2025-01-01')
   TO '/tmp/orders_backup.csv';

   COPY orders_new FROM '/tmp/orders_backup.csv';
   ```

4. **é˜¶æ®µ4ï¼šåˆ‡æ¢è¯»æ“ä½œ**ï¼ˆ1å‘¨ï¼‰
   - é€æ­¥å°†è¯»æ“ä½œåˆ‡æ¢åˆ°æ–°è¡¨
   - ç›‘æ§æ€§èƒ½æŒ‡æ ‡

5. **é˜¶æ®µ5ï¼šå®Œæˆè¿ç§»**ï¼ˆ1å¤©ï¼‰

   ```sql
   -- é‡å‘½åè¡¨
   ALTER TABLE orders RENAME TO orders_old;
   ALTER TABLE orders_new RENAME TO orders;
   ```

**æ•ˆæœ**ï¼š

- é›¶åœæœºæ—¶é—´ï¼š100%
- æ•°æ®ä¸€è‡´æ€§ï¼š100%
- æ€§èƒ½å½±å“ï¼š<5%

### 8.2. æ¡ˆä¾‹2ï¼šæ•°æ®æ¨¡å‹é‡æ„è¿ç§»

**èƒŒæ™¯**ï¼š

æŸç³»ç»Ÿéœ€è¦å°†å¤šç”¨é€”è¡¨æ‹†åˆ†ä¸ºå¤šä¸ªè§„èŒƒåŒ–è¡¨ã€‚

**è¿ç§»ç­–ç•¥**ï¼š

1. **åˆ›å»ºæ–°è¡¨ç»“æ„**

   ```sql
   CREATE TABLE users (...);
   CREATE TABLE orders (...);
   CREATE TABLE products (...);
   ```

2. **æ•°æ®è¿ç§»**

   ```sql
   -- è¿ç§»ç”¨æˆ·æ•°æ®
   INSERT INTO users (id, username, email)
   SELECT id, data->>'username', data->>'email'
   FROM everything
   WHERE type = 'user';

   -- è¿ç§»è®¢å•æ•°æ®
   INSERT INTO orders (id, user_id, total)
   SELECT id, data->>'user_id', (data->>'total')::DECIMAL
   FROM everything
   WHERE type = 'order';
   ```

3. **éªŒè¯æ•°æ®**

   ```sql
   -- éªŒè¯æ•°æ®å®Œæ•´æ€§
   SELECT
       (SELECT COUNT(*) FROM everything WHERE type = 'user') as old_count,
       (SELECT COUNT(*) FROM users) as new_count;
   ```

**æ•ˆæœ**ï¼š

- æ•°æ®å®Œæ•´æ€§ï¼š100%
- æŸ¥è¯¢æ€§èƒ½ï¼šæå‡5x
- ç»´æŠ¤æˆæœ¬ï¼šé™ä½50%

### 8.3. æ¡ˆä¾‹3ï¼šè·¨æ•°æ®åº“è¿ç§»

**èƒŒæ™¯**ï¼š

æŸç³»ç»Ÿéœ€è¦ä»MySQLè¿ç§»åˆ°PostgreSQLã€‚

**è¿ç§»ç­–ç•¥**ï¼š

1. **ä½¿ç”¨pgloaderå·¥å…·**

   ```bash
   pgloader mysql://user:pass@mysql-host/dbname \
            postgresql://user:pass@pg-host/dbname
   ```

2. **æ•°æ®éªŒè¯**

   ```sql
   -- éªŒè¯è®°å½•æ•°
   SELECT COUNT(*) FROM source_table;
   SELECT COUNT(*) FROM target_table;

   -- éªŒè¯æ•°æ®ä¸€è‡´æ€§
   SELECT * FROM source_table
   EXCEPT
   SELECT * FROM target_table;
   ```

3. **åº”ç”¨åˆ‡æ¢**
   - æ›´æ–°è¿æ¥å­—ç¬¦ä¸²
   - æµ‹è¯•åº”ç”¨åŠŸèƒ½
   - é€æ­¥åˆ‡æ¢æµé‡

**æ•ˆæœ**ï¼š

- è¿ç§»æˆåŠŸç‡ï¼š100%
- æ•°æ®ä¸¢å¤±ï¼š0
- åœæœºæ—¶é—´ï¼š4å°æ—¶

---

## 9. è¿ç§»æœ€ä½³å®è·µæ€»ç»“

### 9.1. è¿ç§»åŸåˆ™

1. **æ¸è¿›å¼è¿ç§»**ï¼šåˆ†é˜¶æ®µè¿›è¡Œï¼Œé™ä½é£é™©
2. **é›¶åœæœºä¼˜å…ˆ**ï¼šä¼˜å…ˆè€ƒè™‘é›¶åœæœºè¿ç§»æ–¹æ¡ˆ
3. **æ•°æ®éªŒè¯**ï¼šæ¯ä¸ªé˜¶æ®µéƒ½è¦éªŒè¯æ•°æ®å®Œæ•´æ€§
4. **å¯å›æ»šè®¾è®¡**ï¼šè®¾è®¡å¯å›æ»šçš„è¿ç§»æ–¹æ¡ˆ
5. **å……åˆ†æµ‹è¯•**ï¼šåœ¨æµ‹è¯•ç¯å¢ƒå……åˆ†æµ‹è¯•

### 9.2. è¿ç§»æ£€æŸ¥æ¸…å•

**è¿ç§»å‰æ£€æŸ¥**ï¼š

- [ ] å¤‡ä»½æ•°æ®åº“
- [ ] åœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯è¿ç§»è„šæœ¬
- [ ] è¯„ä¼°è¿ç§»æ—¶é—´å’Œèµ„æºéœ€æ±‚
- [ ] å‡†å¤‡å›æ»šæ–¹æ¡ˆ
- [ ] é€šçŸ¥ç›¸å…³å›¢é˜Ÿ

**è¿ç§»ä¸­æ£€æŸ¥**ï¼š

- [ ] ç›‘æ§è¿ç§»è¿›åº¦
- [ ] éªŒè¯æ•°æ®å®Œæ•´æ€§
- [ ] æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡
- [ ] è®°å½•é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

**è¿ç§»åæ£€æŸ¥**ï¼š

- [ ] éªŒè¯åº”ç”¨åŠŸèƒ½
- [ ] ç›‘æ§ç³»ç»Ÿæ€§èƒ½
- [ ] éªŒè¯æ•°æ®ä¸€è‡´æ€§
- [ ] æ›´æ–°æ–‡æ¡£
- [ ] æ¸…ç†ä¸´æ—¶æ•°æ®

---

## 10. 2024-2025 æ•°æ®åº“è¿ç§»è¶‹åŠ¿

### 10.1. è¿ç§»æŠ€æœ¯æ¼”è¿›æ—¶é—´çº¿

```mermaid
timeline
    title æ•°æ®åº“è¿ç§»æŠ€æœ¯æ¼”è¿›
    2010 : Flywayå‘å¸ƒ
         : SQLè„šæœ¬è¿ç§»
    2015 : Liquibaseæˆç†Ÿ
         : XML/YAMLå£°æ˜å¼
    2018 : GitOpså…´èµ·
         : åŸºç¡€è®¾æ–½å³ä»£ç 
    2020 : äº‘åŸç”Ÿè¿ç§»
         : K8s Operatoræ¨¡å¼
    2022 : å£°æ˜å¼Schema
         : Atlaså‘å¸ƒ
         : SchemaHero
    2024 : AIè¾…åŠ©è¿ç§»
         : æ™ºèƒ½Schemaæ¼”åŒ–
         : è‡ªåŠ¨å›æ»šæ£€æµ‹
    2025 : å¤šæ¨¡å‹è¿ç§»
         : å‘é‡Schemaæ¼”åŒ–
         : è¾¹ç¼˜æ•°æ®åŒæ­¥
```

### 10.2. è¿ç§»å·¥å…·å¯¹æ¯”çŸ©é˜µï¼ˆ2025æ›´æ–°ï¼‰

| å·¥å…· | ç‰ˆæœ¬ | è¿ç§»æ–¹å¼ | GitOps | K8såŸç”Ÿ | AIè¾…åŠ© | å‘é‡Schema | æ¨èåœºæ™¯ |
|------|------|---------|--------|---------|--------|-----------|---------|
| **Flyway** | 10.x | ç‰ˆæœ¬åŒ–SQL | âœ… | âš ï¸ | âŒ | âŒ | Javaä¼ä¸šåº”ç”¨ |
| **Liquibase** | 4.x | å£°æ˜å¼/å˜æ›´é›† | âœ… | âš ï¸ | âœ… Pro | âŒ | å¤æ‚Schemaæ¼”åŒ– |
| **Atlas** | 0.18+ | å£°æ˜å¼HCL | âœ… | âœ… | âœ… | âœ… | äº‘åŸç”Ÿ/ç°ä»£åŒ– |
| **SchemaHero** | 0.14+ | å£°æ˜å¼K8s CRD | âœ… | âœ… | âŒ | âŒ | K8sç¯å¢ƒ |
| **Alembic** | 1.13+ | Pythonè„šæœ¬ | âœ… | âš ï¸ | âŒ | âœ… | Pythonç”Ÿæ€ |
| **Prisma Migrate** | 5.x | å£°æ˜å¼Schema | âœ… | âš ï¸ | âœ… | âŒ | TypeScriptå…¨æ ˆ |
| **SQLMesh** | 0.9+ | å¢é‡æ¨¡å‹ | âœ… | âš ï¸ | âœ… | âŒ | æ•°æ®å·¥ç¨‹ |

### 10.3. GitOpsæ•°æ®åº“è¿ç§»

**GitOpsè¿ç§»å·¥ä½œæµ**ï¼š

```mermaid
flowchart LR
    subgraph Dev["å¼€å‘ç¯å¢ƒ"]
        A[Schemaå˜æ›´] --> B[æœ¬åœ°æµ‹è¯•]
        B --> C[æäº¤PR]
    end

    subgraph CI["CI/CD Pipeline"]
        C --> D[Schema Lint]
        D --> E[Diffæ£€æµ‹]
        E --> F[å®‰å…¨æ‰«æ]
        F --> G[æµ‹è¯•è¿ç§»]
    end

    subgraph GitOps["GitOps Controller"]
        G --> H[åˆå¹¶main]
        H --> I[ArgoCD/FluxåŒæ­¥]
        I --> J[Atlas Operator]
    end

    subgraph Prod["ç”Ÿäº§ç¯å¢ƒ"]
        J --> K[æ¸è¿›å¼è¿ç§»]
        K --> L[å¥åº·æ£€æŸ¥]
        L --> M[å®Œæˆ/å›æ»š]
    end
```

**Atlas GitOpsé…ç½®ç¤ºä¾‹**ï¼š

```hcl
# atlas.hcl - å£°æ˜å¼Schemaå®šä¹‰
schema "public" {
  comment = "Main application schema"
}

table "users" {
  schema = schema.public

  column "id" {
    type = uuid
    default = sql("gen_random_uuid()")
  }

  column "email" {
    type = varchar(255)
    null = false
  }

  column "embedding" {
    type = sql("vector(1536)")  # pgvectoræ”¯æŒ
    null = true
    comment = "User profile embedding"
  }

  column "created_at" {
    type = timestamptz
    default = sql("now()")
  }

  primary_key {
    columns = [column.id]
  }

  index "idx_users_email" {
    columns = [column.email]
    unique  = true
  }

  index "idx_users_embedding" {
    type    = HNSW
    columns = [column.embedding]
    on {
      ops = "vector_cosine_ops"
    }
  }
}

# è¿ç§»ç­–ç•¥é…ç½®
env "production" {
  url = "postgres://user:pass@host:5432/db?sslmode=require"

  migration {
    dir = "file://migrations"
  }

  diff {
    skip {
      drop_schema = true
      drop_table  = true
    }
  }
}
```

**GitHub Actions GitOpså·¥ä½œæµ**ï¼š

```yaml
# .github/workflows/schema-migration.yml
name: Database Schema Migration

on:
  push:
    branches: [main]
    paths:
      - 'schema/**'
      - 'migrations/**'
  pull_request:
    paths:
      - 'schema/**'

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Atlas
        uses: ariga/setup-atlas@v0

      - name: Schema Lint
        run: atlas schema lint --env dev

      - name: Security Check
        run: atlas schema inspect --env dev --format '{{ sql . }}' | sqlfluff lint -

  diff:
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - uses: actions/checkout@v4

      - name: Compute Diff
        id: diff
        run: |
          atlas schema diff \
            --from "postgres://localhost/current" \
            --to "file://schema" \
            --format '{{ sql . }}' > diff.sql

      - name: Comment PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const diff = fs.readFileSync('diff.sql', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Schema Changes\n\`\`\`sql\n${diff}\n\`\`\``
            });

  migrate:
    runs-on: ubuntu-latest
    needs: diff
    if: github.ref == 'refs/heads/main'
    environment: production
    steps:
      - uses: actions/checkout@v4

      - name: Apply Migration
        run: |
          atlas schema apply \
            --env production \
            --auto-approve \
            --tx-mode file

      - name: Verify Migration
        run: atlas schema inspect --env production
```

### 10.4. å£°æ˜å¼Schemaç®¡ç†ï¼ˆAtlasï¼‰

**Atlasè¿ç§»å‘½ä»¤é€ŸæŸ¥**ï¼š

```bash
# Schemaæ£€æŸ¥
atlas schema inspect --url "postgres://localhost/db"

# ç”Ÿæˆè¿ç§»å·®å¼‚
atlas schema diff \
  --from "postgres://localhost/old_db" \
  --to "file://schema.hcl"

# åº”ç”¨è¿ç§»ï¼ˆäº‹åŠ¡æ¨¡å¼ï¼‰
atlas schema apply \
  --url "postgres://localhost/db" \
  --to "file://schema.hcl" \
  --tx-mode file

# ç”Ÿæˆè¿ç§»æ–‡ä»¶
atlas migrate diff create_users \
  --dir "file://migrations" \
  --to "file://schema.hcl"

# æ‰§è¡Œè¿ç§»
atlas migrate apply \
  --dir "file://migrations" \
  --url "postgres://localhost/db"

# è¿ç§»çŠ¶æ€
atlas migrate status \
  --dir "file://migrations" \
  --url "postgres://localhost/db"

# å›æ»š
atlas migrate down \
  --dir "file://migrations" \
  --url "postgres://localhost/db" \
  --count 1
```

**Schemaæ¼”åŒ–ç­–ç•¥å†³ç­–æ ‘**ï¼š

```mermaid
flowchart TD
    A[Schemaå˜æ›´] --> B{å˜æ›´ç±»å‹?}

    B -->|æ·»åŠ | C{æ·»åŠ ä»€ä¹ˆ?}
    B -->|ä¿®æ”¹| D{ä¿®æ”¹ä»€ä¹ˆ?}
    B -->|åˆ é™¤| E{åˆ é™¤ä»€ä¹ˆ?}

    C -->|è¡¨| C1[ç›´æ¥CREATE TABLE]
    C -->|åˆ—| C2{æœ‰é»˜è®¤å€¼?}
    C -->|ç´¢å¼•| C3[CONCURRENTLYåˆ›å»º]
    C -->|çº¦æŸ| C4{æ•°æ®éªŒè¯?}

    C2 -->|æ˜¯| C2a[éœ€è¦å›å¡«æ•°æ®]
    C2 -->|å¦| C2b[ç›´æ¥æ·»åŠ NULLåˆ—]

    C4 -->|éœ€è¦| C4a[å…ˆéªŒè¯å†æ·»åŠ çº¦æŸ]
    C4 -->|ä¸éœ€è¦| C4b[ç›´æ¥æ·»åŠ çº¦æŸ]

    D -->|åˆ—ç±»å‹| D1[åŒåˆ—è¿ç§»ç­–ç•¥]
    D -->|åˆ—å| D2[è§†å›¾æ¡¥æ¥]
    D -->|è¡¨å| D3[è§†å›¾æ¡¥æ¥+æ¸è¿›åˆ‡æ¢]

    E -->|è¡¨| E1[å…ˆæ ‡è®°åºŸå¼ƒâ†’éªŒè¯â†’åˆ é™¤]
    E -->|åˆ—| E2[åœç”¨â†’é‡å‘½åâ†’ç­‰å¾…â†’åˆ é™¤]
    E -->|ç´¢å¼•| E3[åˆ†æä½¿ç”¨â†’ç›´æ¥åˆ é™¤]

    D1 --> F[é›¶åœæœºè¿ç§»]
    D2 --> F
    D3 --> F
    E1 --> F
    E2 --> F

    C1 --> G[æµ‹è¯•éªŒè¯]
    C2a --> G
    C2b --> G
    C3 --> G
    C4a --> G
    C4b --> G
    E3 --> G
    F --> G
```

### 10.5. å˜æ›´æ•°æ®æ•è·ï¼ˆCDCï¼‰é«˜çº§å®è·µ

**Debezium CDCæ¶æ„**ï¼š

```mermaid
flowchart LR
    subgraph Source["æºæ•°æ®åº“"]
        A[(PostgreSQL)] --> B[WALæ—¥å¿—]
    end

    subgraph CDC["CDC Pipeline"]
        B --> C[Debezium Connector]
        C --> D[Kafka Topics]
    end

    subgraph Consumers["æ¶ˆè´¹è€…"]
        D --> E[ç›®æ ‡æ•°æ®åº“åŒæ­¥]
        D --> F[å®æ—¶åˆ†æ]
        D --> G[äº‹ä»¶é©±åŠ¨æœåŠ¡]
        D --> H[å‘é‡ç´¢å¼•æ›´æ–°]
    end
```

**Debezium PostgreSQLé…ç½®**ï¼š

```json
{
  "name": "pg-source-connector",
  "config": {
    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
    "database.hostname": "postgres",
    "database.port": "5432",
    "database.user": "debezium",
    "database.password": "secret",
    "database.dbname": "mydb",
    "database.server.name": "pg-server",
    "plugin.name": "pgoutput",
    "slot.name": "debezium_slot",
    "publication.name": "dbz_publication",

    "table.include.list": "public.users,public.orders",

    "transforms": "route",
    "transforms.route.type": "org.apache.kafka.connect.transforms.RegexRouter",
    "transforms.route.regex": "([^.]+)\\.([^.]+)\\.([^.]+)",
    "transforms.route.replacement": "$3-events",

    "snapshot.mode": "initial",
    "tombstones.on.delete": "false",

    "heartbeat.interval.ms": "10000",
    "heartbeat.action.query": "INSERT INTO debezium_heartbeat (ts) VALUES (now())"
  }
}
```

**CDCè§¦å‘å‘é‡æ›´æ–°**ï¼š

```python
# cdc_vector_sync.py - CDCé©±åŠ¨çš„å‘é‡ç´¢å¼•åŒæ­¥
from kafka import KafkaConsumer
import json
import psycopg2
from sentence_transformers import SentenceTransformer

class CDCVectorSync:
    def __init__(self, kafka_bootstrap, pg_conn_string):
        self.consumer = KafkaConsumer(
            'users-events',
            bootstrap_servers=kafka_bootstrap,
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            auto_offset_reset='earliest',
            group_id='vector-sync-group'
        )
        self.conn = psycopg2.connect(pg_conn_string)
        self.model = SentenceTransformer('all-MiniLM-L6-v2')

    def process_event(self, event):
        """å¤„ç†CDCäº‹ä»¶ï¼Œæ›´æ–°å‘é‡ç´¢å¼•"""
        op = event.get('op')  # c=create, u=update, d=delete
        after = event.get('after', {})
        before = event.get('before', {})

        if op in ('c', 'u') and after:
            # ç”Ÿæˆæ–°embedding
            user_id = after['id']
            text = f"{after.get('name', '')} {after.get('bio', '')}"
            embedding = self.model.encode(text).tolist()

            # æ›´æ–°å‘é‡
            with self.conn.cursor() as cur:
                cur.execute("""
                    UPDATE users
                    SET embedding = %s::vector
                    WHERE id = %s
                """, (embedding, user_id))
            self.conn.commit()

        elif op == 'd' and before:
            # åˆ é™¤æ—¶æ¸…ç©ºå‘é‡ï¼ˆæˆ–è½¯åˆ é™¤ï¼‰
            with self.conn.cursor() as cur:
                cur.execute("""
                    UPDATE users SET embedding = NULL WHERE id = %s
                """, (before['id'],))
            self.conn.commit()

    def run(self):
        for message in self.consumer:
            self.process_event(message.value)
```

### 10.6. AIè¾…åŠ©è¿ç§»åˆ†æ

**è¿ç§»é£é™©è¯„ä¼°æç¤ºè¯**ï¼š

```python
# ai_migration_analysis.py
import openai

def analyze_migration_risk(schema_diff: str, table_stats: dict) -> dict:
    """ä½¿ç”¨AIåˆ†æè¿ç§»é£é™©"""

    prompt = f"""
ä½œä¸ºæ•°æ®åº“è¿ç§»ä¸“å®¶ï¼Œåˆ†æä»¥ä¸‹Schemaå˜æ›´çš„é£é™©ï¼š

## Schemaå·®å¼‚
```sql
{schema_diff}
```

## è¡¨ç»Ÿè®¡ä¿¡æ¯

- è¡¨å¤§å°ï¼š{table_stats.get('size_mb', 'N/A')} MB
- è¡Œæ•°ï¼š{table_stats.get('row_count', 'N/A')}
- æ¯æ—¥å†™å…¥ï¼š{table_stats.get('daily_writes', 'N/A')} è¡Œ
- æ´»è·ƒè¿æ¥ï¼š{table_stats.get('active_connections', 'N/A')}

è¯·è¯„ä¼°ï¼š

1. è¿ç§»é£é™©ç­‰çº§ï¼ˆä½/ä¸­/é«˜/æé«˜ï¼‰
2. é¢„è®¡åœæœºæ—¶é—´
3. æ½œåœ¨é—®é¢˜
4. æ¨èè¿ç§»ç­–ç•¥
5. å›æ»šå¤æ‚åº¦

è¾“å‡ºJSONæ ¼å¼ã€‚
"""
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )

    return json.loads(response.choices[0].message.content)


def generate_migration_plan(
    current_schema: str,
    target_schema: str,
    constraints: dict
) -> str:
    """AIç”Ÿæˆè¯¦ç»†è¿ç§»è®¡åˆ’"""

    prompt = f"""
ç”Ÿæˆä»å½“å‰Schemaåˆ°ç›®æ ‡Schemaçš„é›¶åœæœºè¿ç§»è®¡åˆ’ã€‚

## å½“å‰Schema

```sql
{current_schema}
```

## ç›®æ ‡Schema

```sql
{target_schema}
```

## çº¦æŸæ¡ä»¶

- æœ€å¤§åœæœºæ—¶é—´ï¼š{constraints.get('max_downtime', '0')} åˆ†é’Ÿ
- SLAè¦æ±‚ï¼š{constraints.get('sla', '99.9%')}
- æ•°æ®åº“ç±»å‹ï¼š{constraints.get('db_type', 'PostgreSQL')}

ç”Ÿæˆè¯¦ç»†çš„è¿ç§»æ­¥éª¤ï¼ŒåŒ…æ‹¬ï¼š

1. å‡†å¤‡é˜¶æ®µSQL
2. è¿ç§»æ‰§è¡ŒSQLï¼ˆåˆ†æ‰¹æ¬¡ï¼‰
3. éªŒè¯SQL
4. å›æ»šSQL
5. ç›‘æ§æŒ‡æ ‡
"""

    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content

```
```

### 10.7. è¿ç§»å·¥å…·é€‰å‹å†³ç­–æ ‘ï¼ˆ2025ç‰ˆï¼‰

```mermaid
flowchart TD
    A[é€‰æ‹©è¿ç§»å·¥å…·] --> B{éƒ¨ç½²ç¯å¢ƒ?}

    B -->|Kubernetes| C{éœ€è¦CRDåŸç”Ÿ?}
    B -->|ä¼ ç»ŸVM/å®¹å™¨| D{ç¼–ç¨‹è¯­è¨€?}
    B -->|Serverless| E[Prisma/Atlas Cloud]

    C -->|æ˜¯| F[SchemaHero / Atlas Operator]
    C -->|å¦| G{å£°æ˜å¼ä¼˜å…ˆ?}

    G -->|æ˜¯| H[Atlas]
    G -->|å¦| I[Flyway + Helm]

    D -->|Java| J{å¤æ‚åº¦?}
    D -->|Python| K[Alembic / SQLMesh]
    D -->|TypeScript| L[Prisma Migrate]
    D -->|Go| M[Atlas / golang-migrate]

    J -->|ç®€å•| N[Flyway]
    J -->|å¤æ‚| O[Liquibase]

    F --> P{å‘é‡Schema?}
    H --> P
    K --> P
    M --> P

    P -->|éœ€è¦| Q[Atlas + pgvectoræ‰©å±•]
    P -->|ä¸éœ€è¦| R[é€‰å®šå·¥å…·]

    N --> R
    O --> R
    L --> R
    E --> R
    I --> R
    Q --> R
```

---

## 11. å‚è€ƒèµ„æ–™

### 11.1. è¿ç§»å·¥å…·æ–‡æ¡£

- [Flywayæ–‡æ¡£](https://flywaydb.org/)
- [Liquibaseæ–‡æ¡£](https://www.liquibase.org/)
- [Atlasæ–‡æ¡£](https://atlasgo.io/docs)
- [SchemaHeroæ–‡æ¡£](https://schemahero.io/)
- [Alembicæ–‡æ¡£](https://alembic.sqlalchemy.org/)
- [Prisma Migrateæ–‡æ¡£](https://www.prisma.io/docs/orm/prisma-migrate)
- [pgloaderæ–‡æ¡£](https://pgloader.readthedocs.io/)
- [Debeziumæ–‡æ¡£](https://debezium.io/documentation/)

### 11.2. GitOpsä¸CDèµ„æº

- [ArgoCD](https://argo-cd.readthedocs.io/)
- [Flux CD](https://fluxcd.io/)
- [Atlas Operator for K8s](https://atlasgo.io/integrations/kubernetes/operator)

### 11.3. ç›¸å…³æ–‡æ¡£

- [Schemaè®¾è®¡æ–¹æ³•è®º](./07.01-Schemaè®¾è®¡æ–¹æ³•è®º.md)
- [ç°ä»£æ•°æ®åº“è®¾è®¡æ¨¡å¼](./07.05-ç°ä»£æ•°æ®åº“è®¾è®¡æ¨¡å¼.md)
- [æ•°æ®åº“è®¾è®¡åæ¨¡å¼](./07.06-æ•°æ®åº“è®¾è®¡åæ¨¡å¼ä¸è§£å†³æ–¹æ¡ˆ.md)
- [åˆ†å¸ƒå¼æ•°æ®åº“è®¾è®¡](./07.17-åˆ†å¸ƒå¼æ•°æ®åº“è®¾è®¡æ¨¡å¼.md)
- [æ•°æ®åº“ç›‘æ§ä¸è¿ç»´](./07.25-æ•°æ®åº“ç›‘æ§ä¸è¿ç»´è®¾è®¡æ¨¡å¼.md)

---

**æœ€åæ›´æ–°**ï¼š2025-12-01
**ç»´æŠ¤è€…**ï¼šData-Science Team
**çŠ¶æ€**ï¼šå·²å®Œæˆ âœ…
