# æ•°æ®åº“ç›‘æ§ä¸è¿ç»´è®¾è®¡æ¨¡å¼ï¼šå¯è§‚æµ‹æ€§ä¸è‡ªåŠ¨åŒ–è¿ç»´

> **åˆ›å»ºæ—¥æœŸ**ï¼š2025-01-15
> **æœ€åæ›´æ–°**ï¼š2025-01-15
> **ç‰ˆæœ¬**ï¼šv1.0
> **çŠ¶æ€**ï¼šå®æ–½ä¸­

---

## ğŸ“‹ ç›®å½•

- [æ•°æ®åº“ç›‘æ§ä¸è¿ç»´è®¾è®¡æ¨¡å¼ï¼šå¯è§‚æµ‹æ€§ä¸è‡ªåŠ¨åŒ–è¿ç»´](#æ•°æ®åº“ç›‘æ§ä¸è¿ç»´è®¾è®¡æ¨¡å¼å¯è§‚æµ‹æ€§ä¸è‡ªåŠ¨åŒ–è¿ç»´)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1. ç›‘æ§è¿ç»´åº”ç”¨åœºæ™¯](#11-ç›‘æ§è¿ç»´åº”ç”¨åœºæ™¯)
    - [1.2. ç›‘æ§ç³»ç»Ÿé€‰æ‹©å†³ç­–æ ‘](#12-ç›‘æ§ç³»ç»Ÿé€‰æ‹©å†³ç­–æ ‘)
  - [2. ç›‘æ§æŒ‡æ ‡è®¾è®¡](#2-ç›‘æ§æŒ‡æ ‡è®¾è®¡)
    - [2.1. æ ¸å¿ƒç›‘æ§æŒ‡æ ‡](#21-æ ¸å¿ƒç›‘æ§æŒ‡æ ‡)
    - [2.2. PostgreSQLç›‘æ§æŒ‡æ ‡é‡‡é›†](#22-postgresqlç›‘æ§æŒ‡æ ‡é‡‡é›†)
  - [3. ç›‘æ§æ•°æ®å­˜å‚¨è®¾è®¡](#3-ç›‘æ§æ•°æ®å­˜å‚¨è®¾è®¡)
    - [3.1. ç›‘æ§æ•°æ®Schemaè®¾è®¡](#31-ç›‘æ§æ•°æ®schemaè®¾è®¡)
    - [3.2. æŒ‡æ ‡é‡‡é›†å‡½æ•°](#32-æŒ‡æ ‡é‡‡é›†å‡½æ•°)
  - [4. å‘Šè­¦ç³»ç»Ÿè®¾è®¡](#4-å‘Šè­¦ç³»ç»Ÿè®¾è®¡)
    - [4.1. å‘Šè­¦è§„åˆ™Schemaè®¾è®¡](#41-å‘Šè­¦è§„åˆ™schemaè®¾è®¡)
    - [4.2. å‘Šè­¦æ£€æµ‹å‡½æ•°](#42-å‘Šè­¦æ£€æµ‹å‡½æ•°)
  - [5. æ€§èƒ½åˆ†æè®¾è®¡](#5-æ€§èƒ½åˆ†æè®¾è®¡)
    - [5.1. æ€§èƒ½åˆ†æSchemaè®¾è®¡](#51-æ€§èƒ½åˆ†æschemaè®¾è®¡)
    - [5.2. æ€§èƒ½åˆ†æå‡½æ•°](#52-æ€§èƒ½åˆ†æå‡½æ•°)
  - [6. è‡ªåŠ¨åŒ–è¿ç»´è®¾è®¡](#6-è‡ªåŠ¨åŒ–è¿ç»´è®¾è®¡)
    - [6.1. è‡ªåŠ¨åŒ–ä»»åŠ¡Schemaè®¾è®¡](#61-è‡ªåŠ¨åŒ–ä»»åŠ¡schemaè®¾è®¡)
    - [6.2. è‡ªåŠ¨åŒ–ä»»åŠ¡å‡½æ•°](#62-è‡ªåŠ¨åŒ–ä»»åŠ¡å‡½æ•°)
  - [7. å®é™…åº”ç”¨æ¡ˆä¾‹](#7-å®é™…åº”ç”¨æ¡ˆä¾‹)
    - [7.1. å®Œæ•´ç›‘æ§ç³»ç»Ÿè®¾è®¡](#71-å®Œæ•´ç›‘æ§ç³»ç»Ÿè®¾è®¡)
  - [8. å‚è€ƒèµ„æ–™](#8-å‚è€ƒèµ„æ–™)

---

## 1. æ¦‚è¿°

æ•°æ®åº“ç›‘æ§ä¸è¿ç»´è®¾è®¡æ˜¯ä¿éšœæ•°æ®åº“ç¨³å®šè¿è¡Œçš„å…³é”®ï¼Œéœ€è¦è®¾è®¡å…¨é¢çš„ç›‘æ§æŒ‡æ ‡ã€å‘Šè­¦ç³»ç»Ÿå’Œè‡ªåŠ¨åŒ–è¿ç»´æµç¨‹ã€‚

### 1.1. ç›‘æ§è¿ç»´åº”ç”¨åœºæ™¯

```mermaid
mindmap
  root((ç›‘æ§è¿ç»´))
    æ€§èƒ½ç›‘æ§
      æŸ¥è¯¢æ€§èƒ½
      è¿æ¥æ•°ç›‘æ§
      èµ„æºä½¿ç”¨ç‡
    å¥åº·ç›‘æ§
      æ•°æ®åº“çŠ¶æ€
      å¤åˆ¶çŠ¶æ€
      å¤‡ä»½çŠ¶æ€
    å®¹é‡ç›‘æ§
      å­˜å‚¨ç©ºé—´
      è¡¨å¤§å°
      ç´¢å¼•å¤§å°
    å‘Šè­¦ç³»ç»Ÿ
      æ€§èƒ½å‘Šè­¦
      é”™è¯¯å‘Šè­¦
      å®¹é‡å‘Šè­¦
```

### 1.2. ç›‘æ§ç³»ç»Ÿé€‰æ‹©å†³ç­–æ ‘

```mermaid
flowchart TD
    A[é€‰æ‹©ç›‘æ§ç³»ç»Ÿ] --> B{é›†æˆéœ€æ±‚}

    B -->|PostgreSQLé›†æˆ| C[pg_stat_statements]
    B -->|ç‹¬ç«‹ç›‘æ§| D{ç›‘æ§è§„æ¨¡}

    C --> E[è®¾è®¡å®Œæˆ]

    D -->|å°è§„æ¨¡| F[Prometheus]
    D -->|å¤§è§„æ¨¡| G[Grafana+InfluxDB]

    F --> E
    G --> E
```

---

## 2. ç›‘æ§æŒ‡æ ‡è®¾è®¡

### 2.1. æ ¸å¿ƒç›‘æ§æŒ‡æ ‡

**ç›‘æ§æŒ‡æ ‡åˆ†ç±»çŸ©é˜µ**ï¼š

| æŒ‡æ ‡ç±»åˆ« | å…³é”®æŒ‡æ ‡ | å‘Šè­¦é˜ˆå€¼ | è¯´æ˜ |
|---------|---------|---------|------|
| **æ€§èƒ½æŒ‡æ ‡** | æŸ¥è¯¢å“åº”æ—¶é—´ | >1ç§’ | å¹³å‡æŸ¥è¯¢æ—¶é—´ |
| **æ€§èƒ½æŒ‡æ ‡** | æ…¢æŸ¥è¯¢æ•°é‡ | >100/å°æ—¶ | è¶…è¿‡1ç§’çš„æŸ¥è¯¢ |
| **æ€§èƒ½æŒ‡æ ‡** | è¿æ¥æ•°ä½¿ç”¨ç‡ | >80% | å½“å‰è¿æ¥æ•°/æœ€å¤§è¿æ¥æ•° |
| **èµ„æºæŒ‡æ ‡** | CPUä½¿ç”¨ç‡ | >80% | æ•°æ®åº“è¿›ç¨‹CPUä½¿ç”¨ç‡ |
| **èµ„æºæŒ‡æ ‡** | å†…å­˜ä½¿ç”¨ç‡ | >85% | æ•°æ®åº“å†…å­˜ä½¿ç”¨ç‡ |
| **èµ„æºæŒ‡æ ‡** | ç£ç›˜ä½¿ç”¨ç‡ | >85% | æ•°æ®ç›®å½•ç£ç›˜ä½¿ç”¨ç‡ |
| **å¯ç”¨æ€§æŒ‡æ ‡** | æ•°æ®åº“çŠ¶æ€ | down | æ•°æ®åº“æ˜¯å¦è¿è¡Œ |
| **å¯ç”¨æ€§æŒ‡æ ‡** | å¤åˆ¶å»¶è¿Ÿ | >10ç§’ | ä¸»ä»å¤åˆ¶å»¶è¿Ÿ |
| **å®¹é‡æŒ‡æ ‡** | è¡¨å¤§å°å¢é•¿ | >10GB/å¤© | å•è¡¨æ—¥å¢é•¿é‡ |
| **å®¹é‡æŒ‡æ ‡** | æ•°æ®åº“å¤§å° | >1TB | æ•°æ®åº“æ€»å¤§å° |

### 2.2. PostgreSQLç›‘æ§æŒ‡æ ‡é‡‡é›†

**pg_stat_statementsé…ç½®**ï¼š

```sql
-- å¯ç”¨pg_stat_statementsæ‰©å±•
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- é…ç½®pg_stat_statements
ALTER SYSTEM SET pg_stat_statements.track = 'all';
ALTER SYSTEM SET pg_stat_statements.max = 10000;
SELECT pg_reload_conf();

-- æŸ¥è¯¢æ…¢æŸ¥è¯¢
SELECT
    query,
    calls,
    total_exec_time,
    mean_exec_time,
    max_exec_time,
    stddev_exec_time,
    rows,
    100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent
FROM pg_stat_statements
WHERE mean_exec_time > 1000  -- è¶…è¿‡1ç§’çš„æŸ¥è¯¢
ORDER BY mean_exec_time DESC
LIMIT 20;
```

---

## 3. ç›‘æ§æ•°æ®å­˜å‚¨è®¾è®¡

### 3.1. ç›‘æ§æ•°æ®Schemaè®¾è®¡

**ç›‘æ§æ•°æ®è¡¨è®¾è®¡**ï¼š

```sql
CREATE SCHEMA monitoring;

-- æ•°æ®åº“æŒ‡æ ‡è¡¨ï¼ˆæ—¶åºæ•°æ®ï¼‰
CREATE TABLE monitoring.database_metrics (
    metric_id BIGSERIAL PRIMARY KEY,
    database_name VARCHAR(100) NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    metric_value DOUBLE PRECISION NOT NULL,
    metric_unit VARCHAR(20),
    collected_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (collected_at);

-- åˆ›å»ºåˆ†åŒºï¼ˆæŒ‰å°æ—¶åˆ†åŒºï¼‰
CREATE TABLE monitoring.database_metrics_2024_01_15_00 PARTITION OF monitoring.database_metrics
FOR VALUES FROM ('2024-01-15 00:00:00') TO ('2024-01-15 01:00:00');

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_database_metrics_db_time ON monitoring.database_metrics(database_name, collected_at DESC);
CREATE INDEX idx_database_metrics_name_time ON monitoring.database_metrics(metric_name, collected_at DESC);

-- æŸ¥è¯¢æŒ‡æ ‡è¡¨
CREATE TABLE monitoring.query_metrics (
    query_id BIGSERIAL PRIMARY KEY,
    database_name VARCHAR(100) NOT NULL,
    query_hash BIGINT NOT NULL,
    query_text TEXT NOT NULL,
    calls BIGINT NOT NULL,
    total_exec_time DOUBLE PRECISION NOT NULL,
    mean_exec_time DOUBLE PRECISION NOT NULL,
    max_exec_time DOUBLE PRECISION NOT NULL,
    rows BIGINT NOT NULL,
    shared_blks_hit BIGINT NOT NULL,
    shared_blks_read BIGINT NOT NULL,
    collected_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (collected_at);

CREATE INDEX idx_query_metrics_db_time ON monitoring.query_metrics(database_name, collected_at DESC);
CREATE INDEX idx_query_metrics_hash_time ON monitoring.query_metrics(query_hash, collected_at DESC);

-- è¿æ¥æŒ‡æ ‡è¡¨
CREATE TABLE monitoring.connection_metrics (
    metric_id BIGSERIAL PRIMARY KEY,
    database_name VARCHAR(100) NOT NULL,
    current_connections INTEGER NOT NULL,
    max_connections INTEGER NOT NULL,
    active_connections INTEGER NOT NULL,
    idle_connections INTEGER NOT NULL,
    idle_in_transaction_connections INTEGER NOT NULL,
    collected_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (collected_at);

CREATE INDEX idx_connection_metrics_db_time ON monitoring.connection_metrics(database_name, collected_at DESC);
```

### 3.2. æŒ‡æ ‡é‡‡é›†å‡½æ•°

**æŒ‡æ ‡é‡‡é›†å‡½æ•°**ï¼š

```sql
-- é‡‡é›†æ•°æ®åº“æŒ‡æ ‡å‡½æ•°
CREATE OR REPLACE FUNCTION collect_database_metrics()
RETURNS VOID AS $$
DECLARE
    v_db_name VARCHAR;
    v_db_size BIGINT;
    v_num_connections INTEGER;
    v_max_connections INTEGER;
BEGIN
    -- è·å–å½“å‰æ•°æ®åº“å
    SELECT current_database() INTO v_db_name;

    -- é‡‡é›†æ•°æ®åº“å¤§å°
    SELECT pg_database_size(v_db_name) INTO v_db_size;
    INSERT INTO monitoring.database_metrics (
        database_name, metric_name, metric_value, metric_unit
    )
    VALUES (
        v_db_name, 'database_size', v_db_size, 'bytes'
    );

    -- é‡‡é›†è¿æ¥æ•°
    SELECT count(*) INTO v_num_connections
    FROM pg_stat_activity
    WHERE datname = v_db_name;

    SELECT setting::INTEGER INTO v_max_connections
    FROM pg_settings
    WHERE name = 'max_connections';

    INSERT INTO monitoring.database_metrics (
        database_name, metric_name, metric_value, metric_unit
    )
    VALUES (
        v_db_name, 'current_connections', v_num_connections, 'count'
    ),
    (
        v_db_name, 'max_connections', v_max_connections, 'count'
    ),
    (
        v_db_name, 'connection_usage_percent',
        (v_num_connections::DOUBLE PRECISION / v_max_connections::DOUBLE PRECISION) * 100,
        'percent'
    );
END;
$$ LANGUAGE plpgsql;

-- é‡‡é›†æŸ¥è¯¢æŒ‡æ ‡å‡½æ•°
CREATE OR REPLACE FUNCTION collect_query_metrics()
RETURNS VOID AS $$
DECLARE
    v_db_name VARCHAR;
BEGIN
    SELECT current_database() INTO v_db_name;

    INSERT INTO monitoring.query_metrics (
        database_name, query_hash, query_text,
        calls, total_exec_time, mean_exec_time,
        max_exec_time, rows, shared_blks_hit, shared_blks_read
    )
    SELECT
        v_db_name,
        queryid,
        query,
        calls,
        total_exec_time,
        mean_exec_time,
        max_exec_time,
        rows,
        shared_blks_hit,
        shared_blks_read
    FROM pg_stat_statements
    WHERE calls > 0;
END;
$$ LANGUAGE plpgsql;
```

---

## 4. å‘Šè­¦ç³»ç»Ÿè®¾è®¡

### 4.1. å‘Šè­¦è§„åˆ™Schemaè®¾è®¡

**å‘Šè­¦è§„åˆ™è¡¨è®¾è®¡**ï¼š

```sql
CREATE SCHEMA alerting;

-- å‘Šè­¦è§„åˆ™è¡¨
CREATE TABLE alerting.alert_rules (
    rule_id SERIAL PRIMARY KEY,
    rule_name VARCHAR(200) NOT NULL UNIQUE,
    metric_name VARCHAR(100) NOT NULL,
    database_name VARCHAR(100),
    condition_type VARCHAR(20) NOT NULL CHECK (condition_type IN ('gt', 'lt', 'eq', 'ne', 'between')),
    threshold_value DOUBLE PRECISION,
    threshold_min DOUBLE PRECISION,
    threshold_max DOUBLE PRECISION,
    duration_minutes INTEGER NOT NULL DEFAULT 5,  -- æŒç»­å¤šé•¿æ—¶é—´è§¦å‘å‘Šè­¦
    severity VARCHAR(20) NOT NULL CHECK (severity IN ('critical', 'warning', 'info')),
    is_active BOOLEAN DEFAULT TRUE,
    notification_channels TEXT[],  -- é€šçŸ¥æ¸ é“ï¼šemail, sms, webhook
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_alert_rules_active ON alerting.alert_rules(is_active, metric_name);

-- å‘Šè­¦è®°å½•è¡¨
CREATE TABLE alerting.alerts (
    alert_id BIGSERIAL PRIMARY KEY,
    rule_id INTEGER NOT NULL REFERENCES alerting.alert_rules(rule_id),
    database_name VARCHAR(100),
    metric_name VARCHAR(100) NOT NULL,
    metric_value DOUBLE PRECISION NOT NULL,
    threshold_value DOUBLE PRECISION NOT NULL,
    severity VARCHAR(20) NOT NULL,
    status VARCHAR(20) NOT NULL CHECK (status IN ('firing', 'resolved', 'acknowledged')),
    started_at TIMESTAMPTZ NOT NULL,
    resolved_at TIMESTAMPTZ,
    acknowledged_at TIMESTAMPTZ,
    acknowledged_by VARCHAR(100),
    notification_sent BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (started_at);

CREATE INDEX idx_alerts_status ON alerting.alerts(status, started_at DESC) WHERE status = 'firing';
CREATE INDEX idx_alerts_rule ON alerting.alerts(rule_id, started_at DESC);
CREATE INDEX idx_alerts_db ON alerting.alerts(database_name, started_at DESC);
```

### 4.2. å‘Šè­¦æ£€æµ‹å‡½æ•°

**å‘Šè­¦æ£€æµ‹å‡½æ•°**ï¼š

```sql
-- å‘Šè­¦æ£€æµ‹å‡½æ•°
CREATE OR REPLACE FUNCTION check_alert_rules()
RETURNS TABLE (
    rule_id INTEGER,
    database_name VARCHAR,
    metric_name VARCHAR,
    current_value DOUBLE PRECISION,
    threshold_value DOUBLE PRECISION,
    severity VARCHAR
) AS $$
BEGIN
    RETURN QUERY
    WITH recent_metrics AS (
        SELECT
            dm.database_name,
            dm.metric_name,
            AVG(dm.metric_value) AS avg_value
        FROM monitoring.database_metrics dm
        WHERE dm.collected_at >= CURRENT_TIMESTAMP - INTERVAL '5 minutes'
        GROUP BY dm.database_name, dm.metric_name
    ),
    active_rules AS (
        SELECT * FROM alerting.alert_rules
        WHERE is_active = TRUE
    )
    SELECT
        ar.rule_id,
        COALESCE(ar.database_name, rm.database_name) AS database_name,
        ar.metric_name,
        rm.avg_value AS current_value,
        COALESCE(ar.threshold_value, ar.threshold_min) AS threshold_value,
        ar.severity
    FROM active_rules ar
    JOIN recent_metrics rm ON ar.metric_name = rm.metric_name
        AND (ar.database_name IS NULL OR ar.database_name = rm.database_name)
    WHERE (
        (ar.condition_type = 'gt' AND rm.avg_value > ar.threshold_value) OR
        (ar.condition_type = 'lt' AND rm.avg_value < ar.threshold_value) OR
        (ar.condition_type = 'between' AND rm.avg_value BETWEEN ar.threshold_min AND ar.threshold_max)
    )
    AND NOT EXISTS (
        SELECT 1 FROM alerting.alerts a
        WHERE a.rule_id = ar.rule_id
          AND a.status = 'firing'
          AND a.database_name = COALESCE(ar.database_name, rm.database_name)
    );
END;
$$ LANGUAGE plpgsql;

-- åˆ›å»ºå‘Šè­¦å‡½æ•°
CREATE OR REPLACE FUNCTION create_alert(
    p_rule_id INTEGER,
    p_database_name VARCHAR,
    p_metric_name VARCHAR,
    p_metric_value DOUBLE PRECISION,
    p_threshold_value DOUBLE PRECISION,
    p_severity VARCHAR
)
RETURNS BIGINT AS $$
DECLARE
    v_alert_id BIGINT;
BEGIN
    INSERT INTO alerting.alerts (
        rule_id, database_name, metric_name,
        metric_value, threshold_value, severity,
        status, started_at
    )
    VALUES (
        p_rule_id, p_database_name, p_metric_name,
        p_metric_value, p_threshold_value, p_severity,
        'firing', CURRENT_TIMESTAMP
    )
    RETURNING alert_id INTO v_alert_id;

    RETURN v_alert_id;
END;
$$ LANGUAGE plpgsql;
```

---

## 5. æ€§èƒ½åˆ†æè®¾è®¡

### 5.1. æ€§èƒ½åˆ†æSchemaè®¾è®¡

**æ€§èƒ½åˆ†æè¡¨è®¾è®¡**ï¼š

```sql
CREATE SCHEMA performance_analysis;

-- æ…¢æŸ¥è¯¢åˆ†æè¡¨
CREATE TABLE performance_analysis.slow_queries (
    query_id BIGSERIAL PRIMARY KEY,
    database_name VARCHAR(100) NOT NULL,
    query_hash BIGINT NOT NULL,
    query_text TEXT NOT NULL,
    execution_time DOUBLE PRECISION NOT NULL,
    calls BIGINT NOT NULL,
    rows_processed BIGINT,
    execution_plan JSONB,
    collected_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (collected_at);

CREATE INDEX idx_slow_queries_db_time ON performance_analysis.slow_queries(database_name, collected_at DESC);
CREATE INDEX idx_slow_queries_hash ON performance_analysis.slow_queries(query_hash, collected_at DESC);

-- è¡¨æ€§èƒ½åˆ†æè¡¨
CREATE TABLE performance_analysis.table_performance (
    analysis_id BIGSERIAL PRIMARY KEY,
    database_name VARCHAR(100) NOT NULL,
    schema_name VARCHAR(100) NOT NULL,
    table_name VARCHAR(200) NOT NULL,
    table_size BIGINT NOT NULL,
    index_size BIGINT NOT NULL,
    total_size BIGINT NOT NULL,
    row_count BIGINT NOT NULL,
    seq_scan_count BIGINT NOT NULL,
    seq_tup_read BIGINT NOT NULL,
    idx_scan_count BIGINT NOT NULL,
    idx_tup_fetch BIGINT NOT NULL,
    n_tup_ins BIGINT NOT NULL,
    n_tup_upd BIGINT NOT NULL,
    n_tup_del BIGINT NOT NULL,
    last_vacuum TIMESTAMPTZ,
    last_autovacuum TIMESTAMPTZ,
    last_analyze TIMESTAMPTZ,
    last_autoanalyze TIMESTAMPTZ,
    collected_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (collected_at);

CREATE INDEX idx_table_performance_db_time ON performance_analysis.table_performance(database_name, collected_at DESC);
CREATE INDEX idx_table_performance_table ON performance_analysis.table_performance(schema_name, table_name, collected_at DESC);
```

### 5.2. æ€§èƒ½åˆ†æå‡½æ•°

**æ€§èƒ½åˆ†æå‡½æ•°**ï¼š

```sql
-- åˆ†æè¡¨æ€§èƒ½å‡½æ•°
CREATE OR REPLACE FUNCTION analyze_table_performance()
RETURNS VOID AS $$
DECLARE
    v_db_name VARCHAR;
BEGIN
    SELECT current_database() INTO v_db_name;

    INSERT INTO performance_analysis.table_performance (
        database_name, schema_name, table_name,
        table_size, index_size, total_size,
        row_count, seq_scan_count, seq_tup_read,
        idx_scan_count, idx_tup_fetch,
        n_tup_ins, n_tup_upd, n_tup_del,
        last_vacuum, last_autovacuum,
        last_analyze, last_autoanalyze
    )
    SELECT
        v_db_name,
        schemaname,
        tablename,
        pg_total_relation_size(schemaname||'.'||tablename) AS total_size,
        pg_relation_size(schemaname||'.'||tablename) AS table_size,
        pg_indexes_size(schemaname||'.'||tablename) AS index_size,
        n_live_tup,
        seq_scan,
        seq_tup_read,
        idx_scan,
        idx_tup_fetch,
        n_tup_ins,
        n_tup_upd,
        n_tup_del,
        last_vacuum,
        last_autovacuum,
        last_analyze,
        last_autoanalyze
    FROM pg_stat_user_tables;
END;
$$ LANGUAGE plpgsql;

-- è¯†åˆ«éœ€è¦ä¼˜åŒ–çš„è¡¨
CREATE OR REPLACE FUNCTION identify_optimization_targets()
RETURNS TABLE (
    schema_name VARCHAR,
    table_name VARCHAR,
    table_size BIGINT,
    seq_scan_ratio DOUBLE PRECISION,
    recommendation TEXT
) AS $$
BEGIN
    RETURN QUERY
    WITH table_stats AS (
        SELECT
            schemaname,
            tablename,
            pg_total_relation_size(schemaname||'.'||tablename) AS total_size,
            seq_scan,
            seq_tup_read,
            idx_scan,
            CASE
                WHEN seq_scan + idx_scan > 0
                THEN seq_scan::DOUBLE PRECISION / (seq_scan + idx_scan)::DOUBLE PRECISION
                ELSE 0
            END AS seq_scan_ratio
        FROM pg_stat_user_tables
        WHERE n_live_tup > 1000  -- åªåˆ†ææœ‰æ•°æ®çš„è¡¨
    )
    SELECT
        ts.schemaname,
        ts.tablename,
        ts.total_size,
        ts.seq_scan_ratio,
        CASE
            WHEN ts.seq_scan_ratio > 0.5 AND ts.total_size > 1000000000 THEN
                'Consider adding indexes - high sequential scan ratio on large table'
            WHEN ts.total_size > 10000000000 THEN
                'Consider partitioning - table is very large'
            WHEN ts.seq_scan_ratio > 0.8 THEN
                'High sequential scan ratio - review query patterns'
            ELSE
                'No immediate action needed'
        END AS recommendation
    FROM table_stats ts
    WHERE ts.seq_scan_ratio > 0.5 OR ts.total_size > 1000000000
    ORDER BY ts.total_size DESC;
END;
$$ LANGUAGE plpgsql;
```

---

## 6. è‡ªåŠ¨åŒ–è¿ç»´è®¾è®¡

### 6.1. è‡ªåŠ¨åŒ–ä»»åŠ¡Schemaè®¾è®¡

**è‡ªåŠ¨åŒ–ä»»åŠ¡è¡¨è®¾è®¡**ï¼š

```sql
CREATE SCHEMA automation;

-- è‡ªåŠ¨åŒ–ä»»åŠ¡è¡¨
CREATE TABLE automation.tasks (
    task_id SERIAL PRIMARY KEY,
    task_name VARCHAR(200) NOT NULL UNIQUE,
    task_type VARCHAR(50) NOT NULL,  -- vacuum, analyze, reindex, backup, etc.
    database_name VARCHAR(100),
    schedule_cron VARCHAR(100) NOT NULL,
    task_config JSONB DEFAULT '{}'::jsonb,
    is_active BOOLEAN DEFAULT TRUE,
    last_run_at TIMESTAMPTZ,
    next_run_at TIMESTAMPTZ,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_tasks_active ON automation.tasks(is_active, next_run_at) WHERE is_active = TRUE;

-- ä»»åŠ¡æ‰§è¡Œè®°å½•è¡¨
CREATE TABLE automation.task_executions (
    execution_id BIGSERIAL PRIMARY KEY,
    task_id INTEGER NOT NULL REFERENCES automation.tasks(task_id),
    execution_start_time TIMESTAMPTZ NOT NULL,
    execution_end_time TIMESTAMPTZ,
    execution_status VARCHAR(20) NOT NULL CHECK (execution_status IN ('running', 'completed', 'failed', 'skipped')),
    execution_result JSONB,
    error_message TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (execution_start_time);

CREATE INDEX idx_task_executions_task ON automation.task_executions(task_id, execution_start_time DESC);
CREATE INDEX idx_task_executions_status ON automation.task_executions(execution_status, execution_start_time DESC);
```

### 6.2. è‡ªåŠ¨åŒ–ä»»åŠ¡å‡½æ•°

**è‡ªåŠ¨åŒ–ä»»åŠ¡æ‰§è¡Œå‡½æ•°**ï¼š

```sql
-- Vacuumä»»åŠ¡å‡½æ•°
CREATE OR REPLACE FUNCTION execute_vacuum_task(
    p_database_name VARCHAR,
    p_table_name VARCHAR DEFAULT NULL,
    p_full BOOLEAN DEFAULT FALSE
)
RETURNS JSONB AS $$
DECLARE
    v_result JSONB;
    v_start_time TIMESTAMPTZ;
    v_end_time TIMESTAMPTZ;
BEGIN
    v_start_time := CURRENT_TIMESTAMP;

    IF p_table_name IS NOT NULL THEN
        -- å•è¡¨Vacuum
        IF p_full THEN
            EXECUTE format('VACUUM FULL %I.%I', current_schema(), p_table_name);
        ELSE
            EXECUTE format('VACUUM ANALYZE %I.%I', current_schema(), p_table_name);
        END IF;
    ELSE
        -- å…¨åº“Vacuum
        IF p_full THEN
            PERFORM pg_stat_progress_vacuum();
            -- æ³¨æ„ï¼šVACUUM FULLä¸èƒ½åœ¨å‡½æ•°ä¸­æ‰§è¡Œï¼Œéœ€è¦åœ¨åº”ç”¨å±‚å®ç°
        ELSE
            PERFORM pg_stat_progress_vacuum();
            ANALYZE;
        END IF;
    END IF;

    v_end_time := CURRENT_TIMESTAMP;

    v_result := jsonb_build_object(
        'status', 'completed',
        'start_time', v_start_time,
        'end_time', v_end_time,
        'duration', v_end_time - v_start_time
    );

    RETURN v_result;
EXCEPTION
    WHEN OTHERS THEN
        RETURN jsonb_build_object(
            'status', 'failed',
            'error', SQLERRM
        );
END;
$$ LANGUAGE plpgsql;

-- ç´¢å¼•é‡å»ºä»»åŠ¡å‡½æ•°
CREATE OR REPLACE FUNCTION execute_reindex_task(
    p_database_name VARCHAR,
    p_table_name VARCHAR DEFAULT NULL,
    p_index_name VARCHAR DEFAULT NULL
)
RETURNS JSONB AS $$
DECLARE
    v_result JSONB;
    v_start_time TIMESTAMPTZ;
    v_end_time TIMESTAMPTZ;
BEGIN
    v_start_time := CURRENT_TIMESTAMP;

    IF p_index_name IS NOT NULL THEN
        -- é‡å»ºå•ä¸ªç´¢å¼•
        EXECUTE format('REINDEX INDEX %I', p_index_name);
    ELSIF p_table_name IS NOT NULL THEN
        -- é‡å»ºè¡¨çš„æ‰€æœ‰ç´¢å¼•
        EXECUTE format('REINDEX TABLE %I.%I', current_schema(), p_table_name);
    ELSE
        -- é‡å»ºæ•°æ®åº“çš„æ‰€æœ‰ç´¢å¼•
        -- æ³¨æ„ï¼šREINDEX DATABASEä¸èƒ½åœ¨å‡½æ•°ä¸­æ‰§è¡Œ
        RAISE EXCEPTION 'Full database reindex must be executed outside function';
    END IF;

    v_end_time := CURRENT_TIMESTAMP;

    v_result := jsonb_build_object(
        'status', 'completed',
        'start_time', v_start_time,
        'end_time', v_end_time,
        'duration', v_end_time - v_start_time
    );

    RETURN v_result;
EXCEPTION
    WHEN OTHERS THEN
        RETURN jsonb_build_object(
            'status', 'failed',
            'error', SQLERRM
        );
END;
$$ LANGUAGE plpgsql;
```

---

## 7. å®é™…åº”ç”¨æ¡ˆä¾‹

### 7.1. å®Œæ•´ç›‘æ§ç³»ç»Ÿè®¾è®¡

**å®Œæ•´ç›‘æ§ç³»ç»ŸSchemaè®¾è®¡**ï¼š

```sql
CREATE SCHEMA monitoring_system;

-- ç›‘æ§é…ç½®è¡¨
CREATE TABLE monitoring_system.monitoring_configs (
    config_id SERIAL PRIMARY KEY,
    database_name VARCHAR(100) NOT NULL,
    collection_interval_seconds INTEGER NOT NULL DEFAULT 60,
    retention_days INTEGER NOT NULL DEFAULT 30,
    is_enabled BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(database_name)
);

-- ç›‘æ§ä»ªè¡¨æ¿é…ç½®è¡¨
CREATE TABLE monitoring_system.dashboards (
    dashboard_id SERIAL PRIMARY KEY,
    dashboard_name VARCHAR(200) NOT NULL UNIQUE,
    description TEXT,
    config JSONB NOT NULL,  -- Grafana dashboardé…ç½®
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- ç›‘æ§æŠ¥å‘Šè¡¨
CREATE TABLE monitoring_system.reports (
    report_id BIGSERIAL PRIMARY KEY,
    report_type VARCHAR(50) NOT NULL,  -- daily, weekly, monthly
    report_period_start TIMESTAMPTZ NOT NULL,
    report_period_end TIMESTAMPTZ NOT NULL,
    report_data JSONB NOT NULL,
    generated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    generated_by VARCHAR(100)
) PARTITION BY RANGE (generated_at);

CREATE INDEX idx_reports_type_period ON monitoring_system.reports(report_type, report_period_start DESC);
```

---

## 8. å‚è€ƒèµ„æ–™

- [æ•°æ®åº“æ€§èƒ½è°ƒä¼˜å®æˆ˜](./07.08-æ•°æ®åº“æ€§èƒ½è°ƒä¼˜å®æˆ˜.md)
- [æ—¶åºæ•°æ®åº“è®¾è®¡æ¨¡å¼](./07.18-æ—¶åºæ•°æ®åº“è®¾è®¡æ¨¡å¼.md)
- [PostgreSQLç›‘æ§æ–‡æ¡£](https://www.postgresql.org/docs/current/monitoring-stats.html)

---

**æœ€åæ›´æ–°**ï¼š2025-01-15
**ç»´æŠ¤è€…**ï¼šData-Science Team
**çŠ¶æ€**ï¼šå®æ–½ä¸­
