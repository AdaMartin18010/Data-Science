# æ•°æ®åº“è®¾è®¡æ¨¡å¼å®æˆ˜æ¼”ç»ƒï¼šä»ç†è®ºåˆ°å®è·µ

> **åˆ›å»ºæ—¥æœŸ**ï¼š2025-01-15
> **æœ€åæ›´æ–°**ï¼š2025-12-01
> **ç‰ˆæœ¬**ï¼šv2.0
> **çŠ¶æ€**ï¼šå·²å®Œæˆ âœ…

---

## ğŸ“‹ ç›®å½•

- [æ•°æ®åº“è®¾è®¡æ¨¡å¼å®æˆ˜æ¼”ç»ƒï¼šä»ç†è®ºåˆ°å®è·µ](#æ•°æ®åº“è®¾è®¡æ¨¡å¼å®æˆ˜æ¼”ç»ƒä»ç†è®ºåˆ°å®è·µ)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1. å®æˆ˜æ¼”ç»ƒç›®æ ‡](#11-å®æˆ˜æ¼”ç»ƒç›®æ ‡)
    - [1.2. å®æˆ˜æ¼”ç»ƒç»“æ„](#12-å®æˆ˜æ¼”ç»ƒç»“æ„)
  - [2. å®æˆ˜æ¼”ç»ƒ1ï¼šç”µå•†ç³»ç»Ÿæ•°æ®åº“è®¾è®¡](#2-å®æˆ˜æ¼”ç»ƒ1ç”µå•†ç³»ç»Ÿæ•°æ®åº“è®¾è®¡)
    - [2.1. éœ€æ±‚åˆ†æ](#21-éœ€æ±‚åˆ†æ)
    - [2.2. æ¦‚å¿µè®¾è®¡](#22-æ¦‚å¿µè®¾è®¡)
    - [2.3. é€»è¾‘è®¾è®¡](#23-é€»è¾‘è®¾è®¡)
    - [2.4. ç‰©ç†è®¾è®¡ä¼˜åŒ–](#24-ç‰©ç†è®¾è®¡ä¼˜åŒ–)
    - [2.5. è®¾è®¡è¯„å®¡](#25-è®¾è®¡è¯„å®¡)
  - [3. å®æˆ˜æ¼”ç»ƒ2ï¼šæ¨èç³»ç»Ÿæ•°æ®åº“è®¾è®¡](#3-å®æˆ˜æ¼”ç»ƒ2æ¨èç³»ç»Ÿæ•°æ®åº“è®¾è®¡)
    - [3.1. éœ€æ±‚åˆ†æ](#31-éœ€æ±‚åˆ†æ)
    - [3.2. æ¦‚å¿µè®¾è®¡](#32-æ¦‚å¿µè®¾è®¡)
    - [3.3. é€»è¾‘è®¾è®¡](#33-é€»è¾‘è®¾è®¡)
    - [3.4. æŸ¥è¯¢è®¾è®¡](#34-æŸ¥è¯¢è®¾è®¡)
  - [4. å®æˆ˜æ¼”ç»ƒ3ï¼šIoTç›‘æ§å¹³å°æ•°æ®åº“è®¾è®¡](#4-å®æˆ˜æ¼”ç»ƒ3iotç›‘æ§å¹³å°æ•°æ®åº“è®¾è®¡)
    - [4.1. éœ€æ±‚åˆ†æ](#41-éœ€æ±‚åˆ†æ)
    - [4.2. é€»è¾‘è®¾è®¡](#42-é€»è¾‘è®¾è®¡)
    - [4.3. è¿ç»­èšåˆè®¾è®¡](#43-è¿ç»­èšåˆè®¾è®¡)
  - [5. å®æˆ˜æ¼”ç»ƒ4ï¼šSaaSå¤šç§Ÿæˆ·ç³»ç»Ÿæ•°æ®åº“è®¾è®¡](#5-å®æˆ˜æ¼”ç»ƒ4saaså¤šç§Ÿæˆ·ç³»ç»Ÿæ•°æ®åº“è®¾è®¡)
    - [5.1. éœ€æ±‚åˆ†æ](#51-éœ€æ±‚åˆ†æ)
    - [5.2. é€»è¾‘è®¾è®¡](#52-é€»è¾‘è®¾è®¡)
  - [6. å®æˆ˜æ¼”ç»ƒ5ï¼šä¼ä¸šçŸ¥è¯†åº“æ•°æ®åº“è®¾è®¡](#6-å®æˆ˜æ¼”ç»ƒ5ä¼ä¸šçŸ¥è¯†åº“æ•°æ®åº“è®¾è®¡)
    - [6.1. éœ€æ±‚åˆ†æ](#61-éœ€æ±‚åˆ†æ)
    - [6.2. é€»è¾‘è®¾è®¡](#62-é€»è¾‘è®¾è®¡)
  - [7. å®æˆ˜æ¼”ç»ƒ6ï¼šé‡‘èæ”¯ä»˜ç³»ç»Ÿæ•°æ®åº“è®¾è®¡](#7-å®æˆ˜æ¼”ç»ƒ6é‡‘èæ”¯ä»˜ç³»ç»Ÿæ•°æ®åº“è®¾è®¡)
    - [7.1. éœ€æ±‚åˆ†æ](#71-éœ€æ±‚åˆ†æ)
    - [7.2. é€»è¾‘è®¾è®¡](#72-é€»è¾‘è®¾è®¡)
  - [8. å®æˆ˜æ¼”ç»ƒæ€»ç»“](#8-å®æˆ˜æ¼”ç»ƒæ€»ç»“)
    - [8.1. è®¾è®¡æ¨¡å¼åº”ç”¨æ€»ç»“](#81-è®¾è®¡æ¨¡å¼åº”ç”¨æ€»ç»“)
    - [8.2. è®¾è®¡åŸåˆ™æ€»ç»“](#82-è®¾è®¡åŸåˆ™æ€»ç»“)
  - [9. å®æˆ˜æ¼”ç»ƒ7ï¼šAIåº”ç”¨å¹³å°æ•°æ®åº“è®¾è®¡](#9-å®æˆ˜æ¼”ç»ƒ7aiåº”ç”¨å¹³å°æ•°æ®åº“è®¾è®¡)
    - [9.1. éœ€æ±‚åˆ†æ](#91-éœ€æ±‚åˆ†æ)
    - [9.2. é€»è¾‘è®¾è®¡](#92-é€»è¾‘è®¾è®¡)
    - [9.3. æ ¸å¿ƒæŸ¥è¯¢å‡½æ•°](#93-æ ¸å¿ƒæŸ¥è¯¢å‡½æ•°)
  - [10. å®æˆ˜Labç¯å¢ƒæ­å»º](#10-å®æˆ˜labç¯å¢ƒæ­å»º)
    - [10.1. Docker Composeå®éªŒç¯å¢ƒ](#101-docker-composeå®éªŒç¯å¢ƒ)
    - [10.2. Labç»ƒä¹ ä»»åŠ¡æ¸…å•](#102-labç»ƒä¹ ä»»åŠ¡æ¸…å•)
    - [10.3. è‡ªåŠ¨è¯„ä¼°è„šæœ¬](#103-è‡ªåŠ¨è¯„ä¼°è„šæœ¬)
  - [11. è®¾è®¡æ¨¡å¼é€ŸæŸ¥å¡](#11-è®¾è®¡æ¨¡å¼é€ŸæŸ¥å¡)
    - [11.1. åœºæ™¯-æ¨¡å¼å¿«é€ŸåŒ¹é…](#111-åœºæ™¯-æ¨¡å¼å¿«é€ŸåŒ¹é…)
    - [11.2. æ ¸å¿ƒSQLæ¨¡æ¿åº“](#112-æ ¸å¿ƒsqlæ¨¡æ¿åº“)
  - [12. å‚è€ƒèµ„æ–™](#12-å‚è€ƒèµ„æ–™)
    - [12.1. å®˜æ–¹æ–‡æ¡£](#121-å®˜æ–¹æ–‡æ¡£)
    - [12.2. ç›¸å…³æ–‡æ¡£](#122-ç›¸å…³æ–‡æ¡£)

---

## 1. æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›æ•°æ®åº“è®¾è®¡æ¨¡å¼çš„å®æˆ˜æ¼”ç»ƒï¼Œé€šè¿‡6ä¸ªå®Œæ•´çš„å®æˆ˜æ¡ˆä¾‹ï¼Œå¸®åŠ©å¼€å‘è€…å°†ç†è®ºçŸ¥è¯†è½¬åŒ–ä¸ºå®é™…è®¾è®¡èƒ½åŠ›ã€‚

### 1.1. å®æˆ˜æ¼”ç»ƒç›®æ ‡

- **æŒæ¡è®¾è®¡æµç¨‹**ï¼šä»éœ€æ±‚åˆ†æåˆ°ç‰©ç†å®ç°çš„å®Œæ•´æµç¨‹
- **åº”ç”¨è®¾è®¡æ¨¡å¼**ï¼šåœ¨ä¸åŒåœºæ™¯ä¸‹é€‰æ‹©åˆé€‚çš„è®¾è®¡æ¨¡å¼
- **è§£å†³å®é™…é—®é¢˜**ï¼šå¤„ç†æ€§èƒ½ã€å®‰å…¨ã€æ‰©å±•æ€§ç­‰å®é™…é—®é¢˜
- **ä¼˜åŒ–è®¾è®¡æ–¹æ¡ˆ**ï¼šé€šè¿‡è¯„å®¡å’Œä¼˜åŒ–æå‡è®¾è®¡è´¨é‡

### 1.2. å®æˆ˜æ¼”ç»ƒç»“æ„

æ¯ä¸ªå®æˆ˜æ¼”ç»ƒåŒ…å«ï¼š

- **éœ€æ±‚åˆ†æ**ï¼šä¸šåŠ¡éœ€æ±‚ã€æŠ€æœ¯éœ€æ±‚ã€æ€§èƒ½éœ€æ±‚
- **æ¦‚å¿µè®¾è®¡**ï¼šERå›¾ã€ä¸šåŠ¡è§„åˆ™
- **é€»è¾‘è®¾è®¡**ï¼šè¡¨ç»“æ„ã€å…³ç³»è®¾è®¡
- **ç‰©ç†è®¾è®¡**ï¼šç´¢å¼•ã€åˆ†åŒºã€ä¼˜åŒ–
- **ä»£ç å®ç°**ï¼šå®Œæ•´DDLä»£ç 
- **è®¾è®¡è¯„å®¡**ï¼šè´¨é‡æ£€æŸ¥ã€ä¼˜åŒ–å»ºè®®

---

## 2. å®æˆ˜æ¼”ç»ƒ1ï¼šç”µå•†ç³»ç»Ÿæ•°æ®åº“è®¾è®¡

### 2.1. éœ€æ±‚åˆ†æ

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- ç”¨æˆ·æ³¨å†Œã€ç™»å½•ã€ä¸ªäººä¿¡æ¯ç®¡ç†
- å•†å“ç®¡ç†ï¼ˆåˆ†ç±»ã€å±æ€§ã€åº“å­˜ï¼‰
- è´­ç‰©è½¦ã€è®¢å•ç®¡ç†
- æ”¯ä»˜ã€ç‰©æµè·Ÿè¸ª
- è¯„ä»·ã€æ¨è

**æŠ€æœ¯éœ€æ±‚**ï¼š

- æ”¯æŒé«˜å¹¶å‘è¯»å†™
- åˆ†å¸ƒå¼éƒ¨ç½²
- æ•°æ®ä¸€è‡´æ€§ä¿è¯
- é«˜å¯ç”¨æ€§

**æ€§èƒ½éœ€æ±‚**ï¼š

- æŸ¥è¯¢å“åº”æ—¶é—´ < 100ms
- æ”¯æŒ10ä¸‡+å•†å“
- æ”¯æŒç™¾ä¸‡çº§ç”¨æˆ·
- æ—¥è®¢å•é‡10ä¸‡+

### 2.2. æ¦‚å¿µè®¾è®¡

**ERå›¾è®¾è®¡**ï¼š

```mermaid
erDiagram
    USERS ||--o{ ORDERS : places
    USERS ||--o{ CART_ITEMS : has
    USERS ||--o{ ADDRESSES : has
    PRODUCTS ||--o{ CART_ITEMS : in
    PRODUCTS ||--o{ ORDER_ITEMS : contains
    PRODUCTS }o--|| CATEGORIES : belongs_to
    ORDERS ||--o{ ORDER_ITEMS : contains
    ORDERS ||--|| PAYMENTS : has
    ORDERS ||--|| SHIPMENTS : has
    PRODUCTS ||--o{ PRODUCT_REVIEWS : reviewed_by
    USERS ||--o{ PRODUCT_REVIEWS : writes
```

### 2.3. é€»è¾‘è®¾è®¡

**è¡¨ç»“æ„è®¾è®¡**ï¼š

```sql
CREATE SCHEMA ecommerce;

-- ç”¨æˆ·è¡¨
CREATE TABLE ecommerce.users (
    user_id BIGSERIAL PRIMARY KEY,
    username VARCHAR(50) NOT NULL UNIQUE,
    email VARCHAR(100) NOT NULL UNIQUE,
    password_hash TEXT NOT NULL,
    phone VARCHAR(20),
    status VARCHAR(20) DEFAULT 'active',
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_users_email ON ecommerce.users(email);
CREATE INDEX idx_users_status ON ecommerce.users(status);

-- å•†å“åˆ†ç±»è¡¨
CREATE TABLE ecommerce.categories (
    category_id SERIAL PRIMARY KEY,
    category_name VARCHAR(100) NOT NULL,
    parent_id INTEGER REFERENCES ecommerce.categories(category_id),
    level INTEGER NOT NULL DEFAULT 1,
    sort_order INTEGER DEFAULT 0,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_categories_parent ON ecommerce.categories(parent_id);

-- å•†å“è¡¨
CREATE TABLE ecommerce.products (
    product_id BIGSERIAL PRIMARY KEY,
    category_id INTEGER NOT NULL REFERENCES ecommerce.categories(category_id),
    product_name VARCHAR(200) NOT NULL,
    description TEXT,
    price DECIMAL(10, 2) NOT NULL,
    stock_quantity INTEGER NOT NULL DEFAULT 0,
    sales_count INTEGER DEFAULT 0,
    status VARCHAR(20) DEFAULT 'active',
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (created_at);

CREATE INDEX idx_products_category ON ecommerce.products(category_id);
CREATE INDEX idx_products_status ON ecommerce.products(status);
CREATE INDEX idx_products_price ON ecommerce.products(price);

-- è®¢å•è¡¨ï¼ˆæŒ‰æœˆåˆ†åŒºï¼‰
CREATE TABLE ecommerce.orders (
    order_id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL REFERENCES ecommerce.users(user_id),
    order_sn VARCHAR(64) UNIQUE NOT NULL,
    total_amount DECIMAL(12, 2) NOT NULL,
    actual_payment DECIMAL(12, 2) NOT NULL,
    payment_status VARCHAR(20) DEFAULT 'pending',
    order_status VARCHAR(20) DEFAULT 'created',
    shipping_address JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (created_at);

CREATE INDEX idx_orders_user ON ecommerce.orders(user_id, created_at DESC);
CREATE INDEX idx_orders_status ON ecommerce.orders(order_status, created_at DESC);
CREATE INDEX idx_orders_sn ON ecommerce.orders(order_sn);

-- è®¢å•æ˜ç»†è¡¨
CREATE TABLE ecommerce.order_items (
    item_id BIGSERIAL PRIMARY KEY,
    order_id BIGINT NOT NULL REFERENCES ecommerce.orders(order_id) ON DELETE CASCADE,
    product_id BIGINT NOT NULL REFERENCES ecommerce.products(product_id),
    quantity INTEGER NOT NULL,
    price DECIMAL(10, 2) NOT NULL,
    subtotal DECIMAL(12, 2) NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_order_items_order ON ecommerce.order_items(order_id);
CREATE INDEX idx_order_items_product ON ecommerce.order_items(product_id);

-- è´­ç‰©è½¦è¡¨
CREATE TABLE ecommerce.cart_items (
    cart_id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL REFERENCES ecommerce.users(user_id) ON DELETE CASCADE,
    product_id BIGINT NOT NULL REFERENCES ecommerce.products(product_id),
    quantity INTEGER NOT NULL DEFAULT 1,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(user_id, product_id)
);

CREATE INDEX idx_cart_items_user ON ecommerce.cart_items(user_id);
```

### 2.4. ç‰©ç†è®¾è®¡ä¼˜åŒ–

**åˆ†åŒºç­–ç•¥**ï¼š

```sql
-- åˆ›å»ºè®¢å•è¡¨åˆ†åŒºï¼ˆæŒ‰æœˆåˆ†åŒºï¼‰
CREATE TABLE ecommerce.orders_2025_01 PARTITION OF ecommerce.orders
FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE TABLE ecommerce.orders_2025_02 PARTITION OF ecommerce.orders
FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');

-- åˆ›å»ºå•†å“è¡¨åˆ†åŒºï¼ˆæŒ‰åˆ›å»ºæ—¶é—´åˆ†åŒºï¼‰
CREATE TABLE ecommerce.products_2025_01 PARTITION OF ecommerce.products
FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
```

**æ€§èƒ½ä¼˜åŒ–**ï¼š

```sql
-- ç‰©åŒ–è§†å›¾ï¼šå•†å“é”€å”®ç»Ÿè®¡
CREATE MATERIALIZED VIEW ecommerce.mv_product_sales AS
SELECT
    product_id,
    SUM(quantity) AS total_sold,
    SUM(subtotal) AS total_revenue,
    COUNT(DISTINCT order_id) AS order_count
FROM ecommerce.order_items
GROUP BY product_id;

CREATE UNIQUE INDEX ON ecommerce.mv_product_sales(product_id);

-- å®šæœŸåˆ·æ–°ç‰©åŒ–è§†å›¾
REFRESH MATERIALIZED VIEW CONCURRENTLY ecommerce.mv_product_sales;
```

### 2.5. è®¾è®¡è¯„å®¡

**è´¨é‡è¯„åˆ†**ï¼š

- å‘½åè§„èŒƒï¼šâœ… ç¬¦åˆè§„èŒƒ
- ç»“æ„è®¾è®¡ï¼šâœ… ä¸»é”®ã€å¤–é”®å®Œæ•´
- æ€§èƒ½è®¾è®¡ï¼šâœ… åˆ†åŒºã€ç´¢å¼•åˆç†
- å®‰å…¨è®¾è®¡ï¼šâš ï¸ éœ€è¦æ·»åŠ RLSç­–ç•¥

**ä¼˜åŒ–å»ºè®®**ï¼š

1. æ·»åŠ ç”¨æˆ·å¯†ç åŠ å¯†å­˜å‚¨
2. æ·»åŠ è®¢å•çŠ¶æ€å˜æ›´å®¡è®¡æ—¥å¿—
3. æ·»åŠ å•†å“åº“å­˜é¢„è­¦æœºåˆ¶
4. è€ƒè™‘ä½¿ç”¨Redisç¼“å­˜çƒ­é—¨å•†å“

---

## 3. å®æˆ˜æ¼”ç»ƒ2ï¼šæ¨èç³»ç»Ÿæ•°æ®åº“è®¾è®¡

### 3.1. éœ€æ±‚åˆ†æ

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- ç”¨æˆ·è¡Œä¸ºæ•°æ®æ”¶é›†ï¼ˆæµè§ˆã€ç‚¹å‡»ã€è´­ä¹°ï¼‰
- å•†å“å‘é‡åµŒå…¥å­˜å‚¨
- ç›¸ä¼¼åº¦æœç´¢
- æ¨èç»“æœå­˜å‚¨

**æŠ€æœ¯éœ€æ±‚**ï¼š

- å‘é‡æ•°æ®åº“æ”¯æŒ
- å®æ—¶æ¨èè®¡ç®—
- é«˜å¹¶å‘æŸ¥è¯¢

**æ€§èƒ½éœ€æ±‚**ï¼š

- å‘é‡æ£€ç´¢å“åº”æ—¶é—´ < 50ms
- æ”¯æŒç™¾ä¸‡çº§å•†å“å‘é‡
- æ”¯æŒå®æ—¶æ¨èæ›´æ–°

### 3.2. æ¦‚å¿µè®¾è®¡

**æ•°æ®æ¨¡å‹**ï¼š

- ç”¨æˆ·è¡Œä¸ºè¡¨ï¼ˆæ—¶åºæ•°æ®ï¼‰
- å•†å“å‘é‡è¡¨ï¼ˆå‘é‡æ•°æ®ï¼‰
- æ¨èç»“æœè¡¨ï¼ˆç¼“å­˜æ•°æ®ï¼‰

### 3.3. é€»è¾‘è®¾è®¡

**è¡¨ç»“æ„è®¾è®¡**ï¼š

```sql
CREATE SCHEMA recommendation;

-- ç”¨æˆ·è¡Œä¸ºè¡¨ï¼ˆæ—¶åºæ•°æ®ï¼‰
CREATE TABLE recommendation.user_behaviors (
    behavior_id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL,
    product_id BIGINT NOT NULL,
    behavior_type VARCHAR(20) NOT NULL, -- view, click, purchase, cart
    behavior_time TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    context JSONB -- ä¸Šä¸‹æ–‡ä¿¡æ¯
) PARTITION BY RANGE (behavior_time);

CREATE INDEX idx_behaviors_user_time ON recommendation.user_behaviors(user_id, behavior_time DESC);
CREATE INDEX idx_behaviors_product_time ON recommendation.user_behaviors(product_id, behavior_time DESC);

-- å•†å“å‘é‡è¡¨ï¼ˆä½¿ç”¨pgvectoræ‰©å±•ï¼‰
CREATE EXTENSION IF NOT EXISTS vector;

CREATE TABLE recommendation.product_vectors (
    product_id BIGINT PRIMARY KEY,
    product_name VARCHAR(200) NOT NULL,
    category_id INTEGER,
    embedding vector(384) NOT NULL, -- 384ç»´å‘é‡
    metadata JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- åˆ›å»ºå‘é‡ç´¢å¼•ï¼ˆHNSWï¼‰
CREATE INDEX idx_product_vectors_embedding ON recommendation.product_vectors
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- æ¨èç»“æœè¡¨ï¼ˆç¼“å­˜ï¼‰
CREATE TABLE recommendation.recommendations (
    recommendation_id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL,
    product_id BIGINT NOT NULL REFERENCES recommendation.product_vectors(product_id),
    score DOUBLE PRECISION NOT NULL,
    recommendation_type VARCHAR(50) NOT NULL, -- collaborative, content-based, hybrid
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    expires_at TIMESTAMPTZ NOT NULL,
    UNIQUE(user_id, product_id, recommendation_type)
);

CREATE INDEX idx_recommendations_user ON recommendation.recommendations(user_id, score DESC);
CREATE INDEX idx_recommendations_expires ON recommendation.recommendations(expires_at);
```

### 3.4. æŸ¥è¯¢è®¾è®¡

**å‘é‡ç›¸ä¼¼åº¦æœç´¢**ï¼š

```sql
-- åŸºäºå•†å“ç›¸ä¼¼åº¦çš„æ¨è
CREATE OR REPLACE FUNCTION get_similar_products(
    p_product_id BIGINT,
    p_limit INTEGER DEFAULT 10
)
RETURNS TABLE (
    product_id BIGINT,
    product_name VARCHAR,
    similarity DOUBLE PRECISION
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        pv2.product_id,
        pv2.product_name,
        1 - (pv1.embedding <=> pv2.embedding) AS similarity
    FROM recommendation.product_vectors pv1
    CROSS JOIN recommendation.product_vectors pv2
    WHERE pv1.product_id = p_product_id
      AND pv2.product_id != p_product_id
    ORDER BY pv1.embedding <=> pv2.embedding
    LIMIT p_limit;
END;
$$ LANGUAGE plpgsql;

-- åŸºäºç”¨æˆ·è¡Œä¸ºçš„æ¨è
CREATE OR REPLACE FUNCTION get_user_recommendations(
    p_user_id BIGINT,
    p_limit INTEGER DEFAULT 20
)
RETURNS TABLE (
    product_id BIGINT,
    product_name VARCHAR,
    score DOUBLE PRECISION
) AS $$
BEGIN
    RETURN QUERY
    WITH user_products AS (
        SELECT DISTINCT product_id
        FROM recommendation.user_behaviors
        WHERE user_id = p_user_id
          AND behavior_type IN ('purchase', 'click')
          AND behavior_time >= CURRENT_TIMESTAMP - INTERVAL '30 days'
    ),
    similar_products AS (
        SELECT DISTINCT
            pv2.product_id,
            pv2.product_name,
            AVG(1 - (pv1.embedding <=> pv2.embedding)) AS avg_similarity
        FROM user_products up
        JOIN recommendation.product_vectors pv1 ON up.product_id = pv1.product_id
        CROSS JOIN recommendation.product_vectors pv2
        WHERE pv2.product_id NOT IN (SELECT product_id FROM user_products)
        GROUP BY pv2.product_id, pv2.product_name
    )
    SELECT
        sp.product_id,
        sp.product_name,
        sp.avg_similarity AS score
    FROM similar_products sp
    ORDER BY sp.avg_similarity DESC
    LIMIT p_limit;
END;
$$ LANGUAGE plpgsql;
```

---

## 4. å®æˆ˜æ¼”ç»ƒ3ï¼šIoTç›‘æ§å¹³å°æ•°æ®åº“è®¾è®¡

### 4.1. éœ€æ±‚åˆ†æ

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- è®¾å¤‡ç®¡ç†ï¼ˆæ³¨å†Œã€çŠ¶æ€ç›‘æ§ï¼‰
- ä¼ æ„Ÿå™¨æ•°æ®é‡‡é›†ï¼ˆæ¸©åº¦ã€æ¹¿åº¦ã€å‹åŠ›ç­‰ï¼‰
- å®æ—¶å‘Šè­¦
- å†å²æ•°æ®æŸ¥è¯¢å’Œåˆ†æ

**æŠ€æœ¯éœ€æ±‚**ï¼š

- æ—¶åºæ•°æ®åº“æ”¯æŒ
- é«˜å†™å…¥æ€§èƒ½
- æ•°æ®å‹ç¼©å’Œå½’æ¡£

**æ€§èƒ½éœ€æ±‚**ï¼š

- æ”¯æŒç™¾ä¸‡çº§è®¾å¤‡
- æ¯ç§’ç™¾ä¸‡çº§æ•°æ®ç‚¹å†™å…¥
- æŸ¥è¯¢å“åº”æ—¶é—´ < 1ç§’

### 4.2. é€»è¾‘è®¾è®¡

**è¡¨ç»“æ„è®¾è®¡ï¼ˆä½¿ç”¨TimescaleDBï¼‰**ï¼š

```sql
CREATE SCHEMA iot_monitoring;

-- è®¾å¤‡è¡¨
CREATE TABLE iot_monitoring.devices (
    device_id BIGSERIAL PRIMARY KEY,
    device_name VARCHAR(200) NOT NULL,
    device_type VARCHAR(50) NOT NULL,
    location VARCHAR(200),
    status VARCHAR(20) DEFAULT 'active',
    metadata JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_devices_type ON iot_monitoring.devices(device_type);
CREATE INDEX idx_devices_status ON iot_monitoring.devices(status);

-- ä¼ æ„Ÿå™¨æ•°æ®è¡¨ï¼ˆæ—¶åºæ•°æ®ï¼‰
CREATE TABLE iot_monitoring.sensor_data (
    time TIMESTAMPTZ NOT NULL,
    device_id BIGINT NOT NULL REFERENCES iot_monitoring.devices(device_id),
    sensor_type VARCHAR(50) NOT NULL,
    value DOUBLE PRECISION NOT NULL,
    unit VARCHAR(20),
    quality INTEGER DEFAULT 100, -- æ•°æ®è´¨é‡
    PRIMARY KEY (time, device_id, sensor_type)
);

-- è½¬æ¢ä¸ºè¶…è¡¨
SELECT create_hypertable('iot_monitoring.sensor_data', 'time',
    chunk_time_interval => INTERVAL '1 day'
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_sensor_data_device_time ON iot_monitoring.sensor_data(device_id, time DESC);
CREATE INDEX idx_sensor_data_type_time ON iot_monitoring.sensor_data(sensor_type, time DESC);

-- å‘Šè­¦è§„åˆ™è¡¨
CREATE TABLE iot_monitoring.alert_rules (
    rule_id SERIAL PRIMARY KEY,
    device_id BIGINT REFERENCES iot_monitoring.devices(device_id),
    sensor_type VARCHAR(50) NOT NULL,
    condition_type VARCHAR(20) NOT NULL, -- gt, lt, eq
    threshold_value DOUBLE PRECISION NOT NULL,
    severity VARCHAR(20) NOT NULL,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- å‘Šè­¦è®°å½•è¡¨
CREATE TABLE iot_monitoring.alerts (
    alert_id BIGSERIAL PRIMARY KEY,
    rule_id INTEGER NOT NULL REFERENCES iot_monitoring.alert_rules(rule_id),
    device_id BIGINT NOT NULL,
    sensor_type VARCHAR(50) NOT NULL,
    alert_value DOUBLE PRECISION NOT NULL,
    threshold_value DOUBLE PRECISION NOT NULL,
    severity VARCHAR(20) NOT NULL,
    status VARCHAR(20) DEFAULT 'firing',
    started_at TIMESTAMPTZ NOT NULL,
    resolved_at TIMESTAMPTZ,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (started_at);

CREATE INDEX idx_alerts_status ON iot_monitoring.alerts(status, started_at DESC);
CREATE INDEX idx_alerts_device ON iot_monitoring.alerts(device_id, started_at DESC);
```

### 4.3. è¿ç»­èšåˆè®¾è®¡

**è¿ç»­èšåˆè§†å›¾**ï¼š

```sql
-- æ¯å°æ—¶èšåˆ
CREATE MATERIALIZED VIEW iot_monitoring.sensor_data_hourly
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 hour', time) AS bucket,
    device_id,
    sensor_type,
    AVG(value) AS avg_value,
    MIN(value) AS min_value,
    MAX(value) AS max_value,
    COUNT(*) AS data_points
FROM iot_monitoring.sensor_data
GROUP BY bucket, device_id, sensor_type;

-- æ¯å¤©èšåˆ
CREATE MATERIALIZED VIEW iot_monitoring.sensor_data_daily
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 day', time) AS bucket,
    device_id,
    sensor_type,
    AVG(value) AS avg_value,
    MIN(value) AS min_value,
    MAX(value) AS max_value,
    COUNT(*) AS data_points
FROM iot_monitoring.sensor_data
GROUP BY bucket, device_id, sensor_type;
```

---

## 5. å®æˆ˜æ¼”ç»ƒ4ï¼šSaaSå¤šç§Ÿæˆ·ç³»ç»Ÿæ•°æ®åº“è®¾è®¡

### 5.1. éœ€æ±‚åˆ†æ

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- å¤šç§Ÿæˆ·éš”ç¦»
- ç§Ÿæˆ·èµ„æºç®¡ç†
- ç§Ÿæˆ·æ•°æ®ç‹¬ç«‹

**æŠ€æœ¯éœ€æ±‚**ï¼š

- ä½¿ç”¨RLSå®ç°è¡Œçº§å®‰å…¨
- æ”¯æŒç§Ÿæˆ·æ•°æ®è¿ç§»
- æ”¯æŒç§Ÿæˆ·èµ„æºé™åˆ¶

### 5.2. é€»è¾‘è®¾è®¡

**è¡¨ç»“æ„è®¾è®¡ï¼ˆRLSæ¨¡å¼ï¼‰**ï¼š

```sql
CREATE SCHEMA saas_app;

-- ç§Ÿæˆ·è¡¨
CREATE TABLE saas_app.tenants (
    tenant_id BIGSERIAL PRIMARY KEY,
    tenant_name VARCHAR(200) NOT NULL UNIQUE,
    max_users INTEGER DEFAULT 50,
    max_projects INTEGER DEFAULT 10,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- ç”¨æˆ·è¡¨ï¼ˆå…±äº«ï¼ŒRLSéš”ç¦»ï¼‰
CREATE TABLE saas_app.users (
    user_id BIGSERIAL PRIMARY KEY,
    tenant_id BIGINT NOT NULL REFERENCES saas_app.tenants(tenant_id),
    username VARCHAR(100) NOT NULL,
    email VARCHAR(200) NOT NULL,
    password_hash TEXT NOT NULL,
    is_admin BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(tenant_id, username)
);

-- å¯ç”¨RLS
ALTER TABLE saas_app.users ENABLE ROW LEVEL SECURITY;

-- RLSç­–ç•¥å‡½æ•°
CREATE OR REPLACE FUNCTION saas_app.get_current_tenant_id()
RETURNS BIGINT AS $$
BEGIN
    RETURN current_setting('app.current_tenant_id', TRUE)::BIGINT;
END;
$$ LANGUAGE plpgsql STABLE;

-- RLSç­–ç•¥
CREATE POLICY tenant_isolation_policy ON saas_app.users
    FOR ALL
    USING (tenant_id = saas_app.get_current_tenant_id())
    WITH CHECK (tenant_id = saas_app.get_current_tenant_id());

-- é¡¹ç›®è¡¨
CREATE TABLE saas_app.projects (
    project_id BIGSERIAL PRIMARY KEY,
    tenant_id BIGINT NOT NULL REFERENCES saas_app.tenants(tenant_id),
    project_name VARCHAR(200) NOT NULL,
    description TEXT,
    status VARCHAR(50) DEFAULT 'active',
    created_by BIGINT NOT NULL REFERENCES saas_app.users(user_id),
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(tenant_id, project_name)
);

ALTER TABLE saas_app.projects ENABLE ROW LEVEL SECURITY;

CREATE POLICY tenant_isolation_policy ON saas_app.projects
    FOR ALL
    USING (tenant_id = saas_app.get_current_tenant_id())
    WITH CHECK (tenant_id = saas_app.get_current_tenant_id());
```

---

## 6. å®æˆ˜æ¼”ç»ƒ5ï¼šä¼ä¸šçŸ¥è¯†åº“æ•°æ®åº“è®¾è®¡

### 6.1. éœ€æ±‚åˆ†æ

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- çŸ¥è¯†æ–‡æ¡£ç®¡ç†
- çŸ¥è¯†å›¾è°±æ„å»º
- å‘é‡æ£€ç´¢
- æ™ºèƒ½é—®ç­”

**æŠ€æœ¯éœ€æ±‚**ï¼š

- çŸ¥è¯†å›¾è°±å­˜å‚¨
- å‘é‡æ•°æ®åº“
- æ··åˆæ£€ç´¢

### 6.2. é€»è¾‘è®¾è®¡

**è¡¨ç»“æ„è®¾è®¡ï¼ˆçŸ¥è¯†å›¾è°±+å‘é‡ï¼‰**ï¼š

```sql
CREATE SCHEMA knowledge_base;

-- å®ä½“è¡¨
CREATE TABLE knowledge_base.entities (
    entity_id BIGSERIAL PRIMARY KEY,
    entity_type VARCHAR(50) NOT NULL,
    entity_name VARCHAR(200) NOT NULL,
    properties JSONB NOT NULL DEFAULT '{}',
    embedding vector(384), -- å‘é‡åµŒå…¥
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_entities_type ON knowledge_base.entities(entity_type);
CREATE INDEX idx_entities_name ON knowledge_base.entities(entity_name);
CREATE INDEX idx_entities_embedding ON knowledge_base.entities
USING hnsw (embedding vector_cosine_ops);

-- å…³ç³»è¡¨ï¼ˆä¸‰å…ƒç»„ï¼‰
CREATE TABLE knowledge_base.relations (
    relation_id BIGSERIAL PRIMARY KEY,
    subject_id BIGINT NOT NULL REFERENCES knowledge_base.entities(entity_id),
    predicate VARCHAR(100) NOT NULL,
    object_id BIGINT NOT NULL REFERENCES knowledge_base.entities(entity_id),
    properties JSONB NOT NULL DEFAULT '{}',
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(subject_id, predicate, object_id)
);

CREATE INDEX idx_relations_subject ON knowledge_base.relations(subject_id);
CREATE INDEX idx_relations_object ON knowledge_base.relations(object_id);
CREATE INDEX idx_relations_predicate ON knowledge_base.relations(predicate);

-- æ–‡æ¡£è¡¨
CREATE TABLE knowledge_base.documents (
    document_id BIGSERIAL PRIMARY KEY,
    title VARCHAR(500) NOT NULL,
    content TEXT NOT NULL,
    content_type VARCHAR(50), -- pdf, docx, markdown
    embedding vector(384),
    metadata JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_documents_embedding ON knowledge_base.documents
USING hnsw (embedding vector_cosine_ops);
CREATE INDEX idx_documents_title ON knowledge_base.documents USING GIN(to_tsvector('english', title));
```

---

## 7. å®æˆ˜æ¼”ç»ƒ6ï¼šé‡‘èæ”¯ä»˜ç³»ç»Ÿæ•°æ®åº“è®¾è®¡

### 7.1. éœ€æ±‚åˆ†æ

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- è´¦æˆ·ç®¡ç†
- äº¤æ˜“è®°å½•
- æ”¯ä»˜å¤„ç†
- é£æ§å®¡è®¡

**æŠ€æœ¯éœ€æ±‚**ï¼š

- å¼ºä¸€è‡´æ€§
- äº‹åŠ¡ä¿è¯
- å®‰å…¨åŠ å¯†
- å®¡è®¡æ—¥å¿—

### 7.2. é€»è¾‘è®¾è®¡

**è¡¨ç»“æ„è®¾è®¡**ï¼š

```sql
CREATE SCHEMA finance;

-- è´¦æˆ·è¡¨
CREATE TABLE finance.accounts (
    account_id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL,
    account_type VARCHAR(50) NOT NULL, -- savings, checking, credit
    balance DECIMAL(15, 2) NOT NULL DEFAULT 0,
    currency VARCHAR(3) DEFAULT 'CNY',
    status VARCHAR(20) DEFAULT 'active',
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_accounts_user ON finance.accounts(user_id);
CREATE INDEX idx_accounts_status ON finance.accounts(status);

-- äº¤æ˜“è¡¨
CREATE TABLE finance.transactions (
    transaction_id BIGSERIAL PRIMARY KEY,
    from_account_id BIGINT REFERENCES finance.accounts(account_id),
    to_account_id BIGINT REFERENCES finance.accounts(account_id),
    amount DECIMAL(15, 2) NOT NULL,
    currency VARCHAR(3) NOT NULL,
    transaction_type VARCHAR(50) NOT NULL, -- transfer, deposit, withdrawal
    status VARCHAR(20) DEFAULT 'pending',
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMPTZ
) PARTITION BY RANGE (created_at);

CREATE INDEX idx_transactions_from ON finance.transactions(from_account_id, created_at DESC);
CREATE INDEX idx_transactions_to ON finance.transactions(to_account_id, created_at DESC);
CREATE INDEX idx_transactions_status ON finance.transactions(status, created_at DESC);

-- å®¡è®¡æ—¥å¿—è¡¨
CREATE TABLE finance.audit_logs (
    log_id BIGSERIAL PRIMARY KEY,
    table_name VARCHAR(100) NOT NULL,
    record_id BIGINT NOT NULL,
    operation VARCHAR(20) NOT NULL, -- INSERT, UPDATE, DELETE
    old_values JSONB,
    new_values JSONB,
    user_id BIGINT,
    ip_address INET,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (created_at);

CREATE INDEX idx_audit_logs_table_record ON finance.audit_logs(table_name, record_id);
CREATE INDEX idx_audit_logs_user ON finance.audit_logs(user_id, created_at DESC);
```

---

## 8. å®æˆ˜æ¼”ç»ƒæ€»ç»“

### 8.1. è®¾è®¡æ¨¡å¼åº”ç”¨æ€»ç»“

| å®æˆ˜æ¡ˆä¾‹ | åº”ç”¨çš„è®¾è®¡æ¨¡å¼ | å…³é”®è®¾è®¡å†³ç­– |
|---------|--------------|-------------|
| **ç”µå•†ç³»ç»Ÿ** | åˆ†å¸ƒå¼æ•°æ®åº“ã€åˆ†åŒºã€ç‰©åŒ–è§†å›¾ | è®¢å•è¡¨æŒ‰æœˆåˆ†åŒºã€å•†å“é”€å”®ç»Ÿè®¡ç‰©åŒ–è§†å›¾ |
| **æ¨èç³»ç»Ÿ** | å‘é‡æ•°æ®åº“ã€æ—¶åºæ•°æ®åº“ | pgvectoræ‰©å±•ã€HNSWç´¢å¼•ã€è¡Œä¸ºæ•°æ®æ—¶åºå­˜å‚¨ |
| **IoTç›‘æ§** | æ—¶åºæ•°æ®åº“ã€è¿ç»­èšåˆ | TimescaleDBè¶…è¡¨ã€è¿ç»­èšåˆè§†å›¾ |
| **SaaSå¤šç§Ÿæˆ·** | å¤šç§Ÿæˆ·æ•°æ®åº“ã€RLS | è¡Œçº§å®‰å…¨ç­–ç•¥ã€ç§Ÿæˆ·éš”ç¦» |
| **çŸ¥è¯†åº“** | çŸ¥è¯†å›¾è°±ã€å‘é‡æ•°æ®åº“ | ä¸‰å…ƒç»„å­˜å‚¨ã€å‘é‡æ£€ç´¢ã€æ··åˆæ£€ç´¢ |
| **é‡‘èæ”¯ä»˜** | å…³ç³»æ•°æ®åº“ã€å®¡è®¡æ—¥å¿— | å¼ºä¸€è‡´æ€§ã€äº‹åŠ¡ä¿è¯ã€å®Œæ•´å®¡è®¡ |

### 8.2. è®¾è®¡åŸåˆ™æ€»ç»“

1. **æ€§èƒ½ä¼˜å…ˆ**ï¼šåˆç†ä½¿ç”¨åˆ†åŒºã€ç´¢å¼•ã€ç‰©åŒ–è§†å›¾
2. **å®‰å…¨ç¬¬ä¸€**ï¼šåŠ å¯†å­˜å‚¨ã€RLSç­–ç•¥ã€å®¡è®¡æ—¥å¿—
3. **å¯æ‰©å±•æ€§**ï¼šåˆ†åŒºè®¾è®¡ã€åˆ†å¸ƒå¼æ¶æ„
4. **æ•°æ®ä¸€è‡´æ€§**ï¼šå¤–é”®çº¦æŸã€äº‹åŠ¡ä¿è¯
5. **å¯ç»´æŠ¤æ€§**ï¼šå‘½åè§„èŒƒã€æ–‡æ¡£å®Œæ•´

---

## 9. å®æˆ˜æ¼”ç»ƒ7ï¼šAIåº”ç”¨å¹³å°æ•°æ®åº“è®¾è®¡

### 9.1. éœ€æ±‚åˆ†æ

**ä¸šåŠ¡éœ€æ±‚**ï¼š

- LLMå¯¹è¯å†å²å­˜å‚¨
- å‘é‡çŸ¥è¯†åº“ï¼ˆRAGï¼‰
- Agentå·¥å…·è°ƒç”¨è®°å½•
- æ¨¡å‹ç‰ˆæœ¬ç®¡ç†
- Tokenä½¿ç”¨è®¡é‡

**æŠ€æœ¯éœ€æ±‚**ï¼š

- å‘é‡æ•°æ®åº“ï¼ˆpgvectorï¼‰
- æ—¶åºæ•°æ®ï¼ˆå¯¹è¯æµï¼‰
- å¤šç§Ÿæˆ·éš”ç¦»
- é«˜å¹¶å‘å†™å…¥

**æ€§èƒ½éœ€æ±‚**ï¼š

- å‘é‡æ£€ç´¢ < 50ms
- å¯¹è¯å†å²æŸ¥è¯¢ < 100ms
- æ”¯æŒç™¾ä¸‡çº§æ–‡æ¡£

### 9.2. é€»è¾‘è®¾è®¡

**è¡¨ç»“æ„è®¾è®¡ï¼ˆAIå¹³å°æ ¸å¿ƒSchemaï¼‰**ï¼š

```sql
CREATE SCHEMA ai_platform;
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS pg_trgm;

-- åº”ç”¨/ç§Ÿæˆ·è¡¨
CREATE TABLE ai_platform.applications (
    app_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    app_name VARCHAR(200) NOT NULL,
    app_type VARCHAR(50) NOT NULL,  -- chatbot, agent, rag, workflow
    api_key_hash TEXT NOT NULL,
    settings JSONB DEFAULT '{}',
    quota JSONB DEFAULT '{"tokens_per_day": 100000}',
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- çŸ¥è¯†åº“è¡¨
CREATE TABLE ai_platform.knowledge_bases (
    kb_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    app_id UUID NOT NULL REFERENCES ai_platform.applications(app_id) ON DELETE CASCADE,
    kb_name VARCHAR(200) NOT NULL,
    embedding_model VARCHAR(100) DEFAULT 'text-embedding-3-small',
    embedding_dim INTEGER DEFAULT 1536,
    chunk_size INTEGER DEFAULT 512,
    chunk_overlap INTEGER DEFAULT 50,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(app_id, kb_name)
);

-- æ–‡æ¡£å—è¡¨ï¼ˆRAGæ ¸å¿ƒï¼‰
CREATE TABLE ai_platform.document_chunks (
    chunk_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    kb_id UUID NOT NULL REFERENCES ai_platform.knowledge_bases(kb_id) ON DELETE CASCADE,
    document_id UUID NOT NULL,
    document_name VARCHAR(500),
    content TEXT NOT NULL,
    embedding vector(1536),  -- OpenAI text-embedding-3-small
    tokens INTEGER,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- HNSWå‘é‡ç´¢å¼•
CREATE INDEX idx_chunks_embedding ON ai_platform.document_chunks
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- å…¨æ–‡æœç´¢ç´¢å¼•
CREATE INDEX idx_chunks_content_fts ON ai_platform.document_chunks
USING GIN(to_tsvector('english', content));

-- å¯¹è¯ä¼šè¯è¡¨
CREATE TABLE ai_platform.conversations (
    conversation_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    app_id UUID NOT NULL REFERENCES ai_platform.applications(app_id),
    user_id VARCHAR(200),
    title VARCHAR(500),
    model VARCHAR(100) DEFAULT 'gpt-4o',
    system_prompt TEXT,
    temperature DECIMAL(3,2) DEFAULT 0.7,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_conversations_app_user ON ai_platform.conversations(app_id, user_id);

-- æ¶ˆæ¯è¡¨ï¼ˆå¯¹è¯å†å²ï¼‰
CREATE TABLE ai_platform.messages (
    message_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id UUID NOT NULL REFERENCES ai_platform.conversations(conversation_id) ON DELETE CASCADE,
    role VARCHAR(20) NOT NULL,  -- user, assistant, system, tool
    content TEXT NOT NULL,
    tool_calls JSONB,           -- function callingè®°å½•
    tool_call_id VARCHAR(100),  -- å·¥å…·è°ƒç”¨ID
    tokens_input INTEGER,
    tokens_output INTEGER,
    latency_ms INTEGER,
    model VARCHAR(100),
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMPTZ DEFAULT NOW()
) PARTITION BY RANGE (created_at);

-- æŒ‰æœˆåˆ†åŒº
CREATE TABLE ai_platform.messages_2025_01 PARTITION OF ai_platform.messages
FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE INDEX idx_messages_conversation ON ai_platform.messages(conversation_id, created_at);

-- Agentå·¥å…·è°ƒç”¨è®°å½•
CREATE TABLE ai_platform.tool_executions (
    execution_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    message_id UUID REFERENCES ai_platform.messages(message_id),
    tool_name VARCHAR(200) NOT NULL,
    tool_input JSONB NOT NULL,
    tool_output JSONB,
    status VARCHAR(20) DEFAULT 'pending',  -- pending, running, success, failed
    error_message TEXT,
    execution_time_ms INTEGER,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Tokenä½¿ç”¨ç»Ÿè®¡è¡¨
CREATE TABLE ai_platform.token_usage (
    usage_id BIGSERIAL PRIMARY KEY,
    app_id UUID NOT NULL REFERENCES ai_platform.applications(app_id),
    usage_date DATE NOT NULL,
    model VARCHAR(100) NOT NULL,
    tokens_input BIGINT DEFAULT 0,
    tokens_output BIGINT DEFAULT 0,
    requests_count INTEGER DEFAULT 0,
    cost_usd DECIMAL(10,4) DEFAULT 0,
    UNIQUE(app_id, usage_date, model)
);
```

### 9.3. æ ¸å¿ƒæŸ¥è¯¢å‡½æ•°

**æ··åˆæ£€ç´¢å‡½æ•°ï¼ˆå‘é‡+å…³é”®è¯ï¼‰**ï¼š

```sql
-- RRFæ··åˆæ£€ç´¢
CREATE OR REPLACE FUNCTION ai_platform.hybrid_search(
    p_kb_id UUID,
    p_query TEXT,
    p_query_embedding vector(1536),
    p_limit INTEGER DEFAULT 10,
    p_vector_weight DECIMAL DEFAULT 0.7
)
RETURNS TABLE (
    chunk_id UUID,
    content TEXT,
    document_name VARCHAR,
    score DECIMAL,
    vector_rank INTEGER,
    keyword_rank INTEGER
) AS $$
BEGIN
    RETURN QUERY
    WITH vector_search AS (
        SELECT
            dc.chunk_id,
            dc.content,
            dc.document_name,
            ROW_NUMBER() OVER (ORDER BY dc.embedding <=> p_query_embedding) AS rank
        FROM ai_platform.document_chunks dc
        WHERE dc.kb_id = p_kb_id
        ORDER BY dc.embedding <=> p_query_embedding
        LIMIT p_limit * 2
    ),
    keyword_search AS (
        SELECT
            dc.chunk_id,
            dc.content,
            dc.document_name,
            ROW_NUMBER() OVER (
                ORDER BY ts_rank(to_tsvector('english', dc.content),
                         plainto_tsquery('english', p_query)) DESC
            ) AS rank
        FROM ai_platform.document_chunks dc
        WHERE dc.kb_id = p_kb_id
          AND to_tsvector('english', dc.content) @@ plainto_tsquery('english', p_query)
        ORDER BY ts_rank(to_tsvector('english', dc.content),
                 plainto_tsquery('english', p_query)) DESC
        LIMIT p_limit * 2
    ),
    rrf_scores AS (
        SELECT
            COALESCE(v.chunk_id, k.chunk_id) AS chunk_id,
            COALESCE(v.content, k.content) AS content,
            COALESCE(v.document_name, k.document_name) AS document_name,
            -- RRFå…¬å¼: 1/(k+rank)
            (p_vector_weight * COALESCE(1.0/(60 + v.rank), 0) +
             (1 - p_vector_weight) * COALESCE(1.0/(60 + k.rank), 0)) AS score,
            v.rank AS vector_rank,
            k.rank AS keyword_rank
        FROM vector_search v
        FULL OUTER JOIN keyword_search k ON v.chunk_id = k.chunk_id
    )
    SELECT
        r.chunk_id,
        r.content,
        r.document_name,
        r.score::DECIMAL,
        r.vector_rank::INTEGER,
        r.keyword_rank::INTEGER
    FROM rrf_scores r
    ORDER BY r.score DESC
    LIMIT p_limit;
END;
$$ LANGUAGE plpgsql;

-- è·å–å¯¹è¯ä¸Šä¸‹æ–‡
CREATE OR REPLACE FUNCTION ai_platform.get_conversation_context(
    p_conversation_id UUID,
    p_max_messages INTEGER DEFAULT 20,
    p_max_tokens INTEGER DEFAULT 4000
)
RETURNS TABLE (
    role VARCHAR,
    content TEXT,
    created_at TIMESTAMPTZ
) AS $$
DECLARE
    v_total_tokens INTEGER := 0;
BEGIN
    RETURN QUERY
    WITH ranked_messages AS (
        SELECT
            m.role,
            m.content,
            m.created_at,
            COALESCE(m.tokens_input, 0) + COALESCE(m.tokens_output, 0) AS tokens,
            ROW_NUMBER() OVER (ORDER BY m.created_at DESC) AS rn
        FROM ai_platform.messages m
        WHERE m.conversation_id = p_conversation_id
    ),
    limited_messages AS (
        SELECT
            rm.role,
            rm.content,
            rm.created_at,
            SUM(rm.tokens) OVER (ORDER BY rm.rn) AS cumulative_tokens
        FROM ranked_messages rm
        WHERE rm.rn <= p_max_messages
    )
    SELECT lm.role, lm.content, lm.created_at
    FROM limited_messages lm
    WHERE lm.cumulative_tokens <= p_max_tokens
    ORDER BY lm.created_at ASC;
END;
$$ LANGUAGE plpgsql;
```

---

## 10. å®æˆ˜Labç¯å¢ƒæ­å»º

### 10.1. Docker Composeå®éªŒç¯å¢ƒ

**ä¸€é”®å¯åŠ¨å®Œæ•´å®éªŒç¯å¢ƒ**ï¼š

```yaml
# docker-compose.lab.yml
version: '3.8'

services:
  postgres:
    image: pgvector/pgvector:pg16
    container_name: db-lab-postgres
    environment:
      POSTGRES_USER: lab
      POSTGRES_PASSWORD: labpassword
      POSTGRES_DB: design_lab
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    command:
      - "postgres"
      - "-c"
      - "shared_preload_libraries=pg_stat_statements,auto_explain"
      - "-c"
      - "log_min_duration_statement=100"

  timescale:
    image: timescale/timescaledb:latest-pg16
    container_name: db-lab-timescale
    environment:
      POSTGRES_USER: lab
      POSTGRES_PASSWORD: labpassword
      POSTGRES_DB: timeseries_lab
    ports:
      - "5433:5432"
    volumes:
      - timescale_data:/var/lib/postgresql/data

  redis:
    image: redis/redis-stack:latest
    container_name: db-lab-redis
    ports:
      - "6379:6379"
      - "8001:8001"  # RedisInsight
    volumes:
      - redis_data:/data

  pgadmin:
    image: dpage/pgadmin4
    container_name: db-lab-pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@lab.local
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"
    depends_on:
      - postgres

  # Atlasè¿ç§»å·¥å…·
  atlas:
    image: arigaio/atlas:latest
    container_name: db-lab-atlas
    volumes:
      - ./schema:/schema
      - ./migrations:/migrations
    depends_on:
      - postgres

volumes:
  postgres_data:
  timescale_data:
  redis_data:
```

**åˆå§‹åŒ–è„šæœ¬**ï¼š

```sql
-- init-scripts/01-extensions.sql
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS pg_trgm;
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- åˆ›å»ºå®éªŒç”¨Schema
CREATE SCHEMA IF NOT EXISTS lab_ecommerce;
CREATE SCHEMA IF NOT EXISTS lab_recommendation;
CREATE SCHEMA IF NOT EXISTS lab_iot;
CREATE SCHEMA IF NOT EXISTS lab_saas;
CREATE SCHEMA IF NOT EXISTS lab_knowledge;
CREATE SCHEMA IF NOT EXISTS lab_finance;
CREATE SCHEMA IF NOT EXISTS lab_ai;
```

### 10.2. Labç»ƒä¹ ä»»åŠ¡æ¸…å•

**åˆçº§ä»»åŠ¡**ï¼š

| ä»»åŠ¡ID | ä»»åŠ¡åç§° | æŠ€èƒ½ç‚¹ | é¢„è®¡æ—¶é—´ |
|--------|---------|-------|---------|
| L1-01 | åˆ›å»ºç”µå•†ç”¨æˆ·è¡¨ | CREATE TABLE, PRIMARY KEY | 15min |
| L1-02 | æ·»åŠ ç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢ | CREATE INDEX, EXPLAIN | 20min |
| L1-03 | å®ç°è®¢å•åˆ†åŒº | PARTITION BY RANGE | 30min |
| L1-04 | åˆ›å»ºç‰©åŒ–è§†å›¾ | MATERIALIZED VIEW | 25min |

**ä¸­çº§ä»»åŠ¡**ï¼š

| ä»»åŠ¡ID | ä»»åŠ¡åç§° | æŠ€èƒ½ç‚¹ | é¢„è®¡æ—¶é—´ |
|--------|---------|-------|---------|
| L2-01 | å®ç°RLSå¤šç§Ÿæˆ· | ROW LEVEL SECURITY | 45min |
| L2-02 | å‘é‡æ£€ç´¢å®æˆ˜ | pgvector, HNSW | 60min |
| L2-03 | æ—¶åºæ•°æ®è®¾è®¡ | TimescaleDB | 45min |
| L2-04 | å®¡è®¡æ—¥å¿—è§¦å‘å™¨ | TRIGGER, FUNCTION | 40min |

**é«˜çº§ä»»åŠ¡**ï¼š

| ä»»åŠ¡ID | ä»»åŠ¡åç§° | æŠ€èƒ½ç‚¹ | é¢„è®¡æ—¶é—´ |
|--------|---------|-------|---------|
| L3-01 | æ··åˆæ£€ç´¢å®ç° | RRF, å‘é‡+FTS | 90min |
| L3-02 | åˆ†å¸ƒå¼äº‹åŠ¡Saga | çŠ¶æ€æœº, è¡¥å¿ | 120min |
| L3-03 | CDCå®æ—¶åŒæ­¥ | é€»è¾‘å¤åˆ¶, Debezium | 90min |
| L3-04 | AIå¹³å°å®Œæ•´è®¾è®¡ | ç»¼åˆåº”ç”¨ | 180min |

### 10.3. è‡ªåŠ¨è¯„ä¼°è„šæœ¬

```python
# lab_evaluator.py - Labä»»åŠ¡è‡ªåŠ¨è¯„ä¼°
import psycopg2
from psycopg2.extras import RealDictCursor
import json

class LabEvaluator:
    def __init__(self, conn_string):
        self.conn = psycopg2.connect(conn_string)

    def check_table_exists(self, schema: str, table: str) -> bool:
        with self.conn.cursor() as cur:
            cur.execute("""
                SELECT EXISTS (
                    SELECT 1 FROM information_schema.tables
                    WHERE table_schema = %s AND table_name = %s
                )
            """, (schema, table))
            return cur.fetchone()[0]

    def check_index_exists(self, schema: str, table: str, index_name: str) -> bool:
        with self.conn.cursor() as cur:
            cur.execute("""
                SELECT EXISTS (
                    SELECT 1 FROM pg_indexes
                    WHERE schemaname = %s AND tablename = %s AND indexname = %s
                )
            """, (schema, table, index_name))
            return cur.fetchone()[0]

    def check_partition_exists(self, schema: str, parent_table: str) -> int:
        with self.conn.cursor() as cur:
            cur.execute("""
                SELECT COUNT(*) FROM pg_partitions
                WHERE schemaname = %s AND tablename = %s
            """, (schema, parent_table))
            return cur.fetchone()[0]

    def check_rls_enabled(self, schema: str, table: str) -> bool:
        with self.conn.cursor() as cur:
            cur.execute("""
                SELECT relrowsecurity FROM pg_class c
                JOIN pg_namespace n ON c.relnamespace = n.oid
                WHERE n.nspname = %s AND c.relname = %s
            """, (schema, table))
            result = cur.fetchone()
            return result[0] if result else False

    def check_vector_index(self, schema: str, table: str) -> bool:
        with self.conn.cursor() as cur:
            cur.execute("""
                SELECT EXISTS (
                    SELECT 1 FROM pg_indexes
                    WHERE schemaname = %s AND tablename = %s
                    AND indexdef LIKE '%hnsw%'
                )
            """, (schema, table))
            return cur.fetchone()[0]

    def evaluate_task(self, task_id: str) -> dict:
        """è¯„ä¼°ç‰¹å®šä»»åŠ¡"""
        evaluations = {
            'L1-01': self._eval_l1_01,
            'L1-02': self._eval_l1_02,
            'L2-01': self._eval_l2_01,
            'L2-02': self._eval_l2_02,
        }

        if task_id in evaluations:
            return evaluations[task_id]()
        return {'error': f'Unknown task: {task_id}'}

    def _eval_l1_01(self) -> dict:
        """è¯„ä¼°L1-01: åˆ›å»ºç”µå•†ç”¨æˆ·è¡¨"""
        checks = {
            'table_exists': self.check_table_exists('lab_ecommerce', 'users'),
            'has_primary_key': self._check_primary_key('lab_ecommerce', 'users'),
            'has_email_column': self._check_column_exists('lab_ecommerce', 'users', 'email'),
        }
        score = sum(checks.values()) / len(checks) * 100
        return {'task': 'L1-01', 'checks': checks, 'score': score, 'passed': score >= 80}

    def _eval_l2_02(self) -> dict:
        """è¯„ä¼°L2-02: å‘é‡æ£€ç´¢å®æˆ˜"""
        checks = {
            'table_exists': self.check_table_exists('lab_recommendation', 'product_vectors'),
            'vector_column': self._check_vector_column('lab_recommendation', 'product_vectors'),
            'hnsw_index': self.check_vector_index('lab_recommendation', 'product_vectors'),
        }
        score = sum(checks.values()) / len(checks) * 100
        return {'task': 'L2-02', 'checks': checks, 'score': score, 'passed': score >= 80}

    def _check_primary_key(self, schema: str, table: str) -> bool:
        with self.conn.cursor() as cur:
            cur.execute("""
                SELECT EXISTS (
                    SELECT 1 FROM information_schema.table_constraints
                    WHERE table_schema = %s AND table_name = %s
                    AND constraint_type = 'PRIMARY KEY'
                )
            """, (schema, table))
            return cur.fetchone()[0]

    def _check_column_exists(self, schema: str, table: str, column: str) -> bool:
        with self.conn.cursor() as cur:
            cur.execute("""
                SELECT EXISTS (
                    SELECT 1 FROM information_schema.columns
                    WHERE table_schema = %s AND table_name = %s AND column_name = %s
                )
            """, (schema, table, column))
            return cur.fetchone()[0]

    def _check_vector_column(self, schema: str, table: str) -> bool:
        with self.conn.cursor() as cur:
            cur.execute("""
                SELECT EXISTS (
                    SELECT 1 FROM information_schema.columns
                    WHERE table_schema = %s AND table_name = %s
                    AND udt_name = 'vector'
                )
            """, (schema, table))
            return cur.fetchone()[0]


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    evaluator = LabEvaluator('postgresql://lab:labpassword@localhost/design_lab')

    # è¯„ä¼°æ‰€æœ‰ä»»åŠ¡
    for task_id in ['L1-01', 'L1-02', 'L2-01', 'L2-02']:
        result = evaluator.evaluate_task(task_id)
        print(f"\n{task_id}: {'âœ… PASS' if result.get('passed') else 'âŒ FAIL'}")
        print(f"  Score: {result.get('score', 0):.0f}%")
        for check, passed in result.get('checks', {}).items():
            print(f"  - {check}: {'âœ“' if passed else 'âœ—'}")
```

---

## 11. è®¾è®¡æ¨¡å¼é€ŸæŸ¥å¡

### 11.1. åœºæ™¯-æ¨¡å¼å¿«é€ŸåŒ¹é…

```mermaid
flowchart TD
    A[è®¾è®¡éœ€æ±‚] --> B{ä¸»è¦åœºæ™¯?}

    B -->|é«˜å¹¶å‘è¯»å†™| C[åˆ†åŒº + ç´¢å¼• + ç¼“å­˜]
    B -->|å¤šç§Ÿæˆ·SaaS| D[RLS + Schemaéš”ç¦»]
    B -->|æ—¶åºæ•°æ®| E[TimescaleDB + è¿ç»­èšåˆ]
    B -->|å‘é‡æ£€ç´¢| F[pgvector + HNSW]
    B -->|çŸ¥è¯†å›¾è°±| G[ä¸‰å…ƒç»„ + å‘é‡]
    B -->|é‡‘èäº¤æ˜“| H[å¼ºä¸€è‡´æ€§ + å®¡è®¡]
    B -->|AIåº”ç”¨| I[RAGæ¶æ„ + åˆ†åŒº]

    C --> J[ç”µå•†/ç¤¾äº¤åœºæ™¯]
    D --> K[ä¼ä¸šSaaS]
    E --> L[IoT/ç›‘æ§]
    F --> M[æ¨è/æœç´¢]
    G --> N[çŸ¥è¯†åº“/é—®ç­”]
    H --> O[æ”¯ä»˜/é“¶è¡Œ]
    I --> P[ChatBot/Agent]
```

### 11.2. æ ¸å¿ƒSQLæ¨¡æ¿åº“

**åˆ†åŒºè¡¨æ¨¡æ¿**ï¼š

```sql
-- æŒ‰æ—¶é—´èŒƒå›´åˆ†åŒº
CREATE TABLE {{schema}}.{{table}} (
    id BIGSERIAL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    -- ... å…¶ä»–å­—æ®µ
    PRIMARY KEY (id, created_at)
) PARTITION BY RANGE (created_at);

-- è‡ªåŠ¨åˆ›å»ºåˆ†åŒºï¼ˆä½¿ç”¨pg_partmanï¼‰
SELECT partman.create_parent(
    p_parent_table := '{{schema}}.{{table}}',
    p_control := 'created_at',
    p_type := 'native',
    p_interval := '1 month'
);
```

**RLSå¤šç§Ÿæˆ·æ¨¡æ¿**ï¼š

```sql
-- å¯ç”¨RLS
ALTER TABLE {{schema}}.{{table}} ENABLE ROW LEVEL SECURITY;

-- ç§Ÿæˆ·éš”ç¦»ç­–ç•¥
CREATE POLICY tenant_policy ON {{schema}}.{{table}}
    FOR ALL
    USING (tenant_id = current_setting('app.tenant_id')::BIGINT)
    WITH CHECK (tenant_id = current_setting('app.tenant_id')::BIGINT);

-- è®¾ç½®ç§Ÿæˆ·ä¸Šä¸‹æ–‡
SET app.tenant_id = '123';
```

**å‘é‡æ£€ç´¢æ¨¡æ¿**ï¼š

```sql
-- åˆ›å»ºå‘é‡è¡¨
CREATE TABLE {{schema}}.{{table}} (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    content TEXT NOT NULL,
    embedding vector({{dimensions}}),
    metadata JSONB DEFAULT '{}'
);

-- HNSWç´¢å¼•
CREATE INDEX idx_{{table}}_embedding ON {{schema}}.{{table}}
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- ç›¸ä¼¼åº¦æœç´¢
SELECT id, content, 1 - (embedding <=> $1) AS similarity
FROM {{schema}}.{{table}}
ORDER BY embedding <=> $1
LIMIT $2;
```

---

## 12. å‚è€ƒèµ„æ–™

### 12.1. å®˜æ–¹æ–‡æ¡£

- [PostgreSQLå®˜æ–¹æ–‡æ¡£](https://www.postgresql.org/docs/)
- [pgvectoræ–‡æ¡£](https://github.com/pgvector/pgvector)
- [TimescaleDBæ–‡æ¡£](https://docs.timescale.com/)
- [Citusåˆ†å¸ƒå¼æ–‡æ¡£](https://docs.citusdata.com/)

### 12.2. ç›¸å…³æ–‡æ¡£

- [æ•°æ®åº“è®¾è®¡æ¨¡å¼æ€»ç»“ä¸ç´¢å¼•](./07.27-æ•°æ®åº“è®¾è®¡æ¨¡å¼æ€»ç»“ä¸ç´¢å¼•.md)
- [æ•°æ®åº“è®¾è®¡æ¡ˆä¾‹æ·±åº¦è§£æ](./07.16-æ•°æ®åº“è®¾è®¡æ¡ˆä¾‹æ·±åº¦è§£æ.md)
- [å‘é‡æ•°æ®åº“è®¾è®¡](./07.10-å‘é‡æ•°æ®åº“è®¾è®¡.md)
- [è¡Œä¸šæ¡ˆä¾‹åº“](./07.09-è¡Œä¸šæ¡ˆä¾‹åº“.md)
- [æ•°æ®åº“è¿ç§»ä¸ç‰ˆæœ¬ç®¡ç†](./07.07-æ•°æ®åº“è¿ç§»ä¸ç‰ˆæœ¬ç®¡ç†.md)

---

**æœ€åæ›´æ–°**ï¼š2025-12-01
**ç»´æŠ¤è€…**ï¼šData-Science Team
**çŠ¶æ€**ï¼šå·²å®Œæˆ âœ…
