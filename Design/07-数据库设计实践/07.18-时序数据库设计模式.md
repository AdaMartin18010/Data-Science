# æ—¶åºæ•°æ®åº“è®¾è®¡æ¨¡å¼ï¼šæ—¶é—´åºåˆ—æ•°æ®çš„é«˜æ•ˆå­˜å‚¨ä¸æŸ¥è¯¢

> **åˆ›å»ºæ—¥æœŸ**ï¼š2025-01-15
> **æœ€åæ›´æ–°**ï¼š2025-12-01
> **ç‰ˆæœ¬**ï¼šv2.0 (å¢å¼ºç‰ˆ)
> **çŠ¶æ€**ï¼šå®æ–½ä¸­

---

## ğŸ“‹ ç›®å½•

- [æ—¶åºæ•°æ®åº“è®¾è®¡æ¨¡å¼ï¼šæ—¶é—´åºåˆ—æ•°æ®çš„é«˜æ•ˆå­˜å‚¨ä¸æŸ¥è¯¢](#æ—¶åºæ•°æ®åº“è®¾è®¡æ¨¡å¼æ—¶é—´åºåˆ—æ•°æ®çš„é«˜æ•ˆå­˜å‚¨ä¸æŸ¥è¯¢)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1. æ—¶åºæ•°æ®åº”ç”¨åœºæ™¯](#11-æ—¶åºæ•°æ®åº”ç”¨åœºæ™¯)
    - [1.2. æ—¶åºæ•°æ®åº“é€‰æ‹©å†³ç­–æ ‘](#12-æ—¶åºæ•°æ®åº“é€‰æ‹©å†³ç­–æ ‘)
  - [2. æ—¶åºæ•°æ®ç‰¹æ€§](#2-æ—¶åºæ•°æ®ç‰¹æ€§)
    - [2.1. æ—¶åºæ•°æ®ç‰¹å¾](#21-æ—¶åºæ•°æ®ç‰¹å¾)
    - [2.2. æ—¶åºæ•°æ®æ¨¡å‹](#22-æ—¶åºæ•°æ®æ¨¡å‹)
  - [3. æ—¶åºæ•°æ®åº“Schemaè®¾è®¡](#3-æ—¶åºæ•°æ®åº“schemaè®¾è®¡)
    - [3.1. TimescaleDBè®¾è®¡ï¼ˆPostgreSQLæ‰©å±•ï¼‰](#31-timescaledbè®¾è®¡postgresqlæ‰©å±•)
    - [3.2. æ ‡ç­¾æ¨¡å‹è®¾è®¡](#32-æ ‡ç­¾æ¨¡å‹è®¾è®¡)
  - [4. æ—¶åºæ•°æ®åˆ†åŒºç­–ç•¥](#4-æ—¶åºæ•°æ®åˆ†åŒºç­–ç•¥)
    - [4.1. TimescaleDBè‡ªåŠ¨åˆ†åŒº](#41-timescaledbè‡ªåŠ¨åˆ†åŒº)
    - [4.2. è‡ªå®šä¹‰åˆ†åŒºç­–ç•¥](#42-è‡ªå®šä¹‰åˆ†åŒºç­–ç•¥)
  - [5. æ—¶åºæ•°æ®å‹ç¼©ä¸å½’æ¡£](#5-æ—¶åºæ•°æ®å‹ç¼©ä¸å½’æ¡£)
    - [5.1. TimescaleDBå‹ç¼©](#51-timescaledbå‹ç¼©)
    - [5.2. æ•°æ®å½’æ¡£ç­–ç•¥](#52-æ•°æ®å½’æ¡£ç­–ç•¥)
    - [5.3. æ•°æ®èšåˆä¸é™é‡‡æ ·](#53-æ•°æ®èšåˆä¸é™é‡‡æ ·)
  - [6. æ—¶åºæ•°æ®æŸ¥è¯¢ä¼˜åŒ–](#6-æ—¶åºæ•°æ®æŸ¥è¯¢ä¼˜åŒ–)
    - [6.1. æ—¶é—´èŒƒå›´æŸ¥è¯¢ä¼˜åŒ–](#61-æ—¶é—´èŒƒå›´æŸ¥è¯¢ä¼˜åŒ–)
    - [6.2. é™é‡‡æ ·æŸ¥è¯¢](#62-é™é‡‡æ ·æŸ¥è¯¢)
    - [6.3. çª—å£å‡½æ•°æŸ¥è¯¢](#63-çª—å£å‡½æ•°æŸ¥è¯¢)
  - [7. å®é™…åº”ç”¨æ¡ˆä¾‹](#7-å®é™…åº”ç”¨æ¡ˆä¾‹)
    - [7.1. ç›‘æ§ç³»ç»Ÿè®¾è®¡](#71-ç›‘æ§ç³»ç»Ÿè®¾è®¡)
    - [7.2. IoTæ—¶åºæ•°æ®å¹³å°è®¾è®¡](#72-iotæ—¶åºæ•°æ®å¹³å°è®¾è®¡)
  - [8. 2024-2025æœ€æ–°è¶‹åŠ¿](#8-2024-2025æœ€æ–°è¶‹åŠ¿)
    - [8.1. æ—¶åºæ•°æ®åº“æŠ€æœ¯æ¼”è¿›](#81-æ—¶åºæ•°æ®åº“æŠ€æœ¯æ¼”è¿›)
    - [8.2. æ—¶åºæ•°æ®åº“é€‰å‹çŸ©é˜µ](#82-æ—¶åºæ•°æ®åº“é€‰å‹çŸ©é˜µ)
    - [8.3. æ—¶åº+å‘é‡èåˆæ¨¡å¼](#83-æ—¶åºå‘é‡èåˆæ¨¡å¼)
  - [9. å‚è€ƒèµ„æ–™](#9-å‚è€ƒèµ„æ–™)
    - [9.1. æƒå¨æ–‡çŒ®](#91-æƒå¨æ–‡çŒ®)
    - [9.2. åœ¨çº¿èµ„æº](#92-åœ¨çº¿èµ„æº)
    - [9.3. ç›¸å…³æ–‡æ¡£](#93-ç›¸å…³æ–‡æ¡£)

---

## 1. æ¦‚è¿°

æ—¶åºæ•°æ®åº“ä¸“é—¨ç”¨äºå­˜å‚¨å’ŒæŸ¥è¯¢æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¹¿æ³›åº”ç”¨äºç›‘æ§ã€IoTã€é‡‘èç­‰é¢†åŸŸã€‚

### 1.1. æ—¶åºæ•°æ®åº”ç”¨åœºæ™¯

```mermaid
mindmap
  root((æ—¶åºæ•°æ®åº”ç”¨))
    ç›‘æ§ç³»ç»Ÿ
      ç³»ç»ŸæŒ‡æ ‡
      åº”ç”¨æ€§èƒ½
      ä¸šåŠ¡æŒ‡æ ‡
    IoTå¹³å°
      ä¼ æ„Ÿå™¨æ•°æ®
      è®¾å¤‡çŠ¶æ€
      ç¯å¢ƒæ•°æ®
    é‡‘èç³»ç»Ÿ
      è‚¡ç¥¨ä»·æ ¼
      äº¤æ˜“æ•°æ®
      å¸‚åœºæ•°æ®
    æ—¥å¿—ç³»ç»Ÿ
      åº”ç”¨æ—¥å¿—
      è®¿é—®æ—¥å¿—
      é”™è¯¯æ—¥å¿—
```

### 1.2. æ—¶åºæ•°æ®åº“é€‰æ‹©å†³ç­–æ ‘

```mermaid
flowchart TD
    A[é€‰æ‹©æ—¶åºæ•°æ®åº“] --> B{æ•°æ®è§„æ¨¡}

    B -->|å°è§„æ¨¡| C{é›†æˆéœ€æ±‚}
    B -->|å¤§è§„æ¨¡| D{æŸ¥è¯¢æ¨¡å¼}

    C -->|PostgreSQL| E[TimescaleDB]
    C -->|ç‹¬ç«‹éƒ¨ç½²| F[InfluxDB]

    D -->|å¤æ‚æŸ¥è¯¢| G[TimescaleDB]
    D -->|ç®€å•æŸ¥è¯¢| H[InfluxDB/QuestDB]

    E --> I[è®¾è®¡å®Œæˆ]
    F --> I
    G --> I
    H --> I
```

---

## 2. æ—¶åºæ•°æ®ç‰¹æ€§

### 2.1. æ—¶åºæ•°æ®ç‰¹å¾

**æ—¶åºæ•°æ®å®šä¹‰**ï¼š

```text
æ—¶åºæ•°æ® = (timestamp, metric_name, tags, value)

ç‰¹å¾ï¼š
1. æ—¶é—´æœ‰åºï¼šæ•°æ®æŒ‰æ—¶é—´é¡ºåºäº§ç”Ÿ
2. é«˜é¢‘å†™å…¥ï¼šæ¯ç§’å¯èƒ½äº§ç”Ÿç™¾ä¸‡çº§æ•°æ®ç‚¹
3. ä½é¢‘æ›´æ–°ï¼šæ•°æ®ä¸€æ—¦å†™å…¥å¾ˆå°‘æ›´æ–°
4. æ—¶é—´èŒƒå›´æŸ¥è¯¢ï¼šä¸»è¦æŸ¥è¯¢æ¨¡å¼æ˜¯æŒ‰æ—¶é—´èŒƒå›´æŸ¥è¯¢
5. æ•°æ®å‹ç¼©ï¼šå†å²æ•°æ®å¯ä»¥å‹ç¼©å­˜å‚¨
```

### 2.2. æ—¶åºæ•°æ®æ¨¡å‹

**æ•°æ®æ¨¡å‹å¯¹æ¯”**ï¼š

| æ¨¡å‹ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|---------|
| **çª„è¡¨æ¨¡å‹** | æ¯ä¸ªæŒ‡æ ‡ä¸€è¡Œ | æŒ‡æ ‡æ•°é‡å°‘ï¼ŒæŸ¥è¯¢ç®€å• |
| **å®½è¡¨æ¨¡å‹** | æ¯ä¸ªæ—¶é—´ç‚¹ä¸€è¡Œï¼Œå¤šåˆ—æŒ‡æ ‡ | æŒ‡æ ‡æ•°é‡å¤šï¼Œéœ€è¦å…³è”æŸ¥è¯¢ |
| **æ ‡ç­¾æ¨¡å‹** | æ ‡ç­¾+å€¼ | çµæ´»ï¼Œæ”¯æŒå¤šç»´åº¦æŸ¥è¯¢ |

---

## 3. æ—¶åºæ•°æ®åº“Schemaè®¾è®¡

### 3.1. TimescaleDBè®¾è®¡ï¼ˆPostgreSQLæ‰©å±•ï¼‰

**åŸºç¡€æ—¶åºè¡¨è®¾è®¡**ï¼š

```sql
-- å¯ç”¨TimescaleDBæ‰©å±•
CREATE EXTENSION IF NOT EXISTS timescaledb;

-- åˆ›å»ºæ—¶åºè¡¨ï¼ˆçª„è¡¨æ¨¡å‹ï¼‰
CREATE TABLE metrics (
    time TIMESTAMPTZ NOT NULL,
    device_id BIGINT NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    value DOUBLE PRECISION NOT NULL,
    tags JSONB,
    PRIMARY KEY (time, device_id, metric_name)
);

-- è½¬æ¢ä¸ºè¶…è¡¨ï¼ˆHypertableï¼‰
SELECT create_hypertable('metrics', 'time',
    chunk_time_interval => INTERVAL '1 day',
    if_not_exists => TRUE
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_metrics_device_time ON metrics(device_id, time DESC);
CREATE INDEX idx_metrics_metric_time ON metrics(metric_name, time DESC);
CREATE INDEX idx_metrics_tags ON metrics USING GIN(tags);
```

**å®½è¡¨æ¨¡å‹è®¾è®¡**ï¼š

```sql
-- å®½è¡¨æ¨¡å‹ï¼šæ¯ä¸ªè®¾å¤‡æ¯ä¸ªæ—¶é—´ç‚¹ä¸€è¡Œ
CREATE TABLE device_metrics (
    time TIMESTAMPTZ NOT NULL,
    device_id BIGINT NOT NULL,
    temperature DOUBLE PRECISION,
    humidity DOUBLE PRECISION,
    pressure DOUBLE PRECISION,
    voltage DOUBLE PRECISION,
    current DOUBLE PRECISION,
    PRIMARY KEY (time, device_id)
);

-- è½¬æ¢ä¸ºè¶…è¡¨
SELECT create_hypertable('device_metrics', 'time',
    chunk_time_interval => INTERVAL '1 day'
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_device_metrics_device ON device_metrics(device_id, time DESC);
```

### 3.2. æ ‡ç­¾æ¨¡å‹è®¾è®¡

**æ ‡ç­¾æ¨¡å‹Schema**ï¼š

```sql
CREATE SCHEMA time_series;

-- æŒ‡æ ‡å®šä¹‰è¡¨
CREATE TABLE time_series.metric_definitions (
    metric_id SERIAL PRIMARY KEY,
    metric_name VARCHAR(100) NOT NULL UNIQUE,
    metric_type VARCHAR(50) NOT NULL,  -- gauge, counter, histogram
    unit VARCHAR(20),
    description TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- æ ‡ç­¾é”®å®šä¹‰è¡¨
CREATE TABLE time_series.tag_keys (
    tag_key_id SERIAL PRIMARY KEY,
    tag_key VARCHAR(100) NOT NULL UNIQUE,
    description TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- æ ‡ç­¾å€¼å®šä¹‰è¡¨
CREATE TABLE time_series.tag_values (
    tag_value_id SERIAL PRIMARY KEY,
    tag_key_id INTEGER NOT NULL REFERENCES time_series.tag_keys(tag_key_id),
    tag_value VARCHAR(200) NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(tag_key_id, tag_value)
);

-- æ—¶åºæ•°æ®è¡¨ï¼ˆæ ‡ç­¾æ¨¡å‹ï¼‰
CREATE TABLE time_series.time_series_data (
    time TIMESTAMPTZ NOT NULL,
    metric_id INTEGER NOT NULL REFERENCES time_series.metric_definitions(metric_id),
    value DOUBLE PRECISION NOT NULL,
    tags JSONB NOT NULL,  -- {tag_key: tag_value, ...}
    PRIMARY KEY (time, metric_id, tags)
);

-- è½¬æ¢ä¸ºè¶…è¡¨
SELECT create_hypertable('time_series.time_series_data', 'time',
    chunk_time_interval => INTERVAL '1 day'
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_ts_data_metric_time ON time_series.time_series_data(metric_id, time DESC);
CREATE INDEX idx_ts_data_tags ON time_series.time_series_data USING GIN(tags);
CREATE INDEX idx_ts_data_time ON time_series.time_series_data(time DESC);
```

---

## 4. æ—¶åºæ•°æ®åˆ†åŒºç­–ç•¥

### 4.1. TimescaleDBè‡ªåŠ¨åˆ†åŒº

**åˆ†åŒºé…ç½®**ï¼š

```sql
-- åˆ›å»ºè¶…è¡¨æ—¶æŒ‡å®šåˆ†åŒºé—´éš”
SELECT create_hypertable('metrics', 'time',
    chunk_time_interval => INTERVAL '1 day',  -- æ¯å¤©ä¸€ä¸ªåˆ†åŒº
    if_not_exists => TRUE
);

-- æŸ¥çœ‹åˆ†åŒºä¿¡æ¯
SELECT * FROM timescaledb_information.chunks
WHERE hypertable_name = 'metrics'
ORDER BY range_start DESC;

-- æ‰‹åŠ¨åˆ›å»ºåˆ†åŒºï¼ˆå¦‚æœéœ€è¦ï¼‰
SELECT add_retention_policy('metrics', INTERVAL '90 days');
```

### 4.2. è‡ªå®šä¹‰åˆ†åŒºç­–ç•¥

**æŒ‰è®¾å¤‡+æ—¶é—´åˆ†åŒº**ï¼š

```sql
-- åˆ›å»ºåˆ†åŒºè¡¨
CREATE TABLE metrics_partitioned (
    time TIMESTAMPTZ NOT NULL,
    device_id BIGINT NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    value DOUBLE PRECISION NOT NULL,
    PRIMARY KEY (time, device_id, metric_name)
) PARTITION BY RANGE (time);

-- åˆ›å»ºè®¾å¤‡åˆ†åŒºï¼ˆå¦‚æœéœ€è¦ï¼‰
-- æ³¨æ„ï¼šPostgreSQLä¸æ”¯æŒå¤šçº§åˆ†åŒºï¼Œéœ€è¦åº”ç”¨å±‚å¤„ç†

-- åˆ›å»ºæ—¶é—´åˆ†åŒº
CREATE TABLE metrics_2024_01 PARTITION OF metrics_partitioned
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

-- è‡ªåŠ¨åˆ›å»ºæœªæ¥åˆ†åŒºçš„å‡½æ•°
CREATE OR REPLACE FUNCTION create_monthly_partitions(
    p_table_name TEXT,
    p_start_date DATE,
    p_months_ahead INTEGER DEFAULT 12
)
RETURNS VOID AS $$
DECLARE
    v_date DATE;
    v_partition_name TEXT;
    v_start_date DATE;
    v_end_date DATE;
BEGIN
    v_date := p_start_date;

    FOR i IN 1..p_months_ahead LOOP
        v_start_date := date_trunc('month', v_date);
        v_end_date := v_start_date + INTERVAL '1 month';
        v_partition_name := p_table_name || '_' || to_char(v_start_date, 'YYYY_MM');

        EXECUTE format(
            'CREATE TABLE IF NOT EXISTS %I PARTITION OF %I FOR VALUES FROM (%L) TO (%L)',
            v_partition_name,
            p_table_name,
            v_start_date,
            v_end_date
        );

        v_date := v_end_date;
    END LOOP;
END;
$$ LANGUAGE plpgsql;
```

---

## 5. æ—¶åºæ•°æ®å‹ç¼©ä¸å½’æ¡£

### 5.1. TimescaleDBå‹ç¼©

**å‹ç¼©ç­–ç•¥**ï¼š

```sql
-- å¯ç”¨å‹ç¼©
ALTER TABLE metrics SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'device_id, metric_name',
    timescaledb.compress_orderby = 'time DESC'
);

-- æ·»åŠ å‹ç¼©ç­–ç•¥ï¼ˆ7å¤©å‰çš„æ•°æ®å‹ç¼©ï¼‰
SELECT add_compression_policy('metrics', INTERVAL '7 days');

-- æŸ¥çœ‹å‹ç¼©çŠ¶æ€
SELECT * FROM timescaledb_information.compressed_chunk_stats
WHERE hypertable_name = 'metrics';
```

### 5.2. æ•°æ®å½’æ¡£ç­–ç•¥

**å½’æ¡£Schemaè®¾è®¡**ï¼š

```sql
CREATE SCHEMA archive;

-- å½’æ¡£è¡¨ï¼ˆå‹ç¼©å­˜å‚¨ï¼‰
CREATE TABLE archive.metrics_archive (
    LIKE metrics INCLUDING ALL
) PARTITION BY RANGE (time);

-- å½’æ¡£å‡½æ•°
CREATE OR REPLACE FUNCTION archive_old_metrics(
    p_table_name TEXT,
    p_archive_before_date TIMESTAMPTZ
)
RETURNS INTEGER AS $$
DECLARE
    v_archived_count INTEGER;
BEGIN
    -- å°†æ—§æ•°æ®ç§»åŠ¨åˆ°å½’æ¡£è¡¨
    EXECUTE format(
        'INSERT INTO archive.%I_archive SELECT * FROM %I WHERE time < %L',
        p_table_name,
        p_table_name,
        p_archive_before_date
    );

    GET DIAGNOSTICS v_archived_count = ROW_COUNT;

    -- åˆ é™¤åŸè¡¨ä¸­çš„æ•°æ®
    EXECUTE format(
        'DELETE FROM %I WHERE time < %L',
        p_table_name,
        p_archive_before_date
    );

    RETURN v_archived_count;
END;
$$ LANGUAGE plpgsql;

-- è‡ªåŠ¨å½’æ¡£ç­–ç•¥ï¼ˆä½¿ç”¨pg_cronï¼‰
-- SELECT cron.schedule('archive-metrics', '0 2 * * *',
--     'SELECT archive_old_metrics(''metrics'', CURRENT_TIMESTAMP - INTERVAL ''90 days'')');
```

### 5.3. æ•°æ®èšåˆä¸é™é‡‡æ ·

**èšåˆè¡¨è®¾è®¡**ï¼š

```sql
-- åŸå§‹æ•°æ®è¡¨
CREATE TABLE metrics_raw (
    time TIMESTAMPTZ NOT NULL,
    device_id BIGINT NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    value DOUBLE PRECISION NOT NULL,
    PRIMARY KEY (time, device_id, metric_name)
);

-- 1åˆ†é’Ÿèšåˆè¡¨
CREATE TABLE metrics_1min (
    time TIMESTAMPTZ NOT NULL,
    device_id BIGINT NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    value_avg DOUBLE PRECISION,
    value_min DOUBLE PRECISION,
    value_max DOUBLE PRECISION,
    value_count INTEGER,
    PRIMARY KEY (time, device_id, metric_name)
);

-- 1å°æ—¶èšåˆè¡¨
CREATE TABLE metrics_1hour (
    time TIMESTAMPTZ NOT NULL,
    device_id BIGINT NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    value_avg DOUBLE PRECISION,
    value_min DOUBLE PRECISION,
    value_max DOUBLE PRECISION,
    value_count INTEGER,
    PRIMARY KEY (time, device_id, metric_name)
);

-- èšåˆå‡½æ•°
CREATE OR REPLACE FUNCTION aggregate_metrics(
    p_source_table TEXT,
    p_target_table TEXT,
    p_interval INTERVAL
)
RETURNS VOID AS $$
BEGIN
    EXECUTE format('
        INSERT INTO %I (time, device_id, metric_name, value_avg, value_min, value_max, value_count)
        SELECT
            date_trunc(''minute'', time) AS time,
            device_id,
            metric_name,
            AVG(value) AS value_avg,
            MIN(value) AS value_min,
            MAX(value) AS value_max,
            COUNT(*) AS value_count
        FROM %I
        WHERE time >= CURRENT_TIMESTAMP - %L
          AND time < date_trunc(''minute'', CURRENT_TIMESTAMP)
        GROUP BY date_trunc(''minute'', time), device_id, metric_name
        ON CONFLICT (time, device_id, metric_name) DO UPDATE SET
            value_avg = EXCLUDED.value_avg,
            value_min = EXCLUDED.value_min,
            value_max = EXCLUDED.value_max,
            value_count = EXCLUDED.value_count
    ', p_target_table, p_source_table, p_interval);
END;
$$ LANGUAGE plpgsql;
```

---

## 6. æ—¶åºæ•°æ®æŸ¥è¯¢ä¼˜åŒ–

### 6.1. æ—¶é—´èŒƒå›´æŸ¥è¯¢ä¼˜åŒ–

**æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§**ï¼š

```sql
-- âœ… å¥½çš„æŸ¥è¯¢ï¼šä½¿ç”¨æ—¶é—´èŒƒå›´ç´¢å¼•
SELECT time, device_id, metric_name, value
FROM metrics
WHERE device_id = 123
  AND time >= '2024-01-01'::TIMESTAMPTZ
  AND time < '2024-01-02'::TIMESTAMPTZ
ORDER BY time DESC;

-- âœ… ä½¿ç”¨è¿ç»­èšåˆï¼ˆContinuous Aggregatesï¼‰
CREATE MATERIALIZED VIEW metrics_hourly
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 hour', time) AS bucket,
    device_id,
    metric_name,
    AVG(value) AS avg_value,
    MIN(value) AS min_value,
    MAX(value) AS max_value,
    COUNT(*) AS count
FROM metrics
GROUP BY bucket, device_id, metric_name;

-- è‡ªåŠ¨åˆ·æ–°è¿ç»­èšåˆ
SELECT add_continuous_aggregate_policy('metrics_hourly',
    start_offset => INTERVAL '3 hours',
    end_offset => INTERVAL '1 hour',
    schedule_interval => INTERVAL '1 hour'
);

-- æŸ¥è¯¢è¿ç»­èšåˆï¼ˆæ€§èƒ½æ›´å¥½ï¼‰
SELECT bucket, device_id, metric_name, avg_value
FROM metrics_hourly
WHERE device_id = 123
  AND bucket >= '2024-01-01'::TIMESTAMPTZ
  AND bucket < '2024-01-02'::TIMESTAMPTZ
ORDER BY bucket DESC;
```

### 6.2. é™é‡‡æ ·æŸ¥è¯¢

**é™é‡‡æ ·å‡½æ•°**ï¼š

```sql
-- é™é‡‡æ ·æŸ¥è¯¢å‡½æ•°
CREATE OR REPLACE FUNCTION downsample_metrics(
    p_device_id BIGINT,
    p_metric_name VARCHAR,
    p_start_time TIMESTAMPTZ,
    p_end_time TIMESTAMPTZ,
    p_interval INTERVAL
)
RETURNS TABLE (
    time TIMESTAMPTZ,
    value_avg DOUBLE PRECISION,
    value_min DOUBLE PRECISION,
    value_max DOUBLE PRECISION
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        date_trunc('minute', m.time) AS time,
        AVG(m.value) AS value_avg,
        MIN(m.value) AS value_min,
        MAX(m.value) AS value_max
    FROM metrics m
    WHERE m.device_id = p_device_id
      AND m.metric_name = p_metric_name
      AND m.time >= p_start_time
      AND m.time < p_end_time
    GROUP BY date_trunc('minute', m.time)
    ORDER BY time;
END;
$$ LANGUAGE plpgsql;
```

### 6.3. çª—å£å‡½æ•°æŸ¥è¯¢

**çª—å£å‡½æ•°åº”ç”¨**ï¼š

```sql
-- è®¡ç®—ç§»åŠ¨å¹³å‡
SELECT
    time,
    device_id,
    metric_name,
    value,
    AVG(value) OVER (
        PARTITION BY device_id, metric_name
        ORDER BY time
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    ) AS moving_avg_10
FROM metrics
WHERE device_id = 123
  AND time >= CURRENT_TIMESTAMP - INTERVAL '1 day'
ORDER BY time;

-- è®¡ç®—å˜åŒ–ç‡
SELECT
    time,
    device_id,
    metric_name,
    value,
    value - LAG(value) OVER (
        PARTITION BY device_id, metric_name
        ORDER BY time
    ) AS value_change,
    (value - LAG(value) OVER (
        PARTITION BY device_id, metric_name
        ORDER BY time
    )) / NULLIF(LAG(value) OVER (
        PARTITION BY device_id, metric_name
        ORDER BY time
    ), 0) * 100 AS value_change_percent
FROM metrics
WHERE device_id = 123
  AND time >= CURRENT_TIMESTAMP - INTERVAL '1 day'
ORDER BY time;
```

---

## 7. å®é™…åº”ç”¨æ¡ˆä¾‹

### 7.1. ç›‘æ§ç³»ç»Ÿè®¾è®¡

**å®Œæ•´ç›‘æ§ç³»ç»ŸSchema**ï¼š

```sql
CREATE SCHEMA monitoring;

-- ä¸»æœºè¡¨
CREATE TABLE monitoring.hosts (
    host_id BIGSERIAL PRIMARY KEY,
    hostname VARCHAR(200) NOT NULL UNIQUE,
    ip_address INET,
    host_type VARCHAR(50),
    location VARCHAR(200),
    tags JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- æŒ‡æ ‡å®šä¹‰è¡¨
CREATE TABLE monitoring.metrics (
    metric_id SERIAL PRIMARY KEY,
    metric_name VARCHAR(200) NOT NULL UNIQUE,
    metric_type VARCHAR(50) NOT NULL,  -- counter, gauge, histogram
    unit VARCHAR(20),
    description TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- ç›‘æ§æ•°æ®è¡¨ï¼ˆæ—¶åºæ•°æ®ï¼‰
CREATE TABLE monitoring.metric_data (
    time TIMESTAMPTZ NOT NULL,
    host_id BIGINT NOT NULL REFERENCES monitoring.hosts(host_id),
    metric_id INTEGER NOT NULL REFERENCES monitoring.metrics(metric_id),
    value DOUBLE PRECISION NOT NULL,
    labels JSONB,  -- é¢å¤–çš„æ ‡ç­¾
    PRIMARY KEY (time, host_id, metric_id)
);

-- è½¬æ¢ä¸ºè¶…è¡¨
SELECT create_hypertable('monitoring.metric_data', 'time',
    chunk_time_interval => INTERVAL '1 day'
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_metric_data_host ON monitoring.metric_data(host_id, time DESC);
CREATE INDEX idx_metric_data_metric ON monitoring.metric_data(metric_id, time DESC);
CREATE INDEX idx_metric_data_labels ON monitoring.metric_data USING GIN(labels);

-- å‘Šè­¦è§„åˆ™è¡¨
CREATE TABLE monitoring.alert_rules (
    rule_id SERIAL PRIMARY KEY,
    rule_name VARCHAR(200) NOT NULL,
    metric_id INTEGER NOT NULL REFERENCES monitoring.metrics(metric_id),
    condition_type VARCHAR(20) NOT NULL CHECK (condition_type IN ('gt', 'lt', 'eq', 'ne')),
    threshold_value DOUBLE PRECISION NOT NULL,
    duration INTERVAL NOT NULL,
    severity VARCHAR(20) NOT NULL CHECK (severity IN ('critical', 'warning', 'info')),
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- å‘Šè­¦è®°å½•è¡¨
CREATE TABLE monitoring.alerts (
    alert_id BIGSERIAL PRIMARY KEY,
    rule_id INTEGER NOT NULL REFERENCES monitoring.alert_rules(rule_id),
    host_id BIGINT NOT NULL REFERENCES monitoring.hosts(host_id),
    metric_id INTEGER NOT NULL REFERENCES monitoring.metrics(metric_id),
    alert_value DOUBLE PRECISION NOT NULL,
    threshold_value DOUBLE PRECISION NOT NULL,
    severity VARCHAR(20) NOT NULL,
    status VARCHAR(20) NOT NULL CHECK (status IN ('firing', 'resolved', 'acknowledged')),
    started_at TIMESTAMPTZ NOT NULL,
    resolved_at TIMESTAMPTZ,
    acknowledged_at TIMESTAMPTZ,
    acknowledged_by VARCHAR(100),
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_alerts_status ON monitoring.alerts(status, started_at DESC) WHERE status = 'firing';
CREATE INDEX idx_alerts_host ON monitoring.alerts(host_id, started_at DESC);

-- å‘Šè­¦æ£€æµ‹å‡½æ•°
CREATE OR REPLACE FUNCTION check_alert_rules()
RETURNS TABLE (
    rule_id INTEGER,
    host_id BIGINT,
    metric_id INTEGER,
    current_value DOUBLE PRECISION,
    threshold_value DOUBLE PRECISION
) AS $$
BEGIN
    RETURN QUERY
    WITH recent_metrics AS (
        SELECT
            host_id,
            metric_id,
            AVG(value) AS avg_value
        FROM monitoring.metric_data
        WHERE time >= CURRENT_TIMESTAMP - INTERVAL '5 minutes'
        GROUP BY host_id, metric_id
    )
    SELECT
        ar.rule_id,
        rm.host_id,
        rm.metric_id,
        rm.avg_value AS current_value,
        ar.threshold_value
    FROM monitoring.alert_rules ar
    JOIN recent_metrics rm ON ar.metric_id = rm.metric_id
    WHERE ar.is_active = TRUE
      AND (
          (ar.condition_type = 'gt' AND rm.avg_value > ar.threshold_value) OR
          (ar.condition_type = 'lt' AND rm.avg_value < ar.threshold_value) OR
          (ar.condition_type = 'eq' AND rm.avg_value = ar.threshold_value)
      )
      AND NOT EXISTS (
          SELECT 1 FROM monitoring.alerts a
          WHERE a.rule_id = ar.rule_id
            AND a.host_id = rm.host_id
            AND a.status = 'firing'
      );
END;
$$ LANGUAGE plpgsql;
```

### 7.2. IoTæ—¶åºæ•°æ®å¹³å°è®¾è®¡

**IoTæ—¶åºæ•°æ®Schema**ï¼š

```sql
CREATE SCHEMA iot_ts;

-- è®¾å¤‡è¡¨
CREATE TABLE iot_ts.devices (
    device_id BIGSERIAL PRIMARY KEY,
    device_code VARCHAR(100) NOT NULL UNIQUE,
    device_type VARCHAR(50) NOT NULL,
    location POINT,  -- PostGIS
    metadata JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- ä¼ æ„Ÿå™¨æ•°æ®è¡¨ï¼ˆé«˜é¢‘æ—¶åºæ•°æ®ï¼‰
CREATE TABLE iot_ts.sensor_readings (
    time TIMESTAMPTZ NOT NULL,
    device_id BIGINT NOT NULL REFERENCES iot_ts.devices(device_id),
    sensor_name VARCHAR(100) NOT NULL,
    value DOUBLE PRECISION NOT NULL,
    quality INTEGER CHECK (quality BETWEEN 0 AND 100),
    PRIMARY KEY (time, device_id, sensor_name)
);

-- è½¬æ¢ä¸ºè¶…è¡¨
SELECT create_hypertable('iot_ts.sensor_readings', 'time',
    chunk_time_interval => INTERVAL '1 hour',  -- é«˜é¢‘æ•°æ®ï¼ŒæŒ‰å°æ—¶åˆ†åŒº
    if_not_exists => TRUE
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_sensor_readings_device ON iot_ts.sensor_readings(device_id, time DESC);
CREATE INDEX idx_sensor_readings_sensor ON iot_ts.sensor_readings(device_id, sensor_name, time DESC);

-- è®¾å¤‡çŠ¶æ€è¡¨ï¼ˆçŠ¶æ€å˜æ›´è®°å½•ï¼‰
CREATE TABLE iot_ts.device_status_changes (
    time TIMESTAMPTZ NOT NULL,
    device_id BIGINT NOT NULL REFERENCES iot_ts.devices(device_id),
    old_status VARCHAR(50),
    new_status VARCHAR(50) NOT NULL,
    change_reason TEXT,
    PRIMARY KEY (time, device_id)
);

SELECT create_hypertable('iot_ts.device_status_changes', 'time',
    chunk_time_interval => INTERVAL '1 day'
);

-- å®æ—¶æ•°æ®è§†å›¾ï¼ˆæœ€è¿‘1å°æ—¶çš„æ•°æ®ï¼‰
CREATE MATERIALIZED VIEW iot_ts.realtime_sensor_data
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 minute', time) AS bucket,
    device_id,
    sensor_name,
    AVG(value) AS avg_value,
    MIN(value) AS min_value,
    MAX(value) AS max_value,
    COUNT(*) AS sample_count
FROM iot_ts.sensor_readings
WHERE time >= CURRENT_TIMESTAMP - INTERVAL '1 hour'
GROUP BY bucket, device_id, sensor_name;

-- è‡ªåŠ¨åˆ·æ–°ç­–ç•¥
SELECT add_continuous_aggregate_policy('iot_ts.realtime_sensor_data',
    start_offset => INTERVAL '2 hours',
    end_offset => INTERVAL '1 minute',
    schedule_interval => INTERVAL '1 minute'
);
```

---

## 8. 2024-2025æœ€æ–°è¶‹åŠ¿

### 8.1. æ—¶åºæ•°æ®åº“æŠ€æœ¯æ¼”è¿›

```mermaid
timeline
    title æ—¶åºæ•°æ®åº“æŠ€æœ¯æ¼”è¿›
    2013 : InfluxDBå‘å¸ƒ
         : æ—¶åºæ•°æ®åº“æ¦‚å¿µ
    2017 : TimescaleDBå‘å¸ƒ
         : PostgreSQLæ‰©å±•
    2019 : Prometheusç”Ÿæ€æˆç†Ÿ
         : äº‘åŸç”Ÿç›‘æ§
    2021 : è¾¹ç¼˜æ—¶åºæ•°æ®
         : å®æ—¶åˆ†æ
    2023 : AIæ—¶åºé¢„æµ‹
         : å¼‚å¸¸æ£€æµ‹é›†æˆ
    2025 : å‘é‡æ—¶åºèåˆ
         : å®æ—¶æœºå™¨å­¦ä¹ 
```

### 8.2. æ—¶åºæ•°æ®åº“é€‰å‹çŸ©é˜µ

| æ•°æ®åº“ | ç±»å‹ | å‹ç¼©ç‡ | æŸ¥è¯¢æ€§èƒ½ | ç”Ÿæ€é›†æˆ | é€‚ç”¨åœºæ™¯ |
|-------|------|--------|---------|---------|---------|
| **TimescaleDB** | PGæ‰©å±• | 90%+ | é«˜ | PostgreSQL | é€šç”¨æ—¶åº |
| **InfluxDB** | åŸç”Ÿ | 85%+ | é«˜ | Telegraf/Grafana | ç›‘æ§ |
| **QuestDB** | åŸç”Ÿ | 90%+ | æé«˜ | è½»é‡ | é‡‘è/IoT |
| **ClickHouse** | åˆ—å­˜ | 95%+ | æé«˜ | åˆ†æç”Ÿæ€ | OLAPåˆ†æ |
| **Prometheus** | å†…å­˜ | ä¸­ | é«˜ | Kubernetes | äº‘åŸç”Ÿç›‘æ§ |
| **TDengine** | åŸç”Ÿ | 90%+ | é«˜ | å›½äº§ç”Ÿæ€ | å·¥ä¸šIoT |

### 8.3. æ—¶åº+å‘é‡èåˆæ¨¡å¼

```sql
-- æ—¶åºæ•°æ®ä¸å‘é‡Embeddingèåˆ
CREATE TABLE ts_vector.sensor_readings_with_embedding (
    time TIMESTAMPTZ NOT NULL,
    device_id BIGINT NOT NULL,
    sensor_values DOUBLE PRECISION[] NOT NULL,
    embedding vector(128),  -- ä¼ æ„Ÿå™¨ç‰¹å¾å‘é‡
    anomaly_score FLOAT,
    PRIMARY KEY (time, device_id)
);

-- å¼‚å¸¸æ£€æµ‹ï¼šåŸºäºå‘é‡ç›¸ä¼¼åº¦
CREATE OR REPLACE FUNCTION detect_anomaly_by_embedding(
    p_device_id BIGINT,
    p_current_embedding vector(128),
    p_threshold FLOAT DEFAULT 0.3
)
RETURNS BOOLEAN AS $$
DECLARE
    v_avg_distance FLOAT;
BEGIN
    SELECT AVG(1 - (embedding <=> p_current_embedding))
    INTO v_avg_distance
    FROM ts_vector.sensor_readings_with_embedding
    WHERE device_id = p_device_id
      AND time >= NOW() - INTERVAL '1 hour';

    RETURN v_avg_distance < p_threshold;
END;
$$ LANGUAGE plpgsql;
```

---

## 9. å‚è€ƒèµ„æ–™

### 9.1. æƒå¨æ–‡çŒ®

**æ—¶åºæ•°æ®ç†è®º**ï¼š

- Pelkonen, T. et al. (2015). "Gorilla: A Fast, Scalable, In-Memory Time Series Database" (Facebook)
- Adams, B. et al. (2020). "Time Series Made Easy" (TimescaleDB)

### 9.2. åœ¨çº¿èµ„æº

| èµ„æº | URL | æè¿° |
|------|-----|------|
| **TimescaleDBæ–‡æ¡£** | <https://docs.timescale.com/> | æ—¶åºæ‰©å±• |
| **InfluxDBæ–‡æ¡£** | <https://docs.influxdata.com/> | åŸç”Ÿæ—¶åº |
| **Prometheusæ–‡æ¡£** | <https://prometheus.io/docs/> | äº‘åŸç”Ÿç›‘æ§ |

### 9.3. ç›¸å…³æ–‡æ¡£

- [07.11-åœ°ç†ç©ºé—´æ•°æ®åº“è®¾è®¡](./07.11-åœ°ç†ç©ºé—´æ•°æ®åº“è®¾è®¡.md)
- [07.08-æ•°æ®åº“æ€§èƒ½è°ƒä¼˜å®æˆ˜](./07.08-æ•°æ®åº“æ€§èƒ½è°ƒä¼˜å®æˆ˜.md)
- [07.10-å‘é‡æ•°æ®åº“è®¾è®¡](./07.10-å‘é‡æ•°æ®åº“è®¾è®¡.md)

---

**æœ€åæ›´æ–°**ï¼š2025-12-01
**ç»´æŠ¤è€…**ï¼šData-Science Team
**çŠ¶æ€**ï¼šå®æ–½ä¸­
**ç‰ˆæœ¬**ï¼šv2.0 (å¢å¼ºç‰ˆ)
