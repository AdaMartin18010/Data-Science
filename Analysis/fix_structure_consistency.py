#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨åŒ–ä¿®å¤ Analysis æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰ Markdown æ–‡ä»¶çš„ç»“æ„ä¸€è‡´æ€§é—®é¢˜
- ç»Ÿä¸€æ ‡é¢˜ç¼–å·æ ¼å¼
- ä¿®å¤æ ‡é¢˜å±‚çº§è·³è·ƒ
- ç¡®ä¿ç¼–å·è¿ç»­æ€§
"""

import os
import re
from pathlib import Path
from typing import List, Tuple, Dict
import shutil
from datetime import datetime

class StructureFixer:
    def __init__(self, root_dir: str, backup: bool = True):
        self.root_dir = Path(root_dir)
        self.backup = backup
        self.fixed_files = []
        self.errors = []
        
    def find_markdown_files(self) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰ Markdown æ–‡ä»¶"""
        md_files = []
        for root, dirs, files in os.walk(self.root_dir):
            # è·³è¿‡ä¸€äº›ä¸éœ€è¦æ£€æŸ¥çš„ç›®å½•
            if any(skip in root for skip in ['.git', '__pycache__', 'node_modules']):
                continue
            for file in files:
                if file.endswith('.md') and not file.startswith('structure_') and file != 'check_structure_consistency.py':
                    md_files.append(Path(root) / file)
        return sorted(md_files)
    
    def backup_file(self, file_path: Path):
        """å¤‡ä»½æ–‡ä»¶"""
        if self.backup:
            backup_dir = self.root_dir / '.structure_backup' / file_path.relative_to(self.root_dir).parent
            backup_dir.mkdir(parents=True, exist_ok=True)
            backup_path = backup_dir / file_path.name
            shutil.copy2(file_path, backup_path)
    
    def extract_headings(self, content: str) -> List[Tuple[int, str, int]]:
        """æå–æ‰€æœ‰æ ‡é¢˜"""
        headings = []
        lines = content.split('\n')
        for i, line in enumerate(lines, 1):
            match = re.match(r'^(#{1,6})\s+(.+)$', line.strip())
            if match:
                level = len(match.group(1))
                text = match.group(2).strip()
                headings.append((level, text, i))
        return headings
    
    def remove_emoji_from_heading(self, text: str) -> str:
        """ç§»é™¤æ ‡é¢˜å¼€å¤´çš„emoji"""
        # ç§»é™¤å¸¸è§çš„emoji
        emoji_pattern = r'^[ğŸ“–ğŸ—ï¸ğŸ”¬ğŸ’¡ğŸš€ğŸ“šğŸ¯âš™ï¸ğŸ”§âœ…âŒâš ï¸ğŸ’»ğŸŒğŸ”’ğŸ“ŠğŸ¨ğŸ”ğŸ’¾ğŸŒğŸ”ğŸ“ˆğŸ“‰ğŸ“ğŸ’¼ğŸ†ğŸŒŸâœ¨ğŸªğŸ­ğŸ¬ğŸ²ğŸ°ğŸ±ğŸ³ğŸ´ğŸµğŸ¶ğŸ¸ğŸ¹ğŸºğŸ»ğŸ¥ğŸ¤ğŸ§]\s*'
        text = re.sub(emoji_pattern, '', text)
        return text.strip()
    
    def normalize_heading_numbering(self, headings: List[Tuple[int, str, int]], content: str) -> str:
        """æ ‡å‡†åŒ–æ ‡é¢˜ç¼–å·"""
        lines = content.split('\n')
        new_lines = lines.copy()
        
        # è·Ÿè¸ªæ¯ä¸ªå±‚çº§çš„å½“å‰ç¼–å·
        level_numbers = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0}
        prev_level = 1  # H1æ˜¯æ–‡ä»¶æ ‡é¢˜
        
        # ä»å‰å‘åå¤„ç†
        for level, text, line_num in headings:
            # å¤„ç†H1ï¼ˆæ–‡ä»¶æ ‡é¢˜ï¼‰
            if level == 1:
                # æ¸…ç†H1æ ‡é¢˜ï¼Œç§»é™¤emoji
                cleaned_text = self.remove_emoji_from_heading(text)
                new_lines[line_num - 1] = f"# {cleaned_text}"
                continue
            
            # ç§»é™¤emoji
            cleaned_text = self.remove_emoji_from_heading(text)
            
            # ç§»é™¤ç°æœ‰ç¼–å·ï¼ˆåŒ…æ‹¬é‡å¤ç¼–å·ï¼Œå¦‚ "3. 1." -> ""ï¼‰
            # å…ˆç§»é™¤æ‰€æœ‰å¯èƒ½çš„ç¼–å·æ¨¡å¼ï¼ˆåŒ…æ‹¬é‡å¤ç¼–å·ï¼‰
            cleaned_text = re.sub(r'^(\d+\s*\.\s*)+', '', cleaned_text)  # ç§»é™¤é‡å¤ç¼–å·å¦‚ "3. 1. " æˆ– "1. 1. "
            cleaned_text = re.sub(r'^\d+(\.\d+)*\s*\.?\s*', '', cleaned_text)  # ç§»é™¤æ ‡å‡†ç¼–å·å¦‚ "1. " æˆ– "1.1. "
            cleaned_text = cleaned_text.strip()
            
            # ç¡®å®šåº”è¯¥ä½¿ç”¨çš„ç¼–å·
            if level <= prev_level:
                # é‡ç½®æ›´æ·±å±‚çº§çš„ç¼–å·
                for l in range(level + 1, 7):
                    level_numbers[l] = 0
            
            # å¢åŠ å½“å‰å±‚çº§ç¼–å·
            level_numbers[level] += 1
            
            # ç”Ÿæˆç¼–å·å­—ç¬¦ä¸²
            if level == 2:
                number = str(level_numbers[2])
            elif level == 3:
                number = f"{level_numbers[2]}.{level_numbers[3]}"
            elif level == 4:
                number = f"{level_numbers[2]}.{level_numbers[3]}.{level_numbers[4]}"
            elif level == 5:
                number = f"{level_numbers[2]}.{level_numbers[3]}.{level_numbers[4]}.{level_numbers[5]}"
            elif level == 6:
                number = f"{level_numbers[2]}.{level_numbers[3]}.{level_numbers[4]}.{level_numbers[5]}.{level_numbers[6]}"
            else:
                number = ""
            
            # æ„å»ºæ–°çš„æ ‡é¢˜è¡Œ
            hashes = '#' * level
            new_lines[line_num - 1] = f"{hashes} {number}. {cleaned_text}" if number else f"{hashes} {cleaned_text}"
            
            prev_level = level
        
        return '\n'.join(new_lines)
    
    def fix_heading_level_jumps(self, content: str) -> str:
        """ä¿®å¤æ ‡é¢˜å±‚çº§è·³è·ƒ"""
        lines = content.split('\n')
        new_lines = []
        prev_level = 1  # H1æ˜¯æ–‡ä»¶æ ‡é¢˜
        
        for i, line in enumerate(lines):
            match = re.match(r'^(#{1,6})\s+(.+)$', line.strip())
            if match:
                level = len(match.group(1))
                text = match.group(2).strip()
                
                # æ£€æŸ¥å±‚çº§è·³è·ƒ
                if level > prev_level + 1:
                    # éœ€è¦æ’å…¥ä¸­é—´å±‚çº§
                    # ä½†ä¸ºäº†å®‰å…¨ï¼Œæˆ‘ä»¬åªè°ƒæ•´å½“å‰æ ‡é¢˜çš„å±‚çº§ï¼Œä¸æ’å…¥æ–°å†…å®¹
                    # å°†è·³è·ƒçš„æ ‡é¢˜é™çº§åˆ°åˆç†çš„å±‚çº§
                    new_level = min(level, prev_level + 1)
                    hashes = '#' * new_level
                    new_lines.append(f"{hashes} {text}")
                    prev_level = new_level
                else:
                    new_lines.append(line)
                    if level > 0:
                        prev_level = level
            else:
                new_lines.append(line)
        
        return '\n'.join(new_lines)
    
    def fix_file(self, file_path: Path) -> Tuple[bool, List[str]]:
        """ä¿®å¤å•ä¸ªæ–‡ä»¶"""
        try:
            # å¤‡ä»½æ–‡ä»¶
            self.backup_file(file_path)
            
            # è¯»å–æ–‡ä»¶
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            issues_fixed = []
            
            # æå–æ ‡é¢˜
            headings = self.extract_headings(content)
            
            if not headings:
                return False, ["æ–‡ä»¶æ²¡æœ‰æ ‡é¢˜"]
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿®å¤
            needs_fix = False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ··åˆç¼–å·ï¼ˆæ›´ä¸¥æ ¼çš„æ£€æŸ¥ï¼‰
            numbered_count = 0
            unnumbered_count = 0
            has_duplicate_numbering = False
            for h in headings:
                if h[0] > 1:  # è·³è¿‡H1
                    text = h[1]
                    # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤ç¼–å·ï¼ˆå¦‚ "1. 1. " æˆ– "3. 1. "ï¼‰
                    if re.match(r'^(\d+\s*\.\s*){2,}', text):
                        has_duplicate_numbering = True
                        numbered_count += 1
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡å‡†ç¼–å·
                    elif re.match(r'^\d+(\.\d+)*\s*\.?\s+', text):
                        numbered_count += 1
                    elif not re.match(r'^[ğŸ“–ğŸ—ï¸ğŸ”¬ğŸ’¡ğŸš€ğŸ“šğŸ¯âš™ï¸ğŸ”§âœ…âŒâš ï¸ğŸ’»ğŸŒğŸ”’ğŸ“ŠğŸ¨ğŸ”ğŸ’¾ğŸŒğŸ”ğŸ“ˆğŸ“‰ğŸ“ğŸ’¼ğŸ†ğŸŒŸâœ¨ğŸªğŸ­ğŸ¬ğŸ²ğŸ°ğŸ±ğŸ³ğŸ´ğŸµğŸ¶ğŸ¸ğŸ¹ğŸºğŸ»ğŸ¥ğŸ¤ğŸ§]', text):
                        unnumbered_count += 1
            
            # å¦‚æœæœ‰ç¼–å·å’Œæœªç¼–å·çš„æ ‡é¢˜ï¼Œæˆ–è€…ç¼–å·é¡ºåºä¸å¯¹ï¼Œéƒ½éœ€è¦ä¿®å¤
            if has_duplicate_numbering:
                needs_fix = True
                issues_fixed.append("ä¿®å¤é‡å¤ç¼–å·")
            if numbered_count > 0 and unnumbered_count > 0:
                needs_fix = True
                issues_fixed.append("ä¿®å¤æ··åˆç¼–å·")
            elif numbered_count > 0:
                # æ£€æŸ¥ç¼–å·é¡ºåºæ˜¯å¦æ­£ç¡®
                prev_numbers = {}
                for level, text, line_num in headings:
                    if level > 1:
                        match = re.match(r'^(\d+(?:\.\d+)*)\s*\.?\s+', text)
                        if match:
                            numbers = [int(n) for n in match.group(1).split('.')]
                            # æ£€æŸ¥ç¼–å·æ˜¯å¦è¿ç»­
                            if level in prev_numbers:
                                expected = prev_numbers[level] + 1
                                if numbers[0] != expected:
                                    needs_fix = True
                                    issues_fixed.append("ä¿®å¤ç¼–å·é¡ºåº")
                                    break
                            prev_numbers[level] = numbers[0]
                            # é‡ç½®æ›´æ·±å±‚çº§çš„ç¼–å·
                            for l in range(level + 1, 7):
                                if l in prev_numbers:
                                    del prev_numbers[l]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å±‚çº§è·³è·ƒ
            prev_level = headings[0][0]
            for level, text, line_num in headings[1:]:
                if level > prev_level + 1:
                    needs_fix = True
                    issues_fixed.append(f"ä¿®å¤å±‚çº§è·³è·ƒï¼ˆè¡Œ{line_num}ï¼‰")
                    break
                if level > 0:
                    prev_level = level
            
            # æ£€æŸ¥æ˜¯å¦æœ‰emoji
            has_emoji = any(re.match(r'^[ğŸ“–ğŸ—ï¸ğŸ”¬ğŸ’¡ğŸš€ğŸ“šğŸ¯âš™ï¸ğŸ”§âœ…âŒâš ï¸ğŸ’»ğŸŒğŸ”’ğŸ“ŠğŸ¨ğŸ”ğŸ’¾ğŸŒğŸ”ğŸ“ˆğŸ“‰ğŸ“ğŸ’¼ğŸ†ğŸŒŸâœ¨ğŸªğŸ­ğŸ¬ğŸ²ğŸ°ğŸ±ğŸ³ğŸ´ğŸµğŸ¶ğŸ¸ğŸ¹ğŸºğŸ»ğŸ¥ğŸ¤ğŸ§]', h[1]) for h in headings)
            if has_emoji:
                needs_fix = True
                issues_fixed.append("ç§»é™¤æ ‡é¢˜ä¸­çš„emoji")
            
            if not needs_fix:
                return False, []
            
            # æ‰§è¡Œä¿®å¤
            # 1. å…ˆä¿®å¤å±‚çº§è·³è·ƒ
            content = self.fix_heading_level_jumps(content)
            
            # 2. é‡æ–°æå–æ ‡é¢˜ï¼ˆå› ä¸ºå±‚çº§å¯èƒ½å·²æ”¹å˜ï¼‰
            headings = self.extract_headings(content)
            
            # 3. æ ‡å‡†åŒ–ç¼–å·
            content = self.normalize_heading_numbering(headings, content)
            
            # å†™å…¥æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            return True, issues_fixed
            
        except Exception as e:
            return False, [f"é”™è¯¯: {str(e)}"]
    
    def fix_all_files(self):
        """ä¿®å¤æ‰€æœ‰æ–‡ä»¶"""
        md_files = self.find_markdown_files()
        print(f"æ‰¾åˆ° {len(md_files)} ä¸ª Markdown æ–‡ä»¶\n")
        
        if self.backup:
            backup_dir = self.root_dir / '.structure_backup'
            backup_dir.mkdir(exist_ok=True)
            print(f"å¤‡ä»½ç›®å½•: {backup_dir}\n")
        
        fixed_count = 0
        error_count = 0
        
        for i, file_path in enumerate(md_files, 1):
            rel_path = file_path.relative_to(self.root_dir)
            print(f"[{i}/{len(md_files)}] å¤„ç†: {rel_path}")
            
            success, issues = self.fix_file(file_path)
            
            if success:
                fixed_count += 1
                self.fixed_files.append({
                    'file': str(rel_path),
                    'issues': issues
                })
                print(f"  âœ“ å·²ä¿®å¤: {', '.join(issues)}")
            elif issues:
                error_count += 1
                self.errors.append({
                    'file': str(rel_path),
                    'error': issues[0]
                })
                print(f"  âœ— é”™è¯¯: {issues[0]}")
            else:
                print(f"  - æ— éœ€ä¿®å¤")
        
        print(f"\n{'='*80}")
        print(f"ä¿®å¤å®Œæˆ!")
        print(f"  æ€»æ–‡ä»¶æ•°: {len(md_files)}")
        print(f"  å·²ä¿®å¤: {fixed_count}")
        print(f"  é”™è¯¯: {error_count}")
        print(f"  æ— éœ€ä¿®å¤: {len(md_files) - fixed_count - error_count}")
        
        return {
            'total': len(md_files),
            'fixed': fixed_count,
            'errors': error_count,
            'fixed_files': self.fixed_files,
            'errors': self.errors
        }

def main():
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = Path(__file__).parent
    fixer = StructureFixer(script_dir, backup=True)
    
    print("="*80)
    print("Analysis æ–‡ä»¶å¤¹ç»“æ„ä¸€è‡´æ€§ä¿®å¤å·¥å…·")
    print("="*80)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    results = fixer.fix_all_files()
    
    # ä¿å­˜ä¿®å¤æŠ¥å‘Š
    import json
    report_file = script_dir / 'structure_fix_report.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nä¿®å¤æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == '__main__':
    main()
