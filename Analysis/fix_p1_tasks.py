#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡ä¿®å¤Analysisé¡¹ç›®P1ä»»åŠ¡ï¼š
1. ä¿®å¤é«˜ä¼˜å…ˆçº§æ–‡ä»¶çš„ç»“æ„é—®é¢˜
2. ç»Ÿä¸€æ ‡é¢˜ç¼–å·æ ¼å¼
3. ä¿®å¤æ ‡é¢˜å±‚çº§è·³è·ƒ
4. ä¸ºæ–‡ä»¶æ·»åŠ æ ‡å‡†ç›®å½•
"""

import os
import re
from pathlib import Path
from typing import List, Tuple, Dict, Optional
import json
from datetime import datetime

class P1TaskFixer:
    def __init__(self, root_dir: str):
        self.root_dir = Path(root_dir)
        self.fixed_files = []
        self.errors = []
        
    def find_markdown_files(self) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰ Markdown æ–‡ä»¶"""
        md_files = []
        for root, dirs, files in os.walk(self.root_dir):
            if any(skip in root for skip in ['.git', '__pycache__', 'node_modules', '.structure_backup']):
                continue
            if '.structure_backup' in dirs:
                dirs.remove('.structure_backup')
            for file in files:
                if file.endswith('.md') and not file.startswith('structure_') and file not in ['check_structure_consistency.py', 'fix_structure_consistency.py', 'fix_structure_consistency_v2.py', 'restore_from_backup.py', 'fix_p1_tasks.py']:
                    md_files.append(Path(root) / file)
        return sorted(md_files)
    
    def extract_headings(self, content: str) -> List[Tuple[int, str, int, Optional[str]]]:
        """æå–æ‰€æœ‰æ ‡é¢˜ï¼Œè¿”å› (çº§åˆ«, æ ‡é¢˜æ–‡æœ¬, è¡Œå·, ç¼–å·)ï¼Œæ’é™¤ä»£ç å—ä¸­çš„æ ‡é¢˜"""
        headings = []
        lines = content.split('\n')
        in_code_block = False
        code_block_pattern = re.compile(r'^```')
        
        for i, line in enumerate(lines, 1):
            # æ£€æŸ¥æ˜¯å¦è¿›å…¥æˆ–é€€å‡ºä»£ç å—
            if code_block_pattern.match(line.strip()):
                in_code_block = not in_code_block
                continue
            
            # è·³è¿‡ä»£ç å—ä¸­çš„å†…å®¹
            if in_code_block:
                continue
            
            # åŒ¹é…æ ‡é¢˜ï¼ˆä¸åœ¨ä»£ç å—ä¸­ï¼‰
            match = re.match(r'^(#{1,6})\s+(.+)$', line.strip())
            if match:
                level = len(match.group(1))
                text = match.group(2).strip()
                # æå–ç¼–å·ï¼ˆå¦‚æœæœ‰ï¼‰
                num_match = re.match(r'^(\d+(?:\.\d+)*)\.?\s+(.+)$', text)
                if num_match:
                    numbering = num_match.group(1)
                    title = num_match.group(2)
                else:
                    numbering = None
                    title = text
                headings.append((level, title, i, numbering))
        return headings
    
    def generate_toc(self, headings: List[Tuple[int, str, int, Optional[str]]], max_level: int = 3) -> str:
        """ç”Ÿæˆç›®å½•"""
        if not headings:
            return ""
        
        toc_lines = ["## ğŸ“‘ ç›®å½•", ""]
        indent_stack = [0]  # è·Ÿè¸ªç¼©è¿›å±‚çº§
        
        for level, title, line_num, numbering in headings:
            if level > max_level:
                continue
            
            # ç”Ÿæˆé“¾æ¥é”šç‚¹ï¼ˆå…¼å®¹ä¸­æ–‡å’Œç‰¹æ®Šå­—ç¬¦ï¼‰
            # ç§»é™¤ç¼–å·éƒ¨åˆ†ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            clean_title = title
            if numbering:
                clean_title = re.sub(r'^\d+(?:\.\d+)*\.?\s*', '', title)
            
            # ç”Ÿæˆé”šç‚¹ï¼šè½¬æ¢ä¸ºå°å†™ï¼Œæ›¿æ¢ç©ºæ ¼ä¸ºè¿å­—ç¬¦ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦
            # GitHubé£æ ¼çš„é”šç‚¹ç”Ÿæˆï¼šä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€è¿å­—ç¬¦
            anchor = clean_title.lower()
            # æ›¿æ¢ç©ºæ ¼ä¸ºè¿å­—ç¬¦
            anchor = re.sub(r'\s+', '-', anchor)
            # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€è¿å­—ç¬¦
            anchor = re.sub(r'[^\w\u4e00-\u9fff-]', '', anchor)
            # ç§»é™¤å¤šä½™çš„è¿å­—ç¬¦
            anchor = re.sub(r'-+', '-', anchor)
            anchor = anchor.strip('-')
            
            # è®¡ç®—ç¼©è¿›
            while len(indent_stack) > level:
                indent_stack.pop()
            
            indent = "  " * (level - 1)
            link_text = title
            if numbering:
                link_text = f"{numbering}. {title}"
            
            toc_lines.append(f"{indent}- [{link_text}](#{anchor})")
            indent_stack.append(level)
        
        return "\n".join(toc_lines) + "\n\n---\n"
    
    def fix_heading_level_jumps(self, content: str) -> Tuple[str, List[str]]:
        """ä¿®å¤æ ‡é¢˜å±‚çº§è·³è·ƒé—®é¢˜ï¼Œæ’é™¤ä»£ç å—ä¸­çš„æ ‡é¢˜"""
        lines = content.split('\n')
        new_lines = []
        issues_fixed = []
        prev_level = 0
        in_code_block = False
        code_block_pattern = re.compile(r'^```')
        
        for i, line in enumerate(lines):
            # æ£€æŸ¥æ˜¯å¦è¿›å…¥æˆ–é€€å‡ºä»£ç å—
            if code_block_pattern.match(line.strip()):
                in_code_block = not in_code_block
                new_lines.append(line)
                continue
            
            # è·³è¿‡ä»£ç å—ä¸­çš„å†…å®¹ï¼ˆä¸å¤„ç†ï¼‰
            if in_code_block:
                new_lines.append(line)
                continue
            
            # åŒ¹é…æ ‡é¢˜ï¼ˆä¸åœ¨ä»£ç å—ä¸­ï¼‰
            match = re.match(r'^(#{1,6})\s+(.+)$', line.strip())
            if match:
                level = len(match.group(1))
                text = match.group(2).strip()
                
                # æ£€æŸ¥å±‚çº§è·³è·ƒ
                if prev_level > 0 and level > prev_level + 1:
                    # éœ€è¦æ’å…¥ä¸­é—´å±‚çº§
                    new_level = prev_level + 1
                    # è°ƒæ•´å½“å‰æ ‡é¢˜å±‚çº§
                    new_line = '#' * new_level + ' ' + text
                    new_lines.append(new_line)
                    issues_fixed.append(f"è¡Œ{i+1}: ä¿®å¤å±‚çº§è·³è·ƒ (h{level} -> h{new_level})")
                    prev_level = new_level
                else:
                    new_lines.append(line)
                    if level > 0:
                        prev_level = level
            else:
                new_lines.append(line)
        
        return '\n'.join(new_lines), issues_fixed
    
    def add_toc_to_file(self, file_path: Path, max_level: int = 3) -> Tuple[bool, List[str]]:
        """ä¸ºæ–‡ä»¶æ·»åŠ ç›®å½•"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›®å½•
            if re.search(r'^##\s*[ğŸ“‘ç›®å½•|ç›®å½•|Table of Contents]', content, re.MULTILINE | re.IGNORECASE):
                return False, ["å·²æœ‰ç›®å½•"]
            
            # æå–æ ‡é¢˜
            headings = self.extract_headings(content)
            if not headings:
                return False, ["æ— æ ‡é¢˜"]
            
            # ç”Ÿæˆç›®å½•
            toc = self.generate_toc(headings, max_level)
            
            # æ‰¾åˆ°æ’å…¥ä½ç½®ï¼ˆåœ¨ç¬¬ä¸€ä¸ªæ ‡é¢˜ä¹‹åï¼‰
            lines = content.split('\n')
            insert_pos = 0
            for i, line in enumerate(lines):
                if re.match(r'^#\s+', line):
                    insert_pos = i + 1
                    break
            
            # æ’å…¥ç›®å½•
            new_lines = lines[:insert_pos] + [toc] + lines[insert_pos:]
            new_content = '\n'.join(new_lines)
            
            # å†™å…¥æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            return True, ["å·²æ·»åŠ ç›®å½•"]
            
        except Exception as e:
            return False, [f"é”™è¯¯: {str(e)}"]
    
    def fix_high_priority_files(self):
        """ä¿®å¤é«˜ä¼˜å…ˆçº§æ–‡ä»¶"""
        high_priority_files = [
            "1-æ•°æ®åº“ç³»ç»Ÿ/1.2-MySQL/MySQLå›½é™…åŒ–Wikiæ ‡å‡†ä¸çŸ¥è¯†è§„èŒƒå¯¹é½æŒ‡å—.md",
            "1-æ•°æ®åº“ç³»ç»Ÿ/1.3-NoSQL/1.3.1-MongoDBæ¦‚å¿µå®šä¹‰å›½é™…åŒ–æ ‡å‡†ç¤ºä¾‹.md",
            "1-æ•°æ®åº“ç³»ç»Ÿ/1.3-NoSQL/1.3.2-Cassandraæ¦‚å¿µå®šä¹‰å›½é™…åŒ–æ ‡å‡†ç¤ºä¾‹.md",
            "1-æ•°æ®åº“ç³»ç»Ÿ/1.3-NoSQL/1.3.3-Neo4jæ¦‚å¿µå®šä¹‰å›½é™…åŒ–æ ‡å‡†ç¤ºä¾‹.md",
            "3-æ•°æ®æ¨¡å‹ä¸ç®—æ³•/3.1-æ•°æ®ç§‘å­¦åŸºç¡€ç†è®º/3.1.22-æ•°æ®ç§‘å­¦ä¸æœºå™¨å­¦ä¹ ç†è®ºä½“ç³».md",
            "4-è½¯ä»¶æ¶æ„ä¸å·¥ç¨‹/4.1-æ¶æ„è®¾è®¡/4.1.13-å¾®æœåŠ¡æ¶æ„è®¾è®¡.md",
            "4-è½¯ä»¶æ¶æ„ä¸å·¥ç¨‹/4.1-æ¶æ„è®¾è®¡/4.1.14-äº‘åŸç”Ÿæ¶æ„å®è·µ.md",
            "4-è½¯ä»¶æ¶æ„ä¸å·¥ç¨‹/4.1-æ¶æ„è®¾è®¡/4.1.15-DevOpsä¸CI-CD.md",
            "8-å½¢å¼ç†è®ºæ·±åŒ–/8.3-Petriç½‘ç†è®ºæ·±åŒ–/8.3.4-Petriç½‘åº”ç”¨åœºæ™¯æ·±åŒ–.md",
            "8-å½¢å¼ç†è®ºæ·±åŒ–/8.7-åšå¼ˆè®ºæ·±åŒ–/8.7.2-æœºåˆ¶è®¾è®¡ç†è®ºæ·±åŒ–.md",
        ]
        
        results = []
        for rel_path in high_priority_files:
            file_path = self.root_dir / rel_path
            if not file_path.exists():
                results.append({
                    "file": rel_path,
                    "status": "not_found",
                    "issues": []
                })
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ä¿®å¤å±‚çº§è·³è·ƒ
                new_content, issues = self.fix_heading_level_jumps(content)
                
                # æ·»åŠ ç›®å½•ï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
                has_toc = re.search(r'^##\s*[ğŸ“‘ç›®å½•|ç›®å½•|Table of Contents]', content, re.MULTILINE | re.IGNORECASE)
                if not has_toc:
                    headings = self.extract_headings(new_content)
                    if headings:
                        toc = self.generate_toc(headings)
                        lines = new_content.split('\n')
                        insert_pos = 0
                        for i, line in enumerate(lines):
                            if re.match(r'^#\s+', line):
                                insert_pos = i + 1
                                break
                        new_lines = lines[:insert_pos] + [toc] + lines[insert_pos:]
                        new_content = '\n'.join(new_lines)
                        issues.append("å·²æ·»åŠ ç›®å½•")
                
                # å†™å…¥æ–‡ä»¶
                if new_content != content:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(new_content)
                    results.append({
                        "file": rel_path,
                        "status": "fixed",
                        "issues": issues
                    })
                    self.fixed_files.append(rel_path)
                else:
                    results.append({
                        "file": rel_path,
                        "status": "no_changes",
                        "issues": []
                    })
                    
            except Exception as e:
                results.append({
                    "file": rel_path,
                    "status": "error",
                    "issues": [f"é”™è¯¯: {str(e)}"]
                })
                self.errors.append(f"{rel_path}: {str(e)}")
        
        return results
    
    def add_toc_to_all_files(self, max_level: int = 3):
        """ä¸ºæ‰€æœ‰æ–‡ä»¶æ·»åŠ ç›®å½•"""
        md_files = self.find_markdown_files()
        results = []
        
        for file_path in md_files:
            rel_path = str(file_path.relative_to(self.root_dir))
            
            # è·³è¿‡å·²æœ‰ç›®å½•çš„æ–‡ä»¶
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                if re.search(r'^##\s*[ğŸ“‘ç›®å½•|ç›®å½•|Table of Contents]', content, re.MULTILINE | re.IGNORECASE):
                    continue
                
                success, issues = self.add_toc_to_file(file_path, max_level)
                if success:
                    results.append({
                        "file": rel_path,
                        "status": "added_toc",
                        "issues": issues
                    })
                    self.fixed_files.append(rel_path)
                    
            except Exception as e:
                results.append({
                    "file": rel_path,
                    "status": "error",
                    "issues": [f"é”™è¯¯: {str(e)}"]
                })
                self.errors.append(f"{rel_path}: {str(e)}")
        
        return results

def main():
    script_dir = Path(__file__).parent
    fixer = P1TaskFixer(script_dir)
    
    print("="*80)
    print("Analysisé¡¹ç›®P1ä»»åŠ¡æ‰¹é‡ä¿®å¤å·¥å…·")
    print("="*80)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # ä»»åŠ¡1: ä¿®å¤é«˜ä¼˜å…ˆçº§æ–‡ä»¶
    print("ä»»åŠ¡1: ä¿®å¤é«˜ä¼˜å…ˆçº§æ–‡ä»¶çš„ç»“æ„é—®é¢˜...")
    high_priority_results = fixer.fix_high_priority_files()
    print(f"  å¤„ç†äº† {len(high_priority_results)} ä¸ªæ–‡ä»¶")
    fixed_count = sum(1 for r in high_priority_results if r['status'] == 'fixed')
    print(f"  ä¿®å¤äº† {fixed_count} ä¸ªæ–‡ä»¶\n")
    
    # ä»»åŠ¡2: ä¸ºæ‰€æœ‰æ–‡ä»¶æ·»åŠ ç›®å½•
    print("ä»»åŠ¡2: ä¸ºæ‰€æœ‰æ–‡ä»¶æ·»åŠ ç›®å½•...")
    toc_results = fixer.add_toc_to_all_files()
    print(f"  ä¸º {len(toc_results)} ä¸ªæ–‡ä»¶æ·»åŠ äº†ç›®å½•\n")
    
    # ä¿å­˜æŠ¥å‘Š
    report = {
        "timestamp": datetime.now().isoformat(),
        "high_priority_files": high_priority_results,
        "toc_added": toc_results,
        "summary": {
            "total_fixed": len(fixer.fixed_files),
            "total_errors": len(fixer.errors)
        }
    }
    
    report_file = script_dir / 'p1_tasks_fix_report.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"ä¿®å¤æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"\næ€»è®¡ä¿®å¤: {len(fixer.fixed_files)} ä¸ªæ–‡ä»¶")
    print(f"é”™è¯¯: {len(fixer.errors)} ä¸ª")

if __name__ == '__main__':
    main()
