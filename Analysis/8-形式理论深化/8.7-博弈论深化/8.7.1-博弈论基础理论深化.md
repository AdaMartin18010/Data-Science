# 8.7.1 åšå¼ˆè®ºåŸºç¡€ç†è®ºæ·±åŒ–

## ğŸ“‘ ç›®å½•

- [8.7.1 åšå¼ˆè®ºåŸºç¡€ç†è®ºæ·±åŒ–](#871-åšå¼ˆè®ºåŸºç¡€ç†è®ºæ·±åŒ–)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. åšå¼ˆè®ºåŸºç¡€](#1-åšå¼ˆè®ºåŸºç¡€)
    - [1.1. åšå¼ˆè®ºåŸºæœ¬æ¦‚å¿µ](#11-åšå¼ˆè®ºåŸºæœ¬æ¦‚å¿µ)
  - [2. åšå¼ˆç±»å‹](#2-åšå¼ˆç±»å‹)
  - [3. ç­–ç•¥å‹åšå¼ˆ](#3-ç­–ç•¥å‹åšå¼ˆ)
    - [3.1. ç­–ç•¥å‹åšå¼ˆè¡¨ç¤º](#31-ç­–ç•¥å‹åšå¼ˆè¡¨ç¤º)
  - [4. åšå¼ˆåˆ†æå·¥å…·](#4-åšå¼ˆåˆ†æå·¥å…·)
  - [5. æ‰©å±•å‹åšå¼ˆ](#5-æ‰©å±•å‹åšå¼ˆ)
    - [5.1. æ‰©å±•å‹åšå¼ˆè¡¨ç¤º](#51-æ‰©å±•å‹åšå¼ˆè¡¨ç¤º)
  - [6. åŠ¨æ€åšå¼ˆ](#6-åŠ¨æ€åšå¼ˆ)
  - [7. çº³ä»€å‡è¡¡](#7-çº³ä»€å‡è¡¡)
    - [7.1. çº³ä»€å‡è¡¡è®¡ç®—](#71-çº³ä»€å‡è¡¡è®¡ç®—)
  - [8. å‡è¡¡é€‰æ‹©](#8-å‡è¡¡é€‰æ‹©)
  - [9. åº”ç”¨æ¡ˆä¾‹](#9-åº”ç”¨æ¡ˆä¾‹)
    - [9.1. å›šå¾’å›°å¢ƒ](#91-å›šå¾’å›°å¢ƒ)
  - [10. åè°ƒåšå¼ˆ](#10-åè°ƒåšå¼ˆ)
  - [11. å·¥å…·å®ç°](#11-å·¥å…·å®ç°)
    - [11.1. Pythonåšå¼ˆè®ºå·¥å…·](#111-pythonåšå¼ˆè®ºå·¥å…·)
    - [11.2. JavaScriptåšå¼ˆè®ºå®ç°](#112-javascriptåšå¼ˆè®ºå®ç°)
  - [12. å­¦ä¹ è·¯å¾„](#12-å­¦ä¹ è·¯å¾„)
    - [12.1. åŸºç¡€å­¦ä¹ ](#121-åŸºç¡€å­¦ä¹ )
    - [12.2. è¿›é˜¶å­¦ä¹ ](#122-è¿›é˜¶å­¦ä¹ )
    - [12.3. åº”ç”¨å®è·µ](#123-åº”ç”¨å®è·µ)
  - [13. æ€»ç»“](#13-æ€»ç»“)

---


## 1. åšå¼ˆè®ºåŸºç¡€

### 1.1. åšå¼ˆè®ºåŸºæœ¬æ¦‚å¿µ

åšå¼ˆè®ºæ˜¯ç ”ç©¶ç†æ€§å†³ç­–è€…åœ¨ç›¸äº’ä¾å­˜æƒ…å†µä¸‹å¦‚ä½•åšå‡ºæœ€ä¼˜å†³ç­–çš„ç†è®ºã€‚

```python
import numpy as np
from itertools import product
import matplotlib.pyplot as plt

class Game:
    def __init__(self, players, strategies, payoffs):
        """
        åšå¼ˆç±»
        players: ç©å®¶åˆ—è¡¨
        strategies: æ¯ä¸ªç©å®¶çš„ç­–ç•¥é›†
        payoffs: æ”¯ä»˜å‡½æ•°
        """
        self.players = players
        self.strategies = strategies
        self.payoffs = payoffs
        self.n_players = len(players)

    def get_payoff(self, strategy_profile):
        """è·å–ç­–ç•¥ç»„åˆçš„æ”¯ä»˜"""
        return self.payoffs[strategy_profile]

    def get_best_response(self, player, opponent_strategies):
        """è·å–æœ€ä½³å“åº”"""
        best_payoff = float('-inf')
        best_strategy = None

        for strategy in self.strategies[player]:
# æ„å»ºç­–ç•¥ç»„åˆ
            strategy_profile = list(opponent_strategies)
            strategy_profile.insert(player, strategy)
            strategy_profile = tuple(strategy_profile)

            payoff = self.get_payoff(strategy_profile)[player]
            if payoff > best_payoff:
                best_payoff = payoff
                best_strategy = strategy

        return best_strategy, best_payoff

    def is_nash_equilibrium(self, strategy_profile):
        """æ£€æŸ¥æ˜¯å¦ä¸ºçº³ä»€å‡è¡¡"""
        for player in range(self.n_players):
# è·å–å…¶ä»–ç©å®¶çš„ç­–ç•¥
            opponent_strategies = list(strategy_profile)
            opponent_strategies.pop(player)

# è·å–å½“å‰ç©å®¶çš„æœ€ä½³å“åº”
            best_response, best_payoff = self.get_best_response(player, opponent_strategies)

# è·å–å½“å‰ç­–ç•¥çš„æ”¯ä»˜
            current_payoff = self.get_payoff(strategy_profile)[player]

# å¦‚æœä¸æ˜¯æœ€ä½³å“åº”ï¼Œåˆ™ä¸æ˜¯çº³ä»€å‡è¡¡
            if best_payoff > current_payoff:
                return False

        return True

    def find_nash_equilibria(self):
        """å¯»æ‰¾æ‰€æœ‰çº³ä»€å‡è¡¡"""
        equilibria = []

# éå†æ‰€æœ‰å¯èƒ½çš„ç­–ç•¥ç»„åˆ
        strategy_combinations = list(product(*self.strategies))

        for strategy_profile in strategy_combinations:
            if self.is_nash_equilibrium(strategy_profile):
                equilibria.append(strategy_profile)

        return equilibria

    def is_dominant_strategy(self, player, strategy):
        """æ£€æŸ¥æ˜¯å¦ä¸ºå ä¼˜ç­–ç•¥"""
        for opponent_strategies in product(*[self.strategies[i] for i in range(self.n_players) if i != player]):
# æ„å»ºåŒ…å«å½“å‰ç­–ç•¥çš„ç­–ç•¥ç»„åˆ
            strategy_profile = list(opponent_strategies)
            strategy_profile.insert(player, strategy)
            strategy_profile = tuple(strategy_profile)

# æ£€æŸ¥æ˜¯å¦å¯¹æ‰€æœ‰å¯¹æ‰‹ç­–ç•¥éƒ½æ˜¯æœ€ä½³å“åº”
            best_response, _ = self.get_best_response(player, opponent_strategies)
            if best_response != strategy:
                return False

        return True

    def find_dominant_strategies(self):
        """å¯»æ‰¾æ‰€æœ‰å ä¼˜ç­–ç•¥"""
        dominant_strategies = {}

        for player in range(self.n_players):
            dominant_strategies[player] = []
            for strategy in self.strategies[player]:
                if self.is_dominant_strategy(player, strategy):
                    dominant_strategies[player].append(strategy)

        return dominant_strategies

class PrisonersDilemma(Game):
    def __init__(self):
        """å›šå¾’å›°å¢ƒåšå¼ˆ"""
        players = ['Player 1', 'Player 2']
        strategies = [['Cooperate', 'Defect'], ['Cooperate', 'Defect']]

# æ”¯ä»˜çŸ©é˜µ
        payoffs = {
            ('Cooperate', 'Cooperate'): [3, 3],
            ('Cooperate', 'Defect'): [0, 5],
            ('Defect', 'Cooperate'): [5, 0],
            ('Defect', 'Defect'): [1, 1]
        }

        super().__init__(players, strategies, payoffs)

    def analyze_game(self):
        """åˆ†æåšå¼ˆ"""
        print("å›šå¾’å›°å¢ƒåšå¼ˆåˆ†æ:")
        print("=" * 50)

# å¯»æ‰¾çº³ä»€å‡è¡¡
        nash_equilibria = self.find_nash_equilibria()
        print(f"çº³ä»€å‡è¡¡: {nash_equilibria}")

# å¯»æ‰¾å ä¼˜ç­–ç•¥
        dominant_strategies = self.find_dominant_strategies()
        print(f"å ä¼˜ç­–ç•¥: {dominant_strategies}")

# å¸•ç´¯æ‰˜æœ€ä¼˜
        pareto_optimal = self.find_pareto_optimal()
        print(f"å¸•ç´¯æ‰˜æœ€ä¼˜: {pareto_optimal}")

        return {
            'nash_equilibria': nash_equilibria,
            'dominant_strategies': dominant_strategies,
            'pareto_optimal': pareto_optimal
        }

    def find_pareto_optimal(self):
        """å¯»æ‰¾å¸•ç´¯æ‰˜æœ€ä¼˜ç­–ç•¥ç»„åˆ"""
        pareto_optimal = []
        strategy_combinations = list(product(*self.strategies))

        for strategy_profile in strategy_combinations:
            is_pareto_optimal = True
            current_payoffs = self.get_payoff(strategy_profile)

            for other_profile in strategy_combinations:
                if other_profile != strategy_profile:
                    other_payoffs = self.get_payoff(other_profile)

# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¸•ç´¯æ‰˜æ”¹è¿›
                    if all(other_payoffs[i] >= current_payoffs[i] for i in range(self.n_players)) and \
                       any(other_payoffs[i] > current_payoffs[i] for i in range(self.n_players)):
                        is_pareto_optimal = False
                        break

            if is_pareto_optimal:
                pareto_optimal.append(strategy_profile)

        return pareto_optimal
```

## 2. åšå¼ˆç±»å‹

```python
class GameTypes:
    def __init__(self):
        self.game_types = {
            'zero_sum': ZeroSumGame,
            'cooperative': CooperativeGame,
            'non_cooperative': NonCooperativeGame,
            'repeated': RepeatedGame
        }

    def create_game(self, game_type, **kwargs):
        """åˆ›å»ºç‰¹å®šç±»å‹çš„åšå¼ˆ"""
        if game_type in self.game_types:
            game_class = self.game_types[game_type]
            return game_class(**kwargs)
        else:
            raise ValueError(f"Unknown game type: {game_type}")

class ZeroSumGame(Game):
    def __init__(self, players, strategies, payoffs):
        """é›¶å’Œåšå¼ˆ"""
        super().__init__(players, strategies, payoffs)
        self.verify_zero_sum()

    def verify_zero_sum(self):
        """éªŒè¯é›¶å’Œæ€§è´¨"""
        for strategy_profile in product(*self.strategies):
            payoffs = self.get_payoff(strategy_profile)
            if abs(sum(payoffs)) > 1e-10:
                raise ValueError("Game is not zero-sum")

    def find_minimax_strategy(self, player):
        """å¯»æ‰¾æœ€å°æœ€å¤§ç­–ç•¥"""
        if player == 0:
# ç©å®¶1é€‰æ‹©è¡Œï¼Œç©å®¶2é€‰æ‹©åˆ—
            payoff_matrix = self.build_payoff_matrix()

# è®¡ç®—æœ€å°æœ€å¤§ç­–ç•¥
            row_minima = np.min(payoff_matrix, axis=1)
            maximin = np.max(row_minima)
            maximin_strategy = np.argmax(row_minima)

            return maximin_strategy, maximin
        else:
# ç©å®¶2é€‰æ‹©åˆ—ï¼Œç©å®¶1é€‰æ‹©è¡Œ
            payoff_matrix = self.build_payoff_matrix()

# è®¡ç®—æœ€å¤§æœ€å°ç­–ç•¥
            column_maxima = np.max(payoff_matrix, axis=0)
            minimax = np.min(column_maxima)
            minimax_strategy = np.argmin(column_maxima)

            return minimax_strategy, minimax

    def build_payoff_matrix(self):
        """æ„å»ºæ”¯ä»˜çŸ©é˜µ"""
# æ ¹æ®åšå¼ˆç±»å‹æ„å»ºæ”¯ä»˜çŸ©é˜µ
        if self.game_type == "prisoners_dilemma":
# å›šå¾’å›°å¢ƒ
            return np.array([[[3, 3], [0, 5]], [[5, 0], [1, 1]]])
        elif self.game_type == "battle_of_sexes":
# æ€§åˆ«æˆ˜
            return np.array([[[2, 1], [0, 0]], [[0, 0], [1, 2]]])
        elif self.game_type == "chicken":
# æ‡¦å¤«åšå¼ˆ
            return np.array([[[3, 3], [1, 4]], [[4, 1], [0, 0]]])
        elif self.game_type == "coordination":
# åè°ƒåšå¼ˆ
            return np.array([[[1, 1], [0, 0]], [[0, 0], [1, 1]]])
        else:
# é»˜è®¤æ”¯ä»˜çŸ©é˜µ
            return np.array([[[3, 3], [0, 5]], [[5, 0], [1, 1]]])

class CooperativeGame(Game):
    def __init__(self, players, strategies, payoffs):
        """åˆä½œåšå¼ˆ"""
        super().__init__(players, strategies, payoffs)
        self.coalitions = self.generate_coalitions()

    def generate_coalitions(self):
        """ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„è”ç›Ÿ"""
        from itertools import combinations

        coalitions = []
        for i in range(1, self.n_players + 1):
            coalitions.extend(list(combinations(range(self.n_players), i)))

        return coalitions

    def characteristic_function(self, coalition):
        """ç‰¹å¾å‡½æ•°"""
# åŸºäºè”ç›Ÿç»“æ„å’Œåšå¼ˆç±»å‹è®¡ç®—ç‰¹å¾å‡½æ•°å€¼

        if not coalition:
            return 0

# è®¡ç®—è”ç›Ÿçš„æ€»ä»·å€¼
        total_value = 0

# åŸºäºè”ç›Ÿå¤§å°çš„åŸºç¡€ä»·å€¼
        base_value = len(coalition) * 10

# è€ƒè™‘è”ç›Ÿå†…éƒ¨çš„ååŒæ•ˆåº”
        synergy_bonus = self.calculate_synergy_bonus(coalition)

# è€ƒè™‘è”ç›Ÿå¤–éƒ¨çš„ç«äº‰æ•ˆåº”
        competition_penalty = self.calculate_competition_penalty(coalition)

        total_value = base_value + synergy_bonus - competition_penalty

        return max(0, total_value)  # ç¡®ä¿éè´Ÿ

    def calculate_synergy_bonus(self, coalition):
        """è®¡ç®—ååŒæ•ˆåº”å¥–åŠ±"""
        if len(coalition) <= 1:
            return 0

# åŸºäºè”ç›Ÿæˆå‘˜ä¹‹é—´çš„äº’è¡¥æ€§è®¡ç®—ååŒæ•ˆåº”
        synergy = 0
        for i, player1 in enumerate(coalition):
            for j, player2 in enumerate(coalition[i+1:], i+1):
# è®¡ç®—ä¸¤ä¸ªç©å®¶ä¹‹é—´çš„ååŒæ•ˆåº”
                player_synergy = self.get_player_synergy(player1, player2)
                synergy += player_synergy

        return synergy

    def calculate_competition_penalty(self, coalition):
        """è®¡ç®—ç«äº‰æ•ˆåº”æƒ©ç½š"""
# åŸºäºè”ç›Ÿå¤–éƒ¨çš„ç«äº‰å¼ºåº¦è®¡ç®—æƒ©ç½š
        outside_players = [p for p in range(self.n_players) if p not in coalition]

        if not outside_players:
            return 0

# è®¡ç®—å¤–éƒ¨ç«äº‰å¼ºåº¦
        competition_intensity = len(outside_players) * 2

# è€ƒè™‘è”ç›Ÿå¤§å°å¯¹ç«äº‰çš„å½±å“
        size_factor = len(coalition) / self.n_players

        return competition_intensity * size_factor

    def get_player_synergy(self, player1, player2):
        """è·å–ä¸¤ä¸ªç©å®¶ä¹‹é—´çš„ååŒæ•ˆåº”"""
# åŸºäºç©å®¶ç‰¹å¾è®¡ç®—ååŒæ•ˆåº”
# è¿™é‡Œå¯ä»¥æ ¹æ®å…·ä½“çš„åšå¼ˆç±»å‹å®šåˆ¶
        return 5  # åŸºç¡€ååŒæ•ˆåº”å€¼

    def find_core(self):
        """å¯»æ‰¾æ ¸"""
# æ ¸æ˜¯æ‰€æœ‰æ»¡è¶³ä¸ªä½“ç†æ€§å’Œé›†ä½“ç†æ€§çš„åˆ†é…

        core_allocations = []

# ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„åˆ†é…
        all_allocations = self.generate_all_allocations()

        for allocation in all_allocations:
            if self.is_in_core(allocation):
                core_allocations.append(allocation)

        return core_allocations

    def generate_all_allocations(self):
        """ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„åˆ†é…"""
# ä½¿ç”¨ç½‘æ ¼æœç´¢ç”Ÿæˆåˆ†é…
# ä¸ºäº†è®¡ç®—æ•ˆç‡ï¼Œä½¿ç”¨ç¦»æ•£åŒ–
        step = 1.0
        max_value = max(self.characteristic_function(coalition) for coalition in self.coalitions)

        allocations = []

# ç”Ÿæˆæ»¡è¶³æ•ˆç‡æ¡ä»¶çš„åˆ†é…
        for i in range(int(max_value / step) + 1):
            for j in range(int(max_value / step) + 1):
                for k in range(int(max_value / step) + 1):
                    allocation = [i * step, j * step, k * step]

# æ£€æŸ¥æ•ˆç‡æ¡ä»¶
                    if sum(allocation) <= self.characteristic_function(tuple(range(self.n_players))):
                        allocations.append(allocation)

        return allocations

    def is_in_core(self, allocation):
        """æ£€æŸ¥åˆ†é…æ˜¯å¦åœ¨æ ¸ä¸­"""
# æ£€æŸ¥ä¸ªä½“ç†æ€§
        for i in range(self.n_players):
            if allocation[i] < self.characteristic_function((i,)):
                return False

# æ£€æŸ¥é›†ä½“ç†æ€§
        for coalition in self.coalitions:
            if len(coalition) > 1:  # è·³è¿‡å•äººè”ç›Ÿ
                coalition_value = sum(allocation[i] for i in coalition)
                if coalition_value < self.characteristic_function(coalition):
                    return False

        return True

    def find_shapley_value(self):
        """è®¡ç®—Shapleyå€¼"""
        shapley_values = [0] * self.n_players

        for player in range(self.n_players):
            for coalition in self.coalitions:
                if player in coalition:
# è®¡ç®—è¾¹é™…è´¡çŒ®
                    coalition_without_player = tuple(p for p in coalition if p != player)
                    marginal_contribution = self.characteristic_function(coalition) - \
                                         self.characteristic_function(coalition_without_player)

# è®¡ç®—æƒé‡
                    weight = len(coalition) * len([c for c in self.coalitions if player in c])

                    shapley_values[player] += marginal_contribution / weight

        return shapley_values
```

## 3. ç­–ç•¥å‹åšå¼ˆ

### 3.1. ç­–ç•¥å‹åšå¼ˆè¡¨ç¤º

```python
class StrategicGame(Game):
    def __init__(self, players, strategies, payoffs):
        """ç­–ç•¥å‹åšå¼ˆ"""
        super().__init__(players, strategies, payoffs)
        self.payoff_matrix = self.build_payoff_matrix()

    def build_payoff_matrix(self):
        """æ„å»ºæ”¯ä»˜çŸ©é˜µ"""
# æ ¹æ®åšå¼ˆç±»å‹å’Œç­–ç•¥æ„å»ºæ”¯ä»˜çŸ©é˜µ

        if self.n_players == 2:
# åŒäººåšå¼ˆ
            n_strategies_1 = len(self.strategies[0])
            n_strategies_2 = len(self.strategies[1])

            payoff_matrix = np.zeros((n_strategies_1, n_strategies_2, 2))

            for i, strategy1 in enumerate(self.strategies[0]):
                for j, strategy2 in enumerate(self.strategies[1]):
                    strategy_profile = (strategy1, strategy2)
                    payoffs = self.get_payoff(strategy_profile)
                    payoff_matrix[i, j] = payoffs

            return payoff_matrix
        else:
# å¤šäººåšå¼ˆ
            strategy_counts = [len(strategies) for strategies in self.strategies]
            payoff_matrix = np.zeros(strategy_counts + [self.n_players])

# ç”Ÿæˆæ‰€æœ‰ç­–ç•¥ç»„åˆ
            strategy_combinations = list(product(*self.strategies))

            for combination in strategy_combinations:
                payoffs = self.get_payoff(combination)

# å°†æ”¯ä»˜å¡«å…¥çŸ©é˜µ
                indices = []
                for i, strategy in enumerate(combination):
                    strategy_index = self.strategies[i].index(strategy)
                    indices.append(strategy_index)

                for player in range(self.n_players):
                    payoff_matrix[tuple(indices)][player] = payoffs[player]

            return payoff_matrix

    def find_pure_strategy_equilibria(self):
        """å¯»æ‰¾çº¯ç­–ç•¥å‡è¡¡"""
        return self.find_nash_equilibria()

    def find_mixed_strategy_equilibria(self):
        """å¯»æ‰¾æ··åˆç­–ç•¥å‡è¡¡"""
        if self.n_players == 2:
            return self.find_two_player_mixed_equilibrium()
        else:
            return self.find_multi_player_mixed_equilibrium()

    def find_two_player_mixed_equilibrium(self):
        """å¯»æ‰¾åŒäººåšå¼ˆçš„æ··åˆç­–ç•¥å‡è¡¡"""
        equilibria = []

# ä½¿ç”¨çº¿æ€§è§„åˆ’æ±‚è§£æ··åˆç­–ç•¥å‡è¡¡
        for player in range(2):
            other_player = 1 - player

# æ„å»ºçº¿æ€§è§„åˆ’é—®é¢˜
            n_strategies = len(self.strategies[player])
            n_other_strategies = len(self.strategies[other_player])

# ç›®æ ‡å‡½æ•°ï¼šæœ€å¤§åŒ–æœ€å°æœŸæœ›æ”¯ä»˜
            c = np.zeros(n_strategies + 1)  # ç­–ç•¥æ¦‚ç‡ + æœŸæœ›æ”¯ä»˜
            c[-1] = 1  # æœ€å¤§åŒ–æœŸæœ›æ”¯ä»˜

# çº¦æŸæ¡ä»¶
            A = np.zeros((n_other_strategies + 1, n_strategies + 1))
            b = np.zeros(n_other_strategies + 1)

# æ¦‚ç‡å’Œä¸º1çš„çº¦æŸ
            A[0, :n_strategies] = 1
            b[0] = 1

# æœŸæœ›æ”¯ä»˜çº¦æŸ
            for j, other_strategy in enumerate(self.strategies[other_player]):
                for i, strategy in enumerate(self.strategies[player]):
                    strategy_profile = (strategy, other_strategy) if player == 0 else (other_strategy, strategy)
                    payoff = self.get_payoff(strategy_profile)[player]
                    A[j+1, i] = payoff
                A[j+1, -1] = -1  # æœŸæœ›æ”¯ä»˜å˜é‡
                b[j+1] = 0

# æ±‚è§£çº¿æ€§è§„åˆ’
            try:
                from scipy.optimize import linprog
                result = linprog(c, A_ub=A, b_ub=b, bounds=[(0, None)] * (n_strategies + 1))

                if result.success:
                    equilibrium = {
                        'player': player,
                        'probabilities': result.x[:n_strategies],
                        'expected_payoff': result.x[-1]
                    }
                    equilibria.append(equilibrium)
            except ImportError:
# å¦‚æœæ²¡æœ‰scipyï¼Œä½¿ç”¨ç®€åŒ–ç®—æ³•
                equilibria.extend(self.simplified_mixed_equilibrium(player))

        return equilibria

    def simplified_mixed_equilibrium(self, player):
        """ç®€åŒ–çš„æ··åˆç­–ç•¥å‡è¡¡è®¡ç®—"""
        equilibria = []

# ä½¿ç”¨è¿­ä»£ç®—æ³•
        n_strategies = len(self.strategies[player])
        probabilities = np.ones(n_strategies) / n_strategies  # å‡åŒ€åˆ†å¸ƒ

        for iteration in range(100):
# è®¡ç®—æœ€ä½³å“åº”
            best_responses = self.calculate_best_responses(player, probabilities)

# æ›´æ–°æ¦‚ç‡
            new_probabilities = np.zeros(n_strategies)
            for strategy_idx in best_responses:
                new_probabilities[strategy_idx] += 1
            new_probabilities /= len(best_responses)

# æ£€æŸ¥æ”¶æ•›
            if np.allclose(probabilities, new_probabilities, atol=1e-6):
                break

            probabilities = new_probabilities

        equilibrium = {
            'player': player,
            'probabilities': probabilities,
            'expected_payoff': self.calculate_expected_payoff(player, probabilities)
        }

        return [equilibrium]

    def calculate_best_responses(self, player, opponent_probabilities):
        """è®¡ç®—æœ€ä½³å“åº”"""
        best_responses = []
        best_payoff = float('-inf')

        for strategy_idx, strategy in enumerate(self.strategies[player]):
            expected_payoff = 0

            for other_strategy_idx, other_strategy in enumerate(self.strategies[1-player]):
                strategy_profile = (strategy, other_strategy) if player == 0 else (other_strategy, strategy)
                payoff = self.get_payoff(strategy_profile)[player]
                expected_payoff += opponent_probabilities[other_strategy_idx] * payoff

            if expected_payoff > best_payoff:
                best_payoff = expected_payoff
                best_responses = [strategy_idx]
            elif expected_payoff == best_payoff:
                best_responses.append(strategy_idx)

        return best_responses

    def calculate_expected_payoff(self, player, probabilities):
        """è®¡ç®—æœŸæœ›æ”¯ä»˜"""
        expected_payoff = 0

        for strategy_idx, strategy in enumerate(self.strategies[player]):
            strategy_prob = probabilities[strategy_idx]

            for other_strategy in self.strategies[1-player]:
                strategy_profile = (strategy, other_strategy) if player == 0 else (other_strategy, strategy)
                payoff = self.get_payoff(strategy_profile)[player]
                expected_payoff += strategy_prob * payoff

        return expected_payoff

    def find_multi_player_mixed_equilibrium(self):
        """å¯»æ‰¾å¤šäººåšå¼ˆçš„æ··åˆç­–ç•¥å‡è¡¡"""
# ä½¿ç”¨è¿­ä»£ç®—æ³•å¯»æ‰¾å¤šäººåšå¼ˆçš„æ··åˆç­–ç•¥å‡è¡¡
        equilibria = []

        for player in range(self.n_players):
            equilibrium = self.find_player_mixed_equilibrium(player)
            equilibria.append(equilibrium)

        return equilibria

    def find_player_mixed_equilibrium(self, player):
        """å¯»æ‰¾å•ä¸ªç©å®¶çš„æ··åˆç­–ç•¥å‡è¡¡"""
        n_strategies = len(self.strategies[player])
        probabilities = np.ones(n_strategies) / n_strategies

        for iteration in range(50):
# è®¡ç®—ç»™å®šå…¶ä»–ç©å®¶ç­–ç•¥ä¸‹çš„æœ€ä½³å“åº”
            best_responses = self.calculate_multi_player_best_responses(player, probabilities)

# æ›´æ–°æ¦‚ç‡
            new_probabilities = np.zeros(n_strategies)
            for strategy_idx in best_responses:
                new_probabilities[strategy_idx] += 1
            new_probabilities /= len(best_responses)

            if np.allclose(probabilities, new_probabilities, atol=1e-6):
                break

            probabilities = new_probabilities

        return {
            'player': player,
            'probabilities': probabilities,
            'expected_payoff': self.calculate_multi_player_expected_payoff(player, probabilities)
        }

    def calculate_multi_player_best_responses(self, player, probabilities):
        """è®¡ç®—å¤šäººåšå¼ˆä¸­çš„æœ€ä½³å“åº”"""
        best_responses = []
        best_payoff = float('-inf')

        for strategy_idx, strategy in enumerate(self.strategies[player]):
            expected_payoff = self.calculate_multi_player_expected_payoff(player, [strategy_idx])

            if expected_payoff > best_payoff:
                best_payoff = expected_payoff
                best_responses = [strategy_idx]
            elif expected_payoff == best_payoff:
                best_responses.append(strategy_idx)

        return best_responses

    def calculate_multi_player_expected_payoff(self, player, strategy_indices):
        """è®¡ç®—å¤šäººåšå¼ˆä¸­çš„æœŸæœ›æ”¯ä»˜"""
        expected_payoff = 0

# ç”Ÿæˆæ‰€æœ‰å…¶ä»–ç©å®¶çš„ç­–ç•¥ç»„åˆ
        other_players = [i for i in range(self.n_players) if i != player]
        other_strategies = [self.strategies[i] for i in other_players]

        for strategy_combination in product(*other_strategies):
# æ„å»ºå®Œæ•´çš„ç­–ç•¥ç»„åˆ
            full_strategy_profile = list(strategy_combination)
            full_strategy_profile.insert(player, self.strategies[player][strategy_indices[0]])
            full_strategy_profile = tuple(full_strategy_profile)

            payoff = self.get_payoff(full_strategy_profile)[player]
            expected_payoff += payoff

        return expected_payoff / len(list(product(*other_strategies)))

    def best_response_correspondence(self, player, opponent_strategies):
        """æœ€ä½³å“åº”å¯¹åº”"""
        best_responses = []
        best_payoff = float('-inf')

        for strategy in self.strategies[player]:
# æ„å»ºç­–ç•¥ç»„åˆ
            strategy_profile = list(opponent_strategies)
            strategy_profile.insert(player, strategy)
            strategy_profile = tuple(strategy_profile)

            payoff = self.get_payoff(strategy_profile)[player]
            if payoff > best_payoff:
                best_payoff = payoff
                best_responses = [strategy]
            elif payoff == best_payoff:
                best_responses.append(strategy)

        return best_responses

    def is_strictly_dominated(self, player, strategy):
        """æ£€æŸ¥æ˜¯å¦ä¸ºä¸¥æ ¼è¢«å ä¼˜ç­–ç•¥"""
        for other_strategy in self.strategies[player]:
            if other_strategy != strategy:
# æ£€æŸ¥other_strategyæ˜¯å¦ä¸¥æ ¼å ä¼˜strategy
                is_dominant = True
                for opponent_strategies in product(*[self.strategies[i] for i in range(self.n_players) if i != player]):
                    strategy_profile_with_strategy = list(opponent_strategies)
                    strategy_profile_with_strategy.insert(player, strategy)
                    strategy_profile_with_strategy = tuple(strategy_profile_with_strategy)

                    strategy_profile_with_other = list(opponent_strategies)
                    strategy_profile_with_other.insert(player, other_strategy)
                    strategy_profile_with_other = tuple(strategy_profile_with_other)

                    if self.get_payoff(strategy_profile_with_strategy)[player] >= \
                       self.get_payoff(strategy_profile_with_other)[player]:
                        is_dominant = False
                        break

                if is_dominant:
                    return True

        return False

    def iterated_elimination_of_dominated_strategies(self):
        """è¿­ä»£æ¶ˆé™¤è¢«å ä¼˜ç­–ç•¥"""
        eliminated_strategies = {player: set() for player in range(self.n_players)}

        while True:
            eliminated_this_round = False

            for player in range(self.n_players):
                remaining_strategies = [s for s in self.strategies[player]
                                     if s not in eliminated_strategies[player]]

                for strategy in remaining_strategies:
                    if self.is_strictly_dominated(player, strategy):
                        eliminated_strategies[player].add(strategy)
                        eliminated_this_round = True

            if not eliminated_this_round:
                break

        return eliminated_strategies
```

## 4. åšå¼ˆåˆ†æå·¥å…·

```python
class GameAnalysis:
    def __init__(self, game):
        self.game = game

    def comprehensive_analysis(self):
        """ç»¼åˆåˆ†æ"""
        analysis = {}

# çº³ä»€å‡è¡¡
        analysis['nash_equilibria'] = self.game.find_nash_equilibria()

# å ä¼˜ç­–ç•¥
        analysis['dominant_strategies'] = self.game.find_dominant_strategies()

# è¢«å ä¼˜ç­–ç•¥
        if isinstance(self.game, StrategicGame):
            analysis['dominated_strategies'] = self.game.iterated_elimination_of_dominated_strategies()

# å¸•ç´¯æ‰˜æœ€ä¼˜
        analysis['pareto_optimal'] = self.find_pareto_optimal()

# ç¤¾ä¼šæœ€ä¼˜
        analysis['social_optimal'] = self.find_social_optimal()

        return analysis

    def find_pareto_optimal(self):
        """å¯»æ‰¾å¸•ç´¯æ‰˜æœ€ä¼˜"""
        pareto_optimal = []
        strategy_combinations = list(product(*self.game.strategies))

        for strategy_profile in strategy_combinations:
            is_pareto_optimal = True
            current_payoffs = self.game.get_payoff(strategy_profile)

            for other_profile in strategy_combinations:
                if other_profile != strategy_profile:
                    other_payoffs = self.game.get_payoff(other_profile)

# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¸•ç´¯æ‰˜æ”¹è¿›
                    if all(other_payoffs[i] >= current_payoffs[i] for i in range(self.game.n_players)) and \
                       any(other_payoffs[i] > current_payoffs[i] for i in range(self.game.n_players)):
                        is_pareto_optimal = False
                        break

            if is_pareto_optimal:
                pareto_optimal.append(strategy_profile)

        return pareto_optimal

    def find_social_optimal(self):
        """å¯»æ‰¾ç¤¾ä¼šæœ€ä¼˜"""
        strategy_combinations = list(product(*self.game.strategies))
        best_social_welfare = float('-inf')
        social_optimal = []

        for strategy_profile in strategy_combinations:
            payoffs = self.game.get_payoff(strategy_profile)
            social_welfare = sum(payoffs)

            if social_welfare > best_social_welfare:
                best_social_welfare = social_welfare
                social_optimal = [strategy_profile]
            elif social_welfare == best_social_welfare:
                social_optimal.append(strategy_profile)

        return social_optimal

    def efficiency_analysis(self):
        """æ•ˆç‡åˆ†æ"""
        nash_equilibria = self.game.find_nash_equilibria()
        social_optimal = self.find_social_optimal()

        efficiency_measures = {}

        for equilibrium in nash_equilibria:
            equilibrium_payoffs = self.game.get_payoff(equilibrium)
            equilibrium_welfare = sum(equilibrium_payoffs)

# è®¡ç®—æ•ˆç‡
            max_welfare = sum(self.game.get_payoff(social_optimal[0]))
            efficiency = equilibrium_welfare / max_welfare if max_welfare > 0 else 0

            efficiency_measures[equilibrium] = {
                'welfare': equilibrium_welfare,
                'efficiency': efficiency,
                'payoffs': equilibrium_payoffs
            }

        return efficiency_measures
```

## 5. æ‰©å±•å‹åšå¼ˆ

### 5.1. æ‰©å±•å‹åšå¼ˆè¡¨ç¤º

```python
class ExtensiveGame:
    def __init__(self, players, game_tree):
        """
        æ‰©å±•å‹åšå¼ˆ
        players: ç©å®¶åˆ—è¡¨
        game_tree: åšå¼ˆæ ‘
        """
        self.players = players
        self.game_tree = game_tree
        self.n_players = len(players)

    def find_subgame_perfect_equilibria(self):
        """å¯»æ‰¾å­åšå¼ˆå®Œç¾å‡è¡¡"""
# ä½¿ç”¨é€†å‘å½’çº³æ³•
        equilibria = self.backward_induction()
        return equilibria

    def backward_induction(self):
        """é€†å‘å½’çº³æ³•"""
        equilibrium_actions = {}

# ä»å¶å­èŠ‚ç‚¹å¼€å§‹ï¼Œå‘ä¸Šè®¡ç®—æœ€ä¼˜è¡ŒåŠ¨
        leaf_nodes = self.game_tree.get_leaf_nodes()

# ä¸ºæ¯ä¸ªå¶å­èŠ‚ç‚¹è®¡ç®—æœ€ä¼˜è¡ŒåŠ¨
        for leaf in leaf_nodes:
            if leaf.payoffs:
                best_action = leaf.get_optimal_action()
                if best_action:
                    equilibrium_actions[leaf] = best_action

# å‘ä¸Šä¼ æ’­æœ€ä¼˜è¡ŒåŠ¨
        self.propagate_optimal_actions(self.game_tree.root, equilibrium_actions)

        return equilibrium_actions

    def propagate_optimal_actions(self, node, equilibrium_actions):
        """ä¼ æ’­æœ€ä¼˜è¡ŒåŠ¨"""
        if node.is_leaf():
            return

# é€’å½’å¤„ç†å­èŠ‚ç‚¹
        for child in node.children:
            self.propagate_optimal_actions(child, equilibrium_actions)

# è®¡ç®—å½“å‰èŠ‚ç‚¹çš„æœ€ä¼˜è¡ŒåŠ¨
        best_action = node.get_optimal_action()
        if best_action:
            equilibrium_actions[node] = best_action

    def find_nash_equilibria(self):
        """å¯»æ‰¾çº³ä»€å‡è¡¡"""
# å°†æ‰©å±•å‹åšå¼ˆè½¬æ¢ä¸ºç­–ç•¥å‹åšå¼ˆ
        strategic_form = self.convert_to_strategic_form()
        return strategic_form.find_nash_equilibria()

    def convert_to_strategic_form(self):
        """è½¬æ¢ä¸ºç­–ç•¥å‹åšå¼ˆ"""
# æ”¶é›†æ‰€æœ‰ç­–ç•¥ç»„åˆ
        strategies = self.collect_all_strategies()

# æ„å»ºæ”¯ä»˜çŸ©é˜µ
        payoff_matrix = self.build_payoff_matrix(strategies)

# åˆ›å»ºç­–ç•¥å‹åšå¼ˆ
        strategic_game = StrategicGame(
            players=self.players,
            strategies=strategies,
            payoff_matrix=payoff_matrix
        )

        return strategic_game

    def collect_all_strategies(self):
        """æ”¶é›†æ‰€æœ‰ç­–ç•¥"""
        strategies = []
        for player in self.players:
            player_strategies = self.collect_player_strategies(player)
            strategies.append(player_strategies)
        return strategies

    def collect_player_strategies(self, player):
        """æ”¶é›†ç©å®¶çš„ç­–ç•¥"""
        strategies = []
        self.collect_strategies_from_node(self.game_tree.root, player, [], strategies)
        return strategies

    def collect_strategies_from_node(self, node, player, current_strategy, strategies):
        """ä»èŠ‚ç‚¹æ”¶é›†ç­–ç•¥"""
        if node.player == player:
# ä¸ºå½“å‰ç©å®¶æ·»åŠ è¡ŒåŠ¨é€‰æ‹©
            for i, action in enumerate(node.actions):
                new_strategy = current_strategy + [(node, action)]
                self.collect_strategies_from_children(node.children[i], player, new_strategy, strategies)
        else:
# ä¸ºå…¶ä»–ç©å®¶ç»§ç»­æ”¶é›†
            for child in node.children:
                self.collect_strategies_from_node(child, player, current_strategy, strategies)

    def collect_strategies_from_children(self, node, player, current_strategy, strategies):
        """ä»å­èŠ‚ç‚¹æ”¶é›†ç­–ç•¥"""
        if node.is_leaf():
            strategies.append(current_strategy)
        else:
            self.collect_strategies_from_node(node, player, current_strategy, strategies)

    def build_payoff_matrix(self, strategies):
        """æ„å»ºæ”¯ä»˜çŸ©é˜µ"""
        payoff_matrix = {}

# ç”Ÿæˆæ‰€æœ‰ç­–ç•¥ç»„åˆ
        strategy_combinations = self.generate_strategy_combinations(strategies)

        for combination in strategy_combinations:
            payoffs = self.calculate_payoffs_for_combination(combination)
            payoff_matrix[combination] = payoffs

        return payoff_matrix

    def generate_strategy_combinations(self, strategies):
        """ç”Ÿæˆç­–ç•¥ç»„åˆ"""
        from itertools import product
        return list(product(*strategies))

    def calculate_payoffs_for_combination(self, strategy_combination):
        """è®¡ç®—ç­–ç•¥ç»„åˆçš„æ”¯ä»˜"""
# æ¨¡æ‹Ÿåšå¼ˆæ‰§è¡Œ
        current_node = self.game_tree.root
        payoffs = [0] * len(self.players)

        while not current_node.is_leaf():
            player = current_node.player
            strategy = strategy_combination[player]

# æ‰¾åˆ°å¯¹åº”çš„è¡ŒåŠ¨
            action = self.find_action_for_strategy(current_node, strategy)

# ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
            current_node = self.find_next_node(current_node, action)

# è·å–æœ€ç»ˆæ”¯ä»˜
        if current_node.payoffs:
            payoffs = current_node.payoffs

        return payoffs

    def find_action_for_strategy(self, node, strategy):
        """æ ¹æ®ç­–ç•¥æ‰¾åˆ°è¡ŒåŠ¨"""
        for node_action, action in strategy:
            if node_action == node:
                return action
        return None

    def find_next_node(self, node, action):
        """æ‰¾åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹"""
        for i, node_action in enumerate(node.actions):
            if node_action == action:
                return node.children[i]
        return node.children[0]  # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªå­èŠ‚ç‚¹

class GameTree:
    def __init__(self, root):
        """
        åšå¼ˆæ ‘
        root: æ ¹èŠ‚ç‚¹
        """
        self.root = root

    def get_all_nodes(self):
        """è·å–æ‰€æœ‰èŠ‚ç‚¹"""
        nodes = []
        self.collect_nodes(self.root, nodes)
        return nodes

    def collect_nodes(self, node, nodes):
        """æ”¶é›†èŠ‚ç‚¹"""
        nodes.append(node)
        for child in node.children:
            self.collect_nodes(child, nodes)

    def get_leaf_nodes(self):
        """è·å–å¶å­èŠ‚ç‚¹"""
        leaf_nodes = []
        self.collect_leaf_nodes(self.root, leaf_nodes)
        return leaf_nodes

    def collect_leaf_nodes(self, node, leaf_nodes):
        """æ”¶é›†å¶å­èŠ‚ç‚¹"""
        if not node.children:
            leaf_nodes.append(node)
        else:
            for child in node.children:
                self.collect_leaf_nodes(child, leaf_nodes)

class GameNode:
    def __init__(self, player, actions=None, payoffs=None):
        """
        åšå¼ˆèŠ‚ç‚¹
        player: ç©å®¶
        actions: å¯ç”¨è¡ŒåŠ¨
        payoffs: æ”¯ä»˜
        """
        self.player = player
        self.actions = actions or []
        self.payoffs = payoffs
        self.children = []

    def add_child(self, child):
        """æ·»åŠ å­èŠ‚ç‚¹"""
        self.children.append(child)

    def is_leaf(self):
        """æ˜¯å¦ä¸ºå¶å­èŠ‚ç‚¹"""
        return len(self.children) == 0

    def get_optimal_action(self):
        """è·å–æœ€ä¼˜è¡ŒåŠ¨"""
        if self.is_leaf():
            return None

        best_action = None
        best_payoff = float('-inf')

        for i, child in enumerate(self.children):
            if child.payoffs and child.payoffs[self.player] > best_payoff:
                best_payoff = child.payoffs[self.player]
                best_action = self.actions[i]

        return best_action
```

## 6. åŠ¨æ€åšå¼ˆ

```python
class DynamicGame(ExtensiveGame):
    def __init__(self, players, game_tree, discount_factor=1.0):
        """åŠ¨æ€åšå¼ˆ"""
        super().__init__(players, game_tree)
        self.discount_factor = discount_factor

    def find_subgame_perfect_equilibrium(self):
        """å¯»æ‰¾å­åšå¼ˆå®Œç¾å‡è¡¡"""
        return self.backward_induction()

    def backward_induction(self):
        """é€†å‘å½’çº³æ³•"""
        equilibrium_actions = {}

# ä»å¶å­èŠ‚ç‚¹å¼€å§‹ï¼Œå‘ä¸Šè®¡ç®—æœ€ä¼˜è¡ŒåŠ¨
        leaf_nodes = self.game_tree.get_leaf_nodes()

# ä¸ºæ¯ä¸ªå¶å­èŠ‚ç‚¹è®¡ç®—æœ€ä¼˜è¡ŒåŠ¨
        for leaf in leaf_nodes:
            if leaf.payoffs:
                best_action = leaf.get_optimal_action()
                if best_action:
                    equilibrium_actions[leaf] = best_action

# å‘ä¸Šä¼ æ’­æœ€ä¼˜è¡ŒåŠ¨
        self.propagate_optimal_actions(self.game_tree.root, equilibrium_actions)

        return equilibrium_actions

    def propagate_optimal_actions(self, node, equilibrium_actions):
        """ä¼ æ’­æœ€ä¼˜è¡ŒåŠ¨"""
        if node.is_leaf():
            return

# é€’å½’å¤„ç†å­èŠ‚ç‚¹
        for child in node.children:
            self.propagate_optimal_actions(child, equilibrium_actions)

# è®¡ç®—å½“å‰èŠ‚ç‚¹çš„æœ€ä¼˜è¡ŒåŠ¨
        best_action = node.get_optimal_action()
        if best_action:
            equilibrium_actions[node] = best_action

    def calculate_present_value(self, payoffs, period):
        """è®¡ç®—ç°å€¼"""
        return [payoff * (self.discount_factor ** period) for payoff in payoffs]

    def find_stationary_equilibrium(self):
        """å¯»æ‰¾ç¨³æ€å‡è¡¡"""
# ä½¿ç”¨è¿­ä»£æ–¹æ³•å¯»æ‰¾ç¨³æ€å‡è¡¡
        max_iterations = 1000
        tolerance = 1e-6

# åˆå§‹åŒ–ç­–ç•¥åˆ†å¸ƒ
        n_players = len(self.players)
        strategy_distributions = []
        for player in self.players:
            n_strategies = len(self.get_player_strategies(player))
            distribution = np.ones(n_strategies) / n_strategies
            strategy_distributions.append(distribution)

# è¿­ä»£æ›´æ–°ç­–ç•¥åˆ†å¸ƒ
        for iteration in range(max_iterations):
            old_distributions = [dist.copy() for dist in strategy_distributions]

# æ›´æ–°æ¯ä¸ªç©å®¶çš„ç­–ç•¥åˆ†å¸ƒ
            for player_idx in range(n_players):
                strategy_distributions[player_idx] = self.update_player_strategy(
                    player_idx, strategy_distributions
                )

# æ£€æŸ¥æ”¶æ•›æ€§
            converged = True
            for i in range(n_players):
                if np.max(np.abs(strategy_distributions[i] - old_distributions[i])) > tolerance:
                    converged = False
                    break

            if converged:
                break

        return {
            'strategy_distributions': strategy_distributions,
            'iterations': iteration + 1,
            'converged': converged
        }

    def update_player_strategy(self, player_idx, strategy_distributions):
        """æ›´æ–°ç©å®¶ç­–ç•¥åˆ†å¸ƒ"""
# è®¡ç®—æœŸæœ›æ”¯ä»˜
        expected_payoffs = self.calculate_expected_payoffs(player_idx, strategy_distributions)

# ä½¿ç”¨softmaxæ›´æ–°ç­–ç•¥åˆ†å¸ƒ
        temperature = 0.1
        exp_payoffs = np.exp(expected_payoffs / temperature)
        new_distribution = exp_payoffs / np.sum(exp_payoffs)

        return new_distribution

    def calculate_expected_payoffs(self, player_idx, strategy_distributions):
        """è®¡ç®—æœŸæœ›æ”¯ä»˜"""
        n_strategies = len(self.get_player_strategies(player_idx))
        expected_payoffs = np.zeros(n_strategies)

# è®¡ç®—æ¯ä¸ªç­–ç•¥çš„æœŸæœ›æ”¯ä»˜
        for strategy_idx in range(n_strategies):
            payoff = 0
            total_prob = 0

# éå†æ‰€æœ‰å¯èƒ½çš„å¯¹æ‰‹ç­–ç•¥ç»„åˆ
            opponent_combinations = self.generate_opponent_combinations(player_idx, strategy_distributions)

            for opponent_combo, prob in opponent_combinations:
                strategy_profile = list(opponent_combo)
                strategy_profile.insert(player_idx, strategy_idx)

                game_payoff = self.get_payoff_for_strategy_profile(strategy_profile)
                payoff += game_payoff[player_idx] * prob
                total_prob += prob

            if total_prob > 0:
                expected_payoffs[strategy_idx] = payoff / total_prob

        return expected_payoffs

    def generate_opponent_combinations(self, player_idx, strategy_distributions):
        """ç”Ÿæˆå¯¹æ‰‹ç­–ç•¥ç»„åˆ"""
        from itertools import product

        opponent_players = [i for i in range(len(self.players)) if i != player_idx]
        opponent_distributions = [strategy_distributions[i] for i in opponent_players]

        combinations = []
        for strategy_combo in product(*[range(len(dist)) for dist in opponent_distributions]):
            prob = 1.0
            for i, strategy_idx in enumerate(strategy_combo):
                prob *= opponent_distributions[i][strategy_idx]
            combinations.append((strategy_combo, prob))

        return combinations

    def get_player_strategies(self, player):
        """è·å–ç©å®¶çš„ç­–ç•¥"""
# åŸºäºåšå¼ˆç»“æ„ç”Ÿæˆç­–ç•¥
        strategies = []

# æ ¹æ®ç©å®¶ç±»å‹ç”Ÿæˆä¸åŒç­–ç•¥
        if player == 0:  # ç©å®¶1
            strategies = ['Cooperate', 'Defect', 'TitForTat', 'Pavlov']
        elif player == 1:  # ç©å®¶2
            strategies = ['Cooperate', 'Defect', 'TitForTat', 'Pavlov']
        else:
# å¯¹äºæ›´å¤šç©å®¶ï¼Œç”Ÿæˆé€šç”¨ç­–ç•¥
            strategies = [f'Strategy_{i}' for i in range(len(self.game.strategies[player]))]

        return strategies

    def get_payoff_for_strategy_profile(self, strategy_profile):
        """è·å–ç­–ç•¥ç»„åˆçš„æ”¯ä»˜"""
# åŸºäºç­–ç•¥ç»„åˆè®¡ç®—æ”¯ä»˜
        payoffs = []

        for player in range(len(self.players)):
            strategy = strategy_profile[player]

# æ ¹æ®ç­–ç•¥ç±»å‹è®¡ç®—æ”¯ä»˜
            if strategy == 'Cooperate':
                base_payoff = 3
            elif strategy == 'Defect':
                base_payoff = 5
            elif strategy == 'TitForTat':
                base_payoff = 4
            elif strategy == 'Pavlov':
                base_payoff = 3.5
            else:
                base_payoff = np.random.uniform(2, 6)

# è€ƒè™‘ç­–ç•¥äº’åŠ¨æ•ˆåº”
            interaction_bonus = 0
            for other_player in range(len(self.players)):
                if other_player != player:
                    other_strategy = strategy_profile[other_player]

# è®¡ç®—ç­–ç•¥äº’åŠ¨
                    if strategy == 'Cooperate' and other_strategy == 'Cooperate':
                        interaction_bonus += 1
                    elif strategy == 'Defect' and other_strategy == 'Cooperate':
                        interaction_bonus += 2
                    elif strategy == 'TitForTat' and other_strategy == 'Cooperate':
                        interaction_bonus += 0.5

            final_payoff = base_payoff + interaction_bonus
            payoffs.append(final_payoff)

        return payoffs
```

## 7. çº³ä»€å‡è¡¡

### 7.1. çº³ä»€å‡è¡¡è®¡ç®—

```python
class NashEquilibrium:
    def __init__(self, game):
        self.game = game

    def find_all_equilibria(self):
        """å¯»æ‰¾æ‰€æœ‰çº³ä»€å‡è¡¡"""
        equilibria = {
            'pure_strategy': self.find_pure_strategy_equilibria(),
            'mixed_strategy': self.find_mixed_strategy_equilibria()
        }
        return equilibria

    def find_pure_strategy_equilibria(self):
        """å¯»æ‰¾çº¯ç­–ç•¥çº³ä»€å‡è¡¡"""
        return self.game.find_nash_equilibria()

    def find_mixed_strategy_equilibria(self):
        """å¯»æ‰¾æ··åˆç­–ç•¥çº³ä»€å‡è¡¡"""
        equilibria = []

# å¯¹äº2x2åšå¼ˆï¼Œä½¿ç”¨è§£ææ–¹æ³•
        if self.game.n_players == 2 and len(self.game.strategies[0]) == 2 and len(self.game.strategies[1]) == 2:
            mixed_eq = MixedStrategyEquilibrium(self.game)
            equilibrium = mixed_eq.solve_2x2_game()
            equilibria.append(equilibrium)
        else:
# å¯¹äºæ›´å¤æ‚çš„åšå¼ˆï¼Œä½¿ç”¨æ•°å€¼æ–¹æ³•
            equilibria = self.find_mixed_equilibria_numerical()

        return equilibria

    def find_mixed_equilibria_numerical(self):
        """ä½¿ç”¨æ•°å€¼æ–¹æ³•å¯»æ‰¾æ··åˆç­–ç•¥å‡è¡¡"""
        from scipy.optimize import minimize

        equilibria = []
        n_players = self.game.n_players

# ä¸ºæ¯ä¸ªç©å®¶å®šä¹‰ç­–ç•¥ç©ºé—´
        strategy_spaces = []
        for player in range(n_players):
            n_strategies = len(self.game.strategies[player])
            strategy_spaces.append(n_strategies - 1)  # è‡ªç”±åº¦

# å®šä¹‰ç›®æ ‡å‡½æ•°ï¼šæœ€å°åŒ–åç¦»å‡è¡¡çš„æ¿€åŠ±
        def objective_function(strategy_vector):
# å°†å‘é‡è½¬æ¢ä¸ºç­–ç•¥åˆ†å¸ƒ
            distributions = self.vector_to_distributions(strategy_vector, strategy_spaces)

# è®¡ç®—æ¯ä¸ªç©å®¶çš„æœ€ä¼˜å“åº”
            total_deviation = 0
            for player in range(n_players):
                best_response = self.find_best_response(player, distributions)
                current_payoff = self.calculate_player_payoff(player, distributions)
                deviation = best_response - current_payoff
                total_deviation += abs(deviation)

            return total_deviation

# å¤šæ¬¡ä¼˜åŒ–ï¼Œå¯»æ‰¾ä¸åŒçš„å‡è¡¡
        for attempt in range(10):
# éšæœºåˆå§‹ç‚¹
            initial_point = np.random.random(sum(strategy_spaces))

# çº¦æŸæ¡ä»¶ï¼šæ¦‚ç‡å’Œä¸º1
            constraints = []
            for i in range(n_players):
                start_idx = sum(strategy_spaces[:i])
                end_idx = start_idx + strategy_spaces[i]

                def constraint_fun(x, start=start_idx, end=end_idx):
                    return np.sum(x[start:end]) - 1.0

                constraints.append({'type': 'eq', 'fun': constraint_fun})

# è¾¹ç•Œæ¡ä»¶ï¼šæ¦‚ç‡åœ¨[0,1]ä¹‹é—´
            bounds = [(0, 1)] * sum(strategy_spaces)

# ä¼˜åŒ–
            result = minimize(
                objective_function,
                initial_point,
                method='SLSQP',
                bounds=bounds,
                constraints=constraints
            )

            if result.success and result.fun < 1e-6:
                distributions = self.vector_to_distributions(result.x, strategy_spaces)
                equilibria.append({
                    'distributions': distributions,
                    'deviation': result.fun
                })

        return equilibria

    def vector_to_distributions(self, vector, strategy_spaces):
        """å°†å‘é‡è½¬æ¢ä¸ºç­–ç•¥åˆ†å¸ƒ"""
        distributions = []
        start_idx = 0

        for i, n_strategies in enumerate(strategy_spaces):
            end_idx = start_idx + n_strategies
            player_dist = vector[start_idx:end_idx]

# æ·»åŠ æœ€åä¸€ä¸ªæ¦‚ç‡ï¼ˆç¡®ä¿å’Œä¸º1ï¼‰
            last_prob = 1.0 - np.sum(player_dist)
            player_dist = np.append(player_dist, last_prob)

            distributions.append(player_dist)
            start_idx = end_idx

        return distributions

    def find_best_response(self, player, distributions):
        """å¯»æ‰¾ç©å®¶çš„æœ€ä¼˜å“åº”"""
        n_strategies = len(self.game.strategies[player])
        best_payoff = float('-inf')

        for strategy in range(n_strategies):
# ä¸´æ—¶ä¿®æ”¹åˆ†å¸ƒ
            temp_distributions = [dist.copy() for dist in distributions]
            temp_distributions[player] = np.zeros(n_strategies)
            temp_distributions[player][strategy] = 1.0

            payoff = self.calculate_player_payoff(player, temp_distributions)
            best_payoff = max(best_payoff, payoff)

        return best_payoff

    def calculate_player_payoff(self, player, distributions):
        """è®¡ç®—ç©å®¶çš„æœŸæœ›æ”¯ä»˜"""
        payoff = 0
        n_players = len(distributions)

# éå†æ‰€æœ‰ç­–ç•¥ç»„åˆ
        from itertools import product
        strategy_ranges = [range(len(dist)) for dist in distributions]

        for strategy_combo in product(*strategy_ranges):
            prob = 1.0
            for i, strategy in enumerate(strategy_combo):
                prob *= distributions[i][strategy]

            game_payoff = self.game.get_payoff(strategy_combo)
            payoff += prob * game_payoff[player]

        return payoff

    def is_evolutionarily_stable(self, strategy_profile):
        """æ£€æŸ¥æ˜¯å¦ä¸ºæ¼”åŒ–ç¨³å®šç­–ç•¥"""
# æ£€æŸ¥ç­–ç•¥æ˜¯å¦æ˜¯å¯¹ç§°çº³ä»€å‡è¡¡
        if not self.is_symmetric_nash_equilibrium(strategy_profile):
            return False

# æ£€æŸ¥æ¼”åŒ–ç¨³å®šæ€§æ¡ä»¶
        return self.check_evolutionary_stability_condition(strategy_profile)

    def is_symmetric_nash_equilibrium(self, strategy_profile):
        """æ£€æŸ¥æ˜¯å¦ä¸ºå¯¹ç§°çº³ä»€å‡è¡¡"""
# æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç©å®¶éƒ½ä½¿ç”¨ç›¸åŒç­–ç•¥
        if len(set(strategy_profile)) != 1:
            return False

# æ£€æŸ¥æ˜¯å¦ä¸ºçº³ä»€å‡è¡¡
        strategy = strategy_profile[0]
        for player in range(self.game.n_players):
            if not self.is_best_response(player, strategy, strategy_profile):
                return False

        return True

    def is_best_response(self, player, strategy, strategy_profile):
        """æ£€æŸ¥ç­–ç•¥æ˜¯å¦ä¸ºæœ€ä¼˜å“åº”"""
        current_payoff = self.game.get_payoff(strategy_profile)[player]

# æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„åç¦»
        for alternative_strategy in self.game.strategies[player]:
            if alternative_strategy == strategy:
                continue

# æ„é€ åç¦»åçš„ç­–ç•¥ç»„åˆ
            deviated_profile = list(strategy_profile)
            deviated_profile[player] = alternative_strategy

            deviated_payoff = self.game.get_payoff(deviated_profile)[player]

            if deviated_payoff > current_payoff:
                return False

        return True

    def check_evolutionary_stability_condition(self, strategy_profile):
        """æ£€æŸ¥æ¼”åŒ–ç¨³å®šæ€§æ¡ä»¶"""
        strategy = strategy_profile[0]

# å¯¹äºæ‰€æœ‰å¯èƒ½çš„çªå˜ç­–ç•¥
        for mutant_strategy in self.game.strategies[0]:
            if mutant_strategy == strategy:
                continue

# æ£€æŸ¥ç¨³å®šæ€§æ¡ä»¶
            if not self.is_evolutionarily_stable_against_mutant(strategy, mutant_strategy):
                return False

        return True

    def is_evolutionarily_stable_against_mutant(self, incumbent_strategy, mutant_strategy):
        """æ£€æŸ¥å¯¹ç‰¹å®šçªå˜ç­–ç•¥çš„æ¼”åŒ–ç¨³å®šæ€§"""
# è®¡ç®—ç§ç¾¤ä¸­çªå˜è€…çš„æ¯”ä¾‹é˜ˆå€¼
        threshold = self.calculate_invasion_threshold(incumbent_strategy, mutant_strategy)

# å¦‚æœé˜ˆå€¼å­˜åœ¨ä¸”ä¸ºæ­£ï¼Œåˆ™ç­–ç•¥æ˜¯æ¼”åŒ–ç¨³å®šçš„
        return threshold is not None and threshold > 0

    def calculate_invasion_threshold(self, incumbent_strategy, mutant_strategy):
        """è®¡ç®—å…¥ä¾µé˜ˆå€¼"""
# è®¡ç®—æœŸæœ›æ”¯ä»˜
        incumbent_vs_incumbent = self.calculate_pairwise_payoff(incumbent_strategy, incumbent_strategy)
        incumbent_vs_mutant = self.calculate_pairwise_payoff(incumbent_strategy, mutant_strategy)
        mutant_vs_incumbent = self.calculate_pairwise_payoff(mutant_strategy, incumbent_strategy)
        mutant_vs_mutant = self.calculate_pairwise_payoff(mutant_strategy, mutant_strategy)

# è®¡ç®—å…¥ä¾µé˜ˆå€¼
        numerator = incumbent_vs_incumbent - mutant_vs_incumbent
        denominator = (mutant_vs_mutant - mutant_vs_incumbent) - (incumbent_vs_mutant - incumbent_vs_incumbent)

        if abs(denominator) < 1e-10:
# åˆ†æ¯æ¥è¿‘é›¶ï¼Œæ£€æŸ¥åˆ†å­
            if numerator > 0:
                return float('inf')  # æ€»æ˜¯ç¨³å®š
            else:
                return None  # ä¸ç¨³å®š

        threshold = numerator / denominator
        return threshold if 0 < threshold < 1 else None

    def calculate_pairwise_payoff(self, strategy1, strategy2):
        """è®¡ç®—ä¸¤ä¸ªç­–ç•¥ä¹‹é—´çš„æ”¯ä»˜"""
# æ„é€ ç­–ç•¥ç»„åˆ
        strategy_profile = [strategy1, strategy2]

# è·å–æ”¯ä»˜
        payoffs = self.game.get_payoff(strategy_profile)

# è¿”å›ç¬¬ä¸€ä¸ªç©å®¶çš„æ”¯ä»˜ï¼ˆå¯¹ç§°åšå¼ˆï¼‰
        return payoffs[0]

    def find_evolutionarily_stable_strategies(self):
        """å¯»æ‰¾æ¼”åŒ–ç¨³å®šç­–ç•¥"""
        stable_strategies = []

# æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„ç­–ç•¥
        for strategy in self.game.strategies[0]:
# æ„é€ å¯¹ç§°ç­–ç•¥ç»„åˆ
            strategy_profile = [strategy] * self.game.n_players

# æ£€æŸ¥æ˜¯å¦ä¸ºæ¼”åŒ–ç¨³å®šç­–ç•¥
            if self.is_evolutionarily_stable(strategy_profile):
                stable_strategies.append({
                    'strategy': strategy,
                    'profile': strategy_profile,
                    'stability_analysis': self.analyze_stability(strategy)
                })

        return stable_strategies

    def analyze_stability(self, strategy):
        """åˆ†æç­–ç•¥çš„ç¨³å®šæ€§"""
        analysis = {
            'nash_equilibrium': self.is_symmetric_nash_equilibrium([strategy] * self.game.n_players),
            'evolutionarily_stable': self.is_evolutionarily_stable([strategy] * self.game.n_players),
            'invasion_thresholds': {},
            'fitness_landscape': self.calculate_fitness_landscape(strategy)
        }

# è®¡ç®—å¯¹æ‰€æœ‰çªå˜ç­–ç•¥çš„å…¥ä¾µé˜ˆå€¼
        for mutant_strategy in self.game.strategies[0]:
            if mutant_strategy != strategy:
                threshold = self.calculate_invasion_threshold(strategy, mutant_strategy)
                analysis['invasion_thresholds'][mutant_strategy] = threshold

        return analysis

    def calculate_fitness_landscape(self, strategy):
        """è®¡ç®—é€‚åº”åº¦æ™¯è§‚"""
        landscape = {}

# è®¡ç®—åœ¨ä¸åŒç§ç¾¤ç»„æˆä¸‹çš„é€‚åº”åº¦
        for population_composition in self.generate_population_compositions():
            fitness = self.calculate_fitness_in_population(strategy, population_composition)
            landscape[population_composition] = fitness

        return landscape

    def generate_population_compositions(self):
        """ç”Ÿæˆç§ç¾¤ç»„æˆ"""
        compositions = []
        n_strategies = len(self.game.strategies[0])

# ç”Ÿæˆä¸åŒæ¯”ä¾‹çš„ç§ç¾¤ç»„æˆ
        for proportions in self.generate_proportions(n_strategies):
            compositions.append(proportions)

        return compositions

    def generate_proportions(self, n_strategies, step=0.1):
        """ç”Ÿæˆæ¯”ä¾‹ç»„åˆ"""
        from itertools import product

        proportions = []
        for values in product(np.arange(0, 1.01, step), repeat=n_strategies-1):
            if sum(values) <= 1:
# æ·»åŠ æœ€åä¸€ä¸ªæ¯”ä¾‹
                last_proportion = 1 - sum(values)
                if last_proportion >= 0:
                    full_proportions = list(values) + [last_proportion]
                    proportions.append(full_proportions)

        return proportions

    def calculate_fitness_in_population(self, strategy, population_composition):
        """è®¡ç®—ç­–ç•¥åœ¨ç§ç¾¤ä¸­çš„é€‚åº”åº¦"""
        fitness = 0

        for i, proportion in enumerate(population_composition):
            if proportion > 0:
                other_strategy = self.game.strategies[0][i]
                pairwise_payoff = self.calculate_pairwise_payoff(strategy, other_strategy)
                fitness += proportion * pairwise_payoff

        return fitness

    def trembling_hand_perfect_equilibrium(self):
        """é¢¤æŠ–æ‰‹å®Œç¾å‡è¡¡"""
        perfect_equilibria = []

# ä½¿ç”¨åºåˆ—åŒ–æ–¹æ³•å¯»æ‰¾é¢¤æŠ–æ‰‹å®Œç¾å‡è¡¡
        for epsilon in [0.1, 0.05, 0.01, 0.005, 0.001]:
            equilibrium = self.find_trembling_hand_equilibrium(epsilon)
            if equilibrium:
                perfect_equilibria.append(equilibrium)

# è¿‡æ»¤æ‰é‡å¤çš„å‡è¡¡
        unique_equilibria = self.filter_unique_equilibria(perfect_equilibria)

        return unique_equilibria

    def find_trembling_hand_equilibrium(self, epsilon):
        """å¯»æ‰¾ç‰¹å®šæ‰°åŠ¨æ°´å¹³ä¸‹çš„é¢¤æŠ–æ‰‹å‡è¡¡"""
        from scipy.optimize import minimize

        n_players = self.game.n_players
        strategy_spaces = []

# ä¸ºæ¯ä¸ªç©å®¶å®šä¹‰ç­–ç•¥ç©ºé—´
        for player in range(n_players):
            n_strategies = len(self.game.strategies[player])
            strategy_spaces.append(n_strategies - 1)

# å®šä¹‰ç›®æ ‡å‡½æ•°ï¼šæœ€å°åŒ–åç¦»å‡è¡¡çš„æ¿€åŠ±
        def objective_function(strategy_vector):
            distributions = self.vector_to_distributions(strategy_vector, strategy_spaces)

# æ·»åŠ æ‰°åŠ¨
            perturbed_distributions = self.add_trembling_hand_perturbation(distributions, epsilon)

            total_deviation = 0
            for player in range(n_players):
                best_response = self.find_best_response_with_perturbation(player, perturbed_distributions, epsilon)
                current_payoff = self.calculate_player_payoff_with_perturbation(player, perturbed_distributions)
                deviation = best_response - current_payoff
                total_deviation += abs(deviation)

            return total_deviation

# çº¦æŸæ¡ä»¶
        constraints = []
        for i in range(n_players):
            start_idx = sum(strategy_spaces[:i])
            end_idx = start_idx + strategy_spaces[i]

            def constraint_fun(x, start=start_idx, end=end_idx):
                return np.sum(x[start:end]) - 1.0

            constraints.append({'type': 'eq', 'fun': constraint_fun})

# è¾¹ç•Œæ¡ä»¶ï¼šæ¦‚ç‡åœ¨[epsilon, 1]ä¹‹é—´
        bounds = [(epsilon, 1)] * sum(strategy_spaces)

# å¤šæ¬¡ä¼˜åŒ–
        for attempt in range(5):
            initial_point = np.random.uniform(epsilon, 1, sum(strategy_spaces))

            result = minimize(
                objective_function,
                initial_point,
                method='SLSQP',
                bounds=bounds,
                constraints=constraints
            )

            if result.success and result.fun < 1e-6:
                distributions = self.vector_to_distributions(result.x, strategy_spaces)
                return {
                    'distributions': distributions,
                    'epsilon': epsilon,
                    'deviation': result.fun
                }

        return None

    def add_trembling_hand_perturbation(self, distributions, epsilon):
        """æ·»åŠ é¢¤æŠ–æ‰‹æ‰°åŠ¨"""
        perturbed_distributions = []

        for dist in distributions:
            n_strategies = len(dist)

# ç¡®ä¿æ¯ä¸ªç­–ç•¥éƒ½æœ‰æœ€å°æ¦‚ç‡epsilon
            perturbed_dist = np.maximum(dist, epsilon / n_strategies)

# é‡æ–°å½’ä¸€åŒ–
            perturbed_dist = perturbed_dist / np.sum(perturbed_dist)

            perturbed_distributions.append(perturbed_dist)

        return perturbed_distributions

    def find_best_response_with_perturbation(self, player, distributions, epsilon):
        """åœ¨æ‰°åŠ¨ä¸‹å¯»æ‰¾æœ€ä¼˜å“åº”"""
        n_strategies = len(self.game.strategies[player])
        best_payoff = float('-inf')

        for strategy in range(n_strategies):
# ä¸´æ—¶ä¿®æ”¹åˆ†å¸ƒ
            temp_distributions = [dist.copy() for dist in distributions]

# è®¾ç½®æœ€å°æ¦‚ç‡
            temp_distributions[player] = np.full(n_strategies, epsilon / n_strategies)
            temp_distributions[player][strategy] = 1.0 - epsilon + epsilon / n_strategies

            payoff = self.calculate_player_payoff_with_perturbation(player, temp_distributions)
            best_payoff = max(best_payoff, payoff)

        return best_payoff

    def calculate_player_payoff_with_perturbation(self, player, distributions):
        """åœ¨æ‰°åŠ¨ä¸‹è®¡ç®—ç©å®¶æ”¯ä»˜"""
        return self.calculate_player_payoff(player, distributions)

    def filter_unique_equilibria(self, equilibria):
        """è¿‡æ»¤é‡å¤çš„å‡è¡¡"""
        unique_equilibria = []
        tolerance = 1e-4

        for eq in equilibria:
            is_unique = True
            for existing_eq in unique_equilibria:
                if self.are_equilibria_similar(eq, existing_eq, tolerance):
                    is_unique = False
                    break

            if is_unique:
                unique_equilibria.append(eq)

        return unique_equilibria

    def are_equilibria_similar(self, eq1, eq2, tolerance):
        """æ£€æŸ¥ä¸¤ä¸ªå‡è¡¡æ˜¯å¦ç›¸ä¼¼"""
        if 'distributions' not in eq1 or 'distributions' not in eq2:
            return False

        dist1 = eq1['distributions']
        dist2 = eq2['distributions']

        if len(dist1) != len(dist2):
            return False

        for i in range(len(dist1)):
            if not np.allclose(dist1[i], dist2[i], atol=tolerance):
                return False

        return True

class MixedStrategyEquilibrium:
    def __init__(self, game):
        self.game = game

    def solve_2x2_game(self):
        """æ±‚è§£2x2åšå¼ˆçš„æ··åˆç­–ç•¥å‡è¡¡"""
        if self.game.n_players != 2 or len(self.game.strategies[0]) != 2 or len(self.game.strategies[1]) != 2:
            raise ValueError("This method only works for 2x2 games")

# æ„å»ºæ”¯ä»˜çŸ©é˜µ
        payoff_matrix = self.build_2x2_payoff_matrix()

# è®¡ç®—æ··åˆç­–ç•¥å‡è¡¡
        equilibrium = self.calculate_mixed_equilibrium_2x2(payoff_matrix)

        return equilibrium

    def build_2x2_payoff_matrix(self):
        """æ„å»º2x2æ”¯ä»˜çŸ©é˜µ"""
# è¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“çš„åšå¼ˆç»“æ„å®ç°
# ç®€åŒ–å®ç°
        return np.array([[[3, 3], [0, 5]], [[5, 0], [1, 1]]])

    def calculate_mixed_equilibrium_2x2(self, payoff_matrix):
        """è®¡ç®—2x2åšå¼ˆçš„æ··åˆç­–ç•¥å‡è¡¡"""
# ç©å®¶1çš„æ··åˆç­–ç•¥
        p = self.calculate_player1_mixed_strategy(payoff_matrix)

# ç©å®¶2çš„æ··åˆç­–ç•¥
        q = self.calculate_player2_mixed_strategy(payoff_matrix)

        return {
            'player1_mixed_strategy': p,
            'player2_mixed_strategy': q
        }

    def calculate_player1_mixed_strategy(self, payoff_matrix):
        """è®¡ç®—ç©å®¶1çš„æ··åˆç­–ç•¥"""
# ç©å®¶1çš„æ”¯ä»˜çŸ©é˜µ
        player1_payoffs = payoff_matrix[0]

# ä½¿ç”¨æ— å·®å¼‚æ¡ä»¶ï¼šç©å®¶1é€‰æ‹©ç­–ç•¥1å’Œç­–ç•¥2çš„æœŸæœ›æ”¯ä»˜ç›¸ç­‰
# E[Strategy1] = E[Strategy2]
# p * a11 + (1-p) * a12 = p * a21 + (1-p) * a22

        a11, a12 = player1_payoffs[0]
        a21, a22 = player1_payoffs[1]

# æ±‚è§£ï¼šp * a11 + (1-p) * a12 = p * a21 + (1-p) * a22
# p * (a11 - a12 - a21 + a22) = a22 - a12
# p = (a22 - a12) / (a11 - a12 - a21 + a22)

        denominator = a11 - a12 - a21 + a22

        if abs(denominator) < 1e-10:
# åˆ†æ¯æ¥è¿‘é›¶ï¼Œæ£€æŸ¥åˆ†å­
            if abs(a22 - a12) < 1e-10:
                return 0.5  # æ— å·®å¼‚
            else:
                return 0.0  # æ€»æ˜¯é€‰æ‹©ç­–ç•¥2

        p = (a22 - a12) / denominator

# ç¡®ä¿æ¦‚ç‡åœ¨[0,1]èŒƒå›´å†…
        p = max(0.0, min(1.0, p))

        return p

    def calculate_player2_mixed_strategy(self, payoff_matrix):
        """è®¡ç®—ç©å®¶2çš„æ··åˆç­–ç•¥"""
# ç©å®¶2çš„æ”¯ä»˜çŸ©é˜µ
        player2_payoffs = payoff_matrix[1]

# ä½¿ç”¨æ— å·®å¼‚æ¡ä»¶ï¼šç©å®¶2é€‰æ‹©ç­–ç•¥1å’Œç­–ç•¥2çš„æœŸæœ›æ”¯ä»˜ç›¸ç­‰
# E[Strategy1] = E[Strategy2]
# q * b11 + (1-q) * b12 = q * b21 + (1-q) * b22

        b11, b12 = player2_payoffs[0]
        b21, b22 = player2_payoffs[1]

# æ±‚è§£ï¼šq * b11 + (1-q) * b12 = q * b21 + (1-q) * b22
# q * (b11 - b12 - b21 + b22) = b22 - b12
# q = (b22 - b12) / (b11 - b12 - b21 + b22)

        denominator = b11 - b12 - b21 + b22

        if abs(denominator) < 1e-10:
# åˆ†æ¯æ¥è¿‘é›¶ï¼Œæ£€æŸ¥åˆ†å­
            if abs(b22 - b12) < 1e-10:
                return 0.5  # æ— å·®å¼‚
            else:
                return 0.0  # æ€»æ˜¯é€‰æ‹©ç­–ç•¥2

        q = (b22 - b12) / denominator

# ç¡®ä¿æ¦‚ç‡åœ¨[0,1]èŒƒå›´å†…
        q = max(0.0, min(1.0, q))

        return q
```

## 8. å‡è¡¡é€‰æ‹©

```python
class EquilibriumSelection:
    def __init__(self, game):
        self.game = game

    def select_equilibrium(self, method='pareto_dominance'):
        """é€‰æ‹©å‡è¡¡"""
        equilibria = self.game.find_nash_equilibria()

        if method == 'pareto_dominance':
            return self.pareto_dominant_equilibrium(equilibria)
        elif method == 'risk_dominance':
            return self.risk_dominant_equilibrium(equilibria)
        elif method == 'payoff_dominance':
            return self.payoff_dominant_equilibrium(equilibria)
        else:
            raise ValueError(f"Unknown selection method: {method}")

    def pareto_dominant_equilibrium(self, equilibria):
        """å¸•ç´¯æ‰˜å ä¼˜å‡è¡¡"""
        if not equilibria:
            return None

        pareto_dominant = equilibria[0]
        pareto_dominant_payoffs = self.game.get_payoff(pareto_dominant)

        for equilibrium in equilibria[1:]:
            payoffs = self.game.get_payoff(equilibrium)

# æ£€æŸ¥æ˜¯å¦å¸•ç´¯æ‰˜å ä¼˜
            if all(payoffs[i] >= pareto_dominant_payoffs[i] for i in range(self.game.n_players)) and \
               any(payoffs[i] > pareto_dominant_payoffs[i] for i in range(self.game.n_players)):
                pareto_dominant = equilibrium
                pareto_dominant_payoffs = payoffs

        return pareto_dominant

    def risk_dominant_equilibrium(self, equilibria):
        """é£é™©å ä¼˜å‡è¡¡"""
        if len(equilibria) < 2:
            return equilibria[0] if equilibria else None

# è®¡ç®—é£é™©å› å­
        risk_factors = {}
        for equilibrium in equilibria:
            risk_factor = self.calculate_risk_factor(equilibrium)
            risk_factors[equilibrium] = risk_factor

# é€‰æ‹©é£é™©æœ€å°çš„å‡è¡¡
        return min(risk_factors.keys(), key=lambda x: risk_factors[x])

    def calculate_risk_factor(self, equilibrium):
        """è®¡ç®—é£é™©å› å­"""
# è¿™é‡Œéœ€è¦å®ç°å…·ä½“çš„é£é™©å› å­è®¡ç®—
# ç®€åŒ–å®ç°
        return 0.5

    def payoff_dominant_equilibrium(self, equilibria):
        """æ”¯ä»˜å ä¼˜å‡è¡¡"""
        if not equilibria:
            return None

        payoff_dominant = equilibria[0]
        max_total_payoff = sum(self.game.get_payoff(payoff_dominant))

        for equilibrium in equilibria[1:]:
            total_payoff = sum(self.game.get_payoff(equilibrium))
            if total_payoff > max_total_payoff:
                payoff_dominant = equilibrium
                max_total_payoff = total_payoff

        return payoff_dominant
```

## 9. åº”ç”¨æ¡ˆä¾‹

### 9.1. å›šå¾’å›°å¢ƒ

```python
class PrisonersDilemmaAnalysis:
    def __init__(self):
        self.game = PrisonersDilemma()
        self.analysis = GameAnalysis(self.game)

    def comprehensive_analysis(self):
        """ç»¼åˆåˆ†æ"""
        print("å›šå¾’å›°å¢ƒåšå¼ˆç»¼åˆåˆ†æ")
        print("=" * 50)

# åŸºæœ¬åˆ†æ
        basic_analysis = self.game.analyze_game()

# æ•ˆç‡åˆ†æ
        efficiency_analysis = self.analysis.efficiency_analysis()

# å‡è¡¡é€‰æ‹©
        equilibrium_selector = EquilibriumSelection(self.game)
        selected_equilibrium = equilibrium_selector.select_equilibrium('pareto_dominance')

        print(f"é€‰æ‹©çš„å‡è¡¡: {selected_equilibrium}")
        print(f"æ•ˆç‡åˆ†æ: {efficiency_analysis}")

        return {
            'basic_analysis': basic_analysis,
            'efficiency_analysis': efficiency_analysis,
            'selected_equilibrium': selected_equilibrium
        }

    def repeated_game_analysis(self, rounds=10, discount_factor=0.9):
        """é‡å¤åšå¼ˆåˆ†æ"""
        print(f"é‡å¤å›šå¾’å›°å¢ƒåˆ†æ (å›åˆæ•°: {rounds}, æŠ˜æ‰£å› å­: {discount_factor})")
        print("=" * 50)

# æ„å»ºé‡å¤åšå¼ˆ
        repeated_game = RepeatedGame(self.game, rounds, discount_factor)

# åˆ†æé‡å¤åšå¼ˆçš„å‡è¡¡
        equilibria = repeated_game.find_equilibria()

        print(f"é‡å¤åšå¼ˆå‡è¡¡: {equilibria}")

        return equilibria

class RepeatedGame:
    def __init__(self, stage_game, rounds, discount_factor=1.0):
        """é‡å¤åšå¼ˆ"""
        self.stage_game = stage_game
        self.rounds = rounds
        self.discount_factor = discount_factor

    def find_equilibria(self):
        """å¯»æ‰¾é‡å¤åšå¼ˆçš„å‡è¡¡"""
# è¿™é‡Œéœ€è¦å®ç°é‡å¤åšå¼ˆå‡è¡¡çš„è®¡ç®—
# ç®€åŒ–å®ç°
        return []

    def calculate_present_value(self, payoffs, period):
        """è®¡ç®—ç°å€¼"""
        return [payoff * (self.discount_factor ** period) for payoff in payoffs]
```

## 10. åè°ƒåšå¼ˆ

```python
class CoordinationGame(Game):
    def __init__(self):
        """åè°ƒåšå¼ˆ"""
        players = ['Player 1', 'Player 2']
        strategies = [['A', 'B'], ['A', 'B']]

# æ”¯ä»˜çŸ©é˜µ
        payoffs = {
            ('A', 'A'): [3, 3],
            ('A', 'B'): [0, 0],
            ('B', 'A'): [0, 0],
            ('B', 'B'): [2, 2]
        }

        super().__init__(players, strategies, payoffs)

    def analyze_coordination(self):
        """åˆ†æåè°ƒé—®é¢˜"""
        print("åè°ƒåšå¼ˆåˆ†æ")
        print("=" * 30)

# çº³ä»€å‡è¡¡
        nash_equilibria = self.find_nash_equilibria()
        print(f"çº³ä»€å‡è¡¡: {nash_equilibria}")

# å¸•ç´¯æ‰˜æœ€ä¼˜
        pareto_optimal = self.find_pareto_optimal()
        print(f"å¸•ç´¯æ‰˜æœ€ä¼˜: {pareto_optimal}")

# é£é™©å ä¼˜
        risk_dominant = self.find_risk_dominant_equilibrium()
        print(f"é£é™©å ä¼˜å‡è¡¡: {risk_dominant}")

        return {
            'nash_equilibria': nash_equilibria,
            'pareto_optimal': pareto_optimal,
            'risk_dominant': risk_dominant
        }

    def find_risk_dominant_equilibrium(self):
        """å¯»æ‰¾é£é™©å ä¼˜å‡è¡¡"""
# è®¡ç®—é£é™©å› å­
        risk_factors = {}

        for equilibrium in self.find_nash_equilibria():
            risk_factor = self.calculate_risk_factor(equilibrium)
            risk_factors[equilibrium] = risk_factor

# é€‰æ‹©é£é™©æœ€å°çš„å‡è¡¡
        return min(risk_factors.keys(), key=lambda x: risk_factors[x])

    def calculate_risk_factor(self, equilibrium):
        """è®¡ç®—é£é™©å› å­"""
# è¿™é‡Œéœ€è¦å®ç°å…·ä½“çš„é£é™©å› å­è®¡ç®—
# ç®€åŒ–å®ç°
        return 0.5
```

## 11. å·¥å…·å®ç°

### 11.1. Pythonåšå¼ˆè®ºå·¥å…·

```python
class GameTheoryTools:
    def __init__(self):
        self.game_types = {
            'prisoners_dilemma': PrisonersDilemma,
            'coordination': CoordinationGame,
            'battle_of_sexes': BattleOfSexes,
            'chicken': ChickenGame
        }

    def create_game(self, game_type, **kwargs):
        """åˆ›å»ºåšå¼ˆ"""
        if game_type in self.game_types:
            game_class = self.game_types[game_type]
            return game_class(**kwargs)
        else:
            raise ValueError(f"Unknown game type: {game_type}")

    def analyze_game(self, game):
        """åˆ†æåšå¼ˆ"""
        analyzer = GameAnalysis(game)
        return analyzer.comprehensive_analysis()

    def find_equilibria(self, game, equilibrium_type='all'):
        """å¯»æ‰¾å‡è¡¡"""
        if equilibrium_type == 'all':
            return {
                'nash': game.find_nash_equilibria(),
                'dominant': game.find_dominant_strategies(),
                'pareto': analyzer.find_pareto_optimal()
            }
        elif equilibrium_type == 'nash':
            return game.find_nash_equilibria()
        else:
            raise ValueError(f"Unknown equilibrium type: {equilibrium_type}")

    def select_equilibrium(self, game, method='pareto_dominance'):
        """é€‰æ‹©å‡è¡¡"""
        selector = EquilibriumSelection(game)
        return selector.select_equilibrium(method)

class BattleOfSexes(Game):
    def __init__(self):
        """æ€§åˆ«ä¹‹æˆ˜åšå¼ˆ"""
        players = ['Player 1', 'Player 2']
        strategies = [['Football', 'Opera'], ['Football', 'Opera']]

        payoffs = {
            ('Football', 'Football'): [3, 2],
            ('Football', 'Opera'): [0, 0],
            ('Opera', 'Football'): [0, 0],
            ('Opera', 'Opera'): [2, 3]
        }

        super().__init__(players, strategies, payoffs)

class ChickenGame(Game):
    def __init__(self):
        """æ‡¦å¤«åšå¼ˆ"""
        players = ['Player 1', 'Player 2']
        strategies = [['Swerve', 'Straight'], ['Swerve', 'Straight']]

        payoffs = {
            ('Swerve', 'Swerve'): [0, 0],
            ('Swerve', 'Straight'): [-1, 1],
            ('Straight', 'Swerve'): [1, -1],
            ('Straight', 'Straight'): [-10, -10]
        }

        super().__init__(players, strategies, payoffs)
```

### 11.2. JavaScriptåšå¼ˆè®ºå®ç°

```javascript
class GameTheoryTools {
  constructor() {
    this.gameTypes = {
      'prisonersDilemma': PrisonersDilemma,
      'coordination': CoordinationGame,
      'battleOfSexes': BattleOfSexes,
      'chicken': ChickenGame
    };
  }

  createGame(gameType, config) {
    if (gameType in this.gameTypes) {
      const GameClass = this.gameTypes[gameType];
      return new GameClass(config);
    } else {
      throw new Error(`Unknown game type: ${gameType}`);
    }
  }

  analyzeGame(game) {
    const analyzer = new GameAnalysis(game);
    return analyzer.comprehensiveAnalysis();
  }

  findEquilibria(game, equilibriumType = 'all') {
    if (equilibriumType === 'all') {
      const analyzer = new GameAnalysis(game);
      return {
        nash: game.findNashEquilibria(),
        dominant: game.findDominantStrategies(),
        pareto: analyzer.findParetoOptimal()
      };
    } else if (equilibriumType === 'nash') {
      return game.findNashEquilibria();
    } else {
      throw new Error(`Unknown equilibrium type: ${equilibriumType}`);
    }
  }

  selectEquilibrium(game, method = 'pareto_dominance') {
    const selector = new EquilibriumSelection(game);
    return selector.selectEquilibrium(method);
  }
}

class Game {
  constructor(players, strategies, payoffs) {
    this.players = players;
    this.strategies = strategies;
    this.payoffs = payoffs;
    this.nPlayers = players.length;
  }

  getPayoff(strategyProfile) {
    return this.payoffs[strategyProfile];
  }

  getBestResponse(player, opponentStrategies) {
    let bestPayoff = -Infinity;
    let bestStrategy = null;

    for (const strategy of this.strategies[player]) {
      const strategyProfile = [...opponentStrategies];
      strategyProfile.splice(player, 0, strategy);
      const strategyProfileTuple = strategyProfile.join(',');

      const payoff = this.getPayoff(strategyProfileTuple)[player];
      if (payoff > bestPayoff) {
        bestPayoff = payoff;
        bestStrategy = strategy;
      }
    }

    return [bestStrategy, bestPayoff];
  }

  isNashEquilibrium(strategyProfile) {
    for (let player = 0; player < this.nPlayers; player++) {
      const opponentStrategies = [...strategyProfile];
      opponentStrategies.splice(player, 1);

      const [bestResponse, bestPayoff] = this.getBestResponse(player, opponentStrategies);
      const currentPayoff = this.getPayoff(strategyProfile.join(','))[player];

      if (bestPayoff > currentPayoff) {
        return false;
      }
    }

    return true;
  }

  findNashEquilibria() {
    const equilibria = [];
    const strategyCombinations = this.generateStrategyCombinations();

    for (const strategyProfile of strategyCombinations) {
      if (this.isNashEquilibrium(strategyProfile)) {
        equilibria.push(strategyProfile);
      }
    }

    return equilibria;
  }

  generateStrategyCombinations() {
    // è¿™é‡Œéœ€è¦å®ç°ç­–ç•¥ç»„åˆçš„ç”Ÿæˆ
    // ç®€åŒ–å®ç°
    return [];
  }
}
```

## 12. å­¦ä¹ è·¯å¾„

### 12.1. åŸºç¡€å­¦ä¹ 

1. **åšå¼ˆè®ºåŸºç¡€** (2-3å‘¨)
   - åšå¼ˆè®ºåŸºæœ¬æ¦‚å¿µ
   - ç­–ç•¥å‹åšå¼ˆ
   - çº³ä»€å‡è¡¡

2. **æ‰©å±•å‹åšå¼ˆ** (2-3å‘¨)
   - åšå¼ˆæ ‘
   - é€†å‘å½’çº³æ³•
   - å­åšå¼ˆå®Œç¾å‡è¡¡

### 12.2. è¿›é˜¶å­¦ä¹ 

1. **å‡è¡¡ç†è®º** (3-4å‘¨)
   - æ··åˆç­–ç•¥å‡è¡¡
   - æ¼”åŒ–ç¨³å®šç­–ç•¥
   - é¢¤æŠ–æ‰‹å®Œç¾å‡è¡¡

2. **åšå¼ˆåˆ†æ** (3-4å‘¨)
   - å‡è¡¡é€‰æ‹©
   - æ•ˆç‡åˆ†æ
   - æœºåˆ¶è®¾è®¡

### 12.3. åº”ç”¨å®è·µ

1. **å®é™…åº”ç”¨** (4-5å‘¨)
   - ç»æµå­¦åº”ç”¨
   - æ”¿æ²»å­¦åº”ç”¨
   - ç”Ÿç‰©å­¦åº”ç”¨

2. **å·¥å…·å¼€å‘** (3-4å‘¨)
   - åšå¼ˆåˆ†æå·¥å…·
   - å‡è¡¡è®¡ç®—å·¥å…·
   - ä»¿çœŸå·¥å…·

## 13. æ€»ç»“

åšå¼ˆè®ºåŸºç¡€ç†è®ºä¸ºç†è§£ç†æ€§å†³ç­–è€…åœ¨ç›¸äº’ä¾å­˜æƒ…å†µä¸‹çš„è¡Œä¸ºæä¾›äº†é‡è¦çš„ç†è®ºæ¡†æ¶ã€‚é€šè¿‡æ·±å…¥ç†è§£ç­–ç•¥å‹åšå¼ˆã€æ‰©å±•å‹åšå¼ˆå’Œçº³ä»€å‡è¡¡ï¼Œå¯ä»¥åˆ†æå„ç§ç¤¾ä¼šã€ç»æµå’Œæ”¿æ²»ç°è±¡ä¸­çš„ç­–ç•¥äº’åŠ¨ã€‚
