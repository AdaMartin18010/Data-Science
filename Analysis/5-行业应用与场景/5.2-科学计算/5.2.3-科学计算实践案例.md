# ç§‘å­¦è®¡ç®—å®è·µæ¡ˆä¾‹

## ğŸ“‘ ç›®å½•

- [ç§‘å­¦è®¡ç®—å®è·µæ¡ˆä¾‹](#ç§‘å­¦è®¡ç®—å®è·µæ¡ˆä¾‹)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
  - [2. åŸºç¡€ç§‘å­¦è®¡ç®—](#2-åŸºç¡€ç§‘å­¦è®¡ç®—)
    - [2.1. æ•°å€¼ç§¯åˆ†](#21-æ•°å€¼ç§¯åˆ†)
  - [3. å¾®åˆ†æ–¹ç¨‹æ±‚è§£](#3-å¾®åˆ†æ–¹ç¨‹æ±‚è§£)
  - [4. çº¿æ€§ä»£æ•°è®¡ç®—](#4-çº¿æ€§ä»£æ•°è®¡ç®—)
  - [5. é«˜æ€§èƒ½è®¡ç®—](#5-é«˜æ€§èƒ½è®¡ç®—)
    - [5.1. å¹¶è¡Œè®¡ç®—](#51-å¹¶è¡Œè®¡ç®—)
  - [6. GPUåŠ é€Ÿè®¡ç®—](#6-gpuåŠ é€Ÿè®¡ç®—)
  - [7. å†…å­˜ä¼˜åŒ–](#7-å†…å­˜ä¼˜åŒ–)
  - [8. æ€»ç»“](#8-æ€»ç»“)

---


## 1. æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›ç§‘å­¦è®¡ç®—æ¨¡å—çš„å®è·µæ¡ˆä¾‹ï¼ŒåŒ…æ‹¬åŸºç¡€ç§‘å­¦è®¡ç®—å’Œé«˜æ€§èƒ½è®¡ç®—çš„å…·ä½“åº”ç”¨ã€‚

## 2. åŸºç¡€ç§‘å­¦è®¡ç®—

### 2.1. æ•°å€¼ç§¯åˆ†

```python
import numpy as np
from scipy import integrate

class NumericalIntegration:
    @staticmethod
    def trapezoidal_rule(f, a, b, n=1000):
        """æ¢¯å½¢æ³•åˆ™æ•°å€¼ç§¯åˆ†"""
        x = np.linspace(a, b, n+1)
        y = f(x)
        h = (b - a) / n
        return h * (0.5 * y[0] + np.sum(y[1:-1]) + 0.5 * y[-1])

    @staticmethod
    def simpson_rule(f, a, b, n=1000):
        """è¾›æ™®æ£®æ³•åˆ™æ•°å€¼ç§¯åˆ†"""
        if n % 2 != 0:
            n += 1

        x = np.linspace(a, b, n+1)
        y = f(x)
        h = (b - a) / n

        return h/3 * (y[0] + 4*np.sum(y[1:-1:2]) + 2*np.sum(y[2:-1:2]) + y[-1])

    @staticmethod
    def monte_carlo_integration(f, a, b, n=10000):
        """è’™ç‰¹å¡æ´›ç§¯åˆ†"""
        x = np.random.uniform(a, b, n)
        y = f(x)
        return (b - a) * np.mean(y)

# ä½¿ç”¨ç¤ºä¾‹
def f(x):
    return np.sin(x)

a, b = 0, np.pi
exact_value = 2.0

print("æ•°å€¼ç§¯åˆ†ç»“æœ:")
print(f"æ¢¯å½¢æ³•åˆ™: {NumericalIntegration.trapezoidal_rule(f, a, b):.6f}")
print(f"è¾›æ™®æ£®æ³•åˆ™: {NumericalIntegration.simpson_rule(f, a, b):.6f}")
print(f"è’™ç‰¹å¡æ´›: {NumericalIntegration.monte_carlo_integration(f, a, b):.6f}")
print(f"ç²¾ç¡®å€¼: {exact_value:.6f}")
```

## 3. å¾®åˆ†æ–¹ç¨‹æ±‚è§£

```python
from scipy.integrate import odeint
import matplotlib.pyplot as plt

class DifferentialEquations:
    @staticmethod
    def euler_method(f, y0, t_span, h):
        """æ¬§æ‹‰æ–¹æ³•æ±‚è§£å¸¸å¾®åˆ†æ–¹ç¨‹"""
        t = np.arange(t_span[0], t_span[1] + h, h)
        y = np.zeros(len(t))
        y[0] = y0

        for i in range(1, len(t)):
            y[i] = y[i-1] + h * f(t[i-1], y[i-1])

        return t, y

    @staticmethod
    def runge_kutta_4(f, y0, t_span, h):
        """å››é˜¶é¾™æ ¼åº“å¡”æ–¹æ³•"""
        t = np.arange(t_span[0], t_span[1] + h, h)
        y = np.zeros(len(t))
        y[0] = y0

        for i in range(1, len(t)):
            k1 = h * f(t[i-1], y[i-1])
            k2 = h * f(t[i-1] + h/2, y[i-1] + k1/2)
            k3 = h * f(t[i-1] + h/2, y[i-1] + k2/2)
            k4 = h * f(t[i-1] + h, y[i-1] + k3)

            y[i] = y[i-1] + (k1 + 2*k2 + 2*k3 + k4) / 6

        return t, y

    @staticmethod
    def solve_ode_scipy(f, y0, t_span, t_eval=None):
        """ä½¿ç”¨SciPyæ±‚è§£å¸¸å¾®åˆ†æ–¹ç¨‹"""
        if t_eval is None:
            t_eval = np.linspace(t_span[0], t_span[1], 100)

        solution = odeint(f, y0, t_eval)
        return t_eval, solution

# ä½¿ç”¨ç¤ºä¾‹ï¼šæ±‚è§£y' = -y, y(0) = 1
def f(t, y):
    return -y

y0 = 1.0
t_span = (0, 5)
h = 0.1

# ä¸åŒæ–¹æ³•æ±‚è§£
t_euler, y_euler = DifferentialEquations.euler_method(f, y0, t_span, h)
t_rk4, y_rk4 = DifferentialEquations.runge_kutta_4(f, y0, t_span, h)
t_scipy, y_scipy = DifferentialEquations.solve_ode_scipy(f, y0, t_span)

# ç²¾ç¡®è§£
t_exact = np.linspace(0, 5, 100)
y_exact = np.exp(-t_exact)

print("å¾®åˆ†æ–¹ç¨‹æ±‚è§£ç»“æœæ¯”è¾ƒ:")
print(f"æ¬§æ‹‰æ–¹æ³• (t=5): {y_euler[-1]:.6f}")
print(f"RK4æ–¹æ³• (t=5): {y_rk4[-1]:.6f}")
print(f"SciPyæ–¹æ³• (t=5): {y_scipy[-1]:.6f}")
print(f"ç²¾ç¡®è§£ (t=5): {y_exact[-1]:.6f}")
```

## 4. çº¿æ€§ä»£æ•°è®¡ç®—

```python
class LinearAlgebra:
    @staticmethod
    def gauss_elimination(A, b):
        """é«˜æ–¯æ¶ˆå…ƒæ³•æ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„"""
        n = len(A)
        A_aug = np.column_stack([A, b])

# å‰å‘æ¶ˆå…ƒ
        for i in range(n):
# é€‰æ‹©ä¸»å…ƒ
            max_row = i + np.argmax(np.abs(A_aug[i:, i]))
            A_aug[i], A_aug[max_row] = A_aug[max_row].copy(), A_aug[i].copy()

# æ¶ˆå…ƒ
            for j in range(i + 1, n):
                factor = A_aug[j, i] / A_aug[i, i]
                A_aug[j] -= factor * A_aug[i]

# å›ä»£
        x = np.zeros(n)
        for i in range(n-1, -1, -1):
            x[i] = (A_aug[i, -1] - np.dot(A_aug[i, i+1:n], x[i+1:])) / A_aug[i, i]

        return x

    @staticmethod
    def lu_decomposition(A):
        """LUåˆ†è§£"""
        n = len(A)
        L = np.eye(n)
        U = A.copy()

        for i in range(n):
            for j in range(i+1, n):
                factor = U[j, i] / U[i, i]
                L[j, i] = factor
                U[j] -= factor * U[i]

        return L, U

    @staticmethod
    def power_iteration(A, max_iter=100, tol=1e-6):
        """å¹‚è¿­ä»£æ³•æ±‚æœ€å¤§ç‰¹å¾å€¼"""
        n = len(A)
        x = np.random.rand(n)
        x = x / np.linalg.norm(x)

        for i in range(max_iter):
            x_new = A @ x
            eigenvalue = np.dot(x, x_new)
            x_new = x_new / np.linalg.norm(x_new)

            if np.linalg.norm(x_new - x) < tol:
                break

            x = x_new

        return eigenvalue, x

# ä½¿ç”¨ç¤ºä¾‹
A = np.array([[4, -1, 0], [-1, 4, -1], [0, -1, 4]], dtype=float)
b = np.array([1, 5, 0], dtype=float)

print("çº¿æ€§ä»£æ•°è®¡ç®—:")
print("ç³»æ•°çŸ©é˜µ A:")
print(A)
print("å¸¸æ•°å‘é‡ b:", b)

# é«˜æ–¯æ¶ˆå…ƒæ³•æ±‚è§£
x_gauss = LinearAlgebra.gauss_elimination(A, b)
print("é«˜æ–¯æ¶ˆå…ƒæ³•è§£:", x_gauss)

# LUåˆ†è§£
L, U = LinearAlgebra.lu_decomposition(A)
print("LçŸ©é˜µ:")
print(L)
print("UçŸ©é˜µ:")
print(U)

# å¹‚è¿­ä»£æ³•æ±‚ç‰¹å¾å€¼
eigenvalue, eigenvector = LinearAlgebra.power_iteration(A)
print(f"æœ€å¤§ç‰¹å¾å€¼: {eigenvalue:.6f}")
print(f"å¯¹åº”ç‰¹å¾å‘é‡: {eigenvector}")
```

## 5. é«˜æ€§èƒ½è®¡ç®—

### 5.1. å¹¶è¡Œè®¡ç®—

```python
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
import time

class ParallelComputing:
    @staticmethod
    def parallel_monte_carlo(f, a, b, n=100000, num_processes=None):
        """å¹¶è¡Œè’™ç‰¹å¡æ´›ç§¯åˆ†"""
        if num_processes is None:
            num_processes = mp.cpu_count()

        n_per_process = n // num_processes

        def worker(seed):
            np.random.seed(seed)
            x = np.random.uniform(a, b, n_per_process)
            y = f(x)
            return np.sum(y)

        with ProcessPoolExecutor(max_workers=num_processes) as executor:
            seeds = range(num_processes)
            results = list(executor.map(worker, seeds))

        return (b - a) * sum(results) / n

    @staticmethod
    def parallel_matrix_multiply(A, B, num_processes=None):
        """å¹¶è¡ŒçŸ©é˜µä¹˜æ³•"""
        if num_processes is None:
            num_processes = mp.cpu_count()

        m, n = A.shape
        n, p = B.shape

        def worker(row_start, row_end):
            result = np.zeros((row_end - row_start, p))
            for i in range(row_start, row_end):
                for j in range(p):
                    result[i - row_start, j] = np.dot(A[i, :], B[:, j])
            return result

        rows_per_process = m // num_processes
        with ProcessPoolExecutor(max_workers=num_processes) as executor:
            futures = []
            for i in range(num_processes):
                start = i * rows_per_process
                end = start + rows_per_process if i < num_processes - 1 else m
                futures.append(executor.submit(worker, start, end))

            results = [future.result() for future in futures]

        return np.vstack(results)

    @staticmethod
    def parallel_sort(data, num_processes=None):
        """å¹¶è¡Œæ’åº"""
        if num_processes is None:
            num_processes = mp.cpu_count()

        def worker(chunk):
            return np.sort(chunk)

# åˆ†å‰²æ•°æ®
        chunk_size = len(data) // num_processes
        chunks = [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]

        with ProcessPoolExecutor(max_workers=num_processes) as executor:
            sorted_chunks = list(executor.map(worker, chunks))

# åˆå¹¶æ’åºç»“æœ
        return np.concatenate(sorted_chunks)

# ä½¿ç”¨ç¤ºä¾‹
def test_function(x):
    return np.sin(x) * np.cos(x)

print("å¹¶è¡Œè®¡ç®—æ€§èƒ½æµ‹è¯•:")
print(f"CPUæ ¸å¿ƒæ•°: {mp.cpu_count()}")

# å¹¶è¡Œè’™ç‰¹å¡æ´›ç§¯åˆ†
start_time = time.time()
result_parallel = ParallelComputing.parallel_monte_carlo(test_function, 0, np.pi, 1000000)
parallel_time = time.time() - start_time

start_time = time.time()
result_serial = NumericalIntegration.monte_carlo_integration(test_function, 0, np.pi, 1000000)
serial_time = time.time() - start_time

print(f"ä¸²è¡Œè’™ç‰¹å¡æ´›: {result_serial:.6f}, æ—¶é—´: {serial_time:.3f}s")
print(f"å¹¶è¡Œè’™ç‰¹å¡æ´›: {result_parallel:.6f}, æ—¶é—´: {parallel_time:.3f}s")
print(f"åŠ é€Ÿæ¯”: {serial_time/parallel_time:.2f}x")

# å¹¶è¡ŒçŸ©é˜µä¹˜æ³•
A = np.random.rand(500, 500)
B = np.random.rand(500, 500)

start_time = time.time()
C_parallel = ParallelComputing.parallel_matrix_multiply(A, B)
parallel_time = time.time() - start_time

start_time = time.time()
C_serial = A @ B
serial_time = time.time() - start_time

print(f"ä¸²è¡ŒçŸ©é˜µä¹˜æ³•: {serial_time:.3f}s")
print(f"å¹¶è¡ŒçŸ©é˜µä¹˜æ³•: {parallel_time:.3f}s")
print(f"åŠ é€Ÿæ¯”: {serial_time/parallel_time:.2f}x")
```

## 6. GPUåŠ é€Ÿè®¡ç®—

```python
try:
    import cupy as cp
    GPU_AVAILABLE = True
except ImportError:
    GPU_AVAILABLE = False
    print("CuPyæœªå®‰è£…ï¼ŒGPUåŠ é€Ÿä¸å¯ç”¨")

class GPUComputing:
    @staticmethod
    def gpu_matrix_multiply(A, B):
        """GPUçŸ©é˜µä¹˜æ³•"""
        if not GPU_AVAILABLE:
            return A @ B

        A_gpu = cp.asarray(A)
        B_gpu = cp.asarray(B)
        C_gpu = cp.dot(A_gpu, B_gpu)
        return cp.asnumpy(C_gpu)

    @staticmethod
    def gpu_monte_carlo(f, a, b, n=1000000):
        """GPUè’™ç‰¹å¡æ´›ç§¯åˆ†"""
        if not GPU_AVAILABLE:
            return NumericalIntegration.monte_carlo_integration(f, a, b, n)

        x = cp.random.uniform(a, b, n)
        y = f(x)
        return float((b - a) * cp.mean(y))

    @staticmethod
    def gpu_fft(data):
        """GPUå¿«é€Ÿå‚…é‡Œå¶å˜æ¢"""
        if not GPU_AVAILABLE:
            return np.fft.fft(data)

        data_gpu = cp.asarray(data)
        result_gpu = cp.fft.fft(data_gpu)
        return cp.asnumpy(result_gpu)

# ä½¿ç”¨ç¤ºä¾‹
if GPU_AVAILABLE:
    print("GPUåŠ é€Ÿè®¡ç®—æµ‹è¯•:")

# GPUçŸ©é˜µä¹˜æ³•
    A = np.random.rand(1000, 1000)
    B = np.random.rand(1000, 1000)

    start_time = time.time()
    C_gpu = GPUComputing.gpu_matrix_multiply(A, B)
    gpu_time = time.time() - start_time

    start_time = time.time()
    C_cpu = A @ B
    cpu_time = time.time() - start_time

    print(f"CPUçŸ©é˜µä¹˜æ³•: {cpu_time:.3f}s")
    print(f"GPUçŸ©é˜µä¹˜æ³•: {gpu_time:.3f}s")
    print(f"GPUåŠ é€Ÿæ¯”: {cpu_time/gpu_time:.2f}x")

# GPUè’™ç‰¹å¡æ´›ç§¯åˆ†
    start_time = time.time()
    result_gpu = GPUComputing.gpu_monte_carlo(test_function, 0, np.pi, 1000000)
    gpu_time = time.time() - start_time

    start_time = time.time()
    result_cpu = NumericalIntegration.monte_carlo_integration(test_function, 0, np.pi, 1000000)
    cpu_time = time.time() - start_time

    print(f"CPUè’™ç‰¹å¡æ´›: {result_cpu:.6f}, æ—¶é—´: {cpu_time:.3f}s")
    print(f"GPUè’™ç‰¹å¡æ´›: {result_gpu:.6f}, æ—¶é—´: {gpu_time:.3f}s")
    print(f"GPUåŠ é€Ÿæ¯”: {cpu_time/gpu_time:.2f}x")
else:
    print("GPUåŠ é€Ÿè®¡ç®—éœ€è¦å®‰è£…CuPyåº“")
```

## 7. å†…å­˜ä¼˜åŒ–

```python
import psutil
import gc

class MemoryOptimization:
    @staticmethod
    def memory_efficient_matrix_multiply(A, B, block_size=100):
        """å†…å­˜é«˜æ•ˆçš„çŸ©é˜µä¹˜æ³•"""
        m, n = A.shape
        n, p = B.shape
        C = np.zeros((m, p))

        for i in range(0, m, block_size):
            for j in range(0, p, block_size):
                for k in range(0, n, block_size):
                    i_end = min(i + block_size, m)
                    j_end = min(j + block_size, p)
                    k_end = min(k + block_size, n)

                    C[i:i_end, j:j_end] += A[i:i_end, k:k_end] @ B[k:k_end, j:j_end]

        return C

    @staticmethod
    def memory_usage():
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        process = psutil.Process()
        memory_info = process.memory_info()
        return {
            'rss': memory_info.rss / 1024 / 1024,  # MB
            'vms': memory_info.vms / 1024 / 1024,  # MB
            'percent': process.memory_percent()
        }

    @staticmethod
    def optimize_memory():
        """å†…å­˜ä¼˜åŒ–"""
        gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
        return MemoryOptimization.memory_usage()

# ä½¿ç”¨ç¤ºä¾‹
print("å†…å­˜ä¼˜åŒ–æµ‹è¯•:")
print(f"åˆå§‹å†…å­˜ä½¿ç”¨: {MemoryOptimization.memory_usage()}")

# åˆ›å»ºå¤§çŸ©é˜µ
A = np.random.rand(2000, 2000)
B = np.random.rand(2000, 2000)

print(f"åˆ›å»ºçŸ©é˜µåå†…å­˜ä½¿ç”¨: {MemoryOptimization.memory_usage()}")

# æ ‡å‡†çŸ©é˜µä¹˜æ³•
start_time = time.time()
C_standard = A @ B
standard_time = time.time() - start_time
print(f"æ ‡å‡†çŸ©é˜µä¹˜æ³•: {standard_time:.3f}s")
print(f"æ ‡å‡†ä¹˜æ³•åå†…å­˜ä½¿ç”¨: {MemoryOptimization.memory_usage()}")

# å†…å­˜ä¼˜åŒ–çŸ©é˜µä¹˜æ³•
start_time = time.time()
C_optimized = MemoryOptimization.memory_efficient_matrix_multiply(A, B)
optimized_time = time.time() - start_time
print(f"ä¼˜åŒ–çŸ©é˜µä¹˜æ³•: {optimized_time:.3f}s")
print(f"ä¼˜åŒ–ä¹˜æ³•åå†…å­˜ä½¿ç”¨: {MemoryOptimization.memory_usage()}")

# å†…å­˜ä¼˜åŒ–
MemoryOptimization.optimize_memory()
print(f"å†…å­˜ä¼˜åŒ–å: {MemoryOptimization.memory_usage()}")
```

## 8. æ€»ç»“

æœ¬æ–‡æ¡£æä¾›äº†ç§‘å­¦è®¡ç®—æ¨¡å—çš„å®è·µæ¡ˆä¾‹ï¼ŒåŒ…æ‹¬ï¼š

1. **åŸºç¡€ç§‘å­¦è®¡ç®—**ï¼šæ•°å€¼ç§¯åˆ†ã€å¾®åˆ†æ–¹ç¨‹æ±‚è§£ã€çº¿æ€§ä»£æ•°è®¡ç®—
2. **é«˜æ€§èƒ½è®¡ç®—**ï¼šå¹¶è¡Œè®¡ç®—ã€GPUåŠ é€Ÿã€å†…å­˜ä¼˜åŒ–

è¿™äº›å®è·µæ¡ˆä¾‹å±•ç¤ºäº†å¦‚ä½•å°†ç§‘å­¦è®¡ç®—ç†è®ºåº”ç”¨åˆ°å®é™…çš„é«˜æ€§èƒ½è®¡ç®—åœºæ™¯ä¸­ï¼Œä¸ºç§‘å­¦ç ”ç©¶å’Œå·¥ç¨‹åº”ç”¨æä¾›äº†å®ç”¨çš„å·¥å…·å’Œæ–¹æ³•ã€‚
