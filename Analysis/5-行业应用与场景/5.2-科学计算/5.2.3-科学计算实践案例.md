# 科学计算实践案例

## 概述

本文档提供科学计算模块的实践案例，包括基础科学计算和高性能计算的具体应用。

## 1. 基础科学计算

### 1.1 数值积分

```python
import numpy as np
from scipy import integrate

class NumericalIntegration:
    @staticmethod
    def trapezoidal_rule(f, a, b, n=1000):
        """梯形法则数值积分"""
        x = np.linspace(a, b, n+1)
        y = f(x)
        h = (b - a) / n
        return h * (0.5 * y[0] + np.sum(y[1:-1]) + 0.5 * y[-1])
    
    @staticmethod
    def simpson_rule(f, a, b, n=1000):
        """辛普森法则数值积分"""
        if n % 2 != 0:
            n += 1
        
        x = np.linspace(a, b, n+1)
        y = f(x)
        h = (b - a) / n
        
        return h/3 * (y[0] + 4*np.sum(y[1:-1:2]) + 2*np.sum(y[2:-1:2]) + y[-1])
    
    @staticmethod
    def monte_carlo_integration(f, a, b, n=10000):
        """蒙特卡洛积分"""
        x = np.random.uniform(a, b, n)
        y = f(x)
        return (b - a) * np.mean(y)

# 使用示例
def f(x):
    return np.sin(x)

a, b = 0, np.pi
exact_value = 2.0

print("数值积分结果:")
print(f"梯形法则: {NumericalIntegration.trapezoidal_rule(f, a, b):.6f}")
print(f"辛普森法则: {NumericalIntegration.simpson_rule(f, a, b):.6f}")
print(f"蒙特卡洛: {NumericalIntegration.monte_carlo_integration(f, a, b):.6f}")
print(f"精确值: {exact_value:.6f}")
```

### 1.2 微分方程求解

```python
from scipy.integrate import odeint
import matplotlib.pyplot as plt

class DifferentialEquations:
    @staticmethod
    def euler_method(f, y0, t_span, h):
        """欧拉方法求解常微分方程"""
        t = np.arange(t_span[0], t_span[1] + h, h)
        y = np.zeros(len(t))
        y[0] = y0
        
        for i in range(1, len(t)):
            y[i] = y[i-1] + h * f(t[i-1], y[i-1])
        
        return t, y
    
    @staticmethod
    def runge_kutta_4(f, y0, t_span, h):
        """四阶龙格库塔方法"""
        t = np.arange(t_span[0], t_span[1] + h, h)
        y = np.zeros(len(t))
        y[0] = y0
        
        for i in range(1, len(t)):
            k1 = h * f(t[i-1], y[i-1])
            k2 = h * f(t[i-1] + h/2, y[i-1] + k1/2)
            k3 = h * f(t[i-1] + h/2, y[i-1] + k2/2)
            k4 = h * f(t[i-1] + h, y[i-1] + k3)
            
            y[i] = y[i-1] + (k1 + 2*k2 + 2*k3 + k4) / 6
        
        return t, y
    
    @staticmethod
    def solve_ode_scipy(f, y0, t_span, t_eval=None):
        """使用SciPy求解常微分方程"""
        if t_eval is None:
            t_eval = np.linspace(t_span[0], t_span[1], 100)
        
        solution = odeint(f, y0, t_eval)
        return t_eval, solution

# 使用示例：求解y' = -y, y(0) = 1
def f(t, y):
    return -y

y0 = 1.0
t_span = (0, 5)
h = 0.1

# 不同方法求解
t_euler, y_euler = DifferentialEquations.euler_method(f, y0, t_span, h)
t_rk4, y_rk4 = DifferentialEquations.runge_kutta_4(f, y0, t_span, h)
t_scipy, y_scipy = DifferentialEquations.solve_ode_scipy(f, y0, t_span)

# 精确解
t_exact = np.linspace(0, 5, 100)
y_exact = np.exp(-t_exact)

print("微分方程求解结果比较:")
print(f"欧拉方法 (t=5): {y_euler[-1]:.6f}")
print(f"RK4方法 (t=5): {y_rk4[-1]:.6f}")
print(f"SciPy方法 (t=5): {y_scipy[-1]:.6f}")
print(f"精确解 (t=5): {y_exact[-1]:.6f}")
```

### 1.3 线性代数计算

```python
class LinearAlgebra:
    @staticmethod
    def gauss_elimination(A, b):
        """高斯消元法求解线性方程组"""
        n = len(A)
        A_aug = np.column_stack([A, b])
        
        # 前向消元
        for i in range(n):
            # 选择主元
            max_row = i + np.argmax(np.abs(A_aug[i:, i]))
            A_aug[i], A_aug[max_row] = A_aug[max_row].copy(), A_aug[i].copy()
            
            # 消元
            for j in range(i + 1, n):
                factor = A_aug[j, i] / A_aug[i, i]
                A_aug[j] -= factor * A_aug[i]
        
        # 回代
        x = np.zeros(n)
        for i in range(n-1, -1, -1):
            x[i] = (A_aug[i, -1] - np.dot(A_aug[i, i+1:n], x[i+1:])) / A_aug[i, i]
        
        return x
    
    @staticmethod
    def lu_decomposition(A):
        """LU分解"""
        n = len(A)
        L = np.eye(n)
        U = A.copy()
        
        for i in range(n):
            for j in range(i+1, n):
                factor = U[j, i] / U[i, i]
                L[j, i] = factor
                U[j] -= factor * U[i]
        
        return L, U
    
    @staticmethod
    def power_iteration(A, max_iter=100, tol=1e-6):
        """幂迭代法求最大特征值"""
        n = len(A)
        x = np.random.rand(n)
        x = x / np.linalg.norm(x)
        
        for i in range(max_iter):
            x_new = A @ x
            eigenvalue = np.dot(x, x_new)
            x_new = x_new / np.linalg.norm(x_new)
            
            if np.linalg.norm(x_new - x) < tol:
                break
            
            x = x_new
        
        return eigenvalue, x

# 使用示例
A = np.array([[4, -1, 0], [-1, 4, -1], [0, -1, 4]], dtype=float)
b = np.array([1, 5, 0], dtype=float)

print("线性代数计算:")
print("系数矩阵 A:")
print(A)
print("常数向量 b:", b)

# 高斯消元法求解
x_gauss = LinearAlgebra.gauss_elimination(A, b)
print("高斯消元法解:", x_gauss)

# LU分解
L, U = LinearAlgebra.lu_decomposition(A)
print("L矩阵:")
print(L)
print("U矩阵:")
print(U)

# 幂迭代法求特征值
eigenvalue, eigenvector = LinearAlgebra.power_iteration(A)
print(f"最大特征值: {eigenvalue:.6f}")
print(f"对应特征向量: {eigenvector}")
```

## 2. 高性能计算

### 2.1 并行计算

```python
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
import time

class ParallelComputing:
    @staticmethod
    def parallel_monte_carlo(f, a, b, n=100000, num_processes=None):
        """并行蒙特卡洛积分"""
        if num_processes is None:
            num_processes = mp.cpu_count()
        
        n_per_process = n // num_processes
        
        def worker(seed):
            np.random.seed(seed)
            x = np.random.uniform(a, b, n_per_process)
            y = f(x)
            return np.sum(y)
        
        with ProcessPoolExecutor(max_workers=num_processes) as executor:
            seeds = range(num_processes)
            results = list(executor.map(worker, seeds))
        
        return (b - a) * sum(results) / n
    
    @staticmethod
    def parallel_matrix_multiply(A, B, num_processes=None):
        """并行矩阵乘法"""
        if num_processes is None:
            num_processes = mp.cpu_count()
        
        m, n = A.shape
        n, p = B.shape
        
        def worker(row_start, row_end):
            result = np.zeros((row_end - row_start, p))
            for i in range(row_start, row_end):
                for j in range(p):
                    result[i - row_start, j] = np.dot(A[i, :], B[:, j])
            return result
        
        rows_per_process = m // num_processes
        with ProcessPoolExecutor(max_workers=num_processes) as executor:
            futures = []
            for i in range(num_processes):
                start = i * rows_per_process
                end = start + rows_per_process if i < num_processes - 1 else m
                futures.append(executor.submit(worker, start, end))
            
            results = [future.result() for future in futures]
        
        return np.vstack(results)
    
    @staticmethod
    def parallel_sort(data, num_processes=None):
        """并行排序"""
        if num_processes is None:
            num_processes = mp.cpu_count()
        
        def worker(chunk):
            return np.sort(chunk)
        
        # 分割数据
        chunk_size = len(data) // num_processes
        chunks = [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]
        
        with ProcessPoolExecutor(max_workers=num_processes) as executor:
            sorted_chunks = list(executor.map(worker, chunks))
        
        # 合并排序结果
        return np.concatenate(sorted_chunks)

# 使用示例
def test_function(x):
    return np.sin(x) * np.cos(x)

print("并行计算性能测试:")
print(f"CPU核心数: {mp.cpu_count()}")

# 并行蒙特卡洛积分
start_time = time.time()
result_parallel = ParallelComputing.parallel_monte_carlo(test_function, 0, np.pi, 1000000)
parallel_time = time.time() - start_time

start_time = time.time()
result_serial = NumericalIntegration.monte_carlo_integration(test_function, 0, np.pi, 1000000)
serial_time = time.time() - start_time

print(f"串行蒙特卡洛: {result_serial:.6f}, 时间: {serial_time:.3f}s")
print(f"并行蒙特卡洛: {result_parallel:.6f}, 时间: {parallel_time:.3f}s")
print(f"加速比: {serial_time/parallel_time:.2f}x")

# 并行矩阵乘法
A = np.random.rand(500, 500)
B = np.random.rand(500, 500)

start_time = time.time()
C_parallel = ParallelComputing.parallel_matrix_multiply(A, B)
parallel_time = time.time() - start_time

start_time = time.time()
C_serial = A @ B
serial_time = time.time() - start_time

print(f"串行矩阵乘法: {serial_time:.3f}s")
print(f"并行矩阵乘法: {parallel_time:.3f}s")
print(f"加速比: {serial_time/parallel_time:.2f}x")
```

### 2.2 GPU加速计算

```python
try:
    import cupy as cp
    GPU_AVAILABLE = True
except ImportError:
    GPU_AVAILABLE = False
    print("CuPy未安装，GPU加速不可用")

class GPUComputing:
    @staticmethod
    def gpu_matrix_multiply(A, B):
        """GPU矩阵乘法"""
        if not GPU_AVAILABLE:
            return A @ B
        
        A_gpu = cp.asarray(A)
        B_gpu = cp.asarray(B)
        C_gpu = cp.dot(A_gpu, B_gpu)
        return cp.asnumpy(C_gpu)
    
    @staticmethod
    def gpu_monte_carlo(f, a, b, n=1000000):
        """GPU蒙特卡洛积分"""
        if not GPU_AVAILABLE:
            return NumericalIntegration.monte_carlo_integration(f, a, b, n)
        
        x = cp.random.uniform(a, b, n)
        y = f(x)
        return float((b - a) * cp.mean(y))
    
    @staticmethod
    def gpu_fft(data):
        """GPU快速傅里叶变换"""
        if not GPU_AVAILABLE:
            return np.fft.fft(data)
        
        data_gpu = cp.asarray(data)
        result_gpu = cp.fft.fft(data_gpu)
        return cp.asnumpy(result_gpu)

# 使用示例
if GPU_AVAILABLE:
    print("GPU加速计算测试:")
    
    # GPU矩阵乘法
    A = np.random.rand(1000, 1000)
    B = np.random.rand(1000, 1000)
    
    start_time = time.time()
    C_gpu = GPUComputing.gpu_matrix_multiply(A, B)
    gpu_time = time.time() - start_time
    
    start_time = time.time()
    C_cpu = A @ B
    cpu_time = time.time() - start_time
    
    print(f"CPU矩阵乘法: {cpu_time:.3f}s")
    print(f"GPU矩阵乘法: {gpu_time:.3f}s")
    print(f"GPU加速比: {cpu_time/gpu_time:.2f}x")
    
    # GPU蒙特卡洛积分
    start_time = time.time()
    result_gpu = GPUComputing.gpu_monte_carlo(test_function, 0, np.pi, 1000000)
    gpu_time = time.time() - start_time
    
    start_time = time.time()
    result_cpu = NumericalIntegration.monte_carlo_integration(test_function, 0, np.pi, 1000000)
    cpu_time = time.time() - start_time
    
    print(f"CPU蒙特卡洛: {result_cpu:.6f}, 时间: {cpu_time:.3f}s")
    print(f"GPU蒙特卡洛: {result_gpu:.6f}, 时间: {gpu_time:.3f}s")
    print(f"GPU加速比: {cpu_time/gpu_time:.2f}x")
else:
    print("GPU加速计算需要安装CuPy库")
```

### 2.3 内存优化

```python
import psutil
import gc

class MemoryOptimization:
    @staticmethod
    def memory_efficient_matrix_multiply(A, B, block_size=100):
        """内存高效的矩阵乘法"""
        m, n = A.shape
        n, p = B.shape
        C = np.zeros((m, p))
        
        for i in range(0, m, block_size):
            for j in range(0, p, block_size):
                for k in range(0, n, block_size):
                    i_end = min(i + block_size, m)
                    j_end = min(j + block_size, p)
                    k_end = min(k + block_size, n)
                    
                    C[i:i_end, j:j_end] += A[i:i_end, k:k_end] @ B[k:k_end, j:j_end]
        
        return C
    
    @staticmethod
    def memory_usage():
        """获取当前内存使用情况"""
        process = psutil.Process()
        memory_info = process.memory_info()
        return {
            'rss': memory_info.rss / 1024 / 1024,  # MB
            'vms': memory_info.vms / 1024 / 1024,  # MB
            'percent': process.memory_percent()
        }
    
    @staticmethod
    def optimize_memory():
        """内存优化"""
        gc.collect()  # 强制垃圾回收
        return MemoryOptimization.memory_usage()

# 使用示例
print("内存优化测试:")
print(f"初始内存使用: {MemoryOptimization.memory_usage()}")

# 创建大矩阵
A = np.random.rand(2000, 2000)
B = np.random.rand(2000, 2000)

print(f"创建矩阵后内存使用: {MemoryOptimization.memory_usage()}")

# 标准矩阵乘法
start_time = time.time()
C_standard = A @ B
standard_time = time.time() - start_time
print(f"标准矩阵乘法: {standard_time:.3f}s")
print(f"标准乘法后内存使用: {MemoryOptimization.memory_usage()}")

# 内存优化矩阵乘法
start_time = time.time()
C_optimized = MemoryOptimization.memory_efficient_matrix_multiply(A, B)
optimized_time = time.time() - start_time
print(f"优化矩阵乘法: {optimized_time:.3f}s")
print(f"优化乘法后内存使用: {MemoryOptimization.memory_usage()}")

# 内存优化
MemoryOptimization.optimize_memory()
print(f"内存优化后: {MemoryOptimization.memory_usage()}")
```

## 总结

本文档提供了科学计算模块的实践案例，包括：

1. **基础科学计算**：数值积分、微分方程求解、线性代数计算
2. **高性能计算**：并行计算、GPU加速、内存优化

这些实践案例展示了如何将科学计算理论应用到实际的高性能计算场景中，为科学研究和工程应用提供了实用的工具和方法。
