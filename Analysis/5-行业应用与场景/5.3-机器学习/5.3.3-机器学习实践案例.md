# 机器学习实践案例

## 概述

本文档提供机器学习模块的实践案例，包括基础机器学习和深度学习的具体应用。

## 1. 基础机器学习

### 1.1 线性回归

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

class LinearRegressionModel:
    def __init__(self, learning_rate=0.01, max_iterations=1000):
        self.learning_rate = learning_rate
        self.max_iterations = max_iterations
        self.weights = None
        self.bias = None
        self.cost_history = []
    
    def fit(self, X, y):
        """训练线性回归模型"""
        n_samples, n_features = X.shape
        self.weights = np.zeros(n_features)
        self.bias = 0
        
        for i in range(self.max_iterations):
            # 前向传播
            y_pred = np.dot(X, self.weights) + self.bias
            
            # 计算梯度
            dw = (1/n_samples) * np.dot(X.T, (y_pred - y))
            db = (1/n_samples) * np.sum(y_pred - y)
            
            # 更新参数
            self.weights -= self.learning_rate * dw
            self.bias -= self.learning_rate * db
            
            # 记录成本
            cost = np.mean((y_pred - y) ** 2)
            self.cost_history.append(cost)
    
    def predict(self, X):
        """预测"""
        return np.dot(X, self.weights) + self.bias
    
    def plot_cost_history(self):
        """绘制成本历史"""
        plt.plot(self.cost_history)
        plt.xlabel('Iteration')
        plt.ylabel('Cost')
        plt.title('Cost History')
        plt.show()

# 使用示例
np.random.seed(42)
X = np.random.rand(100, 1) * 10
y = 2 * X.flatten() + 1 + np.random.normal(0, 1, 100)

# 分割数据
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 自定义线性回归
model = LinearRegressionModel(learning_rate=0.01, max_iterations=1000)
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

print("线性回归结果:")
print(f"MSE: {mean_squared_error(y_test, y_pred):.4f}")
print(f"R²: {r2_score(y_test, y_pred):.4f}")

# 绘制结果
plt.scatter(X_test, y_test, color='blue', label='Actual')
plt.scatter(X_test, y_pred, color='red', label='Predicted')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Linear Regression')
plt.legend()
plt.show()
```

### 1.2 逻辑回归

```python
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

class LogisticRegressionModel:
    def __init__(self, learning_rate=0.01, max_iterations=1000):
        self.learning_rate = learning_rate
        self.max_iterations = max_iterations
        self.weights = None
        self.bias = None
    
    def sigmoid(self, z):
        """sigmoid函数"""
        return 1 / (1 + np.exp(-z))
    
    def fit(self, X, y):
        """训练逻辑回归模型"""
        n_samples, n_features = X.shape
        self.weights = np.zeros(n_features)
        self.bias = 0
        
        for i in range(self.max_iterations):
            # 前向传播
            linear_pred = np.dot(X, self.weights) + self.bias
            predictions = self.sigmoid(linear_pred)
            
            # 计算梯度
            dw = (1/n_samples) * np.dot(X.T, (predictions - y))
            db = (1/n_samples) * np.sum(predictions - y)
            
            # 更新参数
            self.weights -= self.learning_rate * dw
            self.bias -= self.learning_rate * db
    
    def predict(self, X):
        """预测"""
        linear_pred = np.dot(X, self.weights) + self.bias
        y_pred = self.sigmoid(linear_pred)
        return (y_pred >= 0.5).astype(int)
    
    def predict_proba(self, X):
        """预测概率"""
        linear_pred = np.dot(X, self.weights) + self.bias
        return self.sigmoid(linear_pred)

# 使用示例
from sklearn.datasets import make_classification

# 生成分类数据
X, y = make_classification(n_samples=1000, n_features=2, n_redundant=0, 
                          n_informative=2, random_state=42, n_clusters_per_class=1)

# 分割数据
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 自定义逻辑回归
model = LogisticRegressionModel(learning_rate=0.1, max_iterations=1000)
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)

print("逻辑回归结果:")
print(f"准确率: {accuracy_score(y_test, y_pred):.4f}")
print("分类报告:")
print(classification_report(y_test, y_pred))
```

### 1.3 决策树

```python
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.datasets import load_iris

class DecisionTree:
    def __init__(self, max_depth=None, min_samples_split=2):
        self.max_depth = max_depth
        self.min_samples_split = min_samples_split
        self.tree = None
    
    def fit(self, X, y):
        """训练决策树"""
        self.tree = DecisionTreeClassifier(
            max_depth=self.max_depth,
            min_samples_split=self.min_samples_split,
            random_state=42
        )
        self.tree.fit(X, y)
    
    def predict(self, X):
        """预测"""
        return self.tree.predict(X)
    
    def plot_tree_structure(self):
        """绘制决策树结构"""
        plt.figure(figsize=(20,10))
        plot_tree(self.tree, filled=True, rounded=True, feature_names=[f'feature_{i}' for i in range(X.shape[1])])
        plt.show()

# 使用示例
iris = load_iris()
X = iris.data
y = iris.target

# 分割数据
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 决策树
dt_model = DecisionTree(max_depth=3)
dt_model.fit(X_train, y_train)

# 预测
y_pred = dt_model.predict(X_test)

print("决策树结果:")
print(f"准确率: {accuracy_score(y_test, y_pred):.4f}")
print("分类报告:")
print(classification_report(y_test, y_pred, target_names=iris.target_names))
```

### 1.4 随机森林

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import feature_importance

class RandomForest:
    def __init__(self, n_estimators=100, max_depth=None):
        self.n_estimators = n_estimators
        self.max_depth = max_depth
        self.model = None
    
    def fit(self, X, y):
        """训练随机森林"""
        self.model = RandomForestClassifier(
            n_estimators=self.n_estimators,
            max_depth=self.max_depth,
            random_state=42
        )
        self.model.fit(X, y)
    
    def predict(self, X):
        """预测"""
        return self.model.predict(X)
    
    def get_feature_importance(self, feature_names=None):
        """获取特征重要性"""
        importance = self.model.feature_importances_
        if feature_names is None:
            feature_names = [f'feature_{i}' for i in range(len(importance))]
        
        return dict(zip(feature_names, importance))

# 使用示例
rf_model = RandomForest(n_estimators=100, max_depth=5)
rf_model.fit(X_train, y_train)

# 预测
y_pred = rf_model.predict(X_test)

print("随机森林结果:")
print(f"准确率: {accuracy_score(y_test, y_pred):.4f}")

# 特征重要性
importance = rf_model.get_feature_importance(iris.feature_names)
print("特征重要性:")
for feature, imp in sorted(importance.items(), key=lambda x: x[1], reverse=True):
    print(f"{feature}: {imp:.4f}")
```

## 2. 深度学习

### 2.1 简单神经网络

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

class SimpleNeuralNetwork(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SimpleNeuralNetwork, self).__init__()
        self.layer1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.layer2 = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        x = self.layer1(x)
        x = self.relu(x)
        x = self.layer2(x)
        return x

class NeuralNetworkTrainer:
    def __init__(self, model, learning_rate=0.01):
        self.model = model
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        self.train_losses = []
        self.val_losses = []
    
    def train(self, train_loader, val_loader, epochs=100):
        """训练神经网络"""
        for epoch in range(epochs):
            # 训练阶段
            self.model.train()
            train_loss = 0
            for batch_X, batch_y in train_loader:
                self.optimizer.zero_grad()
                outputs = self.model(batch_X)
                loss = self.criterion(outputs, batch_y)
                loss.backward()
                self.optimizer.step()
                train_loss += loss.item()
            
            # 验证阶段
            self.model.eval()
            val_loss = 0
            with torch.no_grad():
                for batch_X, batch_y in val_loader:
                    outputs = self.model(batch_X)
                    loss = self.criterion(outputs, batch_y)
                    val_loss += loss.item()
            
            self.train_losses.append(train_loss / len(train_loader))
            self.val_losses.append(val_loss / len(val_loader))
            
            if epoch % 10 == 0:
                print(f'Epoch {epoch}: Train Loss: {self.train_losses[-1]:.4f}, Val Loss: {self.val_losses[-1]:.4f}')
    
    def predict(self, X):
        """预测"""
        self.model.eval()
        with torch.no_grad():
            X_tensor = torch.FloatTensor(X)
            outputs = self.model(X_tensor)
            _, predicted = torch.max(outputs, 1)
            return predicted.numpy()

# 使用示例
# 准备数据
X_tensor = torch.FloatTensor(X_train)
y_tensor = torch.LongTensor(y_train)

train_dataset = TensorDataset(X_tensor, y_tensor)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

X_val_tensor = torch.FloatTensor(X_test)
y_val_tensor = torch.LongTensor(y_test)

val_dataset = TensorDataset(X_val_tensor, y_val_tensor)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# 创建模型
model = SimpleNeuralNetwork(input_size=4, hidden_size=10, output_size=3)
trainer = NeuralNetworkTrainer(model, learning_rate=0.01)

# 训练模型
trainer.train(train_loader, val_loader, epochs=100)

# 预测
y_pred = trainer.predict(X_test)

print("神经网络结果:")
print(f"准确率: {accuracy_score(y_test, y_pred):.4f}")
```

### 2.2 卷积神经网络

```python
import torchvision
import torchvision.transforms as transforms

class CNN(nn.Module):
    def __init__(self, num_classes=10):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, num_classes)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.5)
    
    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = x.view(-1, 64 * 7 * 7)
        x = self.dropout(self.relu(self.fc1(x)))
        x = self.fc2(x)
        return x

# 使用示例（简化版，使用随机数据）
def create_mock_mnist_data():
    """创建模拟MNIST数据"""
    X = torch.randn(1000, 1, 28, 28)  # 模拟图像数据
    y = torch.randint(0, 10, (1000,))  # 模拟标签
    return X, y

# 准备数据
X_mock, y_mock = create_mock_mnist_data()
X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(
    X_mock, y_mock, test_size=0.2, random_state=42
)

# 创建数据加载器
train_dataset = TensorDataset(X_train_cnn, y_train_cnn)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

val_dataset = TensorDataset(X_test_cnn, y_test_cnn)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# 创建CNN模型
cnn_model = CNN(num_classes=10)
cnn_trainer = NeuralNetworkTrainer(cnn_model, learning_rate=0.001)

# 训练模型
cnn_trainer.train(train_loader, val_loader, epochs=50)

# 预测
y_pred_cnn = cnn_trainer.predict(X_test_cnn)

print("CNN结果:")
print(f"准确率: {accuracy_score(y_test_cnn, y_pred_cnn):.4f}")
```

### 2.3 循环神经网络

```python
class RNN(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes):
        super(RNN, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, num_classes)
    
    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)
        
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out

# 使用示例（序列分类）
def create_sequence_data():
    """创建序列数据"""
    X = torch.randn(1000, 10, 5)  # 1000个序列，每个序列10个时间步，每个时间步5个特征
    y = torch.randint(0, 3, (1000,))  # 3个类别
    return X, y

# 准备数据
X_seq, y_seq = create_sequence_data()
X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(
    X_seq, y_seq, test_size=0.2, random_state=42
)

# 创建数据加载器
train_dataset = TensorDataset(X_train_seq, y_train_seq)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

val_dataset = TensorDataset(X_test_seq, y_test_seq)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# 创建RNN模型
rnn_model = RNN(input_size=5, hidden_size=64, num_layers=2, num_classes=3)
rnn_trainer = NeuralNetworkTrainer(rnn_model, learning_rate=0.01)

# 训练模型
rnn_trainer.train(train_loader, val_loader, epochs=50)

# 预测
y_pred_rnn = rnn_trainer.predict(X_test_seq)

print("RNN结果:")
print(f"准确率: {accuracy_score(y_test_seq, y_pred_rnn):.4f}")
```

## 3. 模型评估与优化

### 3.1 交叉验证

```python
from sklearn.model_selection import cross_val_score, KFold
from sklearn.metrics import make_scorer, accuracy_score

class ModelEvaluator:
    @staticmethod
    def cross_validate_model(model, X, y, cv=5):
        """交叉验证"""
        kfold = KFold(n_splits=cv, shuffle=True, random_state=42)
        scores = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')
        
        print(f"交叉验证结果:")
        print(f"平均准确率: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})")
        return scores
    
    @staticmethod
    def plot_learning_curves(trainer):
        """绘制学习曲线"""
        plt.figure(figsize=(10, 5))
        plt.subplot(1, 2, 1)
        plt.plot(trainer.train_losses, label='Training Loss')
        plt.plot(trainer.val_losses, label='Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Learning Curves')
        plt.legend()
        plt.show()

# 使用示例
print("模型评估:")
# 交叉验证
scores = ModelEvaluator.cross_validate_model(rf_model.model, X, y, cv=5)

# 学习曲线
ModelEvaluator.plot_learning_curves(trainer)
```

### 3.2 超参数调优

```python
from sklearn.model_selection import GridSearchCV

class HyperparameterTuner:
    @staticmethod
    def tune_random_forest(X, y):
        """调优随机森林超参数"""
        param_grid = {
            'n_estimators': [50, 100, 200],
            'max_depth': [3, 5, 7, None],
            'min_samples_split': [2, 5, 10]
        }
        
        rf = RandomForestClassifier(random_state=42)
        grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)
        grid_search.fit(X, y)
        
        print("最佳参数:", grid_search.best_params_)
        print("最佳得分:", grid_search.best_score_)
        
        return grid_search.best_estimator_

# 使用示例
print("超参数调优:")
best_rf = HyperparameterTuner.tune_random_forest(X, y)
```

## 总结

本文档提供了机器学习模块的实践案例，包括：

1. **基础机器学习**：线性回归、逻辑回归、决策树、随机森林
2. **深度学习**：简单神经网络、卷积神经网络、循环神经网络
3. **模型评估与优化**：交叉验证、超参数调优

这些实践案例展示了如何将机器学习理论应用到实际的数据分析和预测任务中，为构建智能系统提供了实用的工具和方法。
