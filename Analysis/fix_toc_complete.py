#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´ä¿®å¤ç›®å½•ç»“æ„ï¼š
1. ä¸ºç¼ºå°‘ç›®å½•çš„æ–‡ä»¶æ·»åŠ ç›®å½•
2. ç§»é™¤å¤šä½™çš„ç›®å½•ï¼Œåªä¿ç•™ä¸€ä¸ª
3. ç¡®ä¿ç›®å½•æ ¼å¼ç»Ÿä¸€
"""

import os
import re
from pathlib import Path
from typing import List, Tuple, Dict

def extract_headings(content: str) -> List[Tuple[int, str, str]]:
    """æå–æ‰€æœ‰æ ‡é¢˜ï¼Œè¿”å›(çº§åˆ«, æ ‡é¢˜æ–‡æœ¬, åŸå§‹è¡Œ)"""
    headings = []
    lines = content.split('\n')
    in_code_block = False
    code_block_markers = ['```', '~~~']
    
    for i, line in enumerate(lines):
        # æ£€æµ‹ä»£ç å—
        stripped = line.strip()
        
        # æ£€æµ‹ä»£ç å—å¼€å§‹/ç»“æŸ
        if stripped.startswith('```') or stripped.startswith('~~~'):
            marker_char = stripped[0] if stripped else ''
            if len(stripped) >= 3 and stripped[0] == stripped[1] == stripped[2]:
                in_code_block = not in_code_block
            continue
        
        # è·³è¿‡ä»£ç å—å†…çš„æ‰€æœ‰å†…å®¹
        if in_code_block:
            continue
        
        # è·³è¿‡ç©ºè¡Œ
        if not stripped:
            continue
        
        # è·³è¿‡ç¼©è¿›çš„è¡Œï¼ˆå¯èƒ½æ˜¯ä»£ç æˆ–åˆ—è¡¨é¡¹ï¼‰
        if line.startswith('    ') or line.startswith('\t'):
            continue
        
        # è·³è¿‡çœ‹èµ·æ¥åƒä»£ç æ³¨é‡Šçš„è¡Œ
        if stripped.startswith('#') and not re.match(r'^#{1,6}\s+[^#]', line):
            continue
        
        # è·³è¿‡çœ‹èµ·æ¥åƒä»£ç è¾“å‡ºçš„è¡Œ
        if re.match(r'^[\[\{\(].*[\]\}\)]', stripped) and any(c in stripped for c in ["'", '"', 'b\'', 'b"']):
            continue
        
        # è·³è¿‡é…ç½®æ–‡ä»¶å
        if re.match(r'^[a-z_]+\.(conf|config|yaml|yml|json|xml)$', stripped, re.IGNORECASE):
            continue
        
        # åŒ¹é…æ ‡é¢˜
        match = re.match(r'^(#{1,6})\s+(.+)$', line)
        if match:
            level = len(match.group(1))
            text = match.group(2).strip()
            
            # è¿‡æ»¤æ‰æ˜æ˜¾ä¸æ˜¯æ ‡é¢˜çš„å†…å®¹
            if len(text) < 2:
                continue
            if re.match(r'^[\[\{\(].*[\]\}\)]$', text) and any(c in text for c in ["'", '"', 'b\'']):
                continue
            if text.startswith('b\'') or text.startswith('b"'):
                continue
            
            headings.append((level, text, line))
    
    return headings

def generate_anchor(text: str) -> str:
    """ç”ŸæˆGitHubé£æ ¼çš„é”šç‚¹"""
    anchor = text.lower()
    anchor = re.sub(r'\s+', '-', anchor)
    anchor = re.sub(r'[^\w\u4e00-\u9fff\-\(\)]', '', anchor)
    anchor = re.sub(r'-+', '-', anchor)
    anchor = anchor.strip('-')
    return anchor

def generate_toc(headings: List[Tuple[int, str, str]]) -> str:
    """ç”Ÿæˆç›®å½•ï¼Œä¿ç•™æ ‡é¢˜ç¼–å·"""
    if not headings:
        return ""
    
    toc_lines = ["## ğŸ“‘ ç›®å½•", ""]
    
    # ç¬¬ä¸€ä¸ªæ ‡é¢˜åº”è¯¥æ˜¯H1ï¼Œä½œä¸ºæ–‡æ¡£æ ‡é¢˜
    if headings[0][0] == 1:
        doc_title = headings[0][1]
        doc_anchor = generate_anchor(doc_title)
        toc_lines.append(f"- [{doc_title}](#{doc_anchor})")
        toc_lines.append("  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)")
        start_idx = 1
    else:
        start_idx = 0
    
    # å¤„ç†å…¶ä»–æ ‡é¢˜
    stack = []
    
    for i in range(start_idx, len(headings)):
        level, text, _ = headings[i]
        
        # è·³è¿‡ç›®å½•æ ‡é¢˜æœ¬èº«
        if text == "ğŸ“‘ ç›®å½•" or text == "ç›®å½•":
            continue
        
        # ç¡®å®šç¼©è¿›
        while stack and stack[-1][0] >= level:
            stack.pop()
        
        indent = "  " * len(stack)
        anchor = generate_anchor(text)
        
        toc_item = f"{indent}- [{text}](#{anchor})"
        toc_lines.append(toc_item)
        
        stack.append((level, text))
    
    return "\n".join(toc_lines)

def find_toc_positions(content: str) -> List[Tuple[int, int]]:
    """æ‰¾åˆ°æ‰€æœ‰ç›®å½•çš„ä½ç½®ï¼ˆå¼€å§‹è¡Œï¼Œç»“æŸè¡Œï¼‰ï¼Œæ’é™¤ä»£ç å—ä¸­çš„"""
    lines = content.split('\n')
    toc_positions = []
    in_code_block = False
    code_block_markers = ['```', '~~~']
    
    for i, line in enumerate(lines):
        # æ£€æµ‹ä»£ç å—
        stripped = line.strip()
        if stripped.startswith('```') or stripped.startswith('~~~'):
            marker_char = stripped[0] if stripped else ''
            if len(stripped) >= 3 and stripped[0] == marker_char == stripped[1] == stripped[2]:
                in_code_block = not in_code_block
            continue
        
        # è·³è¿‡ä»£ç å—å†…çš„å†…å®¹
        if in_code_block:
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®å½•æ ‡é¢˜ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰
        if re.match(r'^##\s+[ğŸ“‘]?\s*ç›®å½•', line) or re.match(r'^##\s+.*[Tt]able.*[Cc]ontents', line):
            # æ‰¾åˆ°ç›®å½•å¼€å§‹
            start = i
            # æ‰¾åˆ°ç›®å½•ç»“æŸï¼ˆä¸‹ä¸€ä¸ªåŒçº§æˆ–æ›´é«˜çº§æ ‡é¢˜ï¼Œæˆ–åˆ†éš”çº¿ï¼‰
            end = len(lines)
            for j in range(i + 1, len(lines)):
                if re.match(r'^---', lines[j]):
                    end = j
                    break
                if re.match(r'^##\s+', lines[j]) and not re.match(r'^##\s+[ğŸ“‘]?\s*ç›®å½•', lines[j]):
                    end = j
                    break
                if re.match(r'^#\s+', lines[j]):
                    end = j
                    break
            toc_positions.append((start, end))
    
    return toc_positions

def fix_document(file_path: Path) -> Tuple[bool, str, str]:
    """ä¿®å¤å•ä¸ªæ–‡æ¡£çš„ç›®å½•ç»“æ„"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        return False, f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}", ""
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯å ä½æ–‡ä»¶
    if 'æœ¬æ–‡ä»¶ç”±è‡ªåŠ¨åŒ–å·¥å…·åˆ›å»º' in content:
        return False, "å ä½æ–‡ä»¶ï¼Œè·³è¿‡", ""
    
    # æå–æ ‡é¢˜
    headings = extract_headings(content)
    
    if not headings:
        return False, "æ²¡æœ‰æ‰¾åˆ°æ ‡é¢˜", ""
    
    # ç”Ÿæˆæ–°ç›®å½•
    new_toc = generate_toc(headings)
    
    if not new_toc:
        return False, "æ— æ³•ç”Ÿæˆç›®å½•", ""
    
    # æ£€æŸ¥ç°æœ‰ç›®å½•
    toc_positions = find_toc_positions(content)
    lines = content.split('\n')
    
    if len(toc_positions) == 0:
        # æ²¡æœ‰ç›®å½•ï¼Œæ·»åŠ ä¸€ä¸ª
        insert_pos = 0
        for i, line in enumerate(lines):
            if re.match(r'^#\s+', line):
                insert_pos = i + 1
                break
        
        new_lines = lines[:insert_pos] + [""] + new_toc.split('\n') + [""] + ["---", ""] + lines[insert_pos:]
        new_content = '\n'.join(new_lines)
        action = "æ·»åŠ ç›®å½•"
        
    elif len(toc_positions) == 1:
        # æœ‰ä¸€ä¸ªç›®å½•ï¼Œæ›¿æ¢å®ƒ
        start, end = toc_positions[0]
        new_lines = lines[:start] + new_toc.split('\n') + lines[end:]
        new_content = '\n'.join(new_lines)
        action = "æ›´æ–°ç›®å½•"
        
    else:
        # æœ‰å¤šä¸ªç›®å½•ï¼Œåªä¿ç•™ç¬¬ä¸€ä¸ªï¼Œæ›¿æ¢å®ƒ
        start, end = toc_positions[0]
        # ç§»é™¤å…¶ä»–ç›®å½•
        to_remove = []
        for pos_start, pos_end in toc_positions[1:]:
            to_remove.append((pos_start, pos_end))
        
        # ä»åå¾€å‰åˆ é™¤ï¼Œé¿å…ç´¢å¼•å˜åŒ–
        new_lines = lines[:]
        for pos_start, pos_end in reversed(to_remove):
            new_lines = new_lines[:pos_start] + new_lines[pos_end:]
        
        # æ›´æ–°ç¬¬ä¸€ä¸ªç›®å½•
        # é‡æ–°è®¡ç®—ä½ç½®ï¼ˆå› ä¸ºå¯èƒ½å·²ç»åˆ é™¤äº†å…¶ä»–ç›®å½•ï¼‰
        new_content_temp = '\n'.join(new_lines)
        new_lines_temp = new_content_temp.split('\n')
        for i, line in enumerate(new_lines_temp):
            if re.match(r'^##\s+[ğŸ“‘]?\s*ç›®å½•', line):
                start = i
                end = len(new_lines_temp)
                for j in range(i + 1, len(new_lines_temp)):
                    if re.match(r'^---', new_lines_temp[j]):
                        end = j
                        break
                    if re.match(r'^##\s+', new_lines_temp[j]) and not re.match(r'^##\s+[ğŸ“‘]?\s*ç›®å½•', new_lines_temp[j]):
                        end = j
                        break
                    if re.match(r'^#\s+', new_lines_temp[j]):
                        end = j
                        break
                break
        
        new_lines = new_lines_temp[:start] + new_toc.split('\n') + new_lines_temp[end:]
        new_content = '\n'.join(new_lines)
        action = f"ç§»é™¤{len(toc_positions)-1}ä¸ªå¤šä½™ç›®å½•ï¼Œæ›´æ–°å‰©ä½™ç›®å½•"
    
    # å†™å›æ–‡ä»¶
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        return True, action, ""
    except Exception as e:
        return False, f"å†™å…¥æ–‡ä»¶å¤±è´¥: {e}", ""

def main():
    """ä¸»å‡½æ•°"""
    base_dir = Path(__file__).parent
    
    # æŸ¥æ‰¾æ‰€æœ‰Markdownæ–‡ä»¶
    md_files = list(base_dir.rglob("*.md"))
    md_files = [f for f in md_files if f.name != "README.md"]
    md_files = [f for f in md_files if not f.name.startswith("fix_") and not f.name.startswith("check_")]
    
    print(f"æ‰¾åˆ° {len(md_files)} ä¸ªMarkdownæ–‡ä»¶")
    print("=" * 60)
    
    fixed_count = 0
    error_count = 0
    skipped_count = 0
    multiple_toc_fixed = 0
    
    for md_file in sorted(md_files):
        rel_path = md_file.relative_to(base_dir)
        print(f"\nå¤„ç†: {rel_path}")
        
        success, message, _ = fix_document(md_file)
        
        if success:
            print(f"  âœ… {message}")
            fixed_count += 1
            if "ç§»é™¤" in message and "å¤šä½™ç›®å½•" in message:
                multiple_toc_fixed += 1
        elif "å ä½æ–‡ä»¶" in message or "æ²¡æœ‰æ‰¾åˆ°æ ‡é¢˜" in message or "æ— æ³•ç”Ÿæˆç›®å½•" in message:
            print(f"  â­ï¸  {message}")
            skipped_count += 1
        else:
            print(f"  âŒ {message}")
            error_count += 1
    
    print("\n" + "=" * 60)
    print(f"å¤„ç†å®Œæˆ:")
    print(f"  âœ… æˆåŠŸ: {fixed_count}")
    print(f"    - ä¿®å¤å¤šä¸ªç›®å½•: {multiple_toc_fixed}")
    print(f"  â­ï¸  è·³è¿‡: {skipped_count}")
    print(f"  âŒ é”™è¯¯: {error_count}")
    print(f"  ğŸ“Š æ€»è®¡: {len(md_files)}")

if __name__ == "__main__":
    main()
