# çŸ¥è¯†å›¾è°±éƒ¨ç½²æŒ‡å—

## ğŸ“‘ ç›®å½•

- [çŸ¥è¯†å›¾è°±éƒ¨ç½²æŒ‡å—](#çŸ¥è¯†å›¾è°±éƒ¨ç½²æŒ‡å—)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
- [1. å®¹å™¨åŒ–éƒ¨ç½²](#1-å®¹å™¨åŒ–éƒ¨ç½²)
  - [1.1. Dockeré…ç½®](#11-dockeré…ç½®)
- [2. Docker Composeé…ç½®](#2-docker-composeé…ç½®)
- [3. Kuberneteséƒ¨ç½²é…ç½®](#3-kuberneteséƒ¨ç½²é…ç½®)
- [4. äº‘å¹³å°éƒ¨ç½²](#4-äº‘å¹³å°éƒ¨ç½²)
  - [4.1. AWSéƒ¨ç½²é…ç½®](#41-awséƒ¨ç½²é…ç½®)
- [5. Azureéƒ¨ç½²é…ç½®](#5-azureéƒ¨ç½²é…ç½®)
- [6. Google Cloudéƒ¨ç½²é…ç½®](#6-google-cloudéƒ¨ç½²é…ç½®)
- [7. ç›‘æ§å’Œæ—¥å¿—](#7-ç›‘æ§å’Œæ—¥å¿—)
  - [7.1. Prometheusç›‘æ§é…ç½®](#71-prometheusç›‘æ§é…ç½®)
- [8. Grafanaä»ªè¡¨æ¿é…ç½®](#8-grafanaä»ªè¡¨æ¿é…ç½®)
  - [8.1. æ—¥å¿—é…ç½®](#81-æ—¥å¿—é…ç½®)
- [9. å®‰å…¨é…ç½®](#9-å®‰å…¨é…ç½®)
  - [9.1. SSL/TLSé…ç½®](#91-ssltlsé…ç½®)
- [10. å®‰å…¨ä¸­é—´ä»¶](#10-å®‰å…¨ä¸­é—´ä»¶)
- [11. å¤‡ä»½å’Œæ¢å¤](#11-å¤‡ä»½å’Œæ¢å¤)
  - [11.1. å¤‡ä»½è„šæœ¬](#111-å¤‡ä»½è„šæœ¬)
- [12. å·¥å…·ä¸å¹³å°](#12-å·¥å…·ä¸å¹³å°)
  - [12.1. éƒ¨ç½²å·¥å…·](#121-éƒ¨ç½²å·¥å…·)
  - [12.2. ç›‘æ§å·¥å…·](#122-ç›‘æ§å·¥å…·)
  - [12.3. äº‘å¹³å°](#123-äº‘å¹³å°)
- [13. æœ€ä½³å®è·µ](#13-æœ€ä½³å®è·µ)
  - [13.1. éƒ¨ç½²ç­–ç•¥](#131-éƒ¨ç½²ç­–ç•¥)
  - [13.2. å®‰å…¨è€ƒè™‘](#132-å®‰å…¨è€ƒè™‘)
  - [13.3. æ€§èƒ½ä¼˜åŒ–](#133-æ€§èƒ½ä¼˜åŒ–)
---


## 1. å®¹å™¨åŒ–éƒ¨ç½²

### 1.1. Dockeré…ç½®

```dockerfile
# Dockerfile
FROM python:3.9-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºérootç”¨æˆ·
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

## 2. Docker Composeé…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
# Neo4jæ•°æ®åº“
  neo4j:
    image: neo4j:4.4
    container_name: knowledge-graph-neo4j
    environment:
      - NEO4J_AUTH=neo4j/password
      - NEO4J_PLUGINS=["apoc", "graph-data-science"]
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_import:/var/lib/neo4j/import
      - neo4j_plugins:/plugins
    networks:
      - knowledge-graph-network

# PostgreSQLæ•°æ®åº“
  postgres:
    image: postgres:13
    container_name: knowledge-graph-postgres
    environment:
      - POSTGRES_DB=knowledge_graph
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - knowledge-graph-network

# Redisç¼“å­˜
  redis:
    image: redis:6-alpine
    container_name: knowledge-graph-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - knowledge-graph-network

# çŸ¥è¯†å›¾è°±APIæœåŠ¡
  api:
    build: .
    container_name: knowledge-graph-api
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=password
      - POSTGRES_URI=postgresql://postgres:password@postgres:5432/knowledge_graph
      - REDIS_URI=redis://redis:6379
    ports:
      - "8000:8000"
    depends_on:
      - neo4j
      - postgres
      - redis
    networks:
      - knowledge-graph-network
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs

# å‰ç«¯åº”ç”¨
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: knowledge-graph-frontend
    ports:
      - "3000:3000"
    depends_on:
      - api
    networks:
      - knowledge-graph-network

# Nginxåå‘ä»£ç†
  nginx:
    image: nginx:alpine
    container_name: knowledge-graph-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - api
      - frontend
    networks:
      - knowledge-graph-network

# Prometheusç›‘æ§
  prometheus:
    image: prom/prometheus
    container_name: knowledge-graph-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - knowledge-graph-network

# Grafanaå¯è§†åŒ–
  grafana:
    image: grafana/grafana
    container_name: knowledge-graph-grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    ports:
      - "3001:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    networks:
      - knowledge-graph-network

volumes:
  neo4j_data:
  neo4j_logs:
  neo4j_import:
  neo4j_plugins:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  knowledge-graph-network:
    driver: bridge
```

## 3. Kuberneteséƒ¨ç½²é…ç½®

```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: knowledge-graph-api
  labels:
    app: knowledge-graph-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: knowledge-graph-api
  template:
    metadata:
      labels:
        app: knowledge-graph-api
    spec:
      containers:
      - name: api
        image: knowledge-graph-api:latest
        ports:
        - containerPort: 8000
        env:
        - name: NEO4J_URI
          value: "bolt://neo4j-service:7687"
        - name: NEO4J_USER
          valueFrom:
            secretKeyRef:
              name: neo4j-secret
              key: username
        - name: NEO4J_PASSWORD
          valueFrom:
            secretKeyRef:
              name: neo4j-secret
              key: password
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: knowledge-graph-api-service
spec:
  selector:
    app: knowledge-graph-api
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: knowledge-graph-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: knowledge-graph-api
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

## 4. äº‘å¹³å°éƒ¨ç½²

### 4.1. AWSéƒ¨ç½²é…ç½®

```yaml
# aws-deployment.yaml
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: knowledge-graph-cluster
  region: us-west-2

nodeGroups:
  - name: ng-1
    instanceType: t3.medium
    desiredCapacity: 3
    minSize: 1
    maxSize: 5
    volumeSize: 20
    ssh:
      allow: false

---
apiVersion: v1
kind: Namespace
metadata:
  name: knowledge-graph

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: neo4j
  namespace: knowledge-graph
spec:
  replicas: 1
  selector:
    matchLabels:
      app: neo4j
  template:
    metadata:
      labels:
        app: neo4j
    spec:
      containers:
      - name: neo4j
        image: neo4j:4.4
        ports:
        - containerPort: 7474
        - containerPort: 7687
        env:
        - name: NEO4J_AUTH
          value: "neo4j/password"
        - name: NEO4J_PLUGINS
          value: '["apoc", "graph-data-science"]'
        volumeMounts:
        - name: neo4j-data
          mountPath: /data
        - name: neo4j-logs
          mountPath: /logs
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
      volumes:
      - name: neo4j-data
        persistentVolumeClaim:
          claimName: neo4j-pvc
      - name: neo4j-logs
        persistentVolumeClaim:
          claimName: neo4j-logs-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: neo4j-service
  namespace: knowledge-graph
spec:
  selector:
    app: neo4j
  ports:
  - name: http
    port: 7474
    targetPort: 7474
  - name: bolt
    port: 7687
    targetPort: 7687
  type: ClusterIP

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: neo4j-pvc
  namespace: knowledge-graph
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: gp2
```

## 5. Azureéƒ¨ç½²é…ç½®

```yaml
# azure-deployment.yaml
apiVersion: 2019-02-01
location: eastus
name: knowledge-graph-aks
properties:
  agentPoolProfiles:
  - count: 3
    maxPods: 110
    name: nodepool1
    osDiskSizeGB: 128
    osType: Linux
    type: VirtualMachineScaleSets
    vmSize: Standard_DS2_v2
  dnsPrefix: knowledge-graph-aks
  enableRbac: true
  kubernetesVersion: "1.20.9"
  networkProfile:
    loadBalancerSku: standard
    networkPlugin: azure
  type: Microsoft.ContainerService/ManagedClusters

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: knowledge-graph-config
  namespace: knowledge-graph
data:
  neo4j-uri: "bolt://neo4j-service:7687"
  postgres-uri: "postgresql://postgres:password@postgres-service:5432/knowledge_graph"
  redis-uri: "redis://redis-service:6379"

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: knowledge-graph-api
  namespace: knowledge-graph
spec:
  replicas: 3
  selector:
    matchLabels:
      app: knowledge-graph-api
  template:
    metadata:
      labels:
        app: knowledge-graph-api
    spec:
      containers:
      - name: api
        image: knowledge-graph-api:latest
        ports:
        - containerPort: 8000
        envFrom:
        - configMapRef:
            name: knowledge-graph-config
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: knowledge-graph-api-service
  namespace: knowledge-graph
spec:
  selector:
    app: knowledge-graph-api
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer
```

## 6. Google Cloudéƒ¨ç½²é…ç½®

```yaml
# gcp-deployment.yaml
apiVersion: container.cnrm.cloud.google.com/v1beta1
kind: ContainerCluster
metadata:
  name: knowledge-graph-gke
  namespace: config-control
spec:
  location: us-central1-a
  initialNodeCount: 3
  nodeConfig:
    machineType: n1-standard-2
    diskSizeGb: 100
    diskType: pd-standard
    imageType: COS
  masterAuth:
    clientCertificateConfig:
      issueClientCertificate: false
  networkPolicy:
    provider: CALICO
  addonsConfig:
    networkPolicyConfig:
      disabled: false

---
apiVersion: v1
kind: Namespace
metadata:
  name: knowledge-graph

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: knowledge-graph-api
  namespace: knowledge-graph
spec:
  replicas: 3
  selector:
    matchLabels:
      app: knowledge-graph-api
  template:
    metadata:
      labels:
        app: knowledge-graph-api
    spec:
      containers:
      - name: api
        image: gcr.io/knowledge-graph-project/api:latest
        ports:
        - containerPort: 8000
        env:
        - name: NEO4J_URI
          value: "bolt://neo4j-service:7687"
        - name: NEO4J_USER
          valueFrom:
            secretKeyRef:
              name: neo4j-secret
              key: username
        - name: NEO4J_PASSWORD
          valueFrom:
            secretKeyRef:
              name: neo4j-secret
              key: password
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: knowledge-graph-api-service
  namespace: knowledge-graph
spec:
  selector:
    app: knowledge-graph-api
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer
```

## 7. ç›‘æ§å’Œæ—¥å¿—

### 7.1. Prometheusç›‘æ§é…ç½®

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'knowledge-graph-api'
    static_configs:
      - targets: ['api:8000']
    metrics_path: '/metrics'
    scrape_interval: 5s

  - job_name: 'neo4j'
    static_configs:
      - targets: ['neo4j:7474']
    metrics_path: '/metrics'
    scrape_interval: 10s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    metrics_path: '/metrics'
    scrape_interval: 10s

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    metrics_path: '/metrics'
    scrape_interval: 10s

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
    scrape_interval: 15s
```

## 8. Grafanaä»ªè¡¨æ¿é…ç½®

```json
{
  "dashboard": {
    "id": null,
    "title": "çŸ¥è¯†å›¾è°±ç›‘æ§ä»ªè¡¨æ¿",
    "tags": ["knowledge-graph", "monitoring"],
    "style": "dark",
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "APIè¯·æ±‚ç‡",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 0
        }
      },
      {
        "id": 2,
        "title": "å“åº”æ—¶é—´",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 0
        }
      },
      {
        "id": 3,
        "title": "æ•°æ®åº“è¿æ¥æ•°",
        "type": "graph",
        "targets": [
          {
            "expr": "neo4j_connections_active",
            "legendFormat": "Neo4j"
          },
          {
            "expr": "postgres_connections_active",
            "legendFormat": "PostgreSQL"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 8
        }
      },
      {
        "id": 4,
        "title": "å†…å­˜ä½¿ç”¨ç‡",
        "type": "graph",
        "targets": [
          {
            "expr": "container_memory_usage_bytes / container_spec_memory_limit_bytes * 100",
            "legendFormat": "{{pod}}"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 8
        }
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "10s"
  }
}
```

### 8.1. æ—¥å¿—é…ç½®

```python
# logging_config.py
import logging
import logging.handlers
import os
from datetime import datetime

class LoggingConfig:
    """æ—¥å¿—é…ç½®"""
    
    def __init__(self, app_name: str = "knowledge-graph"):
        self.app_name = app_name
        self.setup_logging()
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
# åˆ›å»ºæ—¥å¿—ç›®å½•
        log_dir = "/app/logs"
        os.makedirs(log_dir, exist_ok=True)
        
# é…ç½®æ ¹æ—¥å¿—å™¨
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.handlers.RotatingFileHandler(
                    f"{log_dir}/{self.app_name}.log",
                    maxBytes=10*1024*1024,  # 10MB
                    backupCount=5
                ),
                logging.StreamHandler()
            ]
        )
        
# é…ç½®ç‰¹å®šæ¨¡å—æ—¥å¿—å™¨
        loggers = {
            'api': logging.getLogger('api'),
            'database': logging.getLogger('database'),
            'cache': logging.getLogger('cache'),
            'security': logging.getLogger('security')
        }
        
        for name, logger in loggers.items():
            logger.setLevel(logging.INFO)
            
# æ·»åŠ æ–‡ä»¶å¤„ç†å™¨
            file_handler = logging.handlers.RotatingFileHandler(
                f"{log_dir}/{name}.log",
                maxBytes=10*1024*1024,
                backupCount=5
            )
            file_handler.setFormatter(
                logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            )
            logger.addHandler(file_handler)
    
    def get_logger(self, name: str) -> logging.Logger:
        """è·å–æ—¥å¿—å™¨"""
        return logging.getLogger(name)

# ä½¿ç”¨ç¤ºä¾‹
logging_config = LoggingConfig()
logger = logging_config.get_logger('api')
```

## 9. å®‰å…¨é…ç½®

### 9.1. SSL/TLSé…ç½®

```nginx
# nginx.conf
events {
    worker_connections 1024;
}

http {
    upstream api_backend {
        server api:8000;
    }
    
    upstream frontend_backend {
        server frontend:3000;
    }
    
# HTTPé‡å®šå‘åˆ°HTTPS
    server {
        listen 80;
        server_name knowledge-graph.example.com;
        return 301 https://$server_name$request_uri;
    }
    
# HTTPSæœåŠ¡å™¨
    server {
        listen 443 ssl http2;
        server_name knowledge-graph.example.com;
        
# SSLè¯ä¹¦é…ç½®
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;
        
# å®‰å…¨å¤´
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
        add_header X-Frame-Options DENY always;
        add_header X-Content-Type-Options nosniff always;
        add_header X-XSS-Protection "1; mode=block" always;
        
# APIä»£ç†
        location /api/ {
            proxy_pass http://api_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
# è¶…æ—¶é…ç½®
            proxy_connect_timeout 30s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
        }
        
# å‰ç«¯ä»£ç†
        location / {
            proxy_pass http://frontend_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}
```

## 10. å®‰å…¨ä¸­é—´ä»¶

```python
# security_middleware.py
from fastapi import Request, HTTPException
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import jwt
import time
from typing import Optional
import logging

logger = logging.getLogger(__name__)

class SecurityMiddleware:
    """å®‰å…¨ä¸­é—´ä»¶"""
    
    def __init__(self, secret_key: str, algorithm: str = "HS256"):
        self.secret_key = secret_key
        self.algorithm = algorithm
        self.security = HTTPBearer()
    
    async def authenticate_token(self, credentials: HTTPAuthorizationCredentials) -> dict:
        """éªŒè¯JWTä»¤ç‰Œ"""
        try:
            payload = jwt.decode(
                credentials.credentials,
                self.secret_key,
                algorithms=[self.algorithm]
            )
            return payload
        except jwt.ExpiredSignatureError:
            raise HTTPException(status_code=401, detail="ä»¤ç‰Œå·²è¿‡æœŸ")
        except jwt.JWTError:
            raise HTTPException(status_code=401, detail="æ— æ•ˆä»¤ç‰Œ")
    
    async def rate_limit(self, request: Request) -> bool:
        """é€Ÿç‡é™åˆ¶"""
        client_ip = request.client.host
        current_time = time.time()
        
# ç®€å•çš„å†…å­˜é€Ÿç‡é™åˆ¶ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨Redisï¼‰
        if not hasattr(self, '_rate_limit'):
            self._rate_limit = {}
        
        if client_ip not in self._rate_limit:
            self._rate_limit[client_ip] = []
        
# æ¸…ç†è¿‡æœŸè®°å½•
        self._rate_limit[client_ip] = [
            t for t in self._rate_limit[client_ip] 
            if current_time - t < 60
        ]
        
# æ£€æŸ¥é™åˆ¶
        if len(self._rate_limit[client_ip]) >= 100:  # æ¯åˆ†é’Ÿ100æ¬¡è¯·æ±‚
            return False
        
        self._rate_limit[client_ip].append(current_time)
        return True
    
    async def validate_input(self, data: dict) -> bool:
        """è¾“å…¥éªŒè¯"""
# æ£€æŸ¥SQLæ³¨å…¥
        sql_keywords = ['SELECT', 'INSERT', 'UPDATE', 'DELETE', 'DROP', 'CREATE']
        data_str = str(data).upper()
        
        for keyword in sql_keywords:
            if keyword in data_str:
                logger.warning(f"æ£€æµ‹åˆ°å¯èƒ½çš„SQLæ³¨å…¥: {keyword}")
                return False
        
# æ£€æŸ¥XSS
        xss_patterns = ['<script>', 'javascript:', 'onload=', 'onerror=']
        for pattern in xss_patterns:
            if pattern.lower() in data_str.lower():
                logger.warning(f"æ£€æµ‹åˆ°å¯èƒ½çš„XSSæ”»å‡»: {pattern}")
                return False
        
        return True
    
    async def log_security_event(self, event_type: str, details: dict):
        """è®°å½•å®‰å…¨äº‹ä»¶"""
        logger.warning(f"å®‰å…¨äº‹ä»¶ - ç±»å‹: {event_type}, è¯¦æƒ…: {details}")

# ä½¿ç”¨ç¤ºä¾‹
security = SecurityMiddleware(secret_key="your-secret-key")
```

## 11. å¤‡ä»½å’Œæ¢å¤

### 11.1. å¤‡ä»½è„šæœ¬

```python
# backup_script.py
import os
import subprocess
import tarfile
from datetime import datetime
import boto3
from google.cloud import storage
import logging

logger = logging.getLogger(__name__)

class BackupManager:
    """å¤‡ä»½ç®¡ç†å™¨"""
    
    def __init__(self, backup_dir: str = "/backups"):
        self.backup_dir = backup_dir
        os.makedirs(backup_dir, exist_ok=True)
    
    def backup_neo4j(self):
        """å¤‡ä»½Neo4jæ•°æ®åº“"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_file = f"{self.backup_dir}/neo4j_backup_{timestamp}.tar.gz"
            
# åœæ­¢Neo4j
            subprocess.run(["systemctl", "stop", "neo4j"], check=True)
            
# åˆ›å»ºå¤‡ä»½
            with tarfile.open(backup_file, "w:gz") as tar:
                tar.add("/var/lib/neo4j/data", arcname="data")
                tar.add("/var/lib/neo4j/logs", arcname="logs")
            
# å¯åŠ¨Neo4j
            subprocess.run(["systemctl", "start", "neo4j"], check=True)
            
            logger.info(f"Neo4jå¤‡ä»½å®Œæˆ: {backup_file}")
            return backup_file
        
        except Exception as e:
            logger.error(f"Neo4jå¤‡ä»½å¤±è´¥: {e}")
            raise
    
    def backup_postgres(self):
        """å¤‡ä»½PostgreSQLæ•°æ®åº“"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_file = f"{self.backup_dir}/postgres_backup_{timestamp}.sql"
            
# æ‰§è¡Œpg_dump
            subprocess.run([
                "pg_dump",
                "-h", "localhost",
                "-U", "postgres",
                "-d", "knowledge_graph",
                "-f", backup_file
            ], check=True)
            
            logger.info(f"PostgreSQLå¤‡ä»½å®Œæˆ: {backup_file}")
            return backup_file
        
        except Exception as e:
            logger.error(f"PostgreSQLå¤‡ä»½å¤±è´¥: {e}")
            raise
    
    def backup_redis(self):
        """å¤‡ä»½Redisæ•°æ®"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_file = f"{self.backup_dir}/redis_backup_{timestamp}.rdb"
            
# å¤åˆ¶RDBæ–‡ä»¶
            subprocess.run([
                "cp", "/var/lib/redis/dump.rdb", backup_file
            ], check=True)
            
            logger.info(f"Rediså¤‡ä»½å®Œæˆ: {backup_file}")
            return backup_file
        
        except Exception as e:
            logger.error(f"Rediså¤‡ä»½å¤±è´¥: {e}")
            raise
    
    def upload_to_s3(self, file_path: str, bucket_name: str):
        """ä¸Šä¼ åˆ°AWS S3"""
        try:
            s3 = boto3.client('s3')
            file_name = os.path.basename(file_path)
            
            s3.upload_file(file_path, bucket_name, f"backups/{file_name}")
            
            logger.info(f"æ–‡ä»¶å·²ä¸Šä¼ åˆ°S3: {file_name}")
        
        except Exception as e:
            logger.error(f"S3ä¸Šä¼ å¤±è´¥: {e}")
            raise
    
    def upload_to_gcs(self, file_path: str, bucket_name: str):
        """ä¸Šä¼ åˆ°Google Cloud Storage"""
        try:
            storage_client = storage.Client()
            bucket = storage_client.bucket(bucket_name)
            blob = bucket.blob(f"backups/{os.path.basename(file_path)}")
            
            blob.upload_from_filename(file_path)
            
            logger.info(f"æ–‡ä»¶å·²ä¸Šä¼ åˆ°GCS: {os.path.basename(file_path)}")
        
        except Exception as e:
            logger.error(f"GCSä¸Šä¼ å¤±è´¥: {e}")
            raise
    
    def cleanup_old_backups(self, days: int = 30):
        """æ¸…ç†æ—§å¤‡ä»½"""
        try:
            current_time = datetime.now()
            
            for file_name in os.listdir(self.backup_dir):
                file_path = os.path.join(self.backup_dir, file_name)
                file_time = datetime.fromtimestamp(os.path.getctime(file_path))
                
                if (current_time - file_time).days > days:
                    os.remove(file_path)
                    logger.info(f"åˆ é™¤æ—§å¤‡ä»½: {file_name}")
        
        except Exception as e:
            logger.error(f"æ¸…ç†æ—§å¤‡ä»½å¤±è´¥: {e}")
            raise

# ä½¿ç”¨ç¤ºä¾‹
def run_backup():
    """è¿è¡Œå¤‡ä»½"""
    backup_manager = BackupManager()
    
    try:
# æ‰§è¡Œå¤‡ä»½
        neo4j_backup = backup_manager.backup_neo4j()
        postgres_backup = backup_manager.backup_postgres()
        redis_backup = backup_manager.backup_redis()
        
# ä¸Šä¼ åˆ°äº‘å­˜å‚¨
        backup_manager.upload_to_s3(neo4j_backup, "knowledge-graph-backups")
        backup_manager.upload_to_s3(postgres_backup, "knowledge-graph-backups")
        backup_manager.upload_to_s3(redis_backup, "knowledge-graph-backups")
        
# æ¸…ç†æ—§å¤‡ä»½
        backup_manager.cleanup_old_backups()
        
        logger.info("å¤‡ä»½å®Œæˆ")
    
    except Exception as e:
        logger.error(f"å¤‡ä»½å¤±è´¥: {e}")
        raise
```

## 12. å·¥å…·ä¸å¹³å°

### 12.1. éƒ¨ç½²å·¥å…·

1. **Docker**ï¼šå®¹å™¨åŒ–éƒ¨ç½²
2. **Kubernetes**ï¼šå®¹å™¨ç¼–æ’
3. **Helm**ï¼šK8såŒ…ç®¡ç†å™¨
4. **Terraform**ï¼šåŸºç¡€è®¾æ–½å³ä»£ç 

### 12.2. ç›‘æ§å·¥å…·

1. **Prometheus**ï¼šæŒ‡æ ‡æ”¶é›†
2. **Grafana**ï¼šå¯è§†åŒ–ç›‘æ§
3. **AlertManager**ï¼šå‘Šè­¦ç®¡ç†
4. **Jaeger**ï¼šåˆ†å¸ƒå¼è¿½è¸ª

### 12.3. äº‘å¹³å°

1. **AWS**ï¼šAmazon Web Services
2. **Azure**ï¼šMicrosoft Azure
3. **GCP**ï¼šGoogle Cloud Platform
4. **é˜¿é‡Œäº‘**ï¼šAlibaba Cloud

## 13. æœ€ä½³å®è·µ

### 13.1. éƒ¨ç½²ç­–ç•¥

1. **è“ç»¿éƒ¨ç½²**ï¼šé›¶åœæœºéƒ¨ç½²
2. **æ»šåŠ¨æ›´æ–°**ï¼šæ¸è¿›å¼æ›´æ–°
3. **é‡‘ä¸é›€å‘å¸ƒ**ï¼šå°èŒƒå›´æµ‹è¯•
4. **è‡ªåŠ¨å›æ»š**ï¼šæ•…éšœè‡ªåŠ¨æ¢å¤

### 13.2. å®‰å…¨è€ƒè™‘

1. **ç½‘ç»œéš”ç¦»**ï¼šVPCå’Œé˜²ç«å¢™
2. **è®¿é—®æ§åˆ¶**ï¼šRBACå’ŒIAM
3. **æ•°æ®åŠ å¯†**ï¼šä¼ è¾“å’Œå­˜å‚¨åŠ å¯†
4. **å®‰å…¨æ‰«æ**ï¼šæ¼æ´æ‰«æå’Œä¿®å¤

### 13.3. æ€§èƒ½ä¼˜åŒ–

1. **è´Ÿè½½å‡è¡¡**ï¼šå¤šå®ä¾‹éƒ¨ç½²
2. **ç¼“å­˜ç­–ç•¥**ï¼šRedisç¼“å­˜
3. **æ•°æ®åº“ä¼˜åŒ–**ï¼šç´¢å¼•å’ŒæŸ¥è¯¢ä¼˜åŒ–
4. **CDNåŠ é€Ÿ**ï¼šé™æ€èµ„æºåŠ é€Ÿ
