# 知识图谱机器学习集成

## 1. 图神经网络 (GNN)

### GNN基础框架
```python
# 图神经网络基础框架
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, GATConv, SAGEConv
from torch_geometric.data import Data, DataLoader
import numpy as np
from typing import Dict, List, Tuple, Optional
import networkx as nx

class GraphNeuralNetwork(nn.Module):
    """图神经网络基础类"""
    
    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int, 
                 num_layers: int = 2, dropout: float = 0.5):
        super(GraphNeuralNetwork, self).__init__()
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.num_layers = num_layers
        self.dropout = dropout
        
        # 图卷积层
        self.convs = nn.ModuleList()
        self.convs.append(GCNConv(input_dim, hidden_dim))
        
        for _ in range(num_layers - 2):
            self.convs.append(GCNConv(hidden_dim, hidden_dim))
        
        self.convs.append(GCNConv(hidden_dim, output_dim))
        
        # 批归一化层
        self.batch_norms = nn.ModuleList()
        for _ in range(num_layers):
            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))
    
    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:
        """前向传播"""
        for i in range(self.num_layers - 1):
            x = self.convs[i](x, edge_index)
            x = self.batch_norms[i](x)
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout, training=self.training)
        
        x = self.convs[-1](x, edge_index)
        return x

class GraphAttentionNetwork(nn.Module):
    """图注意力网络"""
    
    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int,
                 num_heads: int = 8, num_layers: int = 2, dropout: float = 0.5):
        super(GraphAttentionNetwork, self).__init__()
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.num_heads = num_heads
        self.num_layers = num_layers
        self.dropout = dropout
        
        # 图注意力层
        self.gat_layers = nn.ModuleList()
        self.gat_layers.append(GATConv(input_dim, hidden_dim, heads=num_heads, dropout=dropout))
        
        for _ in range(num_layers - 2):
            self.gat_layers.append(GATConv(hidden_dim * num_heads, hidden_dim, heads=num_heads, dropout=dropout))
        
        self.gat_layers.append(GATConv(hidden_dim * num_heads, output_dim, heads=1, dropout=dropout))
    
    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:
        """前向传播"""
        for i in range(self.num_layers - 1):
            x = self.gat_layers[i](x, edge_index)
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout, training=self.training)
        
        x = self.gat_layers[-1](x, edge_index)
        return x

class GraphSAGE(nn.Module):
    """GraphSAGE网络"""
    
    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int,
                 num_layers: int = 2, dropout: float = 0.5):
        super(GraphSAGE, self).__init__()
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.num_layers = num_layers
        self.dropout = dropout
        
        # GraphSAGE层
        self.sage_layers = nn.ModuleList()
        self.sage_layers.append(SAGEConv(input_dim, hidden_dim))
        
        for _ in range(num_layers - 2):
            self.sage_layers.append(SAGEConv(hidden_dim, hidden_dim))
        
        self.sage_layers.append(SAGEConv(hidden_dim, output_dim))
    
    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:
        """前向传播"""
        for i in range(self.num_layers - 1):
            x = self.sage_layers[i](x, edge_index)
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout, training=self.training)
        
        x = self.sage_layers[-1](x, edge_index)
        return x

# GNN训练器
class GNNTrainer:
    """GNN训练器"""
    
    def __init__(self, model: nn.Module, device: str = "cuda" if torch.cuda.is_available() else "cpu"):
        self.model = model.to(device)
        self.device = device
        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)
        self.criterion = nn.CrossEntropyLoss()
    
    def train_epoch(self, train_loader: DataLoader) -> float:
        """训练一个epoch"""
        self.model.train()
        total_loss = 0
        
        for batch in train_loader:
            batch = batch.to(self.device)
            self.optimizer.zero_grad()
            
            out = self.model(batch.x, batch.edge_index)
            loss = self.criterion(out[batch.train_mask], batch.y[batch.train_mask])
            
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
        
        return total_loss / len(train_loader)
    
    def evaluate(self, data_loader: DataLoader) -> Tuple[float, float]:
        """评估模型"""
        self.model.eval()
        total_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for batch in data_loader:
                batch = batch.to(self.device)
                out = self.model(batch.x, batch.edge_index)
                
                loss = self.criterion(out[batch.val_mask], batch.y[batch.val_mask])
                total_loss += loss.item()
                
                pred = out.argmax(dim=1)
                correct += int((pred[batch.val_mask] == batch.y[batch.val_mask]).sum())
                total += int(batch.val_mask.sum())
        
        return total_loss / len(data_loader), correct / total

# 使用示例
def train_gnn_model():
    """训练GNN模型"""
    # 准备数据
    # 这里需要从知识图谱中提取节点特征和边信息
    # 示例数据
    num_nodes = 1000
    num_features = 128
    num_classes = 10
    
    # 随机生成示例数据
    x = torch.randn(num_nodes, num_features)
    edge_index = torch.randint(0, num_nodes, (2, 2000))
    y = torch.randint(0, num_classes, (num_nodes,))
    
    # 创建数据对象
    data = Data(x=x, edge_index=edge_index, y=y)
    data.train_mask = torch.rand(num_nodes) < 0.8
    data.val_mask = torch.rand(num_nodes) < 0.1
    
    # 创建模型
    model = GraphNeuralNetwork(
        input_dim=num_features,
        hidden_dim=64,
        output_dim=num_classes
    )
    
    # 训练模型
    trainer = GNNTrainer(model)
    
    for epoch in range(100):
        loss = trainer.train_epoch([data])
        val_loss, val_acc = trainer.evaluate([data])
        
        if epoch % 10 == 0:
            print(f"Epoch {epoch}: Loss={loss:.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}")
```

## 2. 知识图谱嵌入

### 知识图谱嵌入模型
```python
# 知识图谱嵌入模型
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Tuple, Optional
import numpy as np

class TransE(nn.Module):
    """TransE嵌入模型"""
    
    def __init__(self, num_entities: int, num_relations: int, embedding_dim: int = 100):
        super(TransE, self).__init__()
        
        self.num_entities = num_entities
        self.num_relations = num_relations
        self.embedding_dim = embedding_dim
        
        # 实体和关系嵌入
        self.entity_embeddings = nn.Embedding(num_entities, embedding_dim)
        self.relation_embeddings = nn.Embedding(num_relations, embedding_dim)
        
        # 初始化
        nn.init.xavier_uniform_(self.entity_embeddings.weight.data)
        nn.init.xavier_uniform_(self.relation_embeddings.weight.data)
    
    def forward(self, heads: torch.Tensor, relations: torch.Tensor, tails: torch.Tensor) -> torch.Tensor:
        """前向传播"""
        head_embeddings = self.entity_embeddings(heads)
        relation_embeddings = self.relation_embeddings(relations)
        tail_embeddings = self.entity_embeddings(tails)
        
        # TransE: h + r ≈ t
        scores = head_embeddings + relation_embeddings - tail_embeddings
        return torch.norm(scores, p=2, dim=1)
    
    def predict(self, heads: torch.Tensor, relations: torch.Tensor) -> torch.Tensor:
        """预测尾实体"""
        head_embeddings = self.entity_embeddings(heads)
        relation_embeddings = self.relation_embeddings(relations)
        
        # 计算所有实体的得分
        all_entity_embeddings = self.entity_embeddings.weight
        scores = torch.norm(
            head_embeddings.unsqueeze(1) + relation_embeddings.unsqueeze(1) - all_entity_embeddings.unsqueeze(0),
            p=2, dim=2
        )
        
        return scores

class DistMult(nn.Module):
    """DistMult嵌入模型"""
    
    def __init__(self, num_entities: int, num_relations: int, embedding_dim: int = 100):
        super(DistMult, self).__init__()
        
        self.num_entities = num_entities
        self.num_relations = num_relations
        self.embedding_dim = embedding_dim
        
        # 实体和关系嵌入
        self.entity_embeddings = nn.Embedding(num_entities, embedding_dim)
        self.relation_embeddings = nn.Embedding(num_relations, embedding_dim)
        
        # 初始化
        nn.init.xavier_uniform_(self.entity_embeddings.weight.data)
        nn.init.xavier_uniform_(self.relation_embeddings.weight.data)
    
    def forward(self, heads: torch.Tensor, relations: torch.Tensor, tails: torch.Tensor) -> torch.Tensor:
        """前向传播"""
        head_embeddings = self.entity_embeddings(heads)
        relation_embeddings = self.relation_embeddings(relations)
        tail_embeddings = self.entity_embeddings(tails)
        
        # DistMult: <h, r, t>
        scores = torch.sum(head_embeddings * relation_embeddings * tail_embeddings, dim=1)
        return scores
    
    def predict(self, heads: torch.Tensor, relations: torch.Tensor) -> torch.Tensor:
        """预测尾实体"""
        head_embeddings = self.entity_embeddings(heads)
        relation_embeddings = self.relation_embeddings(relations)
        
        # 计算所有实体的得分
        all_entity_embeddings = self.entity_embeddings.weight
        scores = torch.sum(
            head_embeddings.unsqueeze(1) * relation_embeddings.unsqueeze(1) * all_entity_embeddings.unsqueeze(0),
            dim=2
        )
        
        return scores

class ComplEx(nn.Module):
    """ComplEx嵌入模型"""
    
    def __init__(self, num_entities: int, num_relations: int, embedding_dim: int = 100):
        super(ComplEx, self).__init__()
        
        self.num_entities = num_entities
        self.num_relations = num_relations
        self.embedding_dim = embedding_dim
        
        # 复数嵌入
        self.entity_real = nn.Embedding(num_entities, embedding_dim)
        self.entity_imag = nn.Embedding(num_entities, embedding_dim)
        self.relation_real = nn.Embedding(num_relations, embedding_dim)
        self.relation_imag = nn.Embedding(num_relations, embedding_dim)
        
        # 初始化
        nn.init.xavier_uniform_(self.entity_real.weight.data)
        nn.init.xavier_uniform_(self.entity_imag.weight.data)
        nn.init.xavier_uniform_(self.relation_real.weight.data)
        nn.init.xavier_uniform_(self.relation_imag.weight.data)
    
    def forward(self, heads: torch.Tensor, relations: torch.Tensor, tails: torch.Tensor) -> torch.Tensor:
        """前向传播"""
        h_real = self.entity_real(heads)
        h_imag = self.entity_imag(heads)
        r_real = self.relation_real(relations)
        r_imag = self.relation_imag(relations)
        t_real = self.entity_real(tails)
        t_imag = self.entity_imag(tails)
        
        # ComplEx: Re(<h, r, t̄>)
        real_score = h_real * r_real * t_real + h_real * r_imag * t_imag + h_imag * r_real * t_imag - h_imag * r_imag * t_real
        return torch.sum(real_score, dim=1)
    
    def predict(self, heads: torch.Tensor, relations: torch.Tensor) -> torch.Tensor:
        """预测尾实体"""
        h_real = self.entity_real(heads)
        h_imag = self.entity_imag(heads)
        r_real = self.relation_real(relations)
        r_imag = self.relation_imag(relations)
        
        # 计算所有实体的得分
        all_t_real = self.entity_real.weight
        all_t_imag = self.entity_imag.weight
        
        real_score = (h_real.unsqueeze(1) * r_real.unsqueeze(1) * all_t_real.unsqueeze(0) +
                     h_real.unsqueeze(1) * r_imag.unsqueeze(1) * all_t_imag.unsqueeze(0) +
                     h_imag.unsqueeze(1) * r_real.unsqueeze(1) * all_t_imag.unsqueeze(0) -
                     h_imag.unsqueeze(1) * r_imag.unsqueeze(1) * all_t_real.unsqueeze(0))
        
        return torch.sum(real_score, dim=2)

# 知识图谱嵌入训练器
class KGEmbeddingTrainer:
    """知识图谱嵌入训练器"""
    
    def __init__(self, model: nn.Module, device: str = "cuda" if torch.cuda.is_available() else "cpu"):
        self.model = model.to(device)
        self.device = device
        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        self.criterion = nn.MarginRankingLoss(margin=1.0)
    
    def generate_negative_samples(self, positive_triples: torch.Tensor, num_entities: int) -> torch.Tensor:
        """生成负样本"""
        negative_triples = positive_triples.clone()
        
        # 随机替换头实体或尾实体
        for i in range(positive_triples.size(0)):
            if torch.rand(1) < 0.5:
                # 替换头实体
                negative_triples[i, 0] = torch.randint(0, num_entities, (1,))
            else:
                # 替换尾实体
                negative_triples[i, 2] = torch.randint(0, num_entities, (1,))
        
        return negative_triples
    
    def train_epoch(self, positive_triples: torch.Tensor) -> float:
        """训练一个epoch"""
        self.model.train()
        total_loss = 0
        
        # 生成负样本
        negative_triples = self.generate_negative_samples(positive_triples, self.model.num_entities)
        
        # 计算正样本和负样本的得分
        pos_scores = self.model(positive_triples[:, 0], positive_triples[:, 1], positive_triples[:, 2])
        neg_scores = self.model(negative_triples[:, 0], negative_triples[:, 1], negative_triples[:, 2])
        
        # 计算损失
        target = torch.ones(pos_scores.size(0)).to(self.device)
        loss = self.criterion(pos_scores, neg_scores, target)
        
        # 反向传播
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
        return loss.item()
    
    def evaluate(self, test_triples: torch.Tensor) -> Dict[str, float]:
        """评估模型"""
        self.model.eval()
        
        with torch.no_grad():
            # 计算测试三元组的得分
            scores = self.model(test_triples[:, 0], test_triples[:, 1], test_triples[:, 2])
            
            # 计算排名指标
            ranks = self._calculate_ranks(test_triples, scores)
            
            metrics = {
                "mean_rank": np.mean(ranks),
                "hits@1": np.mean([1 if rank <= 1 else 0 for rank in ranks]),
                "hits@3": np.mean([1 if rank <= 3 else 0 for rank in ranks]),
                "hits@10": np.mean([1 if rank <= 10 else 0 for rank in ranks])
            }
        
        return metrics
    
    def _calculate_ranks(self, triples: torch.Tensor, scores: torch.Tensor) -> List[int]:
        """计算排名"""
        ranks = []
        
        for i, (head, relation, tail) in enumerate(triples):
            # 预测所有可能的尾实体
            predictions = self.model.predict(head.unsqueeze(0), relation.unsqueeze(0))
            
            # 计算正确尾实体的排名
            correct_score = predictions[0, tail]
            rank = (predictions[0] >= correct_score).sum().item()
            ranks.append(rank)
        
        return ranks

# 使用示例
def train_kg_embeddings():
    """训练知识图谱嵌入"""
    # 准备数据
    num_entities = 1000
    num_relations = 50
    embedding_dim = 100
    
    # 生成示例三元组
    num_triples = 5000
    triples = torch.randint(0, num_entities, (num_triples, 3))
    
    # 创建模型
    model = TransE(num_entities, num_relations, embedding_dim)
    trainer = KGEmbeddingTrainer(model)
    
    # 训练模型
    for epoch in range(100):
        loss = trainer.train_epoch(triples)
        
        if epoch % 10 == 0:
            print(f"Epoch {epoch}: Loss={loss:.4f}")
    
    # 评估模型
    test_triples = torch.randint(0, num_entities, (100, 3))
    metrics = trainer.evaluate(test_triples)
    print(f"评估结果: {metrics}")
```

## 3. 推荐系统

### 基于知识图谱的推荐系统
```python
# 基于知识图谱的推荐系统
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Tuple, Optional
import numpy as np

class KGRecommender(nn.Module):
    """基于知识图谱的推荐系统"""
    
    def __init__(self, num_users: int, num_items: int, num_entities: int, num_relations: int,
                 embedding_dim: int = 100, hidden_dim: int = 64):
        super(KGRecommender, self).__init__()
        
        self.num_users = num_users
        self.num_items = num_items
        self.num_entities = num_entities
        self.num_relations = num_relations
        self.embedding_dim = embedding_dim
        self.hidden_dim = hidden_dim
        
        # 用户和物品嵌入
        self.user_embeddings = nn.Embedding(num_users, embedding_dim)
        self.item_embeddings = nn.Embedding(num_items, embedding_dim)
        
        # 知识图谱嵌入
        self.entity_embeddings = nn.Embedding(num_entities, embedding_dim)
        self.relation_embeddings = nn.Embedding(num_relations, embedding_dim)
        
        # 推荐网络
        self.recommendation_net = nn.Sequential(
            nn.Linear(embedding_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )
        
        # 初始化
        nn.init.xavier_uniform_(self.user_embeddings.weight.data)
        nn.init.xavier_uniform_(self.item_embeddings.weight.data)
        nn.init.xavier_uniform_(self.entity_embeddings.weight.data)
        nn.init.xavier_uniform_(self.relation_embeddings.weight.data)
    
    def forward(self, user_ids: torch.Tensor, item_ids: torch.Tensor,
                kg_triples: torch.Tensor) -> torch.Tensor:
        """前向传播"""
        # 获取用户和物品嵌入
        user_embeddings = self.user_embeddings(user_ids)
        item_embeddings = self.item_embeddings(item_ids)
        
        # 获取知识图谱信息
        kg_embeddings = self._get_kg_embeddings(kg_triples)
        
        # 融合用户-物品嵌入和知识图谱嵌入
        combined_embeddings = torch.cat([user_embeddings, item_embeddings + kg_embeddings], dim=1)
        
        # 预测评分
        scores = self.recommendation_net(combined_embeddings)
        return scores.squeeze()
    
    def _get_kg_embeddings(self, kg_triples: torch.Tensor) -> torch.Tensor:
        """获取知识图谱嵌入"""
        if kg_triples.size(0) == 0:
            return torch.zeros(kg_triples.size(0), self.embedding_dim).to(kg_triples.device)
        
        head_embeddings = self.entity_embeddings(kg_triples[:, 0])
        relation_embeddings = self.relation_embeddings(kg_triples[:, 1])
        tail_embeddings = self.entity_embeddings(kg_triples[:, 2])
        
        # 计算知识图谱嵌入
        kg_embeddings = head_embeddings + relation_embeddings + tail_embeddings
        return kg_embeddings.mean(dim=0) if kg_embeddings.size(0) > 0 else torch.zeros(self.embedding_dim).to(kg_triples.device)

class KGRecommenderTrainer:
    """知识图谱推荐系统训练器"""
    
    def __init__(self, model: KGRecommender, device: str = "cuda" if torch.cuda.is_available() else "cpu"):
        self.model = model.to(device)
        self.device = device
        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        self.criterion = nn.BCELoss()
    
    def train_epoch(self, user_item_pairs: torch.Tensor, ratings: torch.Tensor,
                   kg_triples: torch.Tensor) -> float:
        """训练一个epoch"""
        self.model.train()
        total_loss = 0
        
        for i in range(0, len(user_item_pairs), 32):
            batch_users = user_item_pairs[i:i+32, 0]
            batch_items = user_item_pairs[i:i+32, 1]
            batch_ratings = ratings[i:i+32]
            batch_kg_triples = kg_triples[i:i+32] if i < len(kg_triples) else torch.empty(0, 3)
            
            # 前向传播
            predictions = self.model(batch_users, batch_items, batch_kg_triples)
            loss = self.criterion(predictions, batch_ratings.float())
            
            # 反向传播
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
        
        return total_loss / (len(user_item_pairs) // 32)
    
    def recommend(self, user_id: int, top_k: int = 10) -> List[Tuple[int, float]]:
        """为用户推荐物品"""
        self.model.eval()
        
        with torch.no_grad():
            user_tensor = torch.tensor([user_id]).to(self.device)
            
            # 为所有物品计算推荐分数
            all_items = torch.arange(self.model.num_items).to(self.device)
            all_users = user_tensor.repeat(self.model.num_items)
            
            # 这里需要根据实际的KG三元组来获取相关三元组
            # 简化处理，使用空的三元组
            kg_triples = torch.empty(0, 3).to(self.device)
            
            scores = self.model(all_users, all_items, kg_triples)
            
            # 获取top-k推荐
            top_scores, top_indices = torch.topk(scores, top_k)
            
            recommendations = [(item_id.item(), score.item()) 
                             for item_id, score in zip(top_indices, top_scores)]
        
        return recommendations

# 使用示例
def train_kg_recommender():
    """训练知识图谱推荐系统"""
    # 准备数据
    num_users = 1000
    num_items = 500
    num_entities = 2000
    num_relations = 100
    
    # 生成示例数据
    num_interactions = 10000
    user_item_pairs = torch.randint(0, num_users, (num_interactions, 2))
    ratings = torch.rand(num_interactions) > 0.5  # 二值评分
    
    # 生成知识图谱三元组
    num_kg_triples = 5000
    kg_triples = torch.randint(0, num_entities, (num_kg_triples, 3))
    
    # 创建模型
    model = KGRecommender(num_users, num_items, num_entities, num_relations)
    trainer = KGRecommenderTrainer(model)
    
    # 训练模型
    for epoch in range(50):
        loss = trainer.train_epoch(user_item_pairs, ratings, kg_triples)
        
        if epoch % 10 == 0:
            print(f"Epoch {epoch}: Loss={loss:.4f}")
    
    # 生成推荐
    recommendations = trainer.recommend(user_id=0, top_k=10)
    print(f"用户0的推荐: {recommendations}")
```

## 4. 异常检测

### 基于图神经网络的异常检测
```python
# 基于图神经网络的异常检测
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from typing import Dict, List, Tuple, Optional
import numpy as np

class GraphAnomalyDetector(nn.Module):
    """图异常检测器"""
    
    def __init__(self, input_dim: int, hidden_dim: int, num_layers: int = 2):
        super(GraphAnomalyDetector, self).__init__()
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers
        
        # 图卷积层
        self.convs = nn.ModuleList()
        self.convs.append(GCNConv(input_dim, hidden_dim))
        
        for _ in range(num_layers - 1):
            self.convs.append(GCNConv(hidden_dim, hidden_dim))
        
        # 异常检测头
        self.anomaly_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )
        
        # 重构头
        self.reconstruction_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim)
        )
    
    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """前向传播"""
        # 图卷积编码
        h = x
        for conv in self.convs:
            h = conv(h, edge_index)
            h = F.relu(h)
        
        # 异常检测
        anomaly_scores = self.anomaly_head(h)
        
        # 重构
        reconstructed = self.reconstruction_head(h)
        
        return anomaly_scores.squeeze(), reconstructed
    
    def detect_anomalies(self, x: torch.Tensor, edge_index: torch.Tensor, 
                        threshold: float = 0.5) -> Tuple[torch.Tensor, torch.Tensor]:
        """检测异常"""
        anomaly_scores, reconstructed = self.forward(x, edge_index)
        
        # 计算重构误差
        reconstruction_error = F.mse_loss(reconstructed, x, reduction='none').mean(dim=1)
        
        # 综合异常分数
        combined_scores = anomaly_scores + reconstruction_error
        
        # 检测异常
        anomalies = combined_scores > threshold
        
        return anomalies, combined_scores

class AnomalyDetectorTrainer:
    """异常检测训练器"""
    
    def __init__(self, model: GraphAnomalyDetector, device: str = "cuda" if torch.cuda.is_available() else "cpu"):
        self.model = model.to(device)
        self.device = device
        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    def train_epoch(self, data_loader) -> float:
        """训练一个epoch"""
        self.model.train()
        total_loss = 0
        
        for batch in data_loader:
            batch = batch.to(self.device)
            self.optimizer.zero_grad()
            
            # 前向传播
            anomaly_scores, reconstructed = self.model(batch.x, batch.edge_index)
            
            # 计算损失
            reconstruction_loss = F.mse_loss(reconstructed, batch.x)
            anomaly_loss = F.binary_cross_entropy(anomaly_scores, torch.zeros_like(anomaly_scores))
            
            total_loss = reconstruction_loss + 0.1 * anomaly_loss
            
            # 反向传播
            total_loss.backward()
            self.optimizer.step()
        
        return total_loss.item()
    
    def evaluate(self, data_loader) -> Dict[str, float]:
        """评估异常检测性能"""
        self.model.eval()
        
        all_anomalies = []
        all_scores = []
        all_labels = []
        
        with torch.no_grad():
            for batch in data_loader:
                batch = batch.to(self.device)
                
                anomalies, scores = self.model.detect_anomalies(batch.x, batch.edge_index)
                
                all_anomalies.extend(anomalies.cpu().numpy())
                all_scores.extend(scores.cpu().numpy())
                
                # 假设有标签
                if hasattr(batch, 'y'):
                    all_labels.extend(batch.y.cpu().numpy())
        
        # 计算指标
        if all_labels:
            from sklearn.metrics import precision_recall_fscore_support, roc_auc_score
            
            precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_anomalies, average='binary')
            auc = roc_auc_score(all_labels, all_scores)
            
            return {
                "precision": precision,
                "recall": recall,
                "f1": f1,
                "auc": auc
            }
        else:
            return {
                "anomaly_rate": np.mean(all_anomalies),
                "mean_score": np.mean(all_scores)
            }

# 使用示例
def train_anomaly_detector():
    """训练异常检测器"""
    # 准备数据
    num_nodes = 1000
    num_features = 128
    
    # 生成正常数据
    x = torch.randn(num_nodes, num_features)
    edge_index = torch.randint(0, num_nodes, (2, 2000))
    
    # 添加一些异常节点
    anomaly_indices = torch.randperm(num_nodes)[:50]  # 5%的异常节点
    x[anomaly_indices] += torch.randn(50, num_features) * 2  # 添加噪声
    
    # 创建数据对象
    data = Data(x=x, edge_index=edge_index)
    
    # 创建模型
    model = GraphAnomalyDetector(input_dim=num_features, hidden_dim=64)
    trainer = AnomalyDetectorTrainer(model)
    
    # 训练模型
    for epoch in range(100):
        loss = trainer.train_epoch([data])
        
        if epoch % 20 == 0:
            print(f"Epoch {epoch}: Loss={loss:.4f}")
    
    # 检测异常
    anomalies, scores = model.detect_anomalies(data.x, data.edge_index)
    print(f"检测到的异常节点数量: {anomalies.sum().item()}")
    print(f"异常分数范围: {scores.min().item():.4f} - {scores.max().item():.4f}")
```

## 5. 工具与平台

### 机器学习框架
1. **PyTorch Geometric**：图神经网络库
2. **DGL**：深度图库
3. **Spektral**：Keras图神经网络
4. **NetworkX**：图分析库

### 知识图谱工具
1. **OpenKE**：知识图谱嵌入框架
2. **DGL-KE**：分布式知识图谱嵌入
3. **PyKEEN**：Python知识图谱嵌入
4. **AmpliGraph**：知识图谱嵌入库

### 推荐系统工具
1. **Surprise**：推荐系统库
2. **LightFM**：混合推荐系统
3. **RecBole**：推荐系统基准
4. **DeepCTR**：深度CTR预测

### 异常检测工具
1. **PyOD**：异常检测库
2. **Isolation Forest**：隔离森林
3. **LOF**：局部异常因子
4. **One-Class SVM**：一类支持向量机

## 6. 最佳实践

### 模型选择
1. **任务匹配**：根据具体任务选择合适的模型
2. **数据规模**：考虑数据规模选择模型复杂度
3. **计算资源**：根据可用资源选择模型
4. **可解释性**：考虑模型的可解释性需求

### 训练策略
1. **数据预处理**：标准化和归一化
2. **超参数调优**：网格搜索或贝叶斯优化
3. **正则化**：防止过拟合
4. **早停**：避免过度训练

### 评估指标
1. **分类任务**：准确率、精确率、召回率、F1分数
2. **推荐任务**：NDCG、MAP、MRR
3. **异常检测**：AUC、精确率、召回率
4. **知识图谱**：Hits@K、Mean Rank

### 部署考虑
1. **模型压缩**：模型量化和剪枝
2. **在线学习**：增量更新模型
3. **A/B测试**：模型效果对比
4. **监控告警**：模型性能监控 