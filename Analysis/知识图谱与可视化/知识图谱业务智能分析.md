# çŸ¥è¯†å›¾è°±ä¸šåŠ¡æ™ºèƒ½åˆ†æ

## ğŸ“‘ ç›®å½•

- [çŸ¥è¯†å›¾è°±ä¸šåŠ¡æ™ºèƒ½åˆ†æ](#çŸ¥è¯†å›¾è°±ä¸šåŠ¡æ™ºèƒ½åˆ†æ)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
- [1. ä¸šåŠ¡æ™ºèƒ½åˆ†ææ¡†æ¶](#1-ä¸šåŠ¡æ™ºèƒ½åˆ†ææ¡†æ¶)
  - [1.1. ä¸šåŠ¡æŒ‡æ ‡åˆ†æå¼•æ“](#11-ä¸šåŠ¡æŒ‡æ ‡åˆ†æå¼•æ“)
- [2. è¶‹åŠ¿åˆ†ææ¨¡å—](#2-è¶‹åŠ¿åˆ†ææ¨¡å—)
- [3. å¼‚å¸¸æ£€æµ‹æ¨¡å—](#3-å¼‚å¸¸æ£€æµ‹æ¨¡å—)
- [4. é¢„æµ‹åˆ†ææ¨¡å—](#4-é¢„æµ‹åˆ†ææ¨¡å—)
- [5. ä¸šåŠ¡æ™ºèƒ½ä»ªè¡¨æ¿](#5-ä¸šåŠ¡æ™ºèƒ½ä»ªè¡¨æ¿)
---


## 1. ä¸šåŠ¡æ™ºèƒ½åˆ†ææ¡†æ¶

### 1.1. ä¸šåŠ¡æŒ‡æ ‡åˆ†æå¼•æ“

```python
import asyncio
import logging
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import json

class AnalysisType(Enum):
    """åˆ†æç±»å‹"""
    TREND_ANALYSIS = "trend_analysis"
    PATTERN_DETECTION = "pattern_detection"
    ANOMALY_DETECTION = "anomaly_detection"
    PREDICTIVE_ANALYSIS = "predictive_analysis"
    CORRELATION_ANALYSIS = "correlation_analysis"

@dataclass
class BusinessMetric:
    """ä¸šåŠ¡æŒ‡æ ‡"""
    id: str
    name: str
    description: str
    category: str
    calculation_query: str
    unit: str
    target_value: Optional[float] = None
    alert_threshold: Optional[float] = None

@dataclass
class AnalysisResult:
    """åˆ†æç»“æœ"""
    analysis_id: str
    analysis_type: AnalysisType
    metric_id: str
    result_data: Dict[str, Any]
    insights: List[str]
    recommendations: List[str]
    confidence_score: float
    timestamp: datetime

class BusinessIntelligenceEngine:
    """ä¸šåŠ¡æ™ºèƒ½åˆ†æå¼•æ“"""

    def __init__(self, kg_client, config: Dict[str, Any]):
        self.kg_client = kg_client
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.metrics: Dict[str, BusinessMetric] = {}
        self.analysis_results: List[AnalysisResult] = []

    async def initialize(self):
        """åˆå§‹åŒ–ä¸šåŠ¡æ™ºèƒ½å¼•æ“"""
        await self._load_business_metrics()
        await self._setup_analysis_scheduler()

    async def _load_business_metrics(self):
        """åŠ è½½ä¸šåŠ¡æŒ‡æ ‡å®šä¹‰"""
        default_metrics = [
            BusinessMetric(
                id="user_engagement",
                name="ç”¨æˆ·å‚ä¸åº¦",
                description="ç”¨æˆ·ä¸çŸ¥è¯†å›¾è°±çš„äº¤äº’æ´»è·ƒåº¦",
                category="engagement",
                calculation_query="""
                MATCH (u:User)-[:INTERACTS_WITH]->(e:Entity)
                WITH u, count(e) as interaction_count
                RETURN avg(interaction_count) as avg_engagement,
                       max(interaction_count) as max_engagement,
                       min(interaction_count) as min_engagement
                """,
                unit="interactions/user",
                target_value=10.0,
                alert_threshold=5.0
            ),

            BusinessMetric(
                id="knowledge_coverage",
                name="çŸ¥è¯†è¦†ç›–ç‡",
                description="çŸ¥è¯†å›¾è°±è¦†ç›–çš„ä¸šåŠ¡é¢†åŸŸæ¯”ä¾‹",
                category="coverage",
                calculation_query="""
                MATCH (d:Domain)
                WITH count(d) as total_domains
                MATCH (d:Domain)-[:HAS_ENTITY]->(e:Entity)
                WITH total_domains, count(DISTINCT d) as covered_domains
                RETURN (covered_domains * 100.0 / total_domains) as coverage_percentage
                """,
                unit="percentage",
                target_value=85.0,
                alert_threshold=70.0
            ),

            BusinessMetric(
                id="data_quality_score",
                name="æ•°æ®è´¨é‡è¯„åˆ†",
                description="çŸ¥è¯†å›¾è°±æ•°æ®è´¨é‡ç»¼åˆè¯„åˆ†",
                category="quality",
                calculation_query="""
                MATCH (e:Entity)
                WITH count(e) as total_entities
                MATCH (e:Entity)
                WHERE e.completeness_score IS NOT NULL
                WITH total_entities, avg(e.completeness_score) as avg_completeness
                MATCH (e:Entity)
                WHERE e.accuracy_score IS NOT NULL
                WITH avg_completeness, avg(e.accuracy_score) as avg_accuracy
                RETURN (avg_completeness + avg_accuracy) / 2 as quality_score
                """,
                unit="score",
                target_value=0.85,
                alert_threshold=0.70
            ),

            BusinessMetric(
                id="query_performance",
                name="æŸ¥è¯¢æ€§èƒ½",
                description="çŸ¥è¯†å›¾è°±æŸ¥è¯¢å“åº”æ—¶é—´",
                category="performance",
                calculation_query="""
                MATCH (q:QueryLog)
                WHERE q.timestamp > datetime() - duration('P1D')
                RETURN avg(q.response_time) as avg_response_time,
                       max(q.response_time) as max_response_time,
                       min(q.response_time) as min_response_time
                """,
                unit="milliseconds",
                target_value=100.0,
                alert_threshold=500.0
            ),

            BusinessMetric(
                id="knowledge_growth",
                name="çŸ¥è¯†å¢é•¿",
                description="çŸ¥è¯†å›¾è°±å®ä½“å’Œå…³ç³»çš„å¢é•¿ç‡",
                category="growth",
                calculation_query="""
                MATCH (e:Entity)
                WHERE e.created_at > datetime() - duration('P7D')
                WITH count(e) as new_entities
                MATCH (r:Relationship)
                WHERE r.created_at > datetime() - duration('P7D')
                WITH new_entities, count(r) as new_relationships
                RETURN new_entities as weekly_entity_growth,
                       new_relationships as weekly_relationship_growth
                """,
                unit="count/week",
                target_value=1000.0,
                alert_threshold=100.0
            )
        ]

        for metric in default_metrics:
            self.metrics[metric.id] = metric

    async def calculate_metric(self, metric_id: str, time_range: Optional[str] = None) -> Dict[str, Any]:
        """è®¡ç®—ä¸šåŠ¡æŒ‡æ ‡"""
        if metric_id not in self.metrics:
            raise ValueError(f"æœªçŸ¥çš„æŒ‡æ ‡ID: {metric_id}")

        metric = self.metrics[metric_id]

        try:
# æ‰§è¡Œè®¡ç®—æŸ¥è¯¢
            result = await self.kg_client.query(metric.calculation_query)

            if not result:
                return {"value": 0, "status": "no_data"}

# æå–ä¸»è¦æŒ‡æ ‡å€¼
            main_value = self._extract_main_value(result[0], metric)

# è®¡ç®—æŒ‡æ ‡çŠ¶æ€
            status = self._calculate_metric_status(main_value, metric)

            return {
                "metric_id": metric_id,
                "metric_name": metric.name,
                "value": main_value,
                "unit": metric.unit,
                "status": status,
                "target_value": metric.target_value,
                "timestamp": datetime.now().isoformat(),
                "raw_data": result[0]
            }

        except Exception as e:
            self.logger.error(f"è®¡ç®—æŒ‡æ ‡ {metric_id} å¤±è´¥: {e}")
            return {"value": 0, "status": "error", "error": str(e)}

    def _extract_main_value(self, result: Dict[str, Any], metric: BusinessMetric) -> float:
        """æå–ä¸»è¦æŒ‡æ ‡å€¼"""
        if metric.id == "user_engagement":
            return result.get("avg_engagement", 0)
        elif metric.id == "knowledge_coverage":
            return result.get("coverage_percentage", 0)
        elif metric.id == "data_quality_score":
            return result.get("quality_score", 0)
        elif metric.id == "query_performance":
            return result.get("avg_response_time", 0)
        elif metric.id == "knowledge_growth":
            return result.get("weekly_entity_growth", 0) + result.get("weekly_relationship_growth", 0)
        else:
# é»˜è®¤å–ç¬¬ä¸€ä¸ªæ•°å€¼å­—æ®µ
            for key, value in result.items():
                if isinstance(value, (int, float)):
                    return float(value)
            return 0

    def _calculate_metric_status(self, value: float, metric: BusinessMetric) -> str:
        """è®¡ç®—æŒ‡æ ‡çŠ¶æ€"""
        if metric.alert_threshold and value < metric.alert_threshold:
            return "critical"
        elif metric.target_value and value < metric.target_value:
            return "warning"
        else:
            return "healthy"
```

## 2. è¶‹åŠ¿åˆ†ææ¨¡å—

```python
class TrendAnalyzer:
    """è¶‹åŠ¿åˆ†æå™¨"""

    def __init__(self, bi_engine: BusinessIntelligenceEngine):
        self.bi_engine = bi_engine
        self.logger = logging.getLogger(__name__)

    async def analyze_trend(self, metric_id: str, time_period: str = "30d") -> AnalysisResult:
        """åˆ†ææŒ‡æ ‡è¶‹åŠ¿"""
# è·å–å†å²æ•°æ®
        historical_data = await self._get_historical_data(metric_id, time_period)

        if not historical_data:
            return AnalysisResult(
                analysis_id=f"trend_{metric_id}_{datetime.now().strftime('%Y%m%d')}",
                analysis_type=AnalysisType.TREND_ANALYSIS,
                metric_id=metric_id,
                result_data={"error": "æ— å†å²æ•°æ®"},
                insights=[],
                recommendations=[],
                confidence_score=0.0,
                timestamp=datetime.now()
            )

# è®¡ç®—è¶‹åŠ¿æŒ‡æ ‡
        trend_indicators = self._calculate_trend_indicators(historical_data)

# ç”Ÿæˆæ´å¯Ÿ
        insights = self._generate_trend_insights(trend_indicators, metric_id)

# ç”Ÿæˆå»ºè®®
        recommendations = self._generate_trend_recommendations(trend_indicators, metric_id)

        return AnalysisResult(
            analysis_id=f"trend_{metric_id}_{datetime.now().strftime('%Y%m%d')}",
            analysis_type=AnalysisType.TREND_ANALYSIS,
            metric_id=metric_id,
            result_data=trend_indicators,
            insights=insights,
            recommendations=recommendations,
            confidence_score=self._calculate_confidence_score(historical_data),
            timestamp=datetime.now()
        )

    async def _get_historical_data(self, metric_id: str, time_period: str) -> List[Dict[str, Any]]:
        """è·å–å†å²æ•°æ®"""
# æ ¹æ®æ—¶é—´å‘¨æœŸç¡®å®šæŸ¥è¯¢èŒƒå›´
        if time_period == "7d":
            duration = "P7D"
        elif time_period == "30d":
            duration = "P30D"
        elif time_period == "90d":
            duration = "P90D"
        else:
            duration = "P30D"

# æŸ¥è¯¢å†å²æŒ‡æ ‡æ•°æ®
        query = f"""
        MATCH (m:MetricLog {{metric_id: $metric_id}})
        WHERE m.timestamp > datetime() - duration('{duration}')
        RETURN m.timestamp as timestamp, m.value as value
        ORDER BY m.timestamp
        """

        result = await self.bi_engine.kg_client.query(query, {"metric_id": metric_id})

        return [
            {
                "timestamp": row["timestamp"],
                "value": row["value"]
            }
            for row in result
        ]

    def _calculate_trend_indicators(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è®¡ç®—è¶‹åŠ¿æŒ‡æ ‡"""
        if len(data) < 2:
            return {"error": "æ•°æ®ç‚¹ä¸è¶³"}

        values = [point["value"] for point in data]
        timestamps = [point["timestamp"] for point in data]

# è®¡ç®—åŸºæœ¬ç»Ÿè®¡æŒ‡æ ‡
        mean_value = np.mean(values)
        std_value = np.std(values)

# è®¡ç®—è¶‹åŠ¿æ–œç‡
        x = np.arange(len(values))
        slope, intercept = np.polyfit(x, values, 1)

# è®¡ç®—å¢é•¿ç‡
        if len(values) > 1:
            growth_rate = ((values[-1] - values[0]) / values[0]) * 100 if values[0] != 0 else 0
        else:
            growth_rate = 0

# è®¡ç®—ç§»åŠ¨å¹³å‡
        window_size = min(7, len(values))
        moving_average = np.convolve(values, np.ones(window_size)/window_size, mode='valid')

        return {
            "mean": mean_value,
            "std": std_value,
            "slope": slope,
            "growth_rate": growth_rate,
            "trend_direction": "increasing" if slope > 0 else "decreasing",
            "volatility": std_value / mean_value if mean_value != 0 else 0,
            "moving_average": moving_average.tolist(),
            "data_points": len(values)
        }

    def _generate_trend_insights(self, indicators: Dict[str, Any], metric_id: str) -> List[str]:
        """ç”Ÿæˆè¶‹åŠ¿æ´å¯Ÿ"""
        insights = []

        if "error" in indicators:
            return ["æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æ"]

# è¶‹åŠ¿æ–¹å‘æ´å¯Ÿ
        if indicators["trend_direction"] == "increasing":
            insights.append(f"{self.bi_engine.metrics[metric_id].name}å‘ˆä¸Šå‡è¶‹åŠ¿")
        else:
            insights.append(f"{self.bi_engine.metrics[metric_id].name}å‘ˆä¸‹é™è¶‹åŠ¿")

# å¢é•¿ç‡æ´å¯Ÿ
        growth_rate = indicators["growth_rate"]
        if abs(growth_rate) > 10:
            if growth_rate > 0:
                insights.append(f"å¢é•¿ç‡æ˜¾è‘—ï¼Œè¾¾åˆ° {growth_rate:.1f}%")
            else:
                insights.append(f"ä¸‹é™ç‡æ˜¾è‘—ï¼Œè¾¾åˆ° {abs(growth_rate):.1f}%")

# æ³¢åŠ¨æ€§æ´å¯Ÿ
        volatility = indicators["volatility"]
        if volatility > 0.5:
            insights.append("æŒ‡æ ‡æ³¢åŠ¨è¾ƒå¤§ï¼Œéœ€è¦å…³æ³¨ç¨³å®šæ€§")
        elif volatility < 0.1:
            insights.append("æŒ‡æ ‡ç›¸å¯¹ç¨³å®š")

        return insights

    def _generate_trend_recommendations(self, indicators: Dict[str, Any], metric_id: str) -> List[str]:
        """ç”Ÿæˆè¶‹åŠ¿å»ºè®®"""
        recommendations = []

        if "error" in indicators:
            return ["å»ºè®®æ”¶é›†æ›´å¤šæ•°æ®ä»¥è¿›è¡Œå‡†ç¡®åˆ†æ"]

        metric = self.bi_engine.metrics[metric_id]

# åŸºäºè¶‹åŠ¿æ–¹å‘çš„å»ºè®®
        if indicators["trend_direction"] == "decreasing":
            if metric.target_value:
                recommendations.append(f"å½“å‰è¶‹åŠ¿ä¸‹é™ï¼Œå»ºè®®é‡‡å–æªæ–½æå‡{metric.name}")
            recommendations.append("åˆ†æä¸‹é™åŸå› ï¼Œåˆ¶å®šæ”¹è¿›è®¡åˆ’")

# åŸºäºæ³¢åŠ¨æ€§çš„å»ºè®®
        volatility = indicators["volatility"]
        if volatility > 0.5:
            recommendations.append("å»ºè®®å®æ–½ç¨³å®šæ€§æªæ–½ï¼Œå‡å°‘æŒ‡æ ‡æ³¢åŠ¨")

# åŸºäºç›®æ ‡å€¼çš„å»ºè®®
        if metric.target_value:
            current_value = indicators.get("mean", 0)
            if current_value < metric.target_value:
                recommendations.append(f"å½“å‰å€¼ä½äºç›®æ ‡å€¼ï¼Œå»ºè®®åˆ¶å®šæå‡ç­–ç•¥")

        return recommendations

    def _calculate_confidence_score(self, data: List[Dict[str, Any]]) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦åˆ†æ•°"""
        if len(data) < 5:
            return 0.3
        elif len(data) < 10:
            return 0.6
        elif len(data) < 20:
            return 0.8
        else:
            return 0.9
```

## 3. å¼‚å¸¸æ£€æµ‹æ¨¡å—

```python
class AnomalyDetector:
    """å¼‚å¸¸æ£€æµ‹å™¨"""

    def __init__(self, bi_engine: BusinessIntelligenceEngine):
        self.bi_engine = bi_engine
        self.logger = logging.getLogger(__name__)

    async def detect_anomalies(self, metric_id: str, time_period: str = "7d") -> AnalysisResult:
        """æ£€æµ‹æŒ‡æ ‡å¼‚å¸¸"""
# è·å–å†å²æ•°æ®
        historical_data = await self._get_historical_data(metric_id, time_period)

        if len(historical_data) < 10:
            return AnalysisResult(
                analysis_id=f"anomaly_{metric_id}_{datetime.now().strftime('%Y%m%d')}",
                analysis_type=AnalysisType.ANOMALY_DETECTION,
                metric_id=metric_id,
                result_data={"error": "æ•°æ®ç‚¹ä¸è¶³"},
                insights=[],
                recommendations=[],
                confidence_score=0.0,
                timestamp=datetime.now()
            )

# æ£€æµ‹å¼‚å¸¸
        anomalies = self._detect_statistical_anomalies(historical_data)

# ç”Ÿæˆæ´å¯Ÿ
        insights = self._generate_anomaly_insights(anomalies, metric_id)

# ç”Ÿæˆå»ºè®®
        recommendations = self._generate_anomaly_recommendations(anomalies, metric_id)

        return AnalysisResult(
            analysis_id=f"anomaly_{metric_id}_{datetime.now().strftime('%Y%m%d')}",
            analysis_type=AnalysisType.ANOMALY_DETECTION,
            metric_id=metric_id,
            result_data={"anomalies": anomalies},
            insights=insights,
            recommendations=recommendations,
            confidence_score=self._calculate_anomaly_confidence(anomalies),
            timestamp=datetime.now()
        )

    async def _get_historical_data(self, metric_id: str, time_period: str) -> List[Dict[str, Any]]:
        """è·å–å†å²æ•°æ®"""
# ç±»ä¼¼è¶‹åŠ¿åˆ†æçš„å®ç°
        duration = "P7D" if time_period == "7d" else "P30D"

        query = f"""
        MATCH (m:MetricLog {{metric_id: $metric_id}})
        WHERE m.timestamp > datetime() - duration('{duration}')
        RETURN m.timestamp as timestamp, m.value as value
        ORDER BY m.timestamp
        """

        result = await self.bi_engine.kg_client.query(query, {"metric_id": metric_id})

        return [
            {
                "timestamp": row["timestamp"],
                "value": row["value"]
            }
            for row in result
        ]

    def _detect_statistical_anomalies(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ£€æµ‹ç»Ÿè®¡å¼‚å¸¸"""
        values = [point["value"] for point in data]
        timestamps = [point["timestamp"] for point in data]

# è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        mean = np.mean(values)
        std = np.std(values)

# ä½¿ç”¨3-sigmaè§„åˆ™æ£€æµ‹å¼‚å¸¸
        anomalies = []
        threshold = 3 * std

        for i, value in enumerate(values):
            if abs(value - mean) > threshold:
                anomalies.append({
                    "timestamp": timestamps[i],
                    "value": value,
                    "expected_range": [mean - threshold, mean + threshold],
                    "deviation": abs(value - mean) / std,
                    "severity": "high" if abs(value - mean) > 4 * std else "medium"
                })

        return anomalies

    def _generate_anomaly_insights(self, anomalies: List[Dict[str, Any]], metric_id: str) -> List[str]:
        """ç”Ÿæˆå¼‚å¸¸æ´å¯Ÿ"""
        insights = []

        if not anomalies:
            insights.append("æœªæ£€æµ‹åˆ°å¼‚å¸¸ï¼ŒæŒ‡æ ‡è¡¨ç°æ­£å¸¸")
            return insights

        metric_name = self.bi_engine.metrics[metric_id].name

# å¼‚å¸¸æ•°é‡æ´å¯Ÿ
        insights.append(f"æ£€æµ‹åˆ° {len(anomalies)} ä¸ªå¼‚å¸¸ç‚¹")

# å¼‚å¸¸ä¸¥é‡ç¨‹åº¦æ´å¯Ÿ
        high_severity = [a for a in anomalies if a["severity"] == "high"]
        if high_severity:
            insights.append(f"å…¶ä¸­ {len(high_severity)} ä¸ªä¸ºä¸¥é‡å¼‚å¸¸")

# å¼‚å¸¸æ¨¡å¼æ´å¯Ÿ
        if len(anomalies) > 3:
            insights.append("å¼‚å¸¸å‡ºç°é¢‘ç‡è¾ƒé«˜ï¼Œå¯èƒ½å­˜åœ¨ç³»ç»Ÿæ€§é—®é¢˜")

        return insights

    def _generate_anomaly_recommendations(self, anomalies: List[Dict[str, Any]], metric_id: str) -> List[str]:
        """ç”Ÿæˆå¼‚å¸¸å»ºè®®"""
        recommendations = []

        if not anomalies:
            return ["ç»§ç»­ä¿æŒå½“å‰è¿è¥ç­–ç•¥"]

# åŸºäºå¼‚å¸¸æ•°é‡çš„å»ºè®®
        if len(anomalies) > 5:
            recommendations.append("å»ºè®®æ·±å…¥åˆ†æå¼‚å¸¸åŸå› ï¼Œå¯èƒ½å­˜åœ¨ç³»ç»Ÿæ€§é£é™©")

# åŸºäºå¼‚å¸¸ä¸¥é‡ç¨‹åº¦çš„å»ºè®®
        high_severity = [a for a in anomalies if a["severity"] == "high"]
        if high_severity:
            recommendations.append("å»ºè®®ç«‹å³è°ƒæŸ¥ä¸¥é‡å¼‚å¸¸ï¼Œåˆ¶å®šåº”æ€¥æªæ–½")

# é€šç”¨å»ºè®®
        recommendations.append("å»ºè®®å»ºç«‹å¼‚å¸¸ç›‘æ§æœºåˆ¶ï¼ŒåŠæ—¶å‘ç°å’Œå¤„ç†å¼‚å¸¸")
        recommendations.append("å»ºè®®åˆ†æå¼‚å¸¸æ¨¡å¼ï¼Œä¼˜åŒ–ä¸šåŠ¡æµç¨‹")

        return recommendations

    def _calculate_anomaly_confidence(self, anomalies: List[Dict[str, Any]]) -> float:
        """è®¡ç®—å¼‚å¸¸æ£€æµ‹ç½®ä¿¡åº¦"""
        if not anomalies:
            return 0.9  # æ— å¼‚å¸¸ï¼Œç½®ä¿¡åº¦é«˜

# åŸºäºå¼‚å¸¸æ•°é‡å’Œä¸¥é‡ç¨‹åº¦è®¡ç®—ç½®ä¿¡åº¦
        high_severity_count = len([a for a in anomalies if a["severity"] == "high"])
        total_anomalies = len(anomalies)

        if high_severity_count > 0:
            return 0.8
        elif total_anomalies > 5:
            return 0.7
        else:
            return 0.6
```

## 4. é¢„æµ‹åˆ†ææ¨¡å—

```python
class PredictiveAnalyzer:
    """é¢„æµ‹åˆ†æå™¨"""

    def __init__(self, bi_engine: BusinessIntelligenceEngine):
        self.bi_engine = bi_engine
        self.logger = logging.getLogger(__name__)

    async def predict_metric(self, metric_id: str, forecast_period: int = 30) -> AnalysisResult:
        """é¢„æµ‹æŒ‡æ ‡å€¼"""
# è·å–å†å²æ•°æ®
        historical_data = await self._get_historical_data(metric_id, "90d")

        if len(historical_data) < 20:
            return AnalysisResult(
                analysis_id=f"prediction_{metric_id}_{datetime.now().strftime('%Y%m%d')}",
                analysis_type=AnalysisType.PREDICTIVE_ANALYSIS,
                metric_id=metric_id,
                result_data={"error": "å†å²æ•°æ®ä¸è¶³"},
                insights=[],
                recommendations=[],
                confidence_score=0.0,
                timestamp=datetime.now()
            )

# æ‰§è¡Œé¢„æµ‹
        prediction_result = self._perform_prediction(historical_data, forecast_period)

# ç”Ÿæˆæ´å¯Ÿ
        insights = self._generate_prediction_insights(prediction_result, metric_id)

# ç”Ÿæˆå»ºè®®
        recommendations = self._generate_prediction_recommendations(prediction_result, metric_id)

        return AnalysisResult(
            analysis_id=f"prediction_{metric_id}_{datetime.now().strftime('%Y%m%d')}",
            analysis_type=AnalysisType.PREDICTIVE_ANALYSIS,
            metric_id=metric_id,
            result_data=prediction_result,
            insights=insights,
            recommendations=recommendations,
            confidence_score=self._calculate_prediction_confidence(prediction_result),
            timestamp=datetime.now()
        )

    async def _get_historical_data(self, metric_id: str, time_period: str) -> List[Dict[str, Any]]:
        """è·å–å†å²æ•°æ®"""
        duration = "P90D" if time_period == "90d" else "P30D"

        query = f"""
        MATCH (m:MetricLog {{metric_id: $metric_id}})
        WHERE m.timestamp > datetime() - duration('{duration}')
        RETURN m.timestamp as timestamp, m.value as value
        ORDER BY m.timestamp
        """

        result = await self.bi_engine.kg_client.query(query, {"metric_id": metric_id})

        return [
            {
                "timestamp": row["timestamp"],
                "value": row["value"]
            }
            for row in result
        ]

    def _perform_prediction(self, data: List[Dict[str, Any]], forecast_period: int) -> Dict[str, Any]:
        """æ‰§è¡Œé¢„æµ‹"""
        values = [point["value"] for point in data]

# ç®€å•çº¿æ€§å›å½’é¢„æµ‹
        x = np.arange(len(values))
        slope, intercept = np.polyfit(x, values, 1)

# ç”Ÿæˆé¢„æµ‹å€¼
        future_x = np.arange(len(values), len(values) + forecast_period)
        predictions = slope * future_x + intercept

# è®¡ç®—é¢„æµ‹åŒºé—´
        residuals = values - (slope * x + intercept)
        std_residuals = np.std(residuals)

        confidence_interval = 1.96 * std_residuals  # 95%ç½®ä¿¡åŒºé—´

        return {
            "predictions": predictions.tolist(),
            "confidence_interval": confidence_interval,
            "trend_slope": slope,
            "forecast_period": forecast_period,
            "model_type": "linear_regression"
        }

    def _generate_prediction_insights(self, prediction_result: Dict[str, Any], metric_id: str) -> List[str]:
        """ç”Ÿæˆé¢„æµ‹æ´å¯Ÿ"""
        insights = []

        if "error" in prediction_result:
            return ["æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå¯é é¢„æµ‹"]

        metric_name = self.bi_engine.metrics[metric_id].name
        slope = prediction_result["trend_slope"]

# è¶‹åŠ¿æ´å¯Ÿ
        if slope > 0:
            insights.append(f"{metric_name}é¢„è®¡å°†ç»§ç»­å¢é•¿")
        elif slope < 0:
            insights.append(f"{metric_name}é¢„è®¡å°†ä¸‹é™")
        else:
            insights.append(f"{metric_name}é¢„è®¡å°†ä¿æŒç¨³å®š")

# é¢„æµ‹ç²¾åº¦æ´å¯Ÿ
        confidence_interval = prediction_result["confidence_interval"]
        if confidence_interval < 0.1:
            insights.append("é¢„æµ‹ç²¾åº¦è¾ƒé«˜ï¼Œç½®ä¿¡åº¦å¼º")
        else:
            insights.append("é¢„æµ‹å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œå»ºè®®è°¨æ…å†³ç­–")

        return insights

    def _generate_prediction_recommendations(self, prediction_result: Dict[str, Any], metric_id: str) -> List[str]:
        """ç”Ÿæˆé¢„æµ‹å»ºè®®"""
        recommendations = []

        if "error" in prediction_result:
            return ["å»ºè®®æ”¶é›†æ›´å¤šå†å²æ•°æ®ä»¥æé«˜é¢„æµ‹å‡†ç¡®æ€§"]

        metric = self.bi_engine.metrics[metric_id]
        slope = prediction_result["trend_slope"]

# åŸºäºé¢„æµ‹è¶‹åŠ¿çš„å»ºè®®
        if slope < 0 and metric.target_value:
            recommendations.append("é¢„æµ‹æ˜¾ç¤ºä¸‹é™è¶‹åŠ¿ï¼Œå»ºè®®åˆ¶å®šæå‡ç­–ç•¥")
        elif slope > 0:
            recommendations.append("é¢„æµ‹æ˜¾ç¤ºå¢é•¿è¶‹åŠ¿ï¼Œå»ºè®®ä¿æŒå½“å‰ç­–ç•¥")

# åŸºäºç›®æ ‡å€¼çš„å»ºè®®
        if metric.target_value:
            current_value = prediction_result["predictions"][0] if prediction_result["predictions"] else 0
            if current_value < metric.target_value:
                recommendations.append("é¢„æµ‹å€¼ä½äºç›®æ ‡ï¼Œå»ºè®®è°ƒæ•´ç­–ç•¥")

# é€šç”¨å»ºè®®
        recommendations.append("å»ºè®®å®šæœŸæ›´æ–°é¢„æµ‹æ¨¡å‹ï¼Œä¿æŒå‡†ç¡®æ€§")
        recommendations.append("å»ºè®®ç»“åˆå…¶ä»–æŒ‡æ ‡è¿›è¡Œç»¼åˆåˆ†æ")

        return recommendations

    def _calculate_prediction_confidence(self, prediction_result: Dict[str, Any]) -> float:
        """è®¡ç®—é¢„æµ‹ç½®ä¿¡åº¦"""
        if "error" in prediction_result:
            return 0.0

# åŸºäºç½®ä¿¡åŒºé—´è®¡ç®—ç½®ä¿¡åº¦
        confidence_interval = prediction_result["confidence_interval"]
        if confidence_interval < 0.05:
            return 0.9
        elif confidence_interval < 0.1:
            return 0.7
        elif confidence_interval < 0.2:
            return 0.5
        else:
            return 0.3
```

## 5. ä¸šåŠ¡æ™ºèƒ½ä»ªè¡¨æ¿

```python
class BusinessIntelligenceDashboard:
    """ä¸šåŠ¡æ™ºèƒ½ä»ªè¡¨æ¿"""

    def __init__(self, bi_engine: BusinessIntelligenceEngine):
        self.bi_engine = bi_engine
        self.trend_analyzer = TrendAnalyzer(bi_engine)
        self.anomaly_detector = AnomalyDetector(bi_engine)
        self.predictive_analyzer = PredictiveAnalyzer(bi_engine)
        self.logger = logging.getLogger(__name__)

    async def generate_comprehensive_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆä¸šåŠ¡æŠ¥å‘Š"""
# è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
        metrics_data = {}
        for metric_id in self.bi_engine.metrics:
            metrics_data[metric_id] = await self.bi_engine.calculate_metric(metric_id)

# æ‰§è¡Œè¶‹åŠ¿åˆ†æ
        trend_analysis = {}
        for metric_id in self.bi_engine.metrics:
            trend_analysis[metric_id] = await self.trend_analyzer.analyze_trend(metric_id)

# æ‰§è¡Œå¼‚å¸¸æ£€æµ‹
        anomaly_detection = {}
        for metric_id in self.bi_engine.metrics:
            anomaly_detection[metric_id] = await self.anomaly_detector.detect_anomalies(metric_id)

# æ‰§è¡Œé¢„æµ‹åˆ†æ
        prediction_analysis = {}
        for metric_id in self.bi_engine.metrics:
            prediction_analysis[metric_id] = await self.predictive_analyzer.predict_metric(metric_id)

        return {
            "metrics": metrics_data,
            "trends": trend_analysis,
            "anomalies": anomaly_detection,
            "predictions": prediction_analysis,
            "summary": await self._generate_summary(metrics_data, trend_analysis, anomaly_detection),
            "generated_at": datetime.now().isoformat()
        }

    async def _generate_summary(self, metrics: Dict[str, Any], trends: Dict[str, Any], anomalies: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆä¸šåŠ¡æ‘˜è¦"""
        summary = {
            "overall_health": "healthy",
            "critical_issues": 0,
            "warnings": 0,
            "key_insights": [],
            "recommendations": []
        }

# ç»Ÿè®¡é—®é¢˜æ•°é‡
        for metric_id, metric_data in metrics.items():
            if metric_data.get("status") == "critical":
                summary["critical_issues"] += 1
            elif metric_data.get("status") == "warning":
                summary["warnings"] += 1

# ç¡®å®šæ•´ä½“å¥åº·çŠ¶æ€
        if summary["critical_issues"] > 0:
            summary["overall_health"] = "critical"
        elif summary["warnings"] > 2:
            summary["overall_health"] = "warning"

# ç”Ÿæˆå…³é”®æ´å¯Ÿ
        for metric_id, trend_result in trends.items():
            if trend_result.insights:
                summary["key_insights"].extend(trend_result.insights[:2])  # å–å‰2ä¸ªæ´å¯Ÿ

# ç”Ÿæˆå»ºè®®
        for metric_id, anomaly_result in anomalies.items():
            if anomaly_result.recommendations:
                summary["recommendations"].extend(anomaly_result.recommendations[:1])  # å–å‰1ä¸ªå»ºè®®

        return summary

    async def create_bi_dashboard(self) -> str:
        """åˆ›å»ºä¸šåŠ¡æ™ºèƒ½ä»ªè¡¨æ¿"""
        report = await self.generate_comprehensive_report()

        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>ä¸šåŠ¡æ™ºèƒ½ä»ªè¡¨æ¿</title>
            <meta charset="utf-8">
            <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .dashboard-header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                                   color: white; padding: 20px; border-radius: 10px; margin-bottom: 20px; }}
                .metrics-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
                                gap: 20px; margin-bottom: 30px; }}
                .metric-card {{ background: white; border: 1px solid #e0e0e0; border-radius: 8px;
                              padding: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
                .metric-value {{ font-size: 2em; font-weight: bold; color: #2c3e50; }}
                .metric-label {{ color: #7f8c8d; margin-top: 5px; }}
                .status-healthy {{ color: #27ae60; }}
                .status-warning {{ color: #f39c12; }}
                .status-critical {{ color: #e74c3c; }}
                .chart-container {{ background: white; padding: 20px; border-radius: 8px;
                                   box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin: 20px 0; }}
                .insights-section {{ background: #f8f9fa; padding: 15px; border-radius: 5px; margin: 10px 0; }}
            </style>
        </head>
        <body>
            <div class="dashboard-header">
                <h1>ä¸šåŠ¡æ™ºèƒ½ä»ªè¡¨æ¿</h1>
                <p>æœ€åæ›´æ–°: {report['generated_at']}</p>
                <p>æ•´ä½“çŠ¶æ€: <span class="status-{report['summary']['overall_health']}">{report['summary']['overall_health']}</span></p>
            </div>

            <div class="metrics-grid">
        """

        for metric_id, metric_data in report['metrics'].items():
            status_class = f"status-{metric_data.get('status', 'unknown')}"
            html_content += f"""
                <div class="metric-card">
                    <div class="metric-value {status_class}">{metric_data.get('value', 0):.2f}</div>
                    <div class="metric-label">{metric_data.get('metric_name', metric_id)}</div>
                    <div class="insights-section">
                        <h4>è¶‹åŠ¿æ´å¯Ÿ:</h4>
                        <ul>
        """

            trend_result = report['trends'].get(metric_id)
            if trend_result and trend_result.insights:
                for insight in trend_result.insights[:2]:
                    html_content += f"<li>{insight}</li>"

            html_content += """
                        </ul>
                    </div>
                </div>
            """

        html_content += """
            </div>

            <div class="chart-container">
                <h3>å…³é”®æ´å¯Ÿ</h3>
                <ul>
        """

        for insight in report['summary']['key_insights'][:5]:
            html_content += f"<li>{insight}</li>"

        html_content += """
                </ul>
            </div>

            <div class="chart-container">
                <h3>ä¸šåŠ¡å»ºè®®</h3>
                <ul>
        """

        for recommendation in report['summary']['recommendations'][:5]:
            html_content += f"<li>{recommendation}</li>"

        html_content += """
                </ul>
            </div>
        </body>
        </html>
        """

# ä¿å­˜ä»ªè¡¨æ¿
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        dashboard_file = f"bi_dashboard_{timestamp}.html"

        with open(dashboard_file, 'w', encoding='utf-8') as f:
            f.write(html_content)

        self.logger.info(f"ä¸šåŠ¡æ™ºèƒ½ä»ªè¡¨æ¿å·²ç”Ÿæˆ: {dashboard_file}")
        return dashboard_file

# ä¸»ä¸šåŠ¡æ™ºèƒ½åè°ƒå™¨
class BusinessIntelligenceOrchestrator:
    """ä¸šåŠ¡æ™ºèƒ½åè°ƒå™¨"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(__name__)

    async def initialize_bi_system(self):
        """åˆå§‹åŒ–ä¸šåŠ¡æ™ºèƒ½ç³»ç»Ÿ"""
# åˆ›å»ºæ ¸å¿ƒç»„ä»¶
        self.bi_engine = BusinessIntelligenceEngine(None, self.config)
        self.dashboard = BusinessIntelligenceDashboard(self.bi_engine)

# åˆå§‹åŒ–ç»„ä»¶
        await self.bi_engine.initialize()

        self.logger.info("ä¸šåŠ¡æ™ºèƒ½ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    async def run_bi_analysis(self):
        """è¿è¡Œä¸šåŠ¡æ™ºèƒ½åˆ†æ"""
# è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
        for metric_id in self.bi_engine.metrics:
            await self.bi_engine.calculate_metric(metric_id)

# ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        await self.dashboard.generate_comprehensive_report()

    async def create_bi_dashboard(self) -> str:
        """åˆ›å»ºä¸šåŠ¡æ™ºèƒ½ä»ªè¡¨æ¿"""
        return await self.dashboard.create_bi_dashboard()

# é…ç½®ç¤ºä¾‹
BI_CONFIG = {
    "analysis": {
        "trend_analysis_enabled": True,
        "anomaly_detection_enabled": True,
        "prediction_analysis_enabled": True
    },
    "metrics": {
        "calculation_interval": 3600,  # 1å°æ—¶
        "retention_period": 90  # 90å¤©
    },
    "alerts": {
        "enabled": True,
        "threshold": 0.8
    }
}

# ä¸»å‡½æ•°
async def main():
    """ä¸»å‡½æ•°"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

# åˆ›å»ºä¸šåŠ¡æ™ºèƒ½åè°ƒå™¨
    orchestrator = BusinessIntelligenceOrchestrator(BI_CONFIG)
    await orchestrator.initialize_bi_system()

# è¿è¡Œä¸šåŠ¡æ™ºèƒ½åˆ†æ
    await orchestrator.run_bi_analysis()

# ç”Ÿæˆä»ªè¡¨æ¿
    dashboard_file = await orchestrator.create_bi_dashboard()
    print(f"ä¸šåŠ¡æ™ºèƒ½ä»ªè¡¨æ¿å·²åˆ›å»º: {dashboard_file}")

if __name__ == "__main__":
    asyncio.run(main())
```

è¿™ä¸ªä¸šåŠ¡æ™ºèƒ½åˆ†æç³»ç»Ÿæä¾›äº†ï¼š

1. **ä¸šåŠ¡æŒ‡æ ‡è®¡ç®—** - ç”¨æˆ·å‚ä¸åº¦ã€çŸ¥è¯†è¦†ç›–ç‡ã€æ•°æ®è´¨é‡ç­‰å…³é”®æŒ‡æ ‡
2. **è¶‹åŠ¿åˆ†æ** - è¯†åˆ«æŒ‡æ ‡å˜åŒ–è¶‹åŠ¿å’Œæ¨¡å¼
3. **å¼‚å¸¸æ£€æµ‹** - è‡ªåŠ¨å‘ç°å¼‚å¸¸æ•°æ®ç‚¹
4. **é¢„æµ‹åˆ†æ** - åŸºäºå†å²æ•°æ®é¢„æµ‹æœªæ¥è¶‹åŠ¿
5. **æ™ºèƒ½ä»ªè¡¨æ¿** - å¯è§†åŒ–çš„ä¸šåŠ¡æ´å¯Ÿå’Œå»ºè®®

ç³»ç»Ÿä¸ºçŸ¥è¯†å›¾è°±æä¾›äº†æ·±åº¦çš„ä¸šåŠ¡ä»·å€¼åˆ†æå’Œå†³ç­–æ”¯æŒã€‚
