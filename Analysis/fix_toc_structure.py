#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€æ‰€æœ‰æ–‡æ¡£çš„ç›®å½•ç»“æ„ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
å‚è€ƒæ ¼å¼ï¼š3.3.1-æ ¸å¿ƒæ•°æ®å¤„ç†ç®—æ³•.md
ç¡®ä¿ï¼š
1. ä¿ç•™æ ‡é¢˜ä¸­çš„ç¼–å·
2. æ­£ç¡®çš„å±‚çº§ç¼©è¿›
3. å®Œæ•´çš„ç›®å½•ç»“æ„
"""

import os
import re
from pathlib import Path
from typing import List, Tuple, Dict

def extract_headings(content: str) -> List[Tuple[int, str, str]]:
    """æå–æ‰€æœ‰æ ‡é¢˜ï¼Œè¿”å›(çº§åˆ«, æ ‡é¢˜æ–‡æœ¬, åŸå§‹è¡Œ)"""
    headings = []
    lines = content.split('\n')
    in_code_block = False
    code_block_markers = ['```', '~~~']
    
    for i, line in enumerate(lines):
        # æ£€æµ‹ä»£ç å—ï¼ˆæ›´ä¸¥æ ¼çš„æ£€æµ‹ï¼‰
        stripped = line.strip()
        
        # æ£€æµ‹ä»£ç å—å¼€å§‹/ç»“æŸ
        # æ£€æŸ¥æ˜¯å¦æ˜¯ä»£ç å—æ ‡è®°ï¼ˆä»¥```æˆ–~~~å¼€å¤´ï¼Œä¸”è‡³å°‘3ä¸ªç›¸åŒå­—ç¬¦ï¼‰
        if stripped.startswith('```') or stripped.startswith('~~~'):
            # æ£€æŸ¥å‰3ä¸ªå­—ç¬¦æ˜¯å¦ç›¸åŒ
            if len(stripped) >= 3 and stripped[0] == stripped[1] == stripped[2]:
                in_code_block = not in_code_block
            continue
        
        # è·³è¿‡ä»£ç å—å†…çš„æ‰€æœ‰å†…å®¹
        if in_code_block:
            continue
        
        # è·³è¿‡ç©ºè¡Œ
        if not stripped:
            continue
        
        # è·³è¿‡ç¼©è¿›çš„è¡Œï¼ˆå¯èƒ½æ˜¯ä»£ç æˆ–åˆ—è¡¨é¡¹ï¼‰
        if line.startswith('    ') or line.startswith('\t'):
            continue
        
        # è·³è¿‡çœ‹èµ·æ¥åƒä»£ç æ³¨é‡Šçš„è¡Œï¼ˆä»¥ # å¼€å¤´ä½†ä¸æ˜¯æ ‡é¢˜ï¼Œä¸”ä¸åœ¨ä»£ç å—ä¸­ï¼‰
        # ä½†éœ€è¦ç¡®ä¿ä¸æ˜¯Markdownæ ‡é¢˜
        if stripped.startswith('#') and not re.match(r'^#{1,6}\s+[^#]', line):
            continue
        
        # è·³è¿‡çœ‹èµ·æ¥åƒä»£ç è¾“å‡ºçš„è¡Œ
        if re.match(r'^[\[\{\(].*[\]\}\)]', stripped) and any(c in stripped for c in ["'", '"', 'b\'', 'b"']):
            continue
        
        # è·³è¿‡é…ç½®æ–‡ä»¶åï¼ˆå¦‚ redis.confï¼‰
        if re.match(r'^[a-z_]+\.(conf|config|yaml|yml|json|xml)$', stripped, re.IGNORECASE):
            continue
        
        # åŒ¹é…æ ‡é¢˜ï¼ˆå¿…é¡»æ˜¯è¡Œé¦–çš„ #ï¼‰
        match = re.match(r'^(#{1,6})\s+(.+)$', line)
        if match:
            level = len(match.group(1))
            text = match.group(2).strip()
            
            # è¿‡æ»¤æ‰æ˜æ˜¾ä¸æ˜¯æ ‡é¢˜çš„å†…å®¹
            if len(text) < 2:
                continue
            if re.match(r'^[\[\{\(].*[\]\}\)]$', text) and any(c in text for c in ["'", '"', 'b\'']):
                continue
            if text.startswith('b\'') or text.startswith('b"'):
                continue
            
            headings.append((level, text, line))
    
    return headings

def generate_anchor(text: str) -> str:
    """ç”ŸæˆGitHubé£æ ¼çš„é”šç‚¹"""
    # è½¬æ¢ä¸ºå°å†™
    anchor = text.lower()
    # æ›¿æ¢ç©ºæ ¼ä¸ºè¿å­—ç¬¦
    anchor = re.sub(r'\s+', '-', anchor)
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€è¿å­—ç¬¦ã€æ‹¬å·
    anchor = re.sub(r'[^\w\u4e00-\u9fff\-\(\)]', '', anchor)
    # ç§»é™¤å¤šä½™çš„è¿å­—ç¬¦
    anchor = re.sub(r'-+', '-', anchor)
    # ç§»é™¤é¦–å°¾è¿å­—ç¬¦
    anchor = anchor.strip('-')
    return anchor

def generate_toc(headings: List[Tuple[int, str, str]]) -> str:
    """ç”Ÿæˆç›®å½•ï¼Œä¿ç•™æ ‡é¢˜ç¼–å·"""
    if not headings:
        return ""
    
    toc_lines = ["## ğŸ“‘ ç›®å½•", ""]
    
    # ç¬¬ä¸€ä¸ªæ ‡é¢˜åº”è¯¥æ˜¯H1ï¼Œä½œä¸ºæ–‡æ¡£æ ‡é¢˜
    if headings[0][0] == 1:
        doc_title = headings[0][1]
        doc_anchor = generate_anchor(doc_title)
        toc_lines.append(f"- [{doc_title}](#{doc_anchor})")
        toc_lines.append("  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)")
        start_idx = 1
    else:
        start_idx = 0
    
    # å¤„ç†å…¶ä»–æ ‡é¢˜
    stack = []  # ç”¨äºè·Ÿè¸ªç¼©è¿›å±‚çº§ï¼Œå­˜å‚¨(level, text)
    
    for i in range(start_idx, len(headings)):
        level, text, _ = headings[i]
        
        # è·³è¿‡ç›®å½•æ ‡é¢˜æœ¬èº«
        if text == "ğŸ“‘ ç›®å½•" or text == "ç›®å½•":
            continue
        
        # ç¡®å®šç¼©è¿›ï¼šç§»é™¤æ ˆä¸­çº§åˆ«å¤§äºç­‰äºå½“å‰çº§åˆ«çš„é¡¹
        while stack and stack[-1][0] >= level:
            stack.pop()
        
        # è®¡ç®—ç¼©è¿›ï¼ˆæ¯ä¸ªå±‚çº§2ä¸ªç©ºæ ¼ï¼‰
        indent = "  " * len(stack)
        
        # ç”Ÿæˆé”šç‚¹ï¼ˆä½¿ç”¨å®Œæ•´æ ‡é¢˜æ–‡æœ¬ï¼‰
        anchor = generate_anchor(text)
        
        # æ„å»ºç›®å½•é¡¹ï¼ˆä¿ç•™æ ‡é¢˜ä¸­çš„ç¼–å·ï¼‰
        toc_item = f"{indent}- [{text}](#{anchor})"
        toc_lines.append(toc_item)
        
        # å°†å½“å‰æ ‡é¢˜åŠ å…¥æ ˆ
        stack.append((level, text))
    
    return "\n".join(toc_lines)

def find_toc_position(content: str) -> int:
    """æ‰¾åˆ°ç›®å½•åº”è¯¥æ’å…¥çš„ä½ç½®ï¼ˆH1æ ‡é¢˜åï¼‰"""
    lines = content.split('\n')
    
    for i, line in enumerate(lines):
        if re.match(r'^#\s+', line):
            # åœ¨H1æ ‡é¢˜åæ’å…¥ç›®å½•
            return i + 1
    
    return 0

def has_toc(content: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›®å½•"""
    return "## ğŸ“‘ ç›®å½•" in content

def fix_document(file_path: Path) -> Tuple[bool, str]:
    """ä¿®å¤å•ä¸ªæ–‡æ¡£çš„ç›®å½•ç»“æ„"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        return False, f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}"
    
    # æå–æ ‡é¢˜
    headings = extract_headings(content)
    
    if not headings:
        return False, "æ²¡æœ‰æ‰¾åˆ°æ ‡é¢˜"
    
    # ç”Ÿæˆæ–°ç›®å½•
    new_toc = generate_toc(headings)
    
    if not new_toc:
        return False, "æ— æ³•ç”Ÿæˆç›®å½•"
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
    if has_toc(content):
        # æ›¿æ¢ç°æœ‰ç›®å½•
        lines = content.split('\n')
        toc_start = -1
        toc_end = -1
        
        for i, line in enumerate(lines):
            if re.match(r'^##\s+[ğŸ“‘]?\s*ç›®å½•', line):
                toc_start = i
                # æ‰¾åˆ°ç›®å½•ç»“æŸä½ç½®ï¼ˆä¸‹ä¸€ä¸ªåŒçº§æˆ–æ›´é«˜çº§æ ‡é¢˜ï¼Œæˆ–åˆ†éš”çº¿ï¼‰
                for j in range(i + 1, len(lines)):
                    if re.match(r'^---', lines[j]):
                        toc_end = j
                        break
                    if re.match(r'^##\s+', lines[j]) and not re.match(r'^##\s+[ğŸ“‘]?\s*ç›®å½•', lines[j]):
                        toc_end = j
                        break
                if toc_end == -1:
                    # å¦‚æœæ²¡æ‰¾åˆ°ï¼ŒæŸ¥æ‰¾ä¸‹ä¸€ä¸ªH1æˆ–H2æ ‡é¢˜
                    for j in range(i + 1, len(lines)):
                        if re.match(r'^#\s+', lines[j]) or (re.match(r'^##\s+', lines[j]) and not re.match(r'^##\s+[ğŸ“‘]?\s*ç›®å½•', lines[j])):
                            toc_end = j
                            break
                if toc_end == -1:
                    toc_end = len(lines)
                break
        
        if toc_start != -1:
            # æ›¿æ¢ç›®å½•
            new_lines = lines[:toc_start] + new_toc.split('\n') + lines[toc_end:]
            new_content = '\n'.join(new_lines)
        else:
            return False, "æ‰¾åˆ°ç›®å½•æ ‡è®°ä½†æ— æ³•å®šä½"
    else:
        # æ’å…¥æ–°ç›®å½•
        insert_pos = find_toc_position(content)
        lines = content.split('\n')
        # åœ¨H1åæ’å…¥ç›®å½•ï¼Œç„¶åæ·»åŠ åˆ†éš”çº¿
        new_lines = lines[:insert_pos] + [""] + new_toc.split('\n') + [""] + ["---", ""] + lines[insert_pos:]
        new_content = '\n'.join(new_lines)
    
    # å†™å›æ–‡ä»¶
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        return True, "æˆåŠŸ"
    except Exception as e:
        return False, f"å†™å…¥æ–‡ä»¶å¤±è´¥: {e}"

def main():
    """ä¸»å‡½æ•°"""
    base_dir = Path(__file__).parent
    analysis_dir = base_dir  # å¤„ç†æ•´ä¸ª Analysis ç›®å½•
    
    if not analysis_dir.exists():
        print(f"ç›®å½•ä¸å­˜åœ¨: {analysis_dir}")
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰Markdownæ–‡ä»¶
    md_files = list(analysis_dir.rglob("*.md"))
    # æ’é™¤ README.md å’Œæ ¹ç›®å½•çš„ README.md
    md_files = [f for f in md_files if f.name != "README.md"]
    # æ’é™¤è„šæœ¬æ–‡ä»¶æœ¬èº«æ‰€åœ¨ç›®å½•çš„æŸäº›æ–‡ä»¶
    md_files = [f for f in md_files if not f.name.startswith("fix_") and not f.name.startswith("check_")]
    
    print(f"æ‰¾åˆ° {len(md_files)} ä¸ªMarkdownæ–‡ä»¶")
    print("=" * 60)
    
    fixed_count = 0
    error_count = 0
    skipped_count = 0
    
    for md_file in sorted(md_files):
        rel_path = md_file.relative_to(base_dir)
        print(f"\nå¤„ç†: {rel_path}")
        
        success, message = fix_document(md_file)
        
        if success:
            print(f"  âœ… {message}")
            fixed_count += 1
        elif "æ²¡æœ‰æ‰¾åˆ°æ ‡é¢˜" in message or "æ— æ³•ç”Ÿæˆç›®å½•" in message:
            print(f"  â­ï¸  {message}")
            skipped_count += 1
        else:
            print(f"  âŒ {message}")
            error_count += 1
    
    print("\n" + "=" * 60)
    print(f"å¤„ç†å®Œæˆ:")
    print(f"  âœ… æˆåŠŸ: {fixed_count}")
    print(f"  â­ï¸  è·³è¿‡: {skipped_count}")
    print(f"  âŒ é”™è¯¯: {error_count}")
    print(f"  ğŸ“Š æ€»è®¡: {len(md_files)}")

if __name__ == "__main__":
    main()
