# æ€§èƒ½ç›‘æ§ç³»ç»Ÿ

## ğŸ“‘ ç›®å½•

- [æ€§èƒ½ç›‘æ§ç³»ç»Ÿ](#æ€§èƒ½ç›‘æ§ç³»ç»Ÿ)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1. èƒŒæ™¯ä¸åŠ¨æœº](#11-èƒŒæ™¯ä¸åŠ¨æœº)
    - [1.2. ç›®æ ‡ä¸èŒƒå›´](#12-ç›®æ ‡ä¸èŒƒå›´)
  - [2. ç†è®ºåŸºç¡€](#2-ç†è®ºåŸºç¡€)
    - [2.1. ç›‘æ§ç†è®ºæ¡†æ¶](#21-ç›‘æ§ç†è®ºæ¡†æ¶)
      - [2.1.1. ç›‘æ§é‡‘å­—å¡”](#211-ç›‘æ§é‡‘å­—å¡”)
      - [2.1.2. å¯è§‚æµ‹æ€§ä¸‰å¤§æ”¯æŸ±](#212-å¯è§‚æµ‹æ€§ä¸‰å¤§æ”¯æŸ±)
    - [2.2. æ€§èƒ½æŒ‡æ ‡ç†è®º](#22-æ€§èƒ½æŒ‡æ ‡ç†è®º)
      - [2.2.1. å…³é”®æ€§èƒ½æŒ‡æ ‡ï¼ˆKPIï¼‰](#221-å…³é”®æ€§èƒ½æŒ‡æ ‡kpi)
      - [2.2.2. å‘Šè­¦ç†è®º](#222-å‘Šè­¦ç†è®º)
  - [3. æ¶æ„è®¾è®¡](#3-æ¶æ„è®¾è®¡)
    - [3.1. æ•´ä½“æ¶æ„](#31-æ•´ä½“æ¶æ„)
      - [3.1.1. åˆ†å±‚æ¶æ„](#311-åˆ†å±‚æ¶æ„)
      - [3.1.2. å¾®æœåŠ¡ç›‘æ§æ¶æ„](#312-å¾®æœåŠ¡ç›‘æ§æ¶æ„)
  - [4. æ•°æ®æµè®¾è®¡](#4-æ•°æ®æµè®¾è®¡)
    - [4.1. æŒ‡æ ‡æ•°æ®æµ](#41-æŒ‡æ ‡æ•°æ®æµ)
      - [4.1.1. æ—¥å¿—æ•°æ®æµ](#411-æ—¥å¿—æ•°æ®æµ)
  - [5. å­˜å‚¨è®¾è®¡](#5-å­˜å‚¨è®¾è®¡)
    - [5.1. æ—¶åºæ•°æ®åº“è®¾è®¡](#51-æ—¶åºæ•°æ®åº“è®¾è®¡)
      - [5.1.1. æ—¥å¿—å­˜å‚¨è®¾è®¡](#511-æ—¥å¿—å­˜å‚¨è®¾è®¡)
  - [6. å·¥ç¨‹å®ç°](#6-å·¥ç¨‹å®ç°)
    - [6.1. ç›‘æ§Agentå®ç°](#61-ç›‘æ§agentå®ç°)
      - [6.1.1. Goè¯­è¨€Agent](#611-goè¯­è¨€agent)
      - [6.1.2. Pythonç›‘æ§è„šæœ¬](#612-pythonç›‘æ§è„šæœ¬)
  - [7. å‘Šè­¦ç³»ç»Ÿå®ç°](#7-å‘Šè­¦ç³»ç»Ÿå®ç°)
    - [7.1. å‘Šè­¦è§„åˆ™é…ç½®](#71-å‘Šè­¦è§„åˆ™é…ç½®)
  - [8. å‘Šè­¦é€šçŸ¥é…ç½®](#8-å‘Šè­¦é€šçŸ¥é…ç½®)
  - [9. å¯è§†åŒ–ä»ªè¡¨æ¿](#9-å¯è§†åŒ–ä»ªè¡¨æ¿)
    - [9.1. Grafanaä»ªè¡¨æ¿é…ç½®](#91-grafanaä»ªè¡¨æ¿é…ç½®)
  - [10. æœ€ä½³å®è·µ](#10-æœ€ä½³å®è·µ)
    - [10.1. ç›‘æ§ç­–ç•¥](#101-ç›‘æ§ç­–ç•¥)
      - [10.1.1. ç›‘æ§æŒ‡æ ‡é€‰æ‹©](#1011-ç›‘æ§æŒ‡æ ‡é€‰æ‹©)
      - [10.1.2. å‘Šè­¦ç­–ç•¥](#1012-å‘Šè­¦ç­–ç•¥)
    - [10.2. æ€§èƒ½ä¼˜åŒ–](#102-æ€§èƒ½ä¼˜åŒ–)
      - [10.2.1. æ•°æ®å­˜å‚¨ä¼˜åŒ–](#1021-æ•°æ®å­˜å‚¨ä¼˜åŒ–)
      - [10.2.2. æŸ¥è¯¢ä¼˜åŒ–](#1022-æŸ¥è¯¢ä¼˜åŒ–)
  - [11. æ€»ç»“ä¸å±•æœ›](#11-æ€»ç»“ä¸å±•æœ›)
    - [11.1. å®æ–½æ•ˆæœ](#111-å®æ–½æ•ˆæœ)
    - [11.2. æœªæ¥å‘å±•æ–¹å‘](#112-æœªæ¥å‘å±•æ–¹å‘)
      - [11.2.1. AIé©±åŠ¨çš„ç›‘æ§](#1121-aié©±åŠ¨çš„ç›‘æ§)
  - [12. è‡ªåŠ¨åŒ–è¿ç»´](#12-è‡ªåŠ¨åŒ–è¿ç»´)
  - [13. æŒç»­æ”¹è¿›](#13-æŒç»­æ”¹è¿›)
  - [14. å‚è€ƒæ–‡çŒ®](#14-å‚è€ƒæ–‡çŒ®)
  - [15. ç›¸å…³é“¾æ¥](#15-ç›¸å…³é“¾æ¥)
  - [16. è´¡çŒ®æŒ‡å—](#16-è´¡çŒ®æŒ‡å—)
  - [17. è®¸å¯è¯ä¿¡æ¯](#17-è®¸å¯è¯ä¿¡æ¯)

---


## 1. æ¦‚è¿°

### 1.1. èƒŒæ™¯ä¸åŠ¨æœº

æ€§èƒ½ç›‘æ§ç³»ç»Ÿæ˜¯ç°ä»£è½¯ä»¶æ¶æ„çš„æ ¸å¿ƒç»„ä»¶ï¼Œç”¨äºå®æ—¶ç›‘æ§åº”ç”¨æ€§èƒ½ã€ç³»ç»Ÿèµ„æºå’Œä¸šåŠ¡æŒ‡æ ‡ã€‚éšç€å¾®æœåŠ¡æ¶æ„å’Œäº‘åŸç”ŸæŠ€æœ¯çš„æ™®åŠï¼Œä¼ ç»Ÿçš„ç›‘æ§æ–¹å¼å·²æ— æ³•æ»¡è¶³åˆ†å¸ƒå¼ç³»ç»Ÿçš„å¤æ‚éœ€æ±‚ã€‚

### 1.2. ç›®æ ‡ä¸èŒƒå›´

æœ¬æ–‡æ¡£æ—¨åœ¨ï¼š

- å»ºç«‹æ€§èƒ½ç›‘æ§çš„ç†è®ºåŸºç¡€
- è®¾è®¡å¯æ‰©å±•çš„ç›‘æ§æ¶æ„
- æä¾›å®Œæ•´çš„å·¥ç¨‹å®ç°æ–¹æ¡ˆ
- æ¶µç›–äº‘åŸç”Ÿå’Œåˆ†å¸ƒå¼ç›‘æ§åœºæ™¯

## 2. ç†è®ºåŸºç¡€

### 2.1. ç›‘æ§ç†è®ºæ¡†æ¶

#### 2.1.1. ç›‘æ§é‡‘å­—å¡”

```mermaid
graph TD
    A[ä¸šåŠ¡ç›‘æ§] --> B[åº”ç”¨ç›‘æ§]
    B --> C[ç³»ç»Ÿç›‘æ§]
    C --> D[åŸºç¡€è®¾æ–½ç›‘æ§]

    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
```

**ç›‘æ§å±‚æ¬¡**ï¼š

1. **ä¸šåŠ¡ç›‘æ§**ï¼šç”¨æˆ·è¡Œä¸ºã€ä¸šåŠ¡æŒ‡æ ‡ã€æ”¶å…¥æŒ‡æ ‡
2. **åº”ç”¨ç›‘æ§**ï¼šåº”ç”¨æ€§èƒ½ã€é”™è¯¯ç‡ã€å“åº”æ—¶é—´
3. **ç³»ç»Ÿç›‘æ§**ï¼šCPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œ
4. **åŸºç¡€è®¾æ–½ç›‘æ§**ï¼šæœåŠ¡å™¨ã€ç½‘ç»œè®¾å¤‡ã€äº‘èµ„æº

#### 2.1.2. å¯è§‚æµ‹æ€§ä¸‰å¤§æ”¯æŸ±

```yaml
observability_pillars:
  metrics:
    description: "æ•°å€¼å‹æ•°æ®ï¼Œç”¨äºè¶‹åŠ¿åˆ†æå’Œå‘Šè­¦"
    examples:
      - counter: "è¯·æ±‚æ€»æ•°"
      - gauge: "å½“å‰è¿æ¥æ•°"
      - histogram: "å“åº”æ—¶é—´åˆ†å¸ƒ"

  logs:
    description: "ç»“æ„åŒ–æ–‡æœ¬æ•°æ®ï¼Œç”¨äºé—®é¢˜è¯Šæ–­"
    examples:
      - application_logs: "åº”ç”¨æ—¥å¿—"
      - system_logs: "ç³»ç»Ÿæ—¥å¿—"
      - access_logs: "è®¿é—®æ—¥å¿—"

  traces:
    description: "åˆ†å¸ƒå¼è°ƒç”¨é“¾è·¯ï¼Œç”¨äºæ€§èƒ½åˆ†æ"
    examples:
      - request_trace: "è¯·æ±‚è¿½è¸ª"
      - service_trace: "æœåŠ¡è°ƒç”¨é“¾"
      - database_trace: "æ•°æ®åº“æ“ä½œè¿½è¸ª"
```

### 2.2. æ€§èƒ½æŒ‡æ ‡ç†è®º

#### 2.2.1. å…³é”®æ€§èƒ½æŒ‡æ ‡ï¼ˆKPIï¼‰

**æ•°å­¦å®šä¹‰**ï¼š

è®¾ $R$ ä¸ºè¯·æ±‚é›†åˆï¼Œ$T(r)$ ä¸ºè¯·æ±‚ $r$ çš„å“åº”æ—¶é—´ï¼Œåˆ™ï¼š

$$\text{å¹³å‡å“åº”æ—¶é—´} = \frac{1}{|R|} \sum_{r \in R} T(r)$$

$$\text{95%åˆ†ä½æ•°} = \text{Percentile}_{95}(T(r))$$

$$\text{ååé‡} = \frac{|R|}{\Delta t}$$

å…¶ä¸­ $\Delta t$ ä¸ºæ—¶é—´çª—å£ã€‚

**ä»£ç å®ç°**ï¼š

```rust
use std::collections::BinaryHeap;
use std::cmp::Reverse;

#[derive(Debug, Clone)]
pub struct PerformanceMetrics {
    response_times: Vec<f64>,
    request_count: u64,
    error_count: u64,
    start_time: std::time::Instant,
}

impl PerformanceMetrics {
    pub fn new() -> Self {
        Self {
            response_times: Vec::new(),
            request_count: 0,
            error_count: 0,
            start_time: std::time::Instant::now(),
        }
    }

    pub fn record_request(&mut self, response_time: f64, is_error: bool) {
        self.response_times.push(response_time);
        self.request_count += 1;
        if is_error {
            self.error_count += 1;
        }
    }

    pub fn average_response_time(&self) -> f64 {
        if self.response_times.is_empty() {
            return 0.0;
        }
        self.response_times.iter().sum::<f64>() / self.response_times.len() as f64
    }

    pub fn percentile_95(&self) -> f64 {
        if self.response_times.is_empty() {
            return 0.0;
        }

        let mut sorted_times = self.response_times.clone();
        sorted_times.sort_by(|a, b| a.partial_cmp(b).unwrap());

        let index = (sorted_times.len() as f64 * 0.95) as usize;
        sorted_times[index.min(sorted_times.len() - 1)]
    }

    pub fn throughput(&self) -> f64 {
        let elapsed = self.start_time.elapsed().as_secs_f64();
        if elapsed > 0.0 {
            self.request_count as f64 / elapsed
        } else {
            0.0
        }
    }

    pub fn error_rate(&self) -> f64 {
        if self.request_count > 0 {
            self.error_count as f64 / self.request_count as f64
        } else {
            0.0
        }
    }
}
```

#### 2.2.2. å‘Šè­¦ç†è®º

**å‘Šè­¦æ¡ä»¶**ï¼š

è®¾ $M(t)$ ä¸ºæ—¶é—´ $t$ çš„æŒ‡æ ‡å€¼ï¼Œ$T$ ä¸ºé˜ˆå€¼ï¼Œ$W$ ä¸ºæ—¶é—´çª—å£ï¼Œåˆ™å‘Šè­¦æ¡ä»¶ä¸ºï¼š

$$
\text{Alert} = \begin{cases}
\text{true} & \text{if } \frac{1}{W} \int_{t-W}^{t} M(\tau) d\tau > T \\
\text{false} & \text{otherwise}
\end{cases}
$$

**å‘Šè­¦çº§åˆ«**ï¼š

```yaml
alert_levels:
  critical:
    description: "ç³»ç»Ÿä¸¥é‡æ•…éšœï¼Œéœ€è¦ç«‹å³å¤„ç†"
    response_time: "> 5s"
    error_rate: "> 10%"
    cpu_usage: "> 90%"

  warning:
    description: "ç³»ç»Ÿæ€§èƒ½ä¸‹é™ï¼Œéœ€è¦å…³æ³¨"
    response_time: "> 2s"
    error_rate: "> 5%"
    cpu_usage: "> 80%"

  info:
    description: "ç³»ç»ŸçŠ¶æ€å¼‚å¸¸ï¼Œéœ€è¦ç›‘æ§"
    response_time: "> 1s"
    error_rate: "> 1%"
    cpu_usage: "> 70%"
```

## 3. æ¶æ„è®¾è®¡

### 3.1. æ•´ä½“æ¶æ„

#### 3.1.1. åˆ†å±‚æ¶æ„

```mermaid
graph TB
    subgraph "æ•°æ®é‡‡é›†å±‚"
        A1[åº”ç”¨Agent]
        A2[ç³»ç»ŸAgent]
        A3[ä¸šåŠ¡Agent]
    end

    subgraph "æ•°æ®ä¼ è¾“å±‚"
        T1[æ¶ˆæ¯é˜Ÿåˆ—]
        T2[æµå¤„ç†]
        T3[APIç½‘å…³]
    end

    subgraph "æ•°æ®å¤„ç†å±‚"
        P1[æ•°æ®æ¸…æ´—]
        P2[æ•°æ®èšåˆ]
        P3[æ•°æ®å­˜å‚¨]
    end

    subgraph "æ•°æ®å±•ç¤ºå±‚"
        V1[ä»ªè¡¨æ¿]
        V2[å‘Šè­¦ç³»ç»Ÿ]
        V3[åˆ†æå·¥å…·]
    end

    A1 --> T1
    A2 --> T2
    A3 --> T3

    T1 --> P1
    T2 --> P2
    T3 --> P3

    P1 --> V1
    P2 --> V2
    P3 --> V3
```

#### 3.1.2. å¾®æœåŠ¡ç›‘æ§æ¶æ„

```yaml
# å¾®æœåŠ¡ç›‘æ§é…ç½®
microservice_monitoring:
  service_mesh:
    istio:
      metrics_collection: true
      tracing_enabled: true
      access_logs: true

  application_monitoring:
    prometheus:
      scrape_interval: 15s
      metrics_path: /metrics

    jaeger:
      sampling_rate: 0.1
      max_trace_duration: 30s

    elasticsearch:
      log_retention: 30d
      index_pattern: "logs-*"

  infrastructure_monitoring:
    node_exporter:
      enabled: true
      port: 9100

    cadvisor:
      enabled: true
      port: 8080
```

## 4. æ•°æ®æµè®¾è®¡

### 4.1. æŒ‡æ ‡æ•°æ®æµ

```mermaid
sequenceDiagram
    participant App as åº”ç”¨
    participant Agent as ç›‘æ§Agent
    participant Queue as æ¶ˆæ¯é˜Ÿåˆ—
    participant Processor as æ•°æ®å¤„ç†å™¨
    participant Storage as æ—¶åºæ•°æ®åº“
    participant Alert as å‘Šè­¦ç³»ç»Ÿ

    App->>Agent: å‘é€æŒ‡æ ‡æ•°æ®
    Agent->>Queue: æ‰¹é‡å‘é€æ•°æ®
    Queue->>Processor: æ¶ˆè´¹æ•°æ®
    Processor->>Storage: å­˜å‚¨æŒ‡æ ‡
    Processor->>Alert: æ£€æŸ¥å‘Šè­¦æ¡ä»¶
    Alert->>Storage: æŸ¥è¯¢å†å²æ•°æ®
    Alert->>Alert: è§¦å‘å‘Šè­¦
```

#### 4.1.1. æ—¥å¿—æ•°æ®æµ

```yaml
# æ—¥å¿—æ”¶é›†é…ç½®
log_collection:
  fluentd:
    input:
      - type: tail
        path: /var/log/containers/*.log
        tag: kubernetes.*
        parse:
          type: json

    filter:
      - type: kubernetes_metadata
        tag: kubernetes.**

    output:
      - type: elasticsearch
        host: elasticsearch-master
        port: 9200
        logstash_format: true
        logstash_prefix: k8s
```

## 5. å­˜å‚¨è®¾è®¡

### 5.1. æ—¶åºæ•°æ®åº“è®¾è®¡

```sql
-- PrometheusæŒ‡æ ‡è¡¨ç»“æ„
CREATE TABLE metrics (
    timestamp TIMESTAMPTZ NOT NULL,
    metric_name TEXT NOT NULL,
    labels JSONB,
    value DOUBLE PRECISION NOT NULL,
    PRIMARY KEY (timestamp, metric_name, labels)
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_metrics_timestamp ON metrics (timestamp);
CREATE INDEX idx_metrics_name ON metrics (metric_name);
CREATE INDEX idx_metrics_labels ON metrics USING GIN (labels);

-- åˆ†åŒºè¡¨
CREATE TABLE metrics_2025_01 PARTITION OF metrics
FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

-- å‹ç¼©ç­–ç•¥
SELECT create_compression_policy('metrics', INTERVAL '7 days');
```

#### 5.1.1. æ—¥å¿—å­˜å‚¨è®¾è®¡

```yaml
# Elasticsearchç´¢å¼•æ¨¡æ¿
index_template:
  name: "logs-template"
  index_patterns: ["logs-*"]
  settings:
    number_of_shards: 3
    number_of_replicas: 1
    refresh_interval: "30s"
    index.lifecycle.name: "logs-policy"

  mappings:
    properties:
      timestamp:
        type: date
      level:
        type: keyword
      message:
        type: text
        analyzer: standard
      service:
        type: keyword
      pod:
        type: keyword
      namespace:
        type: keyword
```

## 6. å·¥ç¨‹å®ç°

### 6.1. ç›‘æ§Agentå®ç°

#### 6.1.1. Goè¯­è¨€Agent

```go
package main

import (
    "context"
    "encoding/json"
    "log"
    "net/http"
    "time"

    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promhttp"
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/exporters/jaeger"
    "go.opentelemetry.io/otel/sdk/trace"
)

// ç›‘æ§æŒ‡æ ‡å®šä¹‰
var (
    requestCounter = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "endpoint", "status"},
    )

    requestDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "http_request_duration_seconds",
            Help:    "HTTP request duration in seconds",
            Buckets: prometheus.DefBuckets,
        },
        []string{"method", "endpoint"},
    )

    activeConnections = prometheus.NewGauge(
        prometheus.GaugeOpts{
            Name: "active_connections",
            Help: "Number of active connections",
        },
    )
)

// ç›‘æ§ä¸­é—´ä»¶
func monitoringMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()

        // åŒ…è£…ResponseWriterä»¥æ•è·çŠ¶æ€ç 
        wrapped := &responseWriter{ResponseWriter: w, statusCode: 200}

        next.ServeHTTP(wrapped, r)

        duration := time.Since(start).Seconds()

        // è®°å½•æŒ‡æ ‡
        requestCounter.WithLabelValues(r.Method, r.URL.Path, string(wrapped.statusCode)).Inc()
        requestDuration.WithLabelValues(r.Method, r.URL.Path).Observe(duration)
    })
}

// è‡ªå®šä¹‰ResponseWriter
type responseWriter struct {
    http.ResponseWriter
    statusCode int
}

func (rw *responseWriter) WriteHeader(code int) {
    rw.statusCode = code
    rw.ResponseWriter.WriteHeader(code)
}

// åº”ç”¨ç›‘æ§å™¨
type ApplicationMonitor struct {
    tracer trace.Tracer
    metrics map[string]interface{}
}

func NewApplicationMonitor() *ApplicationMonitor {
    // åˆå§‹åŒ–Jaegerè¿½è¸ªå™¨
    tp, err := jaeger.New(jaeger.WithCollectorEndpoint("http://jaeger:14268/api/traces"))
    if err != nil {
        log.Fatal(err)
    }
    otel.SetTracerProvider(tp)

    return &ApplicationMonitor{
        tracer:  otel.Tracer("application-monitor"),
        metrics: make(map[string]interface{}),
    }
}

func (am *ApplicationMonitor) RecordMetric(name string, value interface{}) {
    am.metrics[name] = value
}

func (am *ApplicationMonitor) GetMetrics() map[string]interface{} {
    return am.metrics
}

// å¥åº·æ£€æŸ¥å¤„ç†å™¨
func healthCheckHandler(w http.ResponseWriter, r *http.Request) {
    response := map[string]interface{}{
        "status":    "healthy",
        "timestamp": time.Now().Unix(),
        "version":   "1.0.0",
    }

    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(response)
}

func main() {
    // æ³¨å†ŒPrometheusæŒ‡æ ‡
    prometheus.MustRegister(requestCounter)
    prometheus.MustRegister(requestDuration)
    prometheus.MustRegister(activeConnections)

    // åˆ›å»ºç›‘æ§å™¨
    monitor := NewApplicationMonitor()

    // è®¾ç½®è·¯ç”±
    http.HandleFunc("/health", healthCheckHandler)
    http.HandleFunc("/metrics", promhttp.Handler().ServeHTTP)

    // å¯åŠ¨æœåŠ¡å™¨
    log.Fatal(http.ListenAndServe(":8080", monitoringMiddleware(http.DefaultServeMux)))
}
```

#### 6.1.2. Pythonç›‘æ§è„šæœ¬

```python
# !/usr/bin/env python3
# monitoring_agent.py

import os
import time
import json
import psutil
import requests
from datetime import datetime
from typing import Dict, List, Optional
import logging
from dataclasses import dataclass, asdict

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SystemMetrics:
    cpu_percent: float
    memory_percent: float
    disk_usage_percent: float
    network_io: Dict[str, float]
    timestamp: str

@dataclass
class ApplicationMetrics:
    response_time: float
    error_rate: float
    throughput: float
    active_connections: int
    timestamp: str

class MonitoringAgent:
    def __init__(self, config: Dict):
        self.config = config
        self.metrics_buffer = []
        self.last_network_io = psutil.net_io_counters()
        self.last_network_time = time.time()

    def collect_system_metrics(self) -> SystemMetrics:
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        try:
# CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)

# å†…å­˜ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            memory_percent = memory.percent

# ç£ç›˜ä½¿ç”¨ç‡
            disk = psutil.disk_usage('/')
            disk_usage_percent = disk.percent

# ç½‘ç»œIO
            current_network_io = psutil.net_io_counters()
            current_time = time.time()

            time_diff = current_time - self.last_network_time
            network_io = {
                'bytes_sent': (current_network_io.bytes_sent - self.last_network_io.bytes_sent) / time_diff,
                'bytes_recv': (current_network_io.bytes_recv - self.last_network_io.bytes_recv) / time_diff
            }

            self.last_network_io = current_network_io
            self.last_network_time = current_time

            return SystemMetrics(
                cpu_percent=cpu_percent,
                memory_percent=memory_percent,
                disk_usage_percent=disk_usage_percent,
                network_io=network_io,
                timestamp=datetime.now().isoformat()
            )

        except Exception as e:
            logger.error(f"æ”¶é›†ç³»ç»ŸæŒ‡æ ‡å¤±è´¥: {e}")
            return None

    def collect_application_metrics(self) -> ApplicationMetrics:
        """æ”¶é›†åº”ç”¨æŒ‡æ ‡"""
        try:
# è¿™é‡Œå¯ä»¥æ·»åŠ åº”ç”¨ç‰¹å®šçš„æŒ‡æ ‡æ”¶é›†é€»è¾‘
# ä¾‹å¦‚ï¼šé€šè¿‡APIç«¯ç‚¹è·å–åº”ç”¨æŒ‡æ ‡

            response = requests.get(f"{self.config['app_url']}/metrics", timeout=5)
            app_metrics = response.json()

            return ApplicationMetrics(
                response_time=app_metrics.get('response_time', 0.0),
                error_rate=app_metrics.get('error_rate', 0.0),
                throughput=app_metrics.get('throughput', 0.0),
                active_connections=app_metrics.get('active_connections', 0),
                timestamp=datetime.now().isoformat()
            )

        except Exception as e:
            logger.error(f"æ”¶é›†åº”ç”¨æŒ‡æ ‡å¤±è´¥: {e}")
            return None

    def send_metrics(self, metrics: Dict):
        """å‘é€æŒ‡æ ‡åˆ°ç›‘æ§ç³»ç»Ÿ"""
        try:
            headers = {'Content-Type': 'application/json'}
            response = requests.post(
                self.config['metrics_endpoint'],
                json=metrics,
                headers=headers,
                timeout=10
            )

            if response.status_code == 200:
                logger.debug("æŒ‡æ ‡å‘é€æˆåŠŸ")
            else:
                logger.warning(f"æŒ‡æ ‡å‘é€å¤±è´¥: {response.status_code}")

        except Exception as e:
            logger.error(f"å‘é€æŒ‡æ ‡å¤±è´¥: {e}")

    def check_alerts(self, metrics: Dict):
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        alerts = []

# CPUå‘Šè­¦
        if metrics.get('system', {}).get('cpu_percent', 0) > 80:
            alerts.append({
                'level': 'warning',
                'message': f"CPUä½¿ç”¨ç‡è¿‡é«˜: {metrics['system']['cpu_percent']}%",
                'timestamp': datetime.now().isoformat()
            })

# å†…å­˜å‘Šè­¦
        if metrics.get('system', {}).get('memory_percent', 0) > 85:
            alerts.append({
                'level': 'critical',
                'message': f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {metrics['system']['memory_percent']}%",
                'timestamp': datetime.now().isoformat()
            })

# åº”ç”¨å“åº”æ—¶é—´å‘Šè­¦
        if metrics.get('application', {}).get('response_time', 0) > 2.0:
            alerts.append({
                'level': 'warning',
                'message': f"åº”ç”¨å“åº”æ—¶é—´è¿‡é•¿: {metrics['application']['response_time']}s",
                'timestamp': datetime.now().isoformat()
            })

# å‘é€å‘Šè­¦
        if alerts:
            self.send_alerts(alerts)

    def send_alerts(self, alerts: List[Dict]):
        """å‘é€å‘Šè­¦"""
        try:
            headers = {'Content-Type': 'application/json'}
            response = requests.post(
                self.config['alerts_endpoint'],
                json={'alerts': alerts},
                headers=headers,
                timeout=10
            )

            if response.status_code == 200:
                logger.info(f"å‘Šè­¦å‘é€æˆåŠŸ: {len(alerts)}æ¡")
            else:
                logger.warning(f"å‘Šè­¦å‘é€å¤±è´¥: {response.status_code}")

        except Exception as e:
            logger.error(f"å‘é€å‘Šè­¦å¤±è´¥: {e}")

    def run(self):
        """è¿è¡Œç›‘æ§å¾ªç¯"""
        logger.info("ç›‘æ§Agentå¯åŠ¨")

        while True:
            try:
# æ”¶é›†æŒ‡æ ‡
                system_metrics = self.collect_system_metrics()
                app_metrics = self.collect_application_metrics()

# æ„å»ºæŒ‡æ ‡æ•°æ®
                metrics_data = {
                    'host': self.config['host_name'],
                    'timestamp': datetime.now().isoformat(),
                    'system': asdict(system_metrics) if system_metrics else {},
                    'application': asdict(app_metrics) if app_metrics else {}
                }

# å‘é€æŒ‡æ ‡
                self.send_metrics(metrics_data)

# æ£€æŸ¥å‘Šè­¦
                self.check_alerts(metrics_data)

# ç­‰å¾…ä¸‹æ¬¡æ”¶é›†
                time.sleep(self.config.get('collect_interval', 60))

            except KeyboardInterrupt:
                logger.info("ç›‘æ§Agentåœæ­¢")
                break
            except Exception as e:
                logger.error(f"ç›‘æ§å¾ªç¯å¼‚å¸¸: {e}")
                time.sleep(10)

def main():
# é…ç½®
    config = {
        'host_name': os.getenv('HOSTNAME', 'unknown'),
        'app_url': os.getenv('APP_URL', 'http://localhost:8080'),
        'metrics_endpoint': os.getenv('METRICS_ENDPOINT', 'http://prometheus:9090/api/v1/write'),
        'alerts_endpoint': os.getenv('ALERTS_ENDPOINT', 'http://alertmanager:9093/api/v1/alerts'),
        'collect_interval': int(os.getenv('COLLECT_INTERVAL', '60'))
    }

    agent = MonitoringAgent(config)
    agent.run()

if __name__ == '__main__':
    main()
```

## 7. å‘Šè­¦ç³»ç»Ÿå®ç°

### 7.1. å‘Šè­¦è§„åˆ™é…ç½®

```yaml
# Prometheuså‘Šè­¦è§„åˆ™
groups:
  - name: application_alerts
    rules:
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, http_request_duration_seconds) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s"

      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }}"

      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is {{ $value }}%"

      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is {{ $value }}%"
```

## 8. å‘Šè­¦é€šçŸ¥é…ç½®

```yaml
# AlertManageré…ç½®
global:
  resolve_timeout: 5m
  slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'

route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'web.hook'
  routes:
    - match:
        severity: critical
      receiver: 'slack.critical'
      continue: true
    - match:
        severity: warning
      receiver: 'slack.warning'

receivers:
  - name: 'web.hook'
    webhook_configs:
      - url: 'http://127.0.0.1:5001/'

  - name: 'slack.critical'
    slack_configs:
      - channel: '#alerts-critical'
        title: 'Critical Alert'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
        color: 'danger'

  - name: 'slack.warning'
    slack_configs:
      - channel: '#alerts-warning'
        title: 'Warning Alert'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
        color: 'warning'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'dev', 'instance']
```

## 9. å¯è§†åŒ–ä»ªè¡¨æ¿

### 9.1. Grafanaä»ªè¡¨æ¿é…ç½®

```json
{
  "dashboard": {
    "id": null,
    "title": "Data Science Application Dashboard",
    "tags": ["data-science", "monitoring"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, http_request_duration_seconds)",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, http_request_duration_seconds)",
            "legendFormat": "50th percentile"
          }
        ],
        "yAxes": [
          {
            "label": "Response Time (seconds)",
            "min": 0
          }
        ]
      },
      {
        "id": 2,
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ],
        "yAxes": [
          {
            "label": "Requests per second",
            "min": 0
          }
        ]
      },
      {
        "id": 3,
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m])",
            "legendFormat": "Error Rate"
          }
        ],
        "yAxes": [
          {
            "label": "Error Rate",
            "min": 0,
            "max": 1
          }
        ]
      },
      {
        "id": 4,
        "title": "CPU Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
            "legendFormat": "CPU Usage"
          }
        ],
        "yAxes": [
          {
            "label": "CPU Usage (%)",
            "min": 0,
            "max": 100
          }
        ]
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "30s"
  }
}
```

## 10. æœ€ä½³å®è·µ

### 10.1. ç›‘æ§ç­–ç•¥

#### 10.1.1. ç›‘æ§æŒ‡æ ‡é€‰æ‹©

```yaml
monitoring_strategy:
  golden_signals:
    - latency: "å“åº”æ—¶é—´"
    - traffic: "æµé‡"
    - errors: "é”™è¯¯ç‡"
    - saturation: "é¥±å’Œåº¦"

  business_metrics:
    - user_engagement: "ç”¨æˆ·å‚ä¸åº¦"
    - conversion_rate: "è½¬åŒ–ç‡"
    - revenue: "æ”¶å…¥"
    - customer_satisfaction: "å®¢æˆ·æ»¡æ„åº¦"

  technical_metrics:
    - cpu_usage: "CPUä½¿ç”¨ç‡"
    - memory_usage: "å†…å­˜ä½¿ç”¨ç‡"
    - disk_io: "ç£ç›˜IO"
    - network_io: "ç½‘ç»œIO"
```

#### 10.1.2. å‘Šè­¦ç­–ç•¥

```yaml
alerting_strategy:
  alert_thresholds:
    warning:
      response_time: "> 1s"
      error_rate: "> 1%"
      cpu_usage: "> 70%"

    critical:
      response_time: "> 5s"
      error_rate: "> 10%"
      cpu_usage: "> 90%"

  alert_grouping:
    group_by: ["alertname", "service", "instance"]
    group_wait: "30s"
    group_interval: "5m"
    repeat_interval: "4h"
```

### 10.2. æ€§èƒ½ä¼˜åŒ–

#### 10.2.1. æ•°æ®å­˜å‚¨ä¼˜åŒ–

```sql
-- æ—¶åºæ•°æ®ä¼˜åŒ–
-- 1. åˆ†åŒºè¡¨
CREATE TABLE metrics_partitioned (
    timestamp TIMESTAMPTZ NOT NULL,
    metric_name TEXT NOT NULL,
    value DOUBLE PRECISION NOT NULL
) PARTITION BY RANGE (timestamp);

-- 2. å‹ç¼©
CREATE TABLE metrics_compressed (
    LIKE metrics_partitioned INCLUDING ALL
) WITH (compression = true);

-- 3. ç´¢å¼•ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_metrics_time_name
ON metrics_partitioned (timestamp, metric_name);

-- 4. æ•°æ®ä¿ç•™ç­–ç•¥
CREATE OR REPLACE FUNCTION cleanup_old_metrics()
RETURNS void AS $$
BEGIN
    DELETE FROM metrics_partitioned
    WHERE timestamp < NOW() - INTERVAL '30 days';
END;
$$ LANGUAGE plpgsql;

-- 5. å®šæ—¶æ¸…ç†
SELECT cron.schedule('cleanup-metrics', '0 2 * * *', 'SELECT cleanup_old_metrics();');
```

#### 10.2.2. æŸ¥è¯¢ä¼˜åŒ–

```sql
-- æŸ¥è¯¢ä¼˜åŒ–ç¤ºä¾‹
-- 1. ä½¿ç”¨æ—¶é—´èŒƒå›´è¿‡æ»¤
SELECT metric_name, AVG(value) as avg_value
FROM metrics_partitioned
WHERE timestamp >= NOW() - INTERVAL '1 hour'
  AND timestamp < NOW()
GROUP BY metric_name;

-- 2. ä½¿ç”¨é¢„èšåˆ
CREATE MATERIALIZED VIEW metrics_hourly AS
SELECT
    date_trunc('hour', timestamp) as hour,
    metric_name,
    AVG(value) as avg_value,
    MAX(value) as max_value,
    MIN(value) as min_value
FROM metrics_partitioned
GROUP BY 1, 2;

-- 3. åˆ›å»ºç´¢å¼•æ”¯æŒå¿«é€ŸæŸ¥è¯¢
CREATE INDEX idx_metrics_hourly_hour_name
ON metrics_hourly (hour, metric_name);

-- 4. å®šæœŸåˆ·æ–°ç‰©åŒ–è§†å›¾
REFRESH MATERIALIZED VIEW CONCURRENTLY metrics_hourly;
```

## 11. æ€»ç»“ä¸å±•æœ›

### 11.1. å®æ–½æ•ˆæœ

é€šè¿‡å®æ–½å®Œæ•´çš„æ€§èƒ½ç›‘æ§ç³»ç»Ÿï¼Œæˆ‘ä»¬å®ç°äº†ï¼š

- **å®æ—¶ç›‘æ§**ï¼šæ¯«ç§’çº§çš„æŒ‡æ ‡æ”¶é›†å’Œå‘Šè­¦
- **å…¨é¢è¦†ç›–**ï¼šä»åŸºç¡€è®¾æ–½åˆ°åº”ç”¨å±‚çš„å…¨æ–¹ä½ç›‘æ§
- **æ™ºèƒ½å‘Šè­¦**ï¼šåŸºäºé˜ˆå€¼çš„æ™ºèƒ½å‘Šè­¦æœºåˆ¶
- **å¯è§†åŒ–å±•ç¤º**ï¼šç›´è§‚çš„ä»ªè¡¨æ¿å’ŒæŠ¥è¡¨

### 11.2. æœªæ¥å‘å±•æ–¹å‘

#### 11.2.1. AIé©±åŠ¨çš„ç›‘æ§

```python
# AIé©±åŠ¨çš„å¼‚å¸¸æ£€æµ‹
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler

class AIAnomalyDetector:
    def __init__(self):
        self.model = IsolationForest(contamination=0.1)
        self.scaler = StandardScaler()
        self.is_fitted = False

    def fit(self, metrics_data):
        """è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹"""
        scaled_data = self.scaler.fit_transform(metrics_data)
        self.model.fit(scaled_data)
        self.is_fitted = True

    def detect_anomalies(self, metrics_data):
        """æ£€æµ‹å¼‚å¸¸"""
        if not self.is_fitted:
            return []

        scaled_data = self.scaler.transform(metrics_data)
        predictions = self.model.predict(scaled_data)

# -1è¡¨ç¤ºå¼‚å¸¸ï¼Œ1è¡¨ç¤ºæ­£å¸¸
        anomalies = np.where[predictions == -1](0)
        return anomalies.tolist()
```

## 12. è‡ªåŠ¨åŒ–è¿ç»´

```yaml
# è‡ªåŠ¨åŒ–è¿ç»´é…ç½®
automated_operations:
  auto_scaling:
    enabled: true
    min_replicas: 3
    max_replicas: 10
    target_cpu_utilization: 70

  auto_healing:
    enabled: true
    health_check_interval: 30s
    restart_threshold: 3

  predictive_maintenance:
    enabled: true
    prediction_window: "24h"
    maintenance_threshold: 0.8
```

## 13. æŒç»­æ”¹è¿›

æ€§èƒ½ç›‘æ§ç³»ç»Ÿéœ€è¦æŒç»­æ”¹è¿›ï¼š

1. **æŒ‡æ ‡ä¼˜åŒ–**ï¼šæ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´ç›‘æ§æŒ‡æ ‡
2. **å‘Šè­¦ä¼˜åŒ–**ï¼šå‡å°‘è¯¯æŠ¥ï¼Œæé«˜å‘Šè­¦å‡†ç¡®æ€§
3. **æ€§èƒ½ä¼˜åŒ–**ï¼šæå‡ç›‘æ§ç³»ç»Ÿæœ¬èº«çš„æ€§èƒ½
4. **åŠŸèƒ½æ‰©å±•**ï¼šå¢åŠ æ–°çš„ç›‘æ§ç»´åº¦å’ŒåŠŸèƒ½

## 14. å‚è€ƒæ–‡çŒ®

1. [Site Reliability Engineering](https://sre.google/)
2. [Prometheus Documentation](https://prometheus.io/docs/)
3. [Grafana Documentation](https://grafana.com/docs/)
4. [OpenTelemetry Documentation](https://opentelemetry.io/docs/)
5. [Monitoring Distributed Systems](https://www.oreilly.com/library/view/monitoring-distributed-systems/9781492026011/)

## 15. ç›¸å…³é“¾æ¥

- [DevOpsä¸CI/CD](../4.1.15-DevOpsä¸CI-CD.md)
- [äº‘åŸç”Ÿæ¶æ„å®è·µ](../4.1.14-äº‘åŸç”Ÿæ¶æ„å®è·µ.md)
- [å¾®æœåŠ¡æ¶æ„è®¾è®¡](../4.1.13-å¾®æœåŠ¡æ¶æ„è®¾è®¡.md)

## 16. è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ç›‘æ§ç³»ç»Ÿç›¸å…³çš„æœ€ä½³å®è·µå’Œæ¡ˆä¾‹ã€‚

## 17. è®¸å¯è¯ä¿¡æ¯

æœ¬æ–‡æ¡£é‡‡ç”¨MITè®¸å¯è¯ã€‚
