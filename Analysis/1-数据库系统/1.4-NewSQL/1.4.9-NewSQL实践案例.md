# 1.4.9 NewSQL实践案例

## 概述

本文档提供NewSQL数据库系统的实际应用案例，涵盖TiDB、CockroachDB、YugabyteDB等主流NewSQL数据库的设计模式、分布式事务、性能优化等核心主题。

## 目录

- [1. TiDB实践案例](#1-tidb实践案例)
- [2. CockroachDB实践案例](#2-cockroachdb实践案例)
- [3. 分布式事务实践案例](#3-分布式事务实践案例)
- [4. 性能优化实践案例](#4-性能优化实践案例)

## 1. TiDB实践案例

### 1.1 TiDB集群配置

```yaml
# tidb-cluster.yaml
apiVersion: pingcap.com/v1alpha1
kind: TidbCluster
metadata:
  name: tidb-cluster
spec:
  version: v6.5.0
  pd:
    replicas: 3
    requests:
      storage: "10Gi"
      cpu: 1000m
      memory: 2Gi
  tikv:
    replicas: 3
    requests:
      storage: "100Gi"
      cpu: 2000m
      memory: 4Gi
  tidb:
    replicas: 2
    requests:
      cpu: 1000m
      memory: 2Gi
```

### 1.2 TiDB数据模型设计

```sql
-- 创建分区表
CREATE TABLE users (
    user_id BIGINT PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    status ENUM('active', 'inactive') DEFAULT 'active',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (user_id) (
    PARTITION p0 VALUES LESS THAN (1000000),
    PARTITION p1 VALUES LESS THAN (2000000),
    PARTITION p2 VALUES LESS THAN MAXVALUE
);

-- 创建订单表（按时间分区）
CREATE TABLE orders (
    order_id BIGINT PRIMARY KEY,
    user_id BIGINT NOT NULL,
    total_amount DECIMAL(10,2) NOT NULL,
    status ENUM('pending', 'paid', 'shipped') DEFAULT 'pending',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_user (user_id),
    INDEX idx_status (status)
) PARTITION BY RANGE (TO_DAYS(created_at)) (
    PARTITION p202401 VALUES LESS THAN (TO_DAYS('2024-02-01')),
    PARTITION p202402 VALUES LESS THAN (TO_DAYS('2024-03-01')),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);
```

### 1.3 TiDB事务处理

```python
import pymysql
from contextlib import contextmanager

class TiDBManager:
    def __init__(self, host, port, user, password, database):
        self.connection_params = {
            'host': host, 'port': port, 'user': user,
            'password': password, 'database': database,
            'autocommit': False
        }
    
    @contextmanager
    def transaction(self):
        conn = None
        try:
            conn = pymysql.connect(**self.connection_params)
            cursor = conn.cursor()
            yield cursor
            conn.commit()
        except Exception as e:
            if conn:
                conn.rollback()
            raise
        finally:
            if conn:
                conn.close()
    
    def create_order(self, user_id, items, total_amount):
        with self.transaction() as cursor:
            # 创建订单
            cursor.execute("""
                INSERT INTO orders (user_id, total_amount)
                VALUES (%s, %s)
            """, (user_id, total_amount))
            
            order_id = cursor.lastrowid
            
            # 创建订单项
            for item in items:
                cursor.execute("""
                    INSERT INTO order_items (order_id, product_id, quantity, price)
                    VALUES (%s, %s, %s, %s)
                """, (order_id, item['product_id'], item['quantity'], item['price']))
            
            return order_id

# 使用示例
tidb = TiDBManager('localhost', 4000, 'root', '', 'ecommerce')
order_id = tidb.create_order(1001, [
    {'product_id': 2001, 'quantity': 2, 'price': 100.00}
], 200.00)
```

## 2. CockroachDB实践案例

### 2.1 CockroachDB多区域配置

```sql
-- 设置多区域
ALTER DATABASE ecommerce SET PRIMARY REGION "us-east1";
ALTER DATABASE ecommerce ADD REGION "us-west1";

-- 创建全局表
CREATE TABLE users (
    user_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) LOCALITY GLOBAL;

-- 创建区域表
CREATE TABLE orders (
    order_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL,
    total_amount DECIMAL(10,2) NOT NULL,
    status VARCHAR(20) DEFAULT 'pending',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(user_id)
) LOCALITY REGIONAL BY TABLE IN PRIMARY REGION;
```

### 2.2 CockroachDB事务处理

```python
import psycopg2
from contextlib import contextmanager
import uuid

class CockroachDBManager:
    def __init__(self, host, port, user, password, database):
        self.connection_params = {
            'host': host, 'port': port, 'user': user,
            'password': password, 'database': database
        }
    
    @contextmanager
    def transaction(self):
        conn = None
        try:
            conn = psycopg2.connect(**self.connection_params)
            conn.autocommit = False
            cursor = conn.cursor()
            yield cursor
            conn.commit()
        except Exception as e:
            if conn:
                conn.rollback()
            raise
        finally:
            if conn:
                conn.close()
    
    def create_user_with_order(self, username, email, order_items):
        with self.transaction() as cursor:
            # 创建用户
            user_id = str(uuid.uuid4())
            cursor.execute("""
                INSERT INTO users (user_id, username, email)
                VALUES (%s, %s, %s)
            """, (user_id, username, email))
            
            # 创建订单
            order_id = str(uuid.uuid4())
            total_amount = sum(item['price'] * item['quantity'] for item in order_items)
            
            cursor.execute("""
                INSERT INTO orders (order_id, user_id, total_amount)
                VALUES (%s, %s, %s)
            """, (order_id, user_id, total_amount))
            
            return user_id, order_id

# 使用示例
crdb = CockroachDBManager('localhost', 26257, 'root', '', 'ecommerce')
user_id, order_id = crdb.create_user_with_order(
    'testuser', 'test@example.com',
    [{'price': 100.00, 'quantity': 2}]
)
```

## 3. 分布式事务实践案例

### 3.1 两阶段提交实现

```python
from enum import Enum
import uuid
import time

class TransactionStatus(Enum):
    PREPARING = "preparing"
    PREPARED = "prepared"
    COMMITTED = "committed"
    ABORTED = "aborted"

class TwoPhaseCommitCoordinator:
    def __init__(self):
        self.transactions = {}
    
    def begin_transaction(self):
        transaction_id = str(uuid.uuid4())
        self.transactions[transaction_id] = {
            'status': TransactionStatus.PREPARING,
            'participants': []
        }
        return transaction_id
    
    def add_participant(self, transaction_id, participant_id, prepare_func, commit_func, rollback_func):
        self.transactions[transaction_id]['participants'].append({
            'id': participant_id,
            'prepare_func': prepare_func,
            'commit_func': commit_func,
            'rollback_func': rollback_func,
            'prepared': False
        })
    
    def prepare(self, transaction_id):
        transaction = self.transactions[transaction_id]
        
        for participant in transaction['participants']:
            try:
                if participant['prepare_func']():
                    participant['prepared'] = True
                else:
                    return False
            except Exception:
                return False
        
        transaction['status'] = TransactionStatus.PREPARED
        return True
    
    def commit(self, transaction_id):
        transaction = self.transactions[transaction_id]
        
        for participant in transaction['participants']:
            if participant['prepared']:
                try:
                    if not participant['commit_func']():
                        self.rollback(transaction_id)
                        return False
                except Exception:
                    self.rollback(transaction_id)
                    return False
        
        transaction['status'] = TransactionStatus.COMMITTED
        return True
    
    def rollback(self, transaction_id):
        transaction = self.transactions[transaction_id]
        transaction['status'] = TransactionStatus.ABORTED
        
        for participant in transaction['participants']:
            if participant['prepared']:
                try:
                    participant['rollback_func']()
                except Exception:
                    pass

# 使用示例
coordinator = TwoPhaseCommitCoordinator()

def create_order_distributed(user_id, items):
    transaction_id = coordinator.begin_transaction()
    
    # 添加参与者
    coordinator.add_participant(
        transaction_id, 'inventory',
        lambda: prepare_inventory(items),
        lambda: commit_inventory(items),
        lambda: rollback_inventory(items)
    )
    
    coordinator.add_participant(
        transaction_id, 'payment',
        lambda: prepare_payment(user_id, sum(item['price'] * item['quantity'] for item in items)),
        lambda: commit_payment(user_id),
        lambda: rollback_payment(user_id)
    )
    
    # 执行两阶段提交
    if coordinator.prepare(transaction_id):
        return coordinator.commit(transaction_id)
    return False
```

## 4. 性能优化实践案例

### 4.1 读写分离配置

```python
import psycopg2
import random

class ReadWriteSplitManager:
    def __init__(self, master_config, slave_configs):
        self.master_config = master_config
        self.slave_configs = slave_configs
    
    def get_master_connection(self):
        return psycopg2.connect(**self.master_config)
    
    def get_slave_connection(self):
        slave_config = random.choice(self.slave_configs)
        return psycopg2.connect(**slave_config)
    
    def execute_write(self, sql, params=None):
        conn = self.get_master_connection()
        try:
            cursor = conn.cursor()
            cursor.execute(sql, params)
            result = cursor.fetchall() if cursor.description else None
            conn.commit()
            return result
        finally:
            conn.close()
    
    def execute_read(self, sql, params=None):
        conn = self.get_slave_connection()
        try:
            cursor = conn.cursor()
            cursor.execute(sql, params)
            return cursor.fetchall()
        finally:
            conn.close()

# 使用示例
rw_manager = ReadWriteSplitManager(
    master_config={'host': 'master', 'port': 26257, 'user': 'root', 'database': 'ecommerce'},
    slave_configs=[
        {'host': 'slave1', 'port': 26257, 'user': 'root', 'database': 'ecommerce'},
        {'host': 'slave2', 'port': 26257, 'user': 'root', 'database': 'ecommerce'}
    ]
)

# 写操作
rw_manager.execute_write("INSERT INTO users (username, email) VALUES (%s, %s)", ('user1', 'user1@example.com'))

# 读操作
results = rw_manager.execute_read("SELECT * FROM users WHERE status = %s", ('active',))
```

### 4.2 连接池和缓存优化

```python
import redis
import json
from functools import wraps

class NewSQLOptimizer:
    def __init__(self, db_manager, redis_config):
        self.db_manager = db_manager
        self.redis_client = redis.Redis(**redis_config)
    
    def cache_result(self, ttl=3600):
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                cache_key = f"{func.__name__}:{hash(str(args) + str(sorted(kwargs.items())))}"
                
                cached_result = self.redis_client.get(cache_key)
                if cached_result:
                    return json.loads(cached_result)
                
                result = func(*args, **kwargs)
                self.redis_client.setex(cache_key, ttl, json.dumps(result))
                return result
            return wrapper
        return decorator
    
    @cache_result(ttl=1800)
    def get_user_profile(self, user_id):
        return self.db_manager.execute_read(
            "SELECT * FROM users WHERE user_id = %s", (user_id,)
        )
    
    def batch_insert(self, table, data_list):
        if not data_list:
            return
        
        columns = list(data_list[0].keys())
        placeholders = ','.join(['%s'] * len(columns))
        sql = f"INSERT INTO {table} ({','.join(columns)}) VALUES ({placeholders})"
        
        values = [tuple(data[col] for col in columns) for data in data_list]
        return self.db_manager.execute_write(sql, values)

# 使用示例
optimizer = NewSQLOptimizer(
    db_manager=rw_manager,
    redis_config={'host': 'localhost', 'port': 6379, 'db': 0}
)

# 批量插入
users_data = [
    {'username': 'user1', 'email': 'user1@example.com'},
    {'username': 'user2', 'email': 'user2@example.com'}
]
optimizer.batch_insert('users', users_data)
```

## 总结

这些实践案例展示了NewSQL数据库系统的核心应用场景，包括：

1. **TiDB**：分布式SQL数据库，支持MySQL兼容性
2. **CockroachDB**：全球分布式数据库，支持多区域部署
3. **分布式事务**：两阶段提交（2PC）实现
4. **性能优化**：读写分离、连接池、缓存优化

每个案例都提供了完整的代码示例和最佳实践，可以直接应用于实际项目中。

**相关链接：**

- [1.4.1-形式模型](1.4.1-形式模型.md)
- [1.4.2-系统架构](1.4.2-系统架构.md)
- [1.4.3-数据模型](1.4.3-数据模型.md)
- [1.4.4-分布式事务与一致性](1.4.4-分布式事务与一致性.md)
- [1.4.5-OLAP_OLTP融合](1.4.5-OLAP_OLTP融合.md)
- [1.4.6-性能调优与监控](1.4.6-性能调优与监控.md)
- [1.4.7-安全与合规](1.4.7-安全与合规.md)
- [1.4.8-云原生与容器化部署](1.4.8-云原生与容器化部署.md)
