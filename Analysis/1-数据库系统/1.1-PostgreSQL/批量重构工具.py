#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PostgreSQLå†…å®¹æ‰¹é‡é‡æ„å·¥å…·

æœ¬å·¥å…·ç”¨äºè‡ªåŠ¨åŒ–å¤„ç†PostgreSQLæ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶é‡æ„ï¼Œ
åº”ç”¨ç»Ÿä¸€çš„å†…å®¹æ¨¡æ¿ï¼Œæé«˜å†…å®¹è´¨é‡ã€‚
"""

import os
import re
import json
import shutil
from pathlib import Path
from typing import List, Dict, Tuple

class PostgreSQLContentRefactor:
    """PostgreSQLå†…å®¹é‡æ„å·¥å…·"""
    
    def __init__(self, base_path: str):
        self.base_path = Path(base_path)
        self.template_path = self.base_path / "ç»Ÿä¸€å†…å®¹æ¨¡æ¿.md"
        self.progress_file = self.base_path / "é‡æ„è¿›åº¦.json"
        self.quality_report = self.base_path / "è´¨é‡æŠ¥å‘Š.json"
        
        # æ–‡ä»¶åˆ†ç±»
        self.file_categories = {
            "sql_language": ["SQLè¯­è¨€", "sql", "è¯­è¨€è§„èŒƒ"],
            "system_architecture": ["ç³»ç»Ÿæ¶æ„", "æ¶æ„", "architecture"],
            "query_optimization": ["æŸ¥è¯¢ä¼˜åŒ–", "ä¼˜åŒ–", "optimization"],
            "transaction_management": ["äº‹åŠ¡", "äº‹åŠ¡ç®¡ç†", "transaction"],
            "mvcc": ["MVCC", "å¤šç‰ˆæœ¬", "å¹¶å‘æ§åˆ¶"],
            "formal_proof": ["å½¢å¼åŒ–", "è¯æ˜", "ç†è®º", "formal"],
            "ai_integration": ["AI", "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ "],
            "vector_database": ["å‘é‡", "å‘é‡æ•°æ®åº“", "vector"],
            "performance": ["æ€§èƒ½", "æ€§èƒ½ä¼˜åŒ–", "performance"],
            "security": ["å®‰å…¨", "æƒé™", "security"]
        }
        
        # è´¨é‡è¯„åˆ†æ ‡å‡†
        self.quality_criteria = {
            "concept_definition": 20,  # æ¦‚å¿µå®šä¹‰
            "formal_proof": 25,        # å½¢å¼åŒ–è¯æ˜
            "code_examples": 20,       # ä»£ç ç¤ºä¾‹
            "practical_applications": 15,  # å®é™…åº”ç”¨
            "references": 10,          # å‚è€ƒæ–‡çŒ®
            "wikidata_alignment": 10   # Wikidataå¯¹é½
        }
    
    def scan_files(self) -> List[Dict]:
        """æ‰«ææ‰€æœ‰æ–‡ä»¶å¹¶åˆ†ç±»"""
        files = []
        
        for file_path in self.base_path.rglob("*.md"):
            if file_path.name in ["README.md", "ç»Ÿä¸€å†…å®¹æ¨¡æ¿.md", "æ”¹è¿›è¿›åº¦è·Ÿè¸ª.md"]:
                continue
                
            file_info = {
                "path": str(file_path),
                "name": file_path.name,
                "size": file_path.stat().st_size,
                "category": self._categorize_file(file_path),
                "quality_score": 0,
                "needs_refactor": False
            }
            
            # è¯„ä¼°æ–‡ä»¶è´¨é‡
            file_info["quality_score"] = self._assess_quality(file_path)
            file_info["needs_refactor"] = file_info["quality_score"] < 70
            
            files.append(file_info)
        
        return files
    
    def _categorize_file(self, file_path: Path) -> str:
        """åˆ†ç±»æ–‡ä»¶"""
        content = file_path.read_text(encoding='utf-8', errors='ignore')
        
        for category, keywords in self.file_categories.items():
            for keyword in keywords:
                if keyword.lower() in content.lower() or keyword.lower() in file_path.name.lower():
                    return category
        
        return "other"
    
    def _assess_quality(self, file_path: Path) -> float:
        """è¯„ä¼°æ–‡ä»¶è´¨é‡"""
        try:
            content = file_path.read_text(encoding='utf-8', errors='ignore')
            score = 0
            
            # æ£€æŸ¥æ¦‚å¿µå®šä¹‰
            if re.search(r'ä¸­æ–‡å®šä¹‰|English Definition', content):
                score += self.quality_criteria["concept_definition"]
            
            # æ£€æŸ¥å½¢å¼åŒ–è¯æ˜
            if re.search(r'\\begin\{theorem\}|\\begin\{proof\}', content):
                score += self.quality_criteria["formal_proof"]
            
            # æ£€æŸ¥ä»£ç ç¤ºä¾‹
            if re.search(r'```sql|```python|```c', content):
                score += self.quality_criteria["code_examples"]
            
            # æ£€æŸ¥å®é™…åº”ç”¨
            if re.search(r'å®é™…åº”ç”¨|æœ€ä½³å®è·µ|PostgreSQL', content):
                score += self.quality_criteria["practical_applications"]
            
            # æ£€æŸ¥å‚è€ƒæ–‡çŒ®
            if re.search(r'å‚è€ƒæ–‡çŒ®|References|å­¦æœ¯æ–‡çŒ®', content):
                score += self.quality_criteria["references"]
            
            # æ£€æŸ¥Wikidataå¯¹é½
            if re.search(r'Wikidata|æ¦‚å¿µID', content):
                score += self.quality_criteria["wikidata_alignment"]
            
            return min(score, 100)
            
        except Exception as e:
            print(f"è¯„ä¼°æ–‡ä»¶ {file_path} è´¨é‡æ—¶å‡ºé”™: {e}")
            return 0
    
    def generate_refactor_plan(self, files: List[Dict]) -> Dict:
        """ç”Ÿæˆé‡æ„è®¡åˆ’"""
        plan = {
            "total_files": len(files),
            "high_quality": len([f for f in files if f["quality_score"] >= 80]),
            "medium_quality": len([f for f in files if 60 <= f["quality_score"] < 80]),
            "low_quality": len([f for f in files if f["quality_score"] < 60]),
            "needs_refactor": len([f for f in files if f["needs_refactor"]]),
            "categories": {},
            "priority_files": []
        }
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        for file_info in files:
            category = file_info["category"]
            if category not in plan["categories"]:
                plan["categories"][category] = {
                    "count": 0,
                    "avg_score": 0,
                    "files": []
                }
            
            plan["categories"][category]["count"] += 1
            plan["categories"][category]["files"].append(file_info)
        
        # è®¡ç®—å¹³å‡åˆ†
        for category in plan["categories"]:
            files_in_category = plan["categories"][category]["files"]
            if files_in_category:
                avg_score = sum(f["quality_score"] for f in files_in_category) / len(files_in_category)
                plan["categories"][category]["avg_score"] = round(avg_score, 2)
        
        # ç¡®å®šä¼˜å…ˆçº§æ–‡ä»¶
        priority_files = [f for f in files if f["needs_refactor"]]
        priority_files.sort(key=lambda x: (x["quality_score"], x["size"]))
        plan["priority_files"] = priority_files[:20]  # å‰20ä¸ªä¼˜å…ˆçº§æ–‡ä»¶
        
        return plan
    
    def apply_template(self, file_path: str, category: str) -> str:
        """åº”ç”¨ç»Ÿä¸€æ¨¡æ¿"""
        template = self.template_path.read_text(encoding='utf-8')
        
        # æ ¹æ®ç±»åˆ«è°ƒæ•´æ¨¡æ¿
        if category == "sql_language":
            title = "SQLè¯­è¨€è§„èŒƒ - PostgreSQL 17å®Œæ•´ç‰ˆ"
        elif category == "system_architecture":
            title = "PostgreSQLç³»ç»Ÿæ¶æ„ - PostgreSQL 17å®Œæ•´ç‰ˆ"
        elif category == "query_optimization":
            title = "æŸ¥è¯¢ä¼˜åŒ–ç†è®º - PostgreSQL 17å®Œæ•´ç‰ˆ"
        elif category == "transaction_management":
            title = "äº‹åŠ¡ç®¡ç†ç†è®º - PostgreSQL 17å®Œæ•´ç‰ˆ"
        elif category == "mvcc":
            title = "MVCCå¹¶å‘æ§åˆ¶ç†è®º - PostgreSQL 17å®Œæ•´ç‰ˆ"
        elif category == "formal_proof":
            title = "å½¢å¼åŒ–è¯æ˜ç†è®º - PostgreSQL 17å®Œæ•´ç‰ˆ"
        elif category == "ai_integration":
            title = "AIé›†æˆç†è®º - PostgreSQL 17å®Œæ•´ç‰ˆ"
        elif category == "vector_database":
            title = "å‘é‡æ•°æ®åº“ç†è®º - PostgreSQL 17å®Œæ•´ç‰ˆ"
        else:
            title = "PostgreSQLç†è®º - PostgreSQL 17å®Œæ•´ç‰ˆ"
        
        # æ›¿æ¢æ¨¡æ¿ä¸­çš„å ä½ç¬¦
        content = template.replace("[ä¸»é¢˜åç§°]", title)
        content = content.replace("[å®Œæ•´çš„ä¸­æ–‡æ¦‚å¿µå®šä¹‰ï¼ŒåŒ…å«æ ¸å¿ƒç‰¹å¾å’ŒåŠŸèƒ½]", 
                                f"{title}çš„ä¸­æ–‡å®šä¹‰")
        content = content.replace("[å®Œæ•´çš„è‹±æ–‡æ¦‚å¿µå®šä¹‰ï¼Œä¸ä¸­æ–‡å®šä¹‰å¯¹åº”]", 
                                f"English definition for {title}")
        
        return content
    
    def refactor_file(self, file_info: Dict) -> bool:
        """é‡æ„å•ä¸ªæ–‡ä»¶"""
        try:
            file_path = Path(file_info["path"])
            category = file_info["category"]
            
            # å¤‡ä»½åŸæ–‡ä»¶
            backup_path = file_path.with_suffix('.md.backup')
            shutil.copy2(file_path, backup_path)
            
            # åº”ç”¨æ¨¡æ¿
            new_content = self.apply_template(file_info["path"], category)
            
            # å†™å…¥æ–°å†…å®¹
            file_path.write_text(new_content, encoding='utf-8')
            
            # æ›´æ–°è´¨é‡è¯„åˆ†
            new_score = self._assess_quality(file_path)
            file_info["quality_score"] = new_score
            file_info["refactored"] = True
            
            print(f"âœ… é‡æ„å®Œæˆ: {file_path.name} (è´¨é‡è¯„åˆ†: {new_score})")
            return True
            
        except Exception as e:
            print(f"âŒ é‡æ„å¤±è´¥: {file_info['path']} - {e}")
            return False
    
    def batch_refactor(self, max_files: int = 10) -> Dict:
        """æ‰¹é‡é‡æ„æ–‡ä»¶"""
        print("ğŸ” æ‰«ææ–‡ä»¶...")
        files = self.scan_files()
        
        print("ğŸ“Š ç”Ÿæˆé‡æ„è®¡åˆ’...")
        plan = self.generate_refactor_plan(files)
        
        print(f"ğŸ“ˆ è´¨é‡ç»Ÿè®¡:")
        print(f"   - é«˜è´¨é‡æ–‡ä»¶: {plan['high_quality']}")
        print(f"   - ä¸­ç­‰è´¨é‡æ–‡ä»¶: {plan['medium_quality']}")
        print(f"   - ä½è´¨é‡æ–‡ä»¶: {plan['low_quality']}")
        print(f"   - éœ€è¦é‡æ„: {plan['needs_refactor']}")
        
        # é€‰æ‹©è¦é‡æ„çš„æ–‡ä»¶
        priority_files = plan["priority_files"][:max_files]
        
        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡é‡æ„ ({len(priority_files)} ä¸ªæ–‡ä»¶)...")
        
        success_count = 0
        for file_info in priority_files:
            print(f"\nğŸ“ é‡æ„: {file_info['name']}")
            if self.refactor_file(file_info):
                success_count += 1
        
        # ä¿å­˜è¿›åº¦
        self._save_progress(files, plan)
        
        print(f"\nâœ… æ‰¹é‡é‡æ„å®Œæˆ!")
        print(f"   - æˆåŠŸé‡æ„: {success_count}/{len(priority_files)}")
        print(f"   - å¹³å‡è´¨é‡æå‡: {self._calculate_quality_improvement(files)}")
        
        return {
            "success_count": success_count,
            "total_processed": len(priority_files),
            "plan": plan
        }
    
    def _save_progress(self, files: List[Dict], plan: Dict):
        """ä¿å­˜è¿›åº¦"""
        progress_data = {
            "timestamp": str(Path().cwd()),
            "files": files,
            "plan": plan,
            "total_files": len(files),
            "avg_quality": sum(f["quality_score"] for f in files) / len(files) if files else 0
        }
        
        with open(self.progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
    
    def _calculate_quality_improvement(self, files: List[Dict]) -> float:
        """è®¡ç®—è´¨é‡æå‡"""
        refactored_files = [f for f in files if f.get("refactored", False)]
        if not refactored_files:
            return 0.0
        
        improvement = sum(f["quality_score"] for f in refactored_files) / len(refactored_files)
        return round(improvement, 2)
    
    def generate_report(self) -> str:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        if not self.progress_file.exists():
            return "æ²¡æœ‰æ‰¾åˆ°è¿›åº¦æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œé‡æ„"
        
        with open(self.progress_file, 'r', encoding='utf-8') as f:
            progress_data = json.load(f)
        
        report = f"""
# PostgreSQLå†…å®¹é‡æ„è´¨é‡æŠ¥å‘Š

## æ€»ä½“ç»Ÿè®¡
- æ€»æ–‡ä»¶æ•°: {progress_data['total_files']}
- å¹³å‡è´¨é‡è¯„åˆ†: {progress_data['avg_quality']:.2f}
- é‡æ„æ—¶é—´: {progress_data['timestamp']}

## åˆ†ç±»ç»Ÿè®¡
"""
        
        for category, stats in progress_data['plan']['categories'].items():
            report += f"""
### {category}
- æ–‡ä»¶æ•°é‡: {stats['count']}
- å¹³å‡è´¨é‡: {stats['avg_score']:.2f}
"""
        
        report += f"""
## è´¨é‡åˆ†å¸ƒ
- é«˜è´¨é‡æ–‡ä»¶ (â‰¥80åˆ†): {progress_data['plan']['high_quality']}
- ä¸­ç­‰è´¨é‡æ–‡ä»¶ (60-79åˆ†): {progress_data['plan']['medium_quality']}
- ä½è´¨é‡æ–‡ä»¶ (<60åˆ†): {progress_data['plan']['low_quality']}
- éœ€è¦é‡æ„: {progress_data['plan']['needs_refactor']}

## å»ºè®®
1. ç»§ç»­é‡æ„ä½è´¨é‡æ–‡ä»¶
2. å®Œå–„å½¢å¼åŒ–è¯æ˜
3. æ·»åŠ æ›´å¤šä»£ç ç¤ºä¾‹
4. æ›´æ–°åˆ°PostgreSQL 17ç‰¹æ€§
"""
        
        return report

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®å·¥ä½œç›®å½•
    base_path = Path(__file__).parent
    refactor = PostgreSQLContentRefactor(str(base_path))
    
    print("ğŸ”„ PostgreSQLå†…å®¹æ‰¹é‡é‡æ„å·¥å…·")
    print("=" * 50)
    
    # è¿è¡Œæ‰¹é‡é‡æ„
    result = refactor.batch_refactor(max_files=5)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = refactor.generate_report()
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = base_path / "è´¨é‡æŠ¥å‘Š.md"
    report_path.write_text(report, encoding='utf-8')
    
    print(f"\nğŸ“„ è´¨é‡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

if __name__ == "__main__":
    main()
