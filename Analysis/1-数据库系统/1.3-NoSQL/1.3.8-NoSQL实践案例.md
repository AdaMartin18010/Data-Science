# 1.3.8 NoSQLå®è·µæ¡ˆä¾‹

## ğŸ“‘ ç›®å½•

- [1.3.8 NoSQLå®è·µæ¡ˆä¾‹](#138-nosqlå®è·µæ¡ˆä¾‹)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
  - [3. MongoDBå®è·µæ¡ˆä¾‹](#3-mongodbå®è·µæ¡ˆä¾‹)
    - [3.1. ç”µå•†ç³»ç»Ÿæ–‡æ¡£è®¾è®¡](#31-ç”µå•†ç³»ç»Ÿæ–‡æ¡£è®¾è®¡)
    - [3.2. MongoDBèšåˆç®¡é“ä¼˜åŒ–](#32-mongodbèšåˆç®¡é“ä¼˜åŒ–)
    - [3.3. MongoDBåˆ†ç‰‡é…ç½®](#33-mongodbåˆ†ç‰‡é…ç½®)
  - [4. Rediså®è·µæ¡ˆä¾‹](#4-rediså®è·µæ¡ˆä¾‹)
    - [4.1. ç¼“å­˜ç­–ç•¥è®¾è®¡](#41-ç¼“å­˜ç­–ç•¥è®¾è®¡)
  - [5. Redisæ•°æ®ç»“æ„åº”ç”¨](#5-redisæ•°æ®ç»“æ„åº”ç”¨)
  - [6. Cassandraå®è·µæ¡ˆä¾‹](#6-cassandraå®è·µæ¡ˆä¾‹)
    - [6.1. æ—¶é—´åºåˆ—æ•°æ®è®¾è®¡](#61-æ—¶é—´åºåˆ—æ•°æ®è®¾è®¡)
    - [6.2. CassandraæŸ¥è¯¢ä¼˜åŒ–](#62-cassandraæŸ¥è¯¢ä¼˜åŒ–)
  - [7. æ··åˆæ¶æ„å®è·µæ¡ˆä¾‹](#7-æ··åˆæ¶æ„å®è·µæ¡ˆä¾‹)
    - [7.1. å¤šæ•°æ®åº“ååŒæ¶æ„](#71-å¤šæ•°æ®åº“ååŒæ¶æ„)
  - [8. æ€§èƒ½ä¼˜åŒ–å®è·µæ¡ˆä¾‹](#8-æ€§èƒ½ä¼˜åŒ–å®è·µæ¡ˆä¾‹)
    - [8.1. ç´¢å¼•ä¼˜åŒ–ç­–ç•¥](#81-ç´¢å¼•ä¼˜åŒ–ç­–ç•¥)
    - [8.2. è¿æ¥æ± å’Œé…ç½®ä¼˜åŒ–](#82-è¿æ¥æ± å’Œé…ç½®ä¼˜åŒ–)
  - [9. æ€»ç»“](#9-æ€»ç»“)

---


## 1. æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›NoSQLæ•°æ®åº“ç³»ç»Ÿçš„å®é™…åº”ç”¨æ¡ˆä¾‹ï¼Œæ¶µç›–MongoDBã€Redisã€Cassandraç­‰ä¸»æµNoSQLæ•°æ®åº“çš„è®¾è®¡æ¨¡å¼ã€æ€§èƒ½ä¼˜åŒ–ã€åˆ†å¸ƒå¼é…ç½®ç­‰æ ¸å¿ƒä¸»é¢˜ã€‚æ¯ä¸ªæ¡ˆä¾‹éƒ½åŒ…å«å®Œæ•´çš„ä»£ç ç¤ºä¾‹å’Œæœ€ä½³å®è·µã€‚

## 3. MongoDBå®è·µæ¡ˆä¾‹

### 3.1. ç”µå•†ç³»ç»Ÿæ–‡æ¡£è®¾è®¡

```javascript
// ç”¨æˆ·æ–‡æ¡£è®¾è®¡
const userSchema = {
  _id: ObjectId,
  username: String,
  email: String,
  profile: {
    firstName: String,
    lastName: String,
    phone: String,
    address: {
      street: String,
      city: String,
      state: String,
      zipCode: String
    }
  },
  preferences: {
    language: String,
    currency: String,
    notifications: {
      email: Boolean,
      sms: Boolean,
      push: Boolean
    }
  },
  createdAt: Date,
  updatedAt: Date
};

// å•†å“æ–‡æ¡£è®¾è®¡
const productSchema = {
  _id: ObjectId,
  name: String,
  description: String,
  price: {
    amount: Number,
    currency: String
  },
  category: {
    _id: ObjectId,
    name: String,
    path: [String]  // åˆ†ç±»è·¯å¾„
  },
  attributes: {
    brand: String,
    model: String,
    color: [String],
    size: [String],
    weight: Number,
    dimensions: {
      length: Number,
      width: Number,
      height: Number
    }
  },
  inventory: {
    stock: Number,
    reserved: Number,
    available: Number
  },
  images: [{
    url: String,
    alt: String,
    isPrimary: Boolean
  }],
  ratings: {
    average: Number,
    count: Number,
    distribution: {
      1: Number,
      2: Number,
      3: Number,
      4: Number,
      5: Number
    }
  },
  status: String,
  createdAt: Date,
  updatedAt: Date
};

// è®¢å•æ–‡æ¡£è®¾è®¡
const orderSchema = {
  _id: ObjectId,
  orderNumber: String,
  userId: ObjectId,
  items: [{
    productId: ObjectId,
    productName: String,
    quantity: Number,
    unitPrice: Number,
    totalPrice: Number,
    attributes: {
      color: String,
      size: String
    }
  }],
  totals: {
    subtotal: Number,
    tax: Number,
    shipping: Number,
    discount: Number,
    grandTotal: Number
  },
  shipping: {
    address: {
      street: String,
      city: String,
      state: String,
      zipCode: String,
      country: String
    },
    method: String,
    trackingNumber: String
  },
  payment: {
    method: String,
    status: String,
    transactionId: String,
    processedAt: Date
  },
  status: String,
  statusHistory: [{
    status: String,
    timestamp: Date,
    note: String
  }],
  createdAt: Date,
  updatedAt: Date
};
```

### 3.2. MongoDBèšåˆç®¡é“ä¼˜åŒ–

```javascript
// å¤æ‚èšåˆæŸ¥è¯¢ç¤ºä¾‹
db.orders.aggregate([
  // 1. åŒ¹é…æ¡ä»¶
  {
    $match: {
      status: { $in: ['paid', 'shipped', 'delivered'] },
      createdAt: { $gte: new Date('2024-01-01') }
    }
  },

  // 2. å±•å¼€è®¢å•é¡¹
  { $unwind: '$items' },

  // 3. å…³è”å•†å“ä¿¡æ¯
  {
    $lookup: {
      from: 'products',
      localField: 'items.productId',
      foreignField: '_id',
      as: 'product'
    }
  },

  // 4. å±•å¼€å•†å“ä¿¡æ¯
  { $unwind: '$product' },

  // 5. æŒ‰å•†å“åˆ†ç»„ç»Ÿè®¡
  {
    $group: {
      _id: {
        productId: '$items.productId',
        productName: '$product.name',
        category: '$product.category.name'
      },
      totalQuantity: { $sum: '$items.quantity' },
      totalRevenue: { $sum: '$items.totalPrice' },
      orderCount: { $sum: 1 },
      avgOrderValue: { $avg: '$items.totalPrice' }
    }
  },

  // 6. æŒ‰æ”¶å…¥æ’åº
  { $sort: { totalRevenue: -1 } },

  // 7. é™åˆ¶ç»“æœæ•°é‡
  { $limit: 10 }
]);

// ä½¿ç”¨ç´¢å¼•ä¼˜åŒ–èšåˆæŸ¥è¯¢
db.orders.createIndex({ status: 1, createdAt: 1 });
db.orders.createIndex({ 'items.productId': 1 });
db.products.createIndex({ _id: 1, name: 1, 'category.name': 1 });
```

### 3.3. MongoDBåˆ†ç‰‡é…ç½®

```javascript
// å¯ç”¨åˆ†ç‰‡
sh.enableSharding("ecommerce");

// ä¸ºé›†åˆå¯ç”¨åˆ†ç‰‡
sh.shardCollection("ecommerce.orders", { userId: 1 });
sh.shardCollection("ecommerce.products", { "category._id": 1 });

// æ·»åŠ åˆ†ç‰‡
sh.addShard("shard1/mongodb1:27018");
sh.addShard("shard2/mongodb2:27018");
sh.addShard("shard3/mongodb3:27018");

// é…ç½®åˆ†ç‰‡é”®
sh.shardCollection("ecommerce.users", { email: 1 });

// æŸ¥çœ‹åˆ†ç‰‡çŠ¶æ€
sh.status();
```

## 4. Rediså®è·µæ¡ˆä¾‹

### 4.1. ç¼“å­˜ç­–ç•¥è®¾è®¡

```python
import redis
import json
import hashlib
from datetime import datetime, timedelta

class RedisCacheManager:
    def __init__(self, host='localhost', port=6379, db=0):
        self.redis_client = redis.Redis(host=host, port=port, db=db)
        self.default_ttl = 3600  # 1å°æ—¶é»˜è®¤è¿‡æœŸæ—¶é—´

    def generate_cache_key(self, prefix, *args):
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_parts = [prefix] + [str(arg) for arg in args]
        return ":".join(key_parts)

    def get_cached_data(self, key):
        """è·å–ç¼“å­˜æ•°æ®"""
        try:
            data = self.redis_client.get(key)
            return json.loads(data) if data else None
        except Exception as e:
            print(f"ç¼“å­˜è¯»å–é”™è¯¯: {e}")
            return None

    def set_cached_data(self, key, data, ttl=None):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        try:
            ttl = ttl or self.default_ttl
            self.redis_client.setex(
                key,
                ttl,
                json.dumps(data, ensure_ascii=False)
            )
            return True
        except Exception as e:
            print(f"ç¼“å­˜è®¾ç½®é”™è¯¯: {e}")
            return False

    def invalidate_pattern(self, pattern):
        """æ‰¹é‡åˆ é™¤ç¼“å­˜"""
        try:
            keys = self.redis_client.keys(pattern)
            if keys:
                self.redis_client.delete(*keys)
            return len(keys)
        except Exception as e:
            print(f"ç¼“å­˜åˆ é™¤é”™è¯¯: {e}")
            return 0

# ç”¨æˆ·ä¿¡æ¯ç¼“å­˜
class UserCache:
    def __init__(self):
        self.cache = RedisCacheManager()

    def get_user_profile(self, user_id):
        """è·å–ç”¨æˆ·èµ„æ–™ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = self.cache.generate_cache_key("user:profile", user_id)

# å°è¯•ä»ç¼“å­˜è·å–
        cached_data = self.cache.get_cached_data(cache_key)
        if cached_data:
            return cached_data

# ä»æ•°æ®åº“è·å–
        user_data = self.fetch_user_from_db(user_id)
        if user_data:
# è®¾ç½®ç¼“å­˜ï¼ŒTTLä¸º30åˆ†é’Ÿ
            self.cache.set_cached_data(cache_key, user_data, 1800)

        return user_data

    def update_user_profile(self, user_id, user_data):
        """æ›´æ–°ç”¨æˆ·èµ„æ–™ï¼ˆåŒæ—¶æ›´æ–°ç¼“å­˜ï¼‰"""
# æ›´æ–°æ•°æ®åº“
        success = self.update_user_in_db(user_id, user_data)
        if success:
# åˆ é™¤ç›¸å…³ç¼“å­˜
            cache_key = self.cache.generate_cache_key("user:profile", user_id)
            self.cache.redis_client.delete(cache_key)

        return success
```

## 5. Redisæ•°æ®ç»“æ„åº”ç”¨

```python
# è´­ç‰©è½¦å®ç°
class ShoppingCart:
    def __init__(self):
        self.redis_client = redis.Redis(host='localhost', port=6379, db=1)

    def add_item(self, user_id, product_id, quantity=1):
        """æ·»åŠ å•†å“åˆ°è´­ç‰©è½¦"""
        cart_key = f"cart:{user_id}"

# ä½¿ç”¨Hashå­˜å‚¨è´­ç‰©è½¦æ•°æ®
        self.redis_client.hincrby(cart_key, product_id, quantity)

# è®¾ç½®è´­ç‰©è½¦è¿‡æœŸæ—¶é—´ï¼ˆ7å¤©ï¼‰
        self.redis_client.expire(cart_key, 7 * 24 * 3600)

    def remove_item(self, user_id, product_id):
        """ä»è´­ç‰©è½¦ç§»é™¤å•†å“"""
        cart_key = f"cart:{user_id}"
        return self.redis_client.hdel(cart_key, product_id)

    def get_cart(self, user_id):
        """è·å–è´­ç‰©è½¦å†…å®¹"""
        cart_key = f"cart:{user_id}"
        cart_data = self.redis_client.hgetall(cart_key)

# è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        return {k.decode(): int(v) for k, v in cart_data.items()}

    def clear_cart(self, user_id):
        """æ¸…ç©ºè´­ç‰©è½¦"""
        cart_key = f"cart:{user_id}"
        return self.redis_client.delete(cart_key)

# å•†å“æ’è¡Œæ¦œå®ç°
class ProductRanking:
    def __init__(self):
        self.redis_client = redis.Redis(host='localhost', port=6379, db=2)

    def increment_sales(self, product_id, amount=1):
        """å¢åŠ å•†å“é”€é‡"""
        ranking_key = "product:sales:ranking"
        self.redis_client.zincrby(ranking_key, amount, product_id)

    def get_top_products(self, limit=10):
        """è·å–é”€é‡æ’è¡Œæ¦œ"""
        ranking_key = "product:sales:ranking"
        return self.redis_client.zrevrange(ranking_key, 0, limit-1, withscores=True)

    def get_product_rank(self, product_id):
        """è·å–å•†å“æ’å"""
        ranking_key = "product:sales:ranking"
        rank = self.redis_client.zrevrank(ranking_key, product_id)
        score = self.redis_client.zscore(ranking_key, product_id)
        return rank + 1 if rank is not None else None, score

# é™æµå™¨å®ç°
class RateLimiter:
    def __init__(self):
        self.redis_client = redis.Redis(host='localhost', port=6379, db=3)

    def is_allowed(self, key, limit, window):
        """æ£€æŸ¥æ˜¯å¦å…è®¸è¯·æ±‚"""
        current = self.redis_client.get(key)

        if current is None:
# ç¬¬ä¸€æ¬¡è¯·æ±‚
            self.redis_client.setex(key, window, 1)
            return True

        current_count = int(current)
        if current_count < limit:
# å¢åŠ è®¡æ•°
            self.redis_client.incr(key)
            return True

        return False

    def get_remaining(self, key, limit):
        """è·å–å‰©ä½™è¯·æ±‚æ¬¡æ•°"""
        current = self.redis_client.get(key)
        if current is None:
            return limit
        return max(0, limit - int(current))
```

## 6. Cassandraå®è·µæ¡ˆä¾‹

### 6.1. æ—¶é—´åºåˆ—æ•°æ®è®¾è®¡

```sql
-- åˆ›å»ºé”®ç©ºé—´
CREATE KEYSPACE IF NOT EXISTS metrics
WITH replication = {
    'class': 'SimpleStrategy',
    'replication_factor': 3
};

USE metrics;

-- ç³»ç»ŸæŒ‡æ ‡è¡¨
CREATE TABLE system_metrics (
    host_id text,
    metric_name text,
    timestamp timestamp,
    value double,
    tags map<text, text>,
    PRIMARY KEY ((host_id, metric_name), timestamp)
) WITH CLUSTERING ORDER BY (timestamp DESC);

-- ç”¨æˆ·è¡Œä¸ºè¡¨
CREATE TABLE user_events (
    user_id text,
    event_date date,
    event_timestamp timestamp,
    event_type text,
    event_data text,
    session_id text,
    PRIMARY KEY ((user_id, event_date), event_timestamp, event_type)
) WITH CLUSTERING ORDER BY (event_timestamp DESC, event_type ASC);

-- è®¢å•è¡¨ï¼ˆæŒ‰ç”¨æˆ·åˆ†åŒºï¼‰
CREATE TABLE orders_by_user (
    user_id text,
    order_date date,
    order_id text,
    order_timestamp timestamp,
    total_amount decimal,
    status text,
    items list<text>,
    PRIMARY KEY ((user_id, order_date), order_timestamp, order_id)
) WITH CLUSTERING ORDER BY (order_timestamp DESC, order_id ASC);

-- å•†å“é”€å”®è¡¨ï¼ˆæŒ‰å•†å“åˆ†åŒºï¼‰
CREATE TABLE product_sales (
    product_id text,
    sale_date date,
    sale_timestamp timestamp,
    order_id text,
    quantity int,
    unit_price decimal,
    total_price decimal,
    user_id text,
    PRIMARY KEY ((product_id, sale_date), sale_timestamp, order_id)
) WITH CLUSTERING ORDER BY (sale_timestamp DESC, order_id ASC);
```

### 6.2. CassandraæŸ¥è¯¢ä¼˜åŒ–

```python
from cassandra.cluster import Cluster
from cassandra.query import SimpleStatement
from datetime import datetime, timedelta
import json

class CassandraMetricsManager:
    def __init__(self):
        self.cluster = Cluster(['localhost'])
        self.session = self.cluster.connect('metrics')

    def insert_system_metric(self, host_id, metric_name, value, tags=None):
        """æ’å…¥ç³»ç»ŸæŒ‡æ ‡"""
        query = """
        INSERT INTO system_metrics (host_id, metric_name, timestamp, value, tags)
        VALUES (?, ?, ?, ?, ?)
        """

        self.session.execute(query, (
            host_id,
            metric_name,
            datetime.now(),
            value,
            tags or {}
        ))

    def get_metrics_by_host(self, host_id, metric_name, start_time, end_time):
        """è·å–æŒ‡å®šä¸»æœºçš„æŒ‡æ ‡æ•°æ®"""
        query = """
        SELECT timestamp, value, tags
        FROM system_metrics
        WHERE host_id = ? AND metric_name = ?
        AND timestamp >= ? AND timestamp <= ?
        """

        statement = SimpleStatement(query, fetch_size=1000)
        rows = self.session.execute(statement, (host_id, metric_name, start_time, end_time))

        return [{
            'timestamp': row.timestamp,
            'value': row.value,
            'tags': row.tags
        } for row in rows]

    def get_user_events(self, user_id, event_date, event_type=None):
        """è·å–ç”¨æˆ·äº‹ä»¶"""
        if event_type:
            query = """
            SELECT event_timestamp, event_type, event_data, session_id
            FROM user_events
            WHERE user_id = ? AND event_date = ? AND event_type = ?
            """
            rows = self.session.execute(query, (user_id, event_date, event_type))
        else:
            query = """
            SELECT event_timestamp, event_type, event_data, session_id
            FROM user_events
            WHERE user_id = ? AND event_date = ?
            """
            rows = self.session.execute(query, (user_id, event_date))

        return [{
            'timestamp': row.event_timestamp,
            'type': row.event_type,
            'data': json.loads(row.event_data),
            'session_id': row.session_id
        } for row in rows]

    def get_product_sales(self, product_id, sale_date):
        """è·å–å•†å“é”€å”®æ•°æ®"""
        query = """
        SELECT sale_timestamp, order_id, quantity, unit_price, total_price, user_id
        FROM product_sales
        WHERE product_id = ? AND sale_date = ?
        """

        rows = self.session.execute(query, (product_id, sale_date))

        return [{
            'timestamp': row.sale_timestamp,
            'order_id': row.order_id,
            'quantity': row.quantity,
            'unit_price': float(row.unit_price),
            'total_price': float(row.total_price),
            'user_id': row.user_id
        } for row in rows]
```

## 7. æ··åˆæ¶æ„å®è·µæ¡ˆä¾‹

### 7.1. å¤šæ•°æ®åº“ååŒæ¶æ„

```python
class HybridDataManager:
    def __init__(self):
# åˆå§‹åŒ–å„ç§æ•°æ®åº“è¿æ¥
        self.mongo_client = pymongo.MongoClient('mongodb://localhost:27017/')
        self.redis_client = redis.Redis(host='localhost', port=6379, db=0)
        self.cassandra_session = Cluster(['localhost']).connect('ecommerce')

    def get_product_details(self, product_id):
        """è·å–å•†å“è¯¦æƒ…ï¼ˆå¤šçº§ç¼“å­˜ï¼‰"""
# 1. æ£€æŸ¥Redisç¼“å­˜
        cache_key = f"product:{product_id}"
        cached_data = self.redis_client.get(cache_key)
        if cached_data:
            return json.loads(cached_data)

# 2. ä»MongoDBè·å–
        product = self.mongo_client.ecommerce.products.find_one({'_id': ObjectId(product_id)})
        if product:
# 3. è®¾ç½®Redisç¼“å­˜
            self.redis_client.setex(cache_key, 3600, json.dumps(product, default=str))
            return product

        return None

    def record_user_activity(self, user_id, activity_type, activity_data):
        """è®°å½•ç”¨æˆ·æ´»åŠ¨ï¼ˆå¤šæ•°æ®åº“å­˜å‚¨ï¼‰"""
        timestamp = datetime.now()

# 1. å®æ—¶æ•°æ®å­˜å‚¨åˆ°Cassandra
        self.cassandra_session.execute("""
            INSERT INTO user_events (user_id, event_date, event_timestamp, event_type, event_data)
            VALUES (?, ?, ?, ?, ?)
        """, (user_id, timestamp.date(), timestamp, activity_type, json.dumps(activity_data)))

# 2. æ›´æ–°Redisè®¡æ•°å™¨
        counter_key = f"user:activity:{user_id}:{activity_type}"
        self.redis_client.incr(counter_key)
        self.redis_client.expire(counter_key, 86400)  # 24å°æ—¶è¿‡æœŸ

# 3. é‡è¦æ´»åŠ¨å­˜å‚¨åˆ°MongoDB
        if activity_type in ['purchase', 'login', 'profile_update']:
            self.mongo_client.ecommerce.user_activities.insert_one({
                'user_id': user_id,
                'activity_type': activity_type,
                'activity_data': activity_data,
                'timestamp': timestamp
            })

    def get_user_analytics(self, user_id, start_date, end_date):
        """è·å–ç”¨æˆ·åˆ†ææ•°æ®"""
        analytics = {}

# 1. ä»Redisè·å–å®æ—¶è®¡æ•°å™¨
        activity_types = ['view', 'click', 'purchase', 'login']
        for activity_type in activity_types:
            counter_key = f"user:activity:{user_id}:{activity_type}"
            count = self.redis_client.get(counter_key)
            analytics[f'{activity_type}_count'] = int(count) if count else 0

# 2. ä»Cassandraè·å–å†å²äº‹ä»¶
        events = self.cassandra_session.execute("""
            SELECT event_type, event_timestamp, event_data
            FROM user_events
            WHERE user_id = ? AND event_date >= ? AND event_date <= ?
        """, (user_id, start_date, end_date))

        analytics['events'] = [{
            'type': event.event_type,
            'timestamp': event.event_timestamp,
            'data': json.loads(event.event_data)
        } for event in events]

# 3. ä»MongoDBè·å–è¯¦ç»†æ´»åŠ¨
        detailed_activities = self.mongo_client.ecommerce.user_activities.find({
            'user_id': user_id,
            'timestamp': {'$gte': start_date, '$lte': end_date}
        }).sort('timestamp', -1)

        analytics['detailed_activities'] = list(detailed_activities)

        return analytics
```

## 8. æ€§èƒ½ä¼˜åŒ–å®è·µæ¡ˆä¾‹

### 8.1. ç´¢å¼•ä¼˜åŒ–ç­–ç•¥

```javascript
// MongoDBç´¢å¼•ä¼˜åŒ–
// 1. å¤åˆç´¢å¼•
db.orders.createIndex({ userId: 1, status: 1, createdAt: -1 });

// 2. è¦†ç›–ç´¢å¼•
db.products.createIndex({
  categoryId: 1,
  status: 1,
  name: 1,
  price: 1
});

// 3. æ–‡æœ¬æœç´¢ç´¢å¼•
db.products.createIndex({
  name: "text",
  description: "text"
});

// 4. åœ°ç†ç©ºé—´ç´¢å¼•
db.stores.createIndex({ location: "2dsphere" });

// Redisä¼˜åŒ–
// 1. ä½¿ç”¨Pipelineæ‰¹é‡æ“ä½œ
const pipeline = redis.pipeline();
for (let i = 0; i < 1000; i++) {
    pipeline.set(`key:${i}`, `value:${i}`);
}
pipeline.exec();

// 2. ä½¿ç”¨Luaè„šæœ¬åŸå­æ“ä½œ
const luaScript = `
    local key = KEYS[1]
    local value = ARGV[1]
    local ttl = ARGV[2]

    if redis.call('EXISTS', key) == 0 then
        redis.call('SETEX', key, ttl, value)
        return 1
    else
        return 0
    end
`;

redis.eval(luaScript, 1, 'mykey', 'myvalue', 3600);
```

### 8.2. è¿æ¥æ± å’Œé…ç½®ä¼˜åŒ–

```python
# MongoDBè¿æ¥æ± é…ç½®
from pymongo import MongoClient
from pymongo.errors import ConnectionFailure

class MongoDBManager:
    def __init__(self):
        self.client = MongoClient(
            'mongodb://localhost:27017/',
            maxPoolSize=50,           # æœ€å¤§è¿æ¥æ± å¤§å°
            minPoolSize=10,           # æœ€å°è¿æ¥æ± å¤§å°
            maxIdleTimeMS=30000,      # æœ€å¤§ç©ºé—²æ—¶é—´
            waitQueueTimeoutMS=2500,  # ç­‰å¾…é˜Ÿåˆ—è¶…æ—¶
            connectTimeoutMS=2000,    # è¿æ¥è¶…æ—¶
            serverSelectionTimeoutMS=3000  # æœåŠ¡å™¨é€‰æ‹©è¶…æ—¶
        )

    def get_database(self, db_name):
        return self.client[db_name]

    def health_check(self):
        try:
            self.client.admin.command('ping')
            return True
        except ConnectionFailure:
            return False

# Redisè¿æ¥æ± é…ç½®
import redis
from redis.connection import ConnectionPool

class RedisManager:
    def __init__(self):
        self.pool = ConnectionPool(
            host='localhost',
            port=6379,
            db=0,
            max_connections=20,      # æœ€å¤§è¿æ¥æ•°
            retry_on_timeout=True,   # è¶…æ—¶é‡è¯•
            socket_keepalive=True,   # ä¿æŒè¿æ¥
            socket_keepalive_options={}
        )
        self.client = redis.Redis(connection_pool=self.pool)

    def get_client(self):
        return self.client
```

## 9. æ€»ç»“

è¿™äº›å®è·µæ¡ˆä¾‹å±•ç¤ºäº†NoSQLæ•°æ®åº“ç³»ç»Ÿçš„æ ¸å¿ƒåº”ç”¨åœºæ™¯ï¼ŒåŒ…æ‹¬ï¼š

1. **MongoDB**ï¼šæ–‡æ¡£æ•°æ®åº“è®¾è®¡ã€èšåˆç®¡é“ä¼˜åŒ–ã€åˆ†ç‰‡é…ç½®
2. **Redis**ï¼šç¼“å­˜ç­–ç•¥ã€æ•°æ®ç»“æ„åº”ç”¨ã€é™æµå™¨å®ç°
3. **Cassandra**ï¼šæ—¶é—´åºåˆ—æ•°æ®è®¾è®¡ã€æŸ¥è¯¢ä¼˜åŒ–
4. **æ··åˆæ¶æ„**ï¼šå¤šæ•°æ®åº“ååŒå·¥ä½œ
5. **æ€§èƒ½ä¼˜åŒ–**ï¼šç´¢å¼•ä¼˜åŒ–ã€è¿æ¥æ± é…ç½®

æ¯ä¸ªæ¡ˆä¾‹éƒ½æä¾›äº†å®Œæ•´çš„ä»£ç ç¤ºä¾‹å’Œæœ€ä½³å®è·µï¼Œå¯ä»¥ç›´æ¥åº”ç”¨äºå®é™…é¡¹ç›®ä¸­ã€‚

**ç›¸å…³é“¾æ¥ï¼š**

- [1.3.1-å½¢å¼æ¨¡å‹](1.3.1-å½¢å¼æ¨¡å‹.md)
- [1.3.2-ç³»ç»Ÿæ¶æ„](1.3.2-ç³»ç»Ÿæ¶æ„.md)
- [1.3.3-æ•°æ®æ¨¡å‹](1.3.3-æ•°æ®æ¨¡å‹.md)
- [1.3.4-æŸ¥è¯¢ä¸ç´¢å¼•](1.3.4-æŸ¥è¯¢ä¸ç´¢å¼•.md)
- [1.3.5-åˆ†å¸ƒå¼ä¸€è‡´æ€§ä¸CAP](1.3.5-åˆ†å¸ƒå¼ä¸€è‡´æ€§ä¸CAP.md)
- [1.3.6-æ€§èƒ½è°ƒä¼˜ä¸ç›‘æ§](1.3.6-æ€§èƒ½è°ƒä¼˜ä¸ç›‘æ§.md)
- [1.3.7-å®‰å…¨ä¸åˆè§„](1.3.7-å®‰å…¨ä¸åˆè§„.md)
