# 3.5.6 æ•°æ®ç»“æ„è½¬æ¢ä¸å»ºæ¨¡

## ğŸ“‘ ç›®å½•

- [3.5.6 æ•°æ®ç»“æ„è½¬æ¢ä¸å»ºæ¨¡](#356-æ•°æ®ç»“æ„è½¬æ¢ä¸å»ºæ¨¡)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [1. æ¦‚è¿°](#1-æ¦‚è¿°)
    - [1.1. æ•°æ®ç»“æ„ç±»å‹](#11-æ•°æ®ç»“æ„ç±»å‹)
    - [1.2. è½¬æ¢ä¸å»ºæ¨¡æ„ä¹‰](#12-è½¬æ¢ä¸å»ºæ¨¡æ„ä¹‰)
  - [2. æ•°æ®ç»“æ„ç±»å‹](#2-æ•°æ®ç»“æ„ç±»å‹)
    - [2.1. ç»“æ„åŒ–æ•°æ®](#21-ç»“æ„åŒ–æ•°æ®)
      - [2.1.1. ç»“æ„åŒ–æ•°æ®å®šä¹‰](#211-ç»“æ„åŒ–æ•°æ®å®šä¹‰)
    - [2.2. åŠç»“æ„åŒ–æ•°æ®](#22-åŠç»“æ„åŒ–æ•°æ®)
      - [2.2.1. åŠç»“æ„åŒ–æ•°æ®å®šä¹‰](#221-åŠç»“æ„åŒ–æ•°æ®å®šä¹‰)
    - [2.3. éç»“æ„åŒ–æ•°æ®](#23-éç»“æ„åŒ–æ•°æ®)
      - [2.3.1. éç»“æ„åŒ–æ•°æ®å®šä¹‰](#231-éç»“æ„åŒ–æ•°æ®å®šä¹‰)
  - [3. æ•°æ®ç»“æ„è½¬æ¢æ–¹æ³•](#3-æ•°æ®ç»“æ„è½¬æ¢æ–¹æ³•)
    - [3.1. JSONè½¬æ¢](#31-jsonè½¬æ¢)
      - [3.1.1. JSONåˆ°DataFrame](#311-jsonåˆ°dataframe)
      - [3.1.2. DataFrameåˆ°JSON](#312-dataframeåˆ°json)
    - [3.2. XMLè½¬æ¢](#32-xmlè½¬æ¢)
      - [3.2.1. XMLåˆ°DataFrame](#321-xmlåˆ°dataframe)
    - [3.3. CSVè½¬æ¢](#33-csvè½¬æ¢)
      - [3.3.1. CSVè¯»å†™](#331-csvè¯»å†™)
      - [3.3.2. CSVåˆ°JSON](#332-csvåˆ°json)
    - [3.4. Parquetè½¬æ¢](#34-parquetè½¬æ¢)
      - [3.4.1. Parquetè¯»å†™](#341-parquetè¯»å†™)
      - [3.4.2. Parquetä¼˜åŠ¿](#342-parquetä¼˜åŠ¿)
  - [4. æ•°æ®è§„èŒƒåŒ–](#4-æ•°æ®è§„èŒƒåŒ–)
    - [4.1. è§„èŒƒåŒ–åŸåˆ™](#41-è§„èŒƒåŒ–åŸåˆ™)
    - [4.2. è§„èŒƒåŒ–æ–¹æ³•](#42-è§„èŒƒåŒ–æ–¹æ³•)
      - [4.2.1. æ•°æ®æ¸…æ´—](#421-æ•°æ®æ¸…æ´—)
      - [4.2.2. æ•°æ®ç±»å‹è½¬æ¢](#422-æ•°æ®ç±»å‹è½¬æ¢)
      - [4.2.3. æ•°æ®æ ‡å‡†åŒ–](#423-æ•°æ®æ ‡å‡†åŒ–)
  - [5. æ•°æ®å»ºæ¨¡](#5-æ•°æ®å»ºæ¨¡)
    - [5.1. å…³ç³»æ¨¡å‹](#51-å…³ç³»æ¨¡å‹)
      - [5.1.1. å…³ç³»æ¨¡å‹å®šä¹‰](#511-å…³ç³»æ¨¡å‹å®šä¹‰)
    - [5.2. æ–‡æ¡£æ¨¡å‹](#52-æ–‡æ¡£æ¨¡å‹)
      - [5.2.1. æ–‡æ¡£æ¨¡å‹å®šä¹‰](#521-æ–‡æ¡£æ¨¡å‹å®šä¹‰)
    - [5.3. å›¾æ¨¡å‹](#53-å›¾æ¨¡å‹)
      - [5.3.1. å›¾æ¨¡å‹å®šä¹‰](#531-å›¾æ¨¡å‹å®šä¹‰)
  - [6. å®é™…åº”ç”¨æ¡ˆä¾‹](#6-å®é™…åº”ç”¨æ¡ˆä¾‹)
    - [6.1. åŒ»ç–—è¡Œä¸šæ¡ˆä¾‹](#61-åŒ»ç–—è¡Œä¸šæ¡ˆä¾‹)
    - [6.2. é‡‘èè¡Œä¸šæ¡ˆä¾‹](#62-é‡‘èè¡Œä¸šæ¡ˆä¾‹)
  - [7. å½¢å¼åŒ–å®šä¹‰](#7-å½¢å¼åŒ–å®šä¹‰)
    - [7.1. æ•°æ®ç»“æ„è½¬æ¢å½¢å¼åŒ–](#71-æ•°æ®ç»“æ„è½¬æ¢å½¢å¼åŒ–)
    - [7.2. æ•°æ®å»ºæ¨¡å½¢å¼åŒ–](#72-æ•°æ®å»ºæ¨¡å½¢å¼åŒ–)
  - [8. å¤šè¡¨å¾](#8-å¤šè¡¨å¾)
  - [9. æ€»ç»“ä¸å±•æœ›](#9-æ€»ç»“ä¸å±•æœ›)
    - [9.1. æ€»ç»“](#91-æ€»ç»“)
    - [9.2. å‘å±•è¶‹åŠ¿](#92-å‘å±•è¶‹åŠ¿)

## 1. æ¦‚è¿°

### 1.1. æ•°æ®ç»“æ„ç±»å‹

**æ•°æ®ç»“æ„ç±»å‹åˆ†ç±»**ï¼š

1. **ç»“æ„åŒ–æ•°æ®**ï¼šå…³ç³»å‹æ•°æ®åº“ã€è¡¨æ ¼æ•°æ®
2. **åŠç»“æ„åŒ–æ•°æ®**ï¼šJSONã€XMLã€HTML
3. **éç»“æ„åŒ–æ•°æ®**ï¼šæ–‡æœ¬ã€å›¾åƒã€è§†é¢‘

### 1.2. è½¬æ¢ä¸å»ºæ¨¡æ„ä¹‰

**æ•°æ®ç»“æ„è½¬æ¢ä¸å»ºæ¨¡çš„æ„ä¹‰**ï¼š

1. **æ•°æ®ç»Ÿä¸€**ï¼šç»Ÿä¸€æ•°æ®æ ¼å¼
2. **æé«˜æ•ˆç‡**ï¼šæé«˜æ•°æ®å¤„ç†æ•ˆç‡
3. **ä¾¿äºåˆ†æ**ï¼šä¾¿äºæ•°æ®åˆ†æå’Œå»ºæ¨¡
4. **æ•°æ®è´¨é‡**ï¼šæé«˜æ•°æ®è´¨é‡

---

## 2. æ•°æ®ç»“æ„ç±»å‹

### 2.1. ç»“æ„åŒ–æ•°æ®

#### 2.1.1. ç»“æ„åŒ–æ•°æ®å®šä¹‰

**ç»“æ„åŒ–æ•°æ®**ï¼šå…·æœ‰å›ºå®šæ¨¡å¼çš„æ•°æ®ï¼Œé€šå¸¸å­˜å‚¨åœ¨å…³ç³»å‹æ•°æ®åº“ä¸­ã€‚

**ç‰¹ç‚¹**ï¼š

- **å›ºå®šæ¨¡å¼**ï¼šå›ºå®šçš„æ•°æ®ç»“æ„
- **æ˜“äºæŸ¥è¯¢**ï¼šæ˜“äºSQLæŸ¥è¯¢
- **è§„èŒƒåŒ–**ï¼šé«˜åº¦è§„èŒƒåŒ–

**ç¤ºä¾‹**ï¼š

```python
import pandas as pd

# ç»“æ„åŒ–æ•°æ®ç¤ºä¾‹
data = {
    'id': [1, 2, 3],
    'name': ['Alice', 'Bob', 'Charlie'],
    'age': [25, 30, 35]
}

df = pd.DataFrame(data)
print(df)
```

### 2.2. åŠç»“æ„åŒ–æ•°æ®

#### 2.2.1. åŠç»“æ„åŒ–æ•°æ®å®šä¹‰

**åŠç»“æ„åŒ–æ•°æ®**ï¼šå…·æœ‰ä¸€å®šç»“æ„ä½†ä¸å®Œå…¨å›ºå®šçš„æ•°æ®ã€‚

**ç‰¹ç‚¹**ï¼š

- **çµæ´»æ¨¡å¼**ï¼šçµæ´»çš„æ•°æ®ç»“æ„
- **åµŒå¥—ç»“æ„**ï¼šæ”¯æŒåµŒå¥—ç»“æ„
- **è‡ªæè¿°**ï¼šæ•°æ®åŒ…å«ç»“æ„ä¿¡æ¯

**JSONç¤ºä¾‹**ï¼š

```python
import json

# JSONæ•°æ®ç¤ºä¾‹
json_data = {
    "user": {
        "id": 1,
        "name": "Alice",
        "contacts": [
            {"type": "email", "value": "alice@example.com"},
            {"type": "phone", "value": "123-456-7890"}
        ]
    }
}

json_string = json.dumps(json_data, indent=2)
print(json_string)
```

**XMLç¤ºä¾‹**ï¼š

```python
import xml.etree.ElementTree as ET

# XMLæ•°æ®ç¤ºä¾‹
xml_data = """
<user>
    <id>1</id>
    <name>Alice</name>
    <contacts>
        <contact type="email">alice@example.com</contact>
        <contact type="phone">123-456-7890</contact>
    </contacts>
</user>
"""

root = ET.fromstring(xml_data)
print(root.find('name').text)
```

### 2.3. éç»“æ„åŒ–æ•°æ®

#### 2.3.1. éç»“æ„åŒ–æ•°æ®å®šä¹‰

**éç»“æ„åŒ–æ•°æ®**ï¼šæ²¡æœ‰å›ºå®šç»“æ„çš„æ•°æ®ã€‚

**ç‰¹ç‚¹**ï¼š

- **æ— å›ºå®šæ¨¡å¼**ï¼šæ²¡æœ‰å›ºå®šçš„æ•°æ®ç»“æ„
- **å¤šæ ·åŒ–**ï¼šæ–‡æœ¬ã€å›¾åƒã€è§†é¢‘ç­‰
- **éœ€è¦è§£æ**ï¼šéœ€è¦ç‰¹æ®Šå¤„ç†

---

## 3. æ•°æ®ç»“æ„è½¬æ¢æ–¹æ³•

### 3.1. JSONè½¬æ¢

#### 3.1.1. JSONåˆ°DataFrame

**JSONè½¬DataFrame**ï¼š

```python
import json
import pandas as pd

# JSONæ•°æ®
json_data = [
    {"id": 1, "name": "Alice", "age": 25},
    {"id": 2, "name": "Bob", "age": 30},
    {"id": 3, "name": "Charlie", "age": 35}
]

# è½¬æ¢ä¸ºDataFrame
df = pd.DataFrame(json_data)
print(df)
```

#### 3.1.2. DataFrameåˆ°JSON

**DataFrameè½¬JSON**ï¼š

```python
import pandas as pd

# DataFrameæ•°æ®
df = pd.DataFrame({
    'id': [1, 2, 3],
    'name': ['Alice', 'Bob', 'Charlie'],
    'age': [25, 30, 35]
})

# è½¬æ¢ä¸ºJSON
json_string = df.to_json(orient='records', indent=2)
print(json_string)
```

### 3.2. XMLè½¬æ¢

#### 3.2.1. XMLåˆ°DataFrame

**XMLè½¬DataFrame**ï¼š

```python
import xml.etree.ElementTree as ET
import pandas as pd

# XMLæ•°æ®
xml_string = """
<users>
    <user>
        <id>1</id>
        <name>Alice</name>
        <age>25</age>
    </user>
    <user>
        <id>2</id>
        <name>Bob</name>
        <age>30</age>
    </user>
</users>
"""

root = ET.fromstring(xml_string)
data = []
for user in root.findall('user'):
    data.append({
        'id': int(user.find('id').text),
        'name': user.find('name').text,
        'age': int(user.find('age').text)
    })

df = pd.DataFrame(data)
print(df)
```

### 3.3. CSVè½¬æ¢

#### 3.3.1. CSVè¯»å†™

**CSVè¯»å†™**ï¼š

```python
import pandas as pd

# è¯»å–CSV
df = pd.read_csv('data.csv')

# å†™å…¥CSV
df.to_csv('output.csv', index=False)

# è‡ªå®šä¹‰åˆ†éš”ç¬¦
df.to_csv('output.tsv', sep='\t', index=False)
```

#### 3.3.2. CSVåˆ°JSON

**CSVè½¬JSON**ï¼š

```python
import pandas as pd
import json

# è¯»å–CSV
df = pd.read_csv('data.csv')

# è½¬æ¢ä¸ºJSON
json_data = df.to_json(orient='records')
print(json_data)
```

### 3.4. Parquetè½¬æ¢

#### 3.4.1. Parquetè¯»å†™

**Parquetè¯»å†™**ï¼š

```python
import pandas as pd

# è¯»å–Parquet
df = pd.read_parquet('data.parquet')

# å†™å…¥Parquet
df.to_parquet('output.parquet', compression='snappy')

# æŒ‡å®šåˆ†åŒº
df.to_parquet('output.parquet', partition_cols=['year', 'month'])
```

#### 3.4.2. Parquetä¼˜åŠ¿

**Parquetä¼˜åŠ¿**ï¼š

- **åˆ—å¼å­˜å‚¨**ï¼šåˆ—å¼å­˜å‚¨æ ¼å¼
- **å‹ç¼©ç‡é«˜**ï¼šé«˜å‹ç¼©ç‡
- **æŸ¥è¯¢æ•ˆç‡**ï¼šæŸ¥è¯¢æ•ˆç‡é«˜

---

## 4. æ•°æ®è§„èŒƒåŒ–

### 4.1. è§„èŒƒåŒ–åŸåˆ™

**æ•°æ®è§„èŒƒåŒ–åŸåˆ™**ï¼š

1. **å”¯ä¸€æ€§**ï¼šç¡®ä¿æ•°æ®å”¯ä¸€æ€§
2. **ä¸€è‡´æ€§**ï¼šä¿æŒæ•°æ®ä¸€è‡´æ€§
3. **å®Œæ•´æ€§**ï¼šä¿è¯æ•°æ®å®Œæ•´æ€§
4. **å‡†ç¡®æ€§**ï¼šç¡®ä¿æ•°æ®å‡†ç¡®æ€§

### 4.2. è§„èŒƒåŒ–æ–¹æ³•

#### 4.2.1. æ•°æ®æ¸…æ´—

**æ•°æ®æ¸…æ´—**ï¼š

```python
import pandas as pd
import numpy as np

# æ•°æ®æ¸…æ´—ç¤ºä¾‹
df = pd.DataFrame({
    'id': [1, 2, 3, 4, 5],
    'name': ['Alice', 'Bob', None, 'Charlie', ''],
    'age': [25, 30, 35, None, 40],
    'email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', None, 'dave@example.com']
})

# å¤„ç†ç¼ºå¤±å€¼
df['name'] = df['name'].fillna('Unknown')
df['age'] = df['age'].fillna(df['age'].mean())

# å¤„ç†ç©ºå­—ç¬¦ä¸²
df['name'] = df['name'].replace('', 'Unknown')

# å»é‡
df = df.drop_duplicates()

print(df)
```

#### 4.2.2. æ•°æ®ç±»å‹è½¬æ¢

**æ•°æ®ç±»å‹è½¬æ¢**ï¼š

```python
import pandas as pd

# æ•°æ®ç±»å‹è½¬æ¢
df = pd.DataFrame({
    'id': ['1', '2', '3'],
    'age': ['25', '30', '35'],
    'price': ['10.5', '20.3', '30.7']
})

# è½¬æ¢æ•°æ®ç±»å‹
df['id'] = df['id'].astype(int)
df['age'] = df['age'].astype(int)
df['price'] = df['price'].astype(float)

print(df.dtypes)
```

#### 4.2.3. æ•°æ®æ ‡å‡†åŒ–

**æ•°æ®æ ‡å‡†åŒ–**ï¼š

```python
import pandas as pd
from sklearn.preprocessing import StandardScaler

# æ•°æ®æ ‡å‡†åŒ–
df = pd.DataFrame({
    'feature1': [1, 2, 3, 4, 5],
    'feature2': [10, 20, 30, 40, 50]
})

scaler = StandardScaler()
df_scaled = pd.DataFrame(
    scaler.fit_transform(df),
    columns=df.columns
)

print(df_scaled)
```

---

## 5. æ•°æ®å»ºæ¨¡

### 5.1. å…³ç³»æ¨¡å‹

#### 5.1.1. å…³ç³»æ¨¡å‹å®šä¹‰

**å…³ç³»æ¨¡å‹**ï¼šåŸºäºå…³ç³»ä»£æ•°çš„æ•°æ®æ¨¡å‹ã€‚

**ç‰¹ç‚¹**ï¼š

- **è¡¨ç»“æ„**ï¼šäºŒç»´è¡¨ç»“æ„
- **è§„èŒƒåŒ–**ï¼šé«˜åº¦è§„èŒƒåŒ–
- **å®Œæ•´æ€§çº¦æŸ**ï¼šå®Œæ•´æ€§çº¦æŸ

**ç¤ºä¾‹**ï¼š

```python
import pandas as pd

# å…³ç³»æ¨¡å‹ç¤ºä¾‹
users = pd.DataFrame({
    'user_id': [1, 2, 3],
    'name': ['Alice', 'Bob', 'Charlie'],
    'email': ['alice@example.com', 'bob@example.com', 'charlie@example.com']
})

orders = pd.DataFrame({
    'order_id': [1, 2, 3],
    'user_id': [1, 2, 1],
    'amount': [100, 200, 150]
})

# å…³è”æŸ¥è¯¢
result = pd.merge(users, orders, on='user_id')
print(result)
```

### 5.2. æ–‡æ¡£æ¨¡å‹

#### 5.2.1. æ–‡æ¡£æ¨¡å‹å®šä¹‰

**æ–‡æ¡£æ¨¡å‹**ï¼šåŸºäºæ–‡æ¡£çš„æ•°æ®æ¨¡å‹ã€‚

**ç‰¹ç‚¹**ï¼š

- **åµŒå¥—ç»“æ„**ï¼šæ”¯æŒåµŒå¥—ç»“æ„
- **çµæ´»æ¨¡å¼**ï¼šçµæ´»çš„æ•°æ®æ¨¡å¼
- **è‡ªåŒ…å«**ï¼šæ–‡æ¡£è‡ªåŒ…å«

**ç¤ºä¾‹**ï¼š

```python
import json

# æ–‡æ¡£æ¨¡å‹ç¤ºä¾‹
document = {
    "user_id": 1,
    "name": "Alice",
    "orders": [
        {
            "order_id": 1,
            "amount": 100,
            "items": [
                {"product": "Book", "quantity": 2},
                {"product": "Pen", "quantity": 5}
            ]
        },
        {
            "order_id": 2,
            "amount": 150,
            "items": [
                {"product": "Notebook", "quantity": 3}
            ]
        }
    ]
}

print(json.dumps(document, indent=2))
```

### 5.3. å›¾æ¨¡å‹

#### 5.3.1. å›¾æ¨¡å‹å®šä¹‰

**å›¾æ¨¡å‹**ï¼šåŸºäºå›¾çš„æ•°æ®æ¨¡å‹ã€‚

**ç‰¹ç‚¹**ï¼š

- **èŠ‚ç‚¹å’Œè¾¹**ï¼šèŠ‚ç‚¹å’Œè¾¹ç»“æ„
- **å…³ç³»è¡¨è¾¾**ï¼šè¡¨è¾¾å¤æ‚å…³ç³»
- **å›¾æŸ¥è¯¢**ï¼šæ”¯æŒå›¾æŸ¥è¯¢

**ç¤ºä¾‹**ï¼š

```python
import networkx as nx

# å›¾æ¨¡å‹ç¤ºä¾‹
G = nx.Graph()

# æ·»åŠ èŠ‚ç‚¹
G.add_node(1, name='Alice', age=25)
G.add_node(2, name='Bob', age=30)
G.add_node(3, name='Charlie', age=35)

# æ·»åŠ è¾¹
G.add_edge(1, 2, relation='friend')
G.add_edge(2, 3, relation='colleague')
G.add_edge(1, 3, relation='friend')

# æŸ¥è¯¢
print(f"Nodes: {list(G.nodes(data=True))}")
print(f"Edges: {list(G.edges(data=True))}")
```

---

## 6. å®é™…åº”ç”¨æ¡ˆä¾‹

### 6.1. åŒ»ç–—è¡Œä¸šæ¡ˆä¾‹

**åœºæ™¯**ï¼š

- ç”µå­ç—…å†ï¼ˆEMRï¼‰æ•°æ®ä»XML/JSONè½¬æ¢ä¸ºç»“æ„åŒ–è¡¨ï¼Œä¾¿äºåˆ†æä¸å»ºæ¨¡
- å…¸å‹æµç¨‹ï¼šæ•°æ®é‡‡é›†ã€æ ¼å¼è½¬æ¢ã€è§„èŒƒåŒ–ã€å…¥åº“

**å®ç°**ï¼š

```python
import json
import pandas as pd
from datetime import datetime

# ç”µå­ç—…å†JSONæ•°æ®
emr_json = {
    "patient_id": "P001",
    "name": "John Doe",
    "birth_date": "1980-01-01",
    "visits": [
        {
            "visit_date": "2024-01-15",
            "diagnosis": "Hypertension",
            "medications": ["Lisinopril", "Amlodipine"]
        },
        {
            "visit_date": "2024-02-20",
            "diagnosis": "Diabetes",
            "medications": ["Metformin"]
        }
    ]
}

# è½¬æ¢ä¸ºç»“æ„åŒ–è¡¨
visits_data = []
for visit in emr_json['visits']:
    visits_data.append({
        'patient_id': emr_json['patient_id'],
        'visit_date': visit['visit_date'],
        'diagnosis': visit['diagnosis'],
        'medications': ', '.join(visit['medications'])
    })

df_visits = pd.DataFrame(visits_data)
print(df_visits)
```

### 6.2. é‡‘èè¡Œä¸šæ¡ˆä¾‹

**åœºæ™¯**ï¼š

- äº¤æ˜“æµæ°´æ•°æ®ä»å¤šæ ¼å¼ï¼ˆCSVã€JSONï¼‰å½’ä¸€åŒ–ä¸ºåˆ†æå‹è¡¨ç»“æ„
- å…¸å‹æµç¨‹ï¼šå¤šæºé‡‡é›†ã€æ•°æ®æ¸…æ´—ã€ç»“æ„è½¬æ¢ã€å»ºæ¨¡

**å®ç°**ï¼š

```python
import pandas as pd
from datetime import datetime

# å¤šæºæ•°æ®
csv_data = pd.read_csv('transactions.csv')
json_data = pd.read_json('transactions.json')

# æ•°æ®è§„èŒƒåŒ–
def normalize_transaction(df):
    """è§„èŒƒåŒ–äº¤æ˜“æ•°æ®"""
    df['transaction_date'] = pd.to_datetime(df['transaction_date'])
    df['amount'] = pd.to_numeric(df['amount'], errors='coerce')
    df['transaction_type'] = df['transaction_type'].str.upper()
    return df

# è§„èŒƒåŒ–å¹¶åˆå¹¶
csv_normalized = normalize_transaction(csv_data)
json_normalized = normalize_transaction(json_data)

# åˆå¹¶æ•°æ®
all_transactions = pd.concat([csv_normalized, json_normalized], ignore_index=True)

# æ•°æ®å»ºæ¨¡ï¼šæŒ‰æ—¥æœŸå’Œç±»å‹èšåˆ
summary = all_transactions.groupby(['transaction_date', 'transaction_type']).agg({
    'amount': ['sum', 'count', 'mean']
}).reset_index()

print(summary)
```

---

## 7. å½¢å¼åŒ–å®šä¹‰

### 7.1. æ•°æ®ç»“æ„è½¬æ¢å½¢å¼åŒ–

**æ•°æ®ç»“æ„è½¬æ¢å®šä¹‰**ï¼š

è®¾è½¬æ¢å‡½æ•° $T: D_1 \to D_2$ï¼Œå…¶ä¸­ï¼š

- $D_1$ï¼šæºæ•°æ®ç»“æ„
- $D_2$ï¼šç›®æ ‡æ•°æ®ç»“æ„

è½¬æ¢ä¿æŒæ•°æ®è¯­ä¹‰ï¼š

$$\forall d \in D_1, \text{Semantics}(d) = \text{Semantics}(T(d))$$

### 7.2. æ•°æ®å»ºæ¨¡å½¢å¼åŒ–

**æ•°æ®æ¨¡å‹å®šä¹‰**ï¼š

æ•°æ®æ¨¡å‹ $M = (S, C, O)$ï¼Œå…¶ä¸­ï¼š

- $S$ï¼šç»“æ„å®šä¹‰
- $C$ï¼šçº¦æŸæ¡ä»¶
- $O$ï¼šæ“ä½œé›†åˆ

---

## 8. å¤šè¡¨å¾

æœ¬ä¸»é¢˜æ”¯æŒå¤šç§è¡¨å¾æ–¹å¼ï¼š

1. **ç¬¦å·è¡¨å¾**ï¼šå½¢å¼åŒ–å®šä¹‰ã€æ•°å­¦å…¬å¼
2. **å›¾ç»“æ„**ï¼šæ•°æ®æµç¨‹å›¾ã€ERå›¾ã€å›¾æ¨¡å‹
3. **ä»£ç å®ç°**ï¼šè½¬æ¢ä»£ç ç¤ºä¾‹
4. **è‡ªç„¶è¯­è¨€**ï¼šæ¦‚å¿µå®šä¹‰ã€è½¬æ¢æ–¹æ³•
5. **å¯è§†åŒ–**ï¼šæ•°æ®è½¬æ¢å¯è§†åŒ–ã€æ¨¡å‹å¯è§†åŒ–

---

## 9. æ€»ç»“ä¸å±•æœ›

### 9.1. æ€»ç»“

æ•°æ®ç»“æ„è½¬æ¢ä¸å»ºæ¨¡çš„æ ¸å¿ƒè¦ç‚¹ï¼š

1. **æ•°æ®ç»“æ„ç±»å‹**ï¼šç»“æ„åŒ–ã€åŠç»“æ„åŒ–ã€éç»“æ„åŒ–
2. **è½¬æ¢æ–¹æ³•**ï¼šJSONã€XMLã€CSVã€Parquetè½¬æ¢
3. **æ•°æ®è§„èŒƒåŒ–**ï¼šæ¸…æ´—ã€ç±»å‹è½¬æ¢ã€æ ‡å‡†åŒ–
4. **æ•°æ®å»ºæ¨¡**ï¼šå…³ç³»æ¨¡å‹ã€æ–‡æ¡£æ¨¡å‹ã€å›¾æ¨¡å‹

### 9.2. å‘å±•è¶‹åŠ¿

**æœªæ¥å‘å±•æ–¹å‘**ï¼š

1. **è‡ªåŠ¨åŒ–è½¬æ¢**ï¼šè‡ªåŠ¨åŒ–æ•°æ®è½¬æ¢
2. **æ™ºèƒ½å»ºæ¨¡**ï¼šAIé©±åŠ¨çš„æ•°æ®å»ºæ¨¡
3. **ç»Ÿä¸€æ ¼å¼**ï¼šç»Ÿä¸€æ•°æ®æ ¼å¼æ ‡å‡†

---

**å‚è€ƒæ–‡çŒ®**ï¼š

1. Codd, E. F. (1970). "A Relational Model of Data for Large Shared Data Banks"
2. Abiteboul, S., et al. (2000). "Data on the Web: From Relations to Semistructured Data and XML"

---

[è¿”å›æ•°æ®åˆ†æä¸ETLå¯¼èˆª](../README.md)
