# AI与机器学习算法实践案例

## 1. 监督学习实践案例

### 1.1 线性回归与逻辑回归

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler

# 线性回归示例
class LinearRegressionExample:
    def __init__(self):
        self.model = LinearRegression()
        self.scaler = StandardScaler()
    
    def generate_data(self, n_samples=100):
        """生成示例数据"""
        np.random.seed(42)
        X = np.random.randn(n_samples, 2)
        # 真实关系: y = 2*x1 + 3*x2 + 1 + noise
        y = 2 * X[:, 0] + 3 * X[:, 1] + 1 + np.random.normal(0, 0.1, n_samples)
        return X, y
    
    def train(self, X, y):
        """训练模型"""
        X_scaled = self.scaler.fit_transform(X)
        self.model.fit(X_scaled, y)
        
        # 打印模型参数
        print(f"截距: {self.model.intercept_:.4f}")
        print(f"系数: {self.model.coef_}")
    
    def predict(self, X):
        """预测"""
        X_scaled = self.scaler.transform(X)
        return self.model.predict(X_scaled)
    
    def evaluate(self, X, y):
        """评估模型"""
        y_pred = self.predict(X)
        mse = mean_squared_error(y, y_pred)
        print(f"均方误差: {mse:.4f}")
        return mse

# 逻辑回归示例
class LogisticRegressionExample:
    def __init__(self):
        self.model = LogisticRegression(random_state=42)
        self.scaler = StandardScaler()
    
    def generate_data(self, n_samples=200):
        """生成二分类数据"""
        np.random.seed(42)
        # 两个高斯分布
        X1 = np.random.multivariate_normal([0, 0], [[1, 0.5], [0.5, 1]], n_samples//2)
        X2 = np.random.multivariate_normal([2, 2], [[1, 0.5], [0.5, 1]], n_samples//2)
        
        X = np.vstack([X1, X2])
        y = np.hstack([np.zeros(n_samples//2), np.ones(n_samples//2)])
        
        return X, y
    
    def train(self, X, y):
        """训练模型"""
        X_scaled = self.scaler.fit_transform(X)
        self.model.fit(X_scaled, y)
        
        print(f"截距: {self.model.intercept_[0]:.4f}")
        print(f"系数: {self.model.coef_[0]}")
    
    def predict(self, X):
        """预测"""
        X_scaled = self.scaler.transform(X)
        return self.model.predict(X_scaled)
    
    def predict_proba(self, X):
        """预测概率"""
        X_scaled = self.scaler.transform(X)
        return self.model.predict_proba(X_scaled)
    
    def evaluate(self, X, y):
        """评估模型"""
        y_pred = self.predict(X)
        accuracy = accuracy_score(y, y_pred)
        print(f"准确率: {accuracy:.4f}")
        print("\n分类报告:")
        print(classification_report(y, y_pred))
        return accuracy

# 使用示例
print("=== 线性回归示例 ===")
lr_example = LinearRegressionExample()
X, y = lr_example.generate_data()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

lr_example.train(X_train, y_train)
lr_example.evaluate(X_test, y_test)

print("\n=== 逻辑回归示例 ===")
logreg_example = LogisticRegressionExample()
X, y = logreg_example.generate_data()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

logreg_example.train(X_train, y_train)
logreg_example.evaluate(X_test, y_test)
```

### 1.2 决策树与随机森林

```python
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
import pandas as pd

class DecisionTreeExample:
    def __init__(self, max_depth=3):
        self.model = DecisionTreeClassifier(max_depth=max_depth, random_state=42)
    
    def generate_data(self, n_samples=300):
        """生成多分类数据"""
        X, y = make_classification(
            n_samples=n_samples,
            n_features=4,
            n_informative=3,
            n_redundant=1,
            n_classes=3,
            random_state=42
        )
        return X, y
    
    def train(self, X, y):
        """训练模型"""
        self.model.fit(X, y)
        
        # 特征重要性
        feature_importance = pd.DataFrame({
            'feature': [f'Feature_{i}' for i in range(X.shape[1])],
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("特征重要性:")
        print(feature_importance)
    
    def predict(self, X):
        """预测"""
        return self.model.predict(X)
    
    def evaluate(self, X, y):
        """评估模型"""
        y_pred = self.predict(X)
        accuracy = accuracy_score(y, y_pred)
        print(f"决策树准确率: {accuracy:.4f}")
        return accuracy

class RandomForestExample:
    def __init__(self, n_estimators=100, max_depth=5):
        self.model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            random_state=42
        )
    
    def train(self, X, y):
        """训练模型"""
        self.model.fit(X, y)
        
        # 特征重要性
        feature_importance = pd.DataFrame({
            'feature': [f'Feature_{i}' for i in range(X.shape[1])],
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("随机森林特征重要性:")
        print(feature_importance)
    
    def predict(self, X):
        """预测"""
        return self.model.predict(X)
    
    def predict_proba(self, X):
        """预测概率"""
        return self.model.predict_proba(X)
    
    def evaluate(self, X, y):
        """评估模型"""
        y_pred = self.predict(X)
        accuracy = accuracy_score(y, y_pred)
        print(f"随机森林准确率: {accuracy:.4f}")
        return accuracy

# 使用示例
print("=== 决策树示例 ===")
dt_example = DecisionTreeExample(max_depth=3)
X, y = dt_example.generate_data()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

dt_example.train(X_train, y_train)
dt_example.evaluate(X_test, y_test)

print("\n=== 随机森林示例 ===")
rf_example = RandomForestExample(n_estimators=50, max_depth=5)
rf_example.train(X_train, y_train)
rf_example.evaluate(X_test, y_test)
```

## 2. 无监督学习实践案例

### 2.1 K-means聚类

```python
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

class KMeansExample:
    def __init__(self, n_clusters=3):
        self.model = KMeans(n_clusters=n_clusters, random_state=42)
        self.n_clusters = n_clusters
    
    def generate_data(self, n_samples=300):
        """生成聚类数据"""
        X, _ = make_blobs(
            n_samples=n_samples,
            centers=4,
            cluster_std=0.6,
            random_state=42
        )
        return X
    
    def train(self, X):
        """训练模型"""
        self.model.fit(X)
        
        # 聚类中心
        print(f"聚类中心:\n{self.model.cluster_centers_}")
        
        # 轮廓系数
        labels = self.model.labels_
        silhouette_avg = silhouette_score(X, labels)
        print(f"平均轮廓系数: {silhouette_avg:.4f}")
    
    def predict(self, X):
        """预测聚类标签"""
        return self.model.predict(X)
    
    def find_optimal_k(self, X, max_k=10):
        """寻找最优聚类数"""
        silhouette_scores = []
        inertias = []
        
        for k in range(2, max_k + 1):
            kmeans = KMeans(n_clusters=k, random_state=42)
            kmeans.fit(X)
            
            labels = kmeans.labels_
            silhouette_avg = silhouette_score(X, labels)
            silhouette_scores.append(silhouette_avg)
            inertias.append(kmeans.inertia_)
            
            print(f"k={k}: 轮廓系数={silhouette_avg:.4f}, 惯性={kmeans.inertia_:.2f}")
        
        optimal_k = silhouette_scores.index(max(silhouette_scores)) + 2
        print(f"\n最优聚类数: {optimal_k}")
        
        return optimal_k, silhouette_scores, inertias

# 使用示例
print("=== K-means聚类示例 ===")
kmeans_example = KMeansExample(n_clusters=4)
X = kmeans_example.generate_data()

# 寻找最优聚类数
optimal_k, scores, inertias = kmeans_example.find_optimal_k(X)

# 使用最优聚类数重新训练
kmeans_example = KMeansExample(n_clusters=optimal_k)
kmeans_example.train(X)
labels = kmeans_example.predict(X)

print(f"聚类结果: {np.bincount(labels)}")
```

### 2.2 主成分分析(PCA)

```python
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

class PCAExample:
    def __init__(self, n_components=2):
        self.pca = PCA(n_components=n_components)
        self.scaler = StandardScaler()
    
    def generate_data(self, n_samples=1000):
        """生成高维数据"""
        np.random.seed(42)
        # 生成相关的高维数据
        X = np.random.randn(n_samples, 10)
        # 添加一些相关性
        X[:, 2] = X[:, 0] + X[:, 1] + np.random.normal(0, 0.1, n_samples)
        X[:, 3] = X[:, 0] * 2 + np.random.normal(0, 0.1, n_samples)
        return X
    
    def fit_transform(self, X):
        """拟合并转换数据"""
        X_scaled = self.scaler.fit_transform(X)
        X_pca = self.pca.fit_transform(X_scaled)
        
        # 解释方差比
        explained_variance_ratio = self.pca.explained_variance_ratio_
        cumulative_variance_ratio = np.cumsum(explained_variance_ratio)
        
        print("解释方差比:")
        for i, (var_ratio, cum_var_ratio) in enumerate(zip(explained_variance_ratio, cumulative_variance_ratio)):
            print(f"PC{i+1}: {var_ratio:.4f} (累计: {cum_var_ratio:.4f})")
        
        return X_pca
    
    def transform(self, X):
        """转换新数据"""
        X_scaled = self.scaler.transform(X)
        return self.pca.transform(X_scaled)
    
    def inverse_transform(self, X_pca):
        """逆转换"""
        X_scaled = self.pca.inverse_transform(X_pca)
        return self.scaler.inverse_transform(X_scaled)
    
    def find_optimal_components(self, X, threshold=0.95):
        """寻找最优主成分数"""
        X_scaled = self.scaler.fit_transform(X)
        
        # 使用所有主成分
        pca_full = PCA()
        pca_full.fit(X_scaled)
        
        # 计算累计解释方差
        cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)
        
        # 找到达到阈值所需的主成分数
        n_components = np.argmax(cumulative_variance >= threshold) + 1
        
        print(f"达到{threshold*100}%解释方差需要的主成分数: {n_components}")
        
        return n_components

# 使用示例
print("=== PCA降维示例 ===")
pca_example = PCAExample(n_components=2)
X = pca_example.generate_data()

# 寻找最优主成分数
optimal_components = pca_example.find_optimal_components(X, threshold=0.9)

# 使用2个主成分进行降维
X_pca = pca_example.fit_transform(X)
print(f"原始维度: {X.shape[1]}")
print(f"降维后维度: {X_pca.shape[1]}")

# 逆转换示例
X_reconstructed = pca_example.inverse_transform(X_pca)
reconstruction_error = np.mean((X - X_reconstructed) ** 2)
print(f"重构误差: {reconstruction_error:.6f}")
```

## 3. 深度学习实践案例

### 3.1 简单神经网络

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

class SimpleNeuralNetwork(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SimpleNeuralNetwork, self).__init__()
        self.layer1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.layer2 = nn.Linear(hidden_size, hidden_size)
        self.output = nn.Linear(hidden_size, output_size)
        self.dropout = nn.Dropout(0.2)
    
    def forward(self, x):
        x = self.layer1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.layer2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.output(x)
        return x

class DeepLearningExample:
    def __init__(self, input_size, hidden_size, output_size):
        self.model = SimpleNeuralNetwork(input_size, hidden_size, output_size)
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
    
    def generate_data(self, n_samples=1000):
        """生成分类数据"""
        np.random.seed(42)
        X = np.random.randn(n_samples, 10)
        y = np.random.randint(0, 3, n_samples)
        return X, y
    
    def train(self, X, y, epochs=100, batch_size=32):
        """训练模型"""
        # 转换为PyTorch张量
        X_tensor = torch.FloatTensor(X)
        y_tensor = torch.LongTensor(y)
        
        # 创建数据加载器
        dataset = TensorDataset(X_tensor, y_tensor)
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
        
        train_losses = []
        
        for epoch in range(epochs):
            self.model.train()
            total_loss = 0
            
            for batch_X, batch_y in dataloader:
                batch_X = batch_X.to(self.device)
                batch_y = batch_y.to(self.device)
                
                # 前向传播
                outputs = self.model(batch_X)
                loss = self.criterion(outputs, batch_y)
                
                # 反向传播
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()
                
                total_loss += loss.item()
            
            avg_loss = total_loss / len(dataloader)
            train_losses.append(avg_loss)
            
            if (epoch + 1) % 20 == 0:
                print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')
        
        return train_losses
    
    def predict(self, X):
        """预测"""
        self.model.eval()
        with torch.no_grad():
            X_tensor = torch.FloatTensor(X).to(self.device)
            outputs = self.model(X_tensor)
            _, predicted = torch.max(outputs.data, 1)
            return predicted.cpu().numpy()
    
    def evaluate(self, X, y):
        """评估模型"""
        y_pred = self.predict(X)
        accuracy = accuracy_score(y, y_pred)
        print(f"神经网络准确率: {accuracy:.4f}")
        return accuracy

# 使用示例
print("=== 深度学习示例 ===")
dl_example = DeepLearningExample(input_size=10, hidden_size=64, output_size=3)
X, y = dl_example.generate_data()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 训练模型
train_losses = dl_example.train(X_train, y_train, epochs=100, batch_size=32)

# 评估模型
dl_example.evaluate(X_test, y_test)
```

### 3.2 卷积神经网络(CNN)

```python
import torchvision.transforms as transforms
from torchvision import datasets

class CNNExample:
    def __init__(self):
        self.model = self.build_cnn()
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
    
    def build_cnn(self):
        """构建CNN模型"""
        model = nn.Sequential(
            # 第一个卷积块
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            
            # 第二个卷积块
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            
            # 全连接层
            nn.Flatten(),
            nn.Linear(64 * 7 * 7, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, 10)
        )
        return model
    
    def load_mnist_data(self, batch_size=64):
        """加载MNIST数据集"""
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
        
        # 加载训练数据
        train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        
        # 加载测试数据
        test_dataset = datasets.MNIST('./data', train=False, transform=transform)
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
        
        return train_loader, test_loader
    
    def train_epoch(self, train_loader):
        """训练一个epoch"""
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(self.device), target.to(self.device)
            
            self.optimizer.zero_grad()
            output = self.model(data)
            loss = self.criterion(output, target)
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
            total += target.size(0)
        
        return total_loss / len(train_loader), correct / total
    
    def test(self, test_loader):
        """测试模型"""
        self.model.eval()
        test_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(self.device), target.to(self.device)
                output = self.model(data)
                test_loss += self.criterion(output, target).item()
                pred = output.argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()
                total += target.size(0)
        
        test_loss /= len(test_loader)
        accuracy = correct / total
        
        print(f'测试集: 平均损失: {test_loss:.4f}, 准确率: {accuracy:.4f}')
        return test_loss, accuracy

# 使用示例（简化版，实际运行需要下载MNIST数据集）
print("=== CNN示例 ===")
print("注意: 此示例需要下载MNIST数据集，实际运行时请确保网络连接")

# cnn_example = CNNExample()
# train_loader, test_loader = cnn_example.load_mnist_data()

# # 训练模型
# for epoch in range(5):
#     train_loss, train_acc = cnn_example.train_epoch(train_loader)
#     print(f'Epoch {epoch+1}: 训练损失={train_loss:.4f}, 训练准确率={train_acc:.4f}')
#     cnn_example.test(test_loader)
```

## 4. 强化学习实践案例

### 4.1 Q-Learning

```python
import random
from collections import defaultdict

class QLearningExample:
    def __init__(self, n_states, n_actions, learning_rate=0.1, discount_factor=0.95, epsilon=0.1):
        self.n_states = n_states
        self.n_actions = n_actions
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.epsilon = epsilon
        self.q_table = defaultdict(lambda: np.zeros(n_actions))
    
    def choose_action(self, state):
        """选择动作（ε-贪婪策略）"""
        if random.random() < self.epsilon:
            return random.randint(0, self.n_actions - 1)
        else:
            return np.argmax(self.q_table[state])
    
    def update_q_value(self, state, action, reward, next_state):
        """更新Q值"""
        current_q = self.q_table[state][action]
        max_next_q = np.max(self.q_table[next_state])
        new_q = current_q + self.learning_rate * (reward + self.discount_factor * max_next_q - current_q)
        self.q_table[state][action] = new_q
    
    def train(self, episodes=1000):
        """训练Q-Learning智能体"""
        # 简单的网格世界环境
        # 0: 普通格子, 1: 目标, -1: 陷阱
        grid = [
            [0, 0, 0, 1],
            [0, -1, 0, -1],
            [0, 0, 0, 0],
            [-1, 0, 0, 0]
        ]
        
        total_rewards = []
        
        for episode in range(episodes):
            state = (0, 0)  # 起始位置
            total_reward = 0
            
            for step in range(100):  # 最大步数
                # 选择动作
                action = self.choose_action(state)
                
                # 执行动作
                next_state = self.get_next_state(state, action, grid)
                reward = grid[next_state[0]][next_state[1]]
                
                # 更新Q值
                self.update_q_value(state, action, reward, next_state)
                
                total_reward += reward
                state = next_state
                
                # 检查是否到达目标或陷阱
                if reward == 1 or reward == -1:
                    break
            
            total_rewards.append(total_reward)
            
            if (episode + 1) % 100 == 0:
                avg_reward = np.mean(total_rewards[-100:])
                print(f"Episode {episode+1}, 平均奖励: {avg_reward:.2f}")
        
        return total_rewards
    
    def get_next_state(self, state, action, grid):
        """获取下一个状态"""
        row, col = state
        n_rows, n_cols = len(grid), len(grid[0])
        
        if action == 0:  # 上
            next_row = max(0, row - 1)
            next_col = col
        elif action == 1:  # 下
            next_row = min(n_rows - 1, row + 1)
            next_col = col
        elif action == 2:  # 左
            next_row = row
            next_col = max(0, col - 1)
        else:  # 右
            next_row = row
            next_col = min(n_cols - 1, col + 1)
        
        return (next_row, next_col)
    
    def get_optimal_policy(self):
        """获取最优策略"""
        policy = {}
        for state in self.q_table:
            policy[state] = np.argmax(self.q_table[state])
        return policy

# 使用示例
print("=== Q-Learning示例 ===")
ql_example = QLearningExample(n_states=16, n_actions=4, learning_rate=0.1, epsilon=0.1)
rewards = ql_example.train(episodes=500)

# 获取最优策略
optimal_policy = ql_example.get_optimal_policy()
print("\n最优策略:")
for state, action in optimal_policy.items():
    action_names = ['上', '下', '左', '右']
    print(f"状态 {state}: {action_names[action]}")
```

这些实践案例展示了AI与机器学习算法中的核心概念和实际应用，包括监督学习、无监督学习、深度学习和强化学习等。每个案例都提供了完整的代码实现和使用示例，帮助理解这些算法的实际应用。
