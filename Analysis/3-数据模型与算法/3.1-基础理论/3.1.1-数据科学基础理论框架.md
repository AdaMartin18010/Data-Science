# 3.1.1-æ•°æ®ç§‘å­¦åŸºç¡€ç†è®ºæ¡†æ¶

## ğŸ“‘ ç›®å½•

- [3.1.1-æ•°æ®ç§‘å­¦åŸºç¡€ç†è®ºæ¡†æ¶](#311-æ•°æ®ç§‘å­¦åŸºç¡€ç†è®ºæ¡†æ¶)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [æ¦‚è¿°](#æ¦‚è¿°)
  - [æ•°æ®ç§‘å­¦å®šä¹‰](#æ•°æ®ç§‘å­¦å®šä¹‰)
    - [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
    - [ä¸»è¦ç›®æ ‡](#ä¸»è¦ç›®æ ‡)
  - [æ•°æ®ç§‘å­¦æ–¹æ³•è®º](#æ•°æ®ç§‘å­¦æ–¹æ³•è®º)
    - [CRISP-DMæ¨¡å‹](#crisp-dmæ¨¡å‹)
    - [åŸºæœ¬æµç¨‹](#åŸºæœ¬æµç¨‹)
  - [æ•°æ®ç±»å‹](#æ•°æ®ç±»å‹)
    - [åˆ†ç±»](#åˆ†ç±»)
    - [è´¨é‡ç»´åº¦](#è´¨é‡ç»´åº¦)
  - [ç»Ÿè®¡å­¦ä¹ ç†è®º](#ç»Ÿè®¡å­¦ä¹ ç†è®º)
    - [ç›‘ç£å­¦ä¹ ](#ç›‘ç£å­¦ä¹ )
    - [æ— ç›‘ç£å­¦ä¹ ](#æ— ç›‘ç£å­¦ä¹ )
  - [æœºå™¨å­¦ä¹ åŸºç¡€](#æœºå™¨å­¦ä¹ åŸºç¡€)
    - [æ¨¡å‹è¯„ä¼°](#æ¨¡å‹è¯„ä¼°)
    - [äº¤å‰éªŒè¯](#äº¤å‰éªŒè¯)
  - [æ•°æ®å¯è§†åŒ–](#æ•°æ®å¯è§†åŒ–)
    - [åŸºæœ¬åŸåˆ™](#åŸºæœ¬åŸåˆ™)
    - [å¸¸ç”¨å›¾è¡¨](#å¸¸ç”¨å›¾è¡¨)
  - [æ•°æ®ç§‘å­¦ä¼¦ç†](#æ•°æ®ç§‘å­¦ä¼¦ç†)
    - [éšç§ä¿æŠ¤](#éšç§ä¿æŠ¤)
    - [å…¬å¹³æ€§æ£€æŸ¥](#å…¬å¹³æ€§æ£€æŸ¥)
  - [æŠ€æœ¯æ ˆ](#æŠ€æœ¯æ ˆ)
    - [æ ¸å¿ƒå·¥å…·](#æ ¸å¿ƒå·¥å…·)
  - [æ€»ç»“](#æ€»ç»“)

---


## æ¦‚è¿°

æ•°æ®ç§‘å­¦åŸºç¡€ç†è®ºæ¡†æ¶æ˜¯æ•°æ®ç§‘å­¦å­¦ç§‘çš„ç†è®ºåŸºç¡€ï¼Œæ¶µç›–äº†æ•°æ®å¤„ç†ã€åˆ†æå’Œåº”ç”¨çš„æ ¸å¿ƒæ¦‚å¿µã€‚

## æ•°æ®ç§‘å­¦å®šä¹‰

### æ ¸å¿ƒæ¦‚å¿µ

```text
æ•°æ®ç§‘å­¦ = ç»Ÿè®¡å­¦ + è®¡ç®—æœºç§‘å­¦ + é¢†åŸŸçŸ¥è¯†
```

### ä¸»è¦ç›®æ ‡

1. æ•°æ®ç†è§£ä¸æ¢ç´¢
2. æ¨¡å¼å‘ç°ä¸é¢„æµ‹
3. å†³ç­–æ”¯æŒä¸ä¼˜åŒ–

## æ•°æ®ç§‘å­¦æ–¹æ³•è®º

### CRISP-DMæ¨¡å‹

1. ä¸šåŠ¡ç†è§£
2. æ•°æ®ç†è§£
3. æ•°æ®å‡†å¤‡
4. å»ºæ¨¡
5. è¯„ä¼°
6. éƒ¨ç½²

### åŸºæœ¬æµç¨‹

```python
import pandas as pd
from sklearn.model_selection import train_test_split

# æ•°æ®åŠ è½½
data = pd.read_csv('data.csv')

# æ•°æ®é¢„å¤„ç†
X = data.drop('target', axis=1)
y = data['target']

# æ¨¡å‹è®­ç»ƒ
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
```

## æ•°æ®ç±»å‹

### åˆ†ç±»

- ç»“æ„åŒ–æ•°æ®ï¼šè¡¨æ ¼ã€æ•°æ®åº“
- åŠç»“æ„åŒ–æ•°æ®ï¼šJSONã€XML
- éç»“æ„åŒ–æ•°æ®ï¼šæ–‡æœ¬ã€å›¾åƒ

### è´¨é‡ç»´åº¦

- å®Œæ•´æ€§
- ä¸€è‡´æ€§
- å‡†ç¡®æ€§
- åŠæ—¶æ€§

## ç»Ÿè®¡å­¦ä¹ ç†è®º

### ç›‘ç£å­¦ä¹ 

```python
class SupervisedLearning:
    def train(self, X, y):
        self.model.fit(X, y)

    def predict(self, X):
        return self.model.predict(X)
```

### æ— ç›‘ç£å­¦ä¹ 

```python
class UnsupervisedLearning:
    def fit(self, X):
        self.model.fit(X)

    def transform(self, X):
        return self.model.transform(X)
```

## æœºå™¨å­¦ä¹ åŸºç¡€

### æ¨¡å‹è¯„ä¼°

```python
from sklearn.metrics import accuracy_score

def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)
```

### äº¤å‰éªŒè¯

```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X, y, cv=5)
print(f"å¹³å‡åˆ†æ•°: {scores.mean():.3f}")
```

## æ•°æ®å¯è§†åŒ–

### åŸºæœ¬åŸåˆ™

1. ç®€æ´æ€§
2. æ¸…æ™°æ€§
3. å‡†ç¡®æ€§

### å¸¸ç”¨å›¾è¡¨

```python
import matplotlib.pyplot as plt

def plot_distribution(data, column):
    plt.hist(data[column])
    plt.title(f'{column}åˆ†å¸ƒ')
    plt.show()
```

## æ•°æ®ç§‘å­¦ä¼¦ç†

### éšç§ä¿æŠ¤

```python
def anonymize_data(data, sensitive_columns):
    for col in sensitive_columns:
        data[col] = data[col].apply(hash)
    return data
```

### å…¬å¹³æ€§æ£€æŸ¥

```python
def check_fairness(model, X, y, sensitive_attribute):
    groups = X[sensitive_attribute].unique()
    for group in groups:
        mask = X[sensitive_attribute] == group
        accuracy = model.score(X[mask], y[mask])
        print(f"ç»„ {group}: {accuracy:.3f}")
```

## æŠ€æœ¯æ ˆ

### æ ¸å¿ƒå·¥å…·

- æ•°æ®å¤„ç†ï¼špandas, numpy
- æœºå™¨å­¦ä¹ ï¼šscikit-learn, xgboost
- å¯è§†åŒ–ï¼šmatplotlib, seaborn
- æ·±åº¦å­¦ä¹ ï¼štensorflow, pytorch

## æ€»ç»“

æ•°æ®ç§‘å­¦åŸºç¡€ç†è®ºæ¡†æ¶ä¸ºæ•°æ®ç§‘å­¦å®è·µæä¾›äº†ç³»ç»Ÿæ€§çš„æ–¹æ³•è®ºå’Œç†è®ºåŸºç¡€ï¼Œæ¶µç›–äº†ä»æ•°æ®ç†è§£åˆ°æ¨¡å‹éƒ¨ç½²çš„å®Œæ•´æµç¨‹ã€‚

---

**ç›¸å…³é“¾æ¥ï¼š**

- [3.2-å½¢å¼åŒ–æ¨¡å‹](3.2-å½¢å¼åŒ–æ¨¡å‹/README.md)
- [3.3-ç®—æ³•å®ç°](3.3-ç®—æ³•å®ç°/README.md)
- [3.4-AIä¸æœºå™¨å­¦ä¹ ç®—æ³•](3.4-AIä¸æœºå™¨å­¦ä¹ ç®—æ³•/README.md)
