# 日志与可观测性-落地指南（Runbook）

对齐：`04-部署运维/04.04-监控与诊断.md`

## 1. 日志配置建议

```text
log_line_prefix = '%m [%p] %u@%d %r %a '
log_min_duration_statement = 500ms
log_checkpoints = on
log_autovacuum_min_duration = 1s
log_lock_waits = on
track_io_timing = on
shared_preload_libraries = 'pg_stat_statements,auto_explain'
auto_explain.log_min_duration = '200ms'
auto_explain.log_analyze = on
auto_explain.log_buffers = on
```

### 1.1 完整日志配置

```sql
-- postgresql.conf完整日志配置

-- 基本日志设置
logging_collector = on
log_directory = 'log'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_rotation_age = 1d
log_rotation_size = 100MB
log_truncate_on_rotation = on

-- 日志格式
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
log_timezone = 'Asia/Shanghai'

-- 慢查询日志
log_min_duration_statement = 500  -- 记录执行时间>500ms的查询
log_min_messages = warning  -- 记录warning及以上级别

-- 检查点日志
log_checkpoints = on

-- Autovacuum日志
log_autovacuum_min_duration = 1s  -- 记录执行时间>1s的autovacuum

-- 锁等待日志
log_lock_waits = on  -- 记录锁等待>deadlock_timeout的事件

-- I/O时间跟踪
track_io_timing = on

-- 扩展统计
shared_preload_libraries = 'pg_stat_statements,auto_explain'

-- auto_explain配置
auto_explain.log_min_duration = 200  -- 记录执行时间>200ms的查询计划
auto_explain.log_analyze = on
auto_explain.log_buffers = on
auto_explain.log_timing = on
auto_explain.log_verbose = on
auto_explain.log_format = json  -- JSON格式便于解析
```

### 1.2 日志格式说明

```text
log_line_prefix格式说明：
%t: 时间戳（带毫秒）
%p: 进程ID
%l: 日志行号
%u: 用户名
%d: 数据库名
%a: 应用名称
%h: 客户端地址
%r: 客户端地址和端口
%m: 时间戳（不带毫秒）
%s: 会话开始时间
%i: 命令标签
%e: SQL状态码
```

## 2. 日志采集

- Filebeat/Vector → Loki/Elastic；建立索引/生命周期策略；
- 慢SQL归一化（fingerprint）用于TopN 聚合与画像。

### 2.1 Filebeat配置

```yaml
# filebeat.yml
filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - /var/lib/postgresql/14/data/log/postgresql-*.log
    fields:
      service: postgresql
      environment: production
    fields_under_root: true
    multiline.pattern: '^\d{4}-\d{2}-\d{2}'
    multiline.negate: true
    multiline.match: after

processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
  - add_fields:
      target: ''
      fields:
        log_type: postgresql

output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  index: "postgresql-logs-%{+yyyy.MM.dd}"

# 或输出到Loki
output.loki:
  hosts: ["loki:3100"]
  labels:
    job: postgresql
    service: postgresql
```

### 2.2 Vector配置

```toml
# vector.toml
[sources.postgresql_logs]
type = "file"
include = ["/var/lib/postgresql/14/data/log/postgresql-*.log"]
read_from = "beginning"

[transforms.postgresql_parse]
type = "regex_parser"
inputs = ["postgresql_logs"]
field = "message"
patterns = ['^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) \[(?P<pid>\d+)\]: \[(?P<log_level>\w+)\] (?P<message>.*)']

[transforms.postgresql_enrich]
type = "remap"
inputs = ["postgresql_parse"]
source = '''
.@timestamp = parse_timestamp(.timestamp, format: "%Y-%m-%d %H:%M:%S")
.service = "postgresql"
'''

[sinks.loki]
type = "loki"
inputs = ["postgresql_enrich"]
endpoint = "http://loki:3100"
labels.service = "{{ service }}"
labels.level = "{{ log_level }}"
```

### 2.3 慢SQL归一化

```sql
-- 使用pg_stat_statements进行慢SQL归一化
SELECT
    LEFT(query, 200) as query_preview,
    calls,
    mean_exec_time,
    max_exec_time,
    total_exec_time,
    rows,
    -- 归一化查询（移除参数值）
    regexp_replace(
        regexp_replace(query, '\$\d+', '?', 'g'),
        '\d{4}-\d{2}-\d{2}', 'YYYY-MM-DD', 'g'
    ) as normalized_query
FROM pg_stat_statements
WHERE mean_exec_time > 100
ORDER BY total_exec_time DESC
LIMIT 20;

-- 创建慢SQL指纹表
CREATE TABLE IF NOT EXISTS slow_query_fingerprints (
    fingerprint_id SERIAL PRIMARY KEY,
    normalized_query TEXT UNIQUE,
    first_seen TIMESTAMP DEFAULT NOW(),
    last_seen TIMESTAMP DEFAULT NOW(),
    total_calls BIGINT DEFAULT 0,
    total_time NUMERIC DEFAULT 0,
    avg_time NUMERIC DEFAULT 0,
    max_time NUMERIC DEFAULT 0
);

-- 定期更新慢SQL指纹
INSERT INTO slow_query_fingerprints (normalized_query, last_seen, total_calls, total_time, avg_time, max_time)
SELECT
    regexp_replace(
        regexp_replace(query, '\$\d+', '?', 'g'),
        '\d{4}-\d{2}-\d{2}', 'YYYY-MM-DD', 'g'
    ) as normalized_query,
    NOW() as last_seen,
    calls as total_calls,
    total_exec_time as total_time,
    mean_exec_time as avg_time,
    max_exec_time as max_time
FROM pg_stat_statements
WHERE mean_exec_time > 100
ON CONFLICT (normalized_query) DO UPDATE
SET
    last_seen = EXCLUDED.last_seen,
    total_calls = slow_query_fingerprints.total_calls + EXCLUDED.total_calls,
    total_time = slow_query_fingerprints.total_time + EXCLUDED.total_time,
    avg_time = (slow_query_fingerprints.total_time + EXCLUDED.total_time) /
               (slow_query_fingerprints.total_calls + EXCLUDED.total_calls),
    max_time = GREATEST(slow_query_fingerprints.max_time, EXCLUDED.max_time);
```

## 3. 面板与告警

- 连接/事务、命中率/WAL速率、检查点、Autovacuum、锁等待、慢SQL；
- 告警：连接>80%、命中率<95%、WAL 暴涨、检查点频繁、Vacuum 滞后、死锁事件。

### 3.1 Grafana仪表板设计

**面板1: 概览**

```json
{
  "panels": [
    {
      "title": "连接数",
      "targets": [
        {
          "expr": "pg_stat_database_numbackends{datname=\"postgres\"}"
        }
      ]
    },
    {
      "title": "事务速率",
      "targets": [
        {
          "expr": "rate(pg_stat_database_xact_commit{datname=\"postgres\"}[5m])"
        }
      ]
    },
    {
      "title": "缓冲区命中率",
      "targets": [
        {
          "expr": "100 * (pg_stat_database_blks_hit{datname=\"postgres\"} / (pg_stat_database_blks_hit{datname=\"postgres\"} + pg_stat_database_blks_read{datname=\"postgres\"}))"
        }
      ]
    }
  ]
}
```

**面板2: 查询性能**

```json
{
  "panels": [
    {
      "title": "Top 10 慢查询",
      "targets": [
        {
          "expr": "topk(10, pg_stat_statements_mean_exec_time)"
        }
      ]
    },
    {
      "title": "查询执行时间分布",
      "targets": [
        {
          "expr": "histogram_quantile(0.95, rate(pg_stat_statements_calls[5m]))"
        }
      ]
    }
  ]
}
```

### 3.2 告警规则配置

```yaml
# prometheus_alerts.yml
groups:
  - name: postgresql_logs
    rules:
      - alert: PostgreSQLSlowQueries
        expr: |
          count(
            pg_stat_statements_mean_exec_time > 1000
          ) > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "PostgreSQL慢查询过多"
          description: "执行时间>1秒的查询数量: {{ $value }}"

      - alert: PostgreSQLDeadlocks
        expr: |
          increase(
            pg_stat_database_deadlocks{datname="postgres"}[5m]
          ) > 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "PostgreSQL检测到死锁"
          description: "数据库发生死锁事件"

      - alert: PostgreSQLLockWaits
        expr: |
          count(
            pg_stat_activity_wait_event_type{wait_event_type="Lock"}
          ) > 10
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "PostgreSQL锁等待过多"
          description: "锁等待数量: {{ $value }}"
```

## 4. 关联追踪

- 通过 `log_line_prefix` 注入 `application_name`/请求ID，打通应用追踪；
- 将 TopN 语句映射回服务/接口，形成优化闭环。

### 4.1 应用追踪配置

```sql
-- 1. 在应用连接字符串中设置application_name
-- 示例：postgresql://user:pass@host/db?application_name=order-service-v1.2.3

-- 2. 在log_line_prefix中包含application_name
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h,request_id=%i '

-- 3. 使用session变量传递请求ID
SET application_name = 'order-service';
SET log_statement = 'all';  -- 临时启用，用于调试

-- 4. 查询时包含请求ID
SELECT set_config('application_name', 'order-service-request-12345', false);
SELECT * FROM orders WHERE order_id = 100;
```

### 4.2 慢SQL到服务映射

```sql
-- 创建服务-查询映射表
CREATE TABLE IF NOT EXISTS service_query_mapping (
    mapping_id SERIAL PRIMARY KEY,
    service_name VARCHAR(100),
    normalized_query TEXT,
    endpoint VARCHAR(200),
    first_seen TIMESTAMP DEFAULT NOW(),
    last_seen TIMESTAMP DEFAULT NOW()
);

-- 从日志中提取服务-查询映射
-- 使用正则表达式解析日志
-- 示例日志格式：
-- 2024-11-22 10:00:00 [12345]: [1-1] user=app_user,db=postgres,app=order-service,client=10.0.0.1 SELECT * FROM orders WHERE order_id = 100;

-- 定期更新映射
INSERT INTO service_query_mapping (service_name, normalized_query, endpoint)
SELECT DISTINCT
    application_name as service_name,
    regexp_replace(
        regexp_replace(query, '\$\d+', '?', 'g'),
        '\d{4}-\d{2}-\d{2}', 'YYYY-MM-DD', 'g'
    ) as normalized_query,
    '/api/orders' as endpoint  -- 从应用日志中提取
FROM pg_stat_statements
WHERE application_name IS NOT NULL
ON CONFLICT DO NOTHING;

-- 查询服务级别的慢SQL
SELECT
    s.service_name,
    s.endpoint,
    q.normalized_query,
    q.mean_exec_time,
    q.calls
FROM service_query_mapping s
JOIN (
    SELECT
        regexp_replace(
            regexp_replace(query, '\$\d+', '?', 'g'),
            '\d{4}-\d{2}-\d{2}', 'YYYY-MM-DD', 'g'
        ) as normalized_query,
        mean_exec_time,
        calls
    FROM pg_stat_statements
    WHERE mean_exec_time > 100
) q ON s.normalized_query = q.normalized_query
ORDER BY q.mean_exec_time DESC;
```

### 4.3 分布式追踪集成

```sql
-- 使用OpenTelemetry集成
-- 1. 安装pg_telemetry扩展（如果可用）
-- CREATE EXTENSION pg_telemetry;

-- 2. 在log_line_prefix中包含trace_id
log_line_prefix = '%t [%p]: trace_id=%i span_id=%i '

-- 3. 从应用传递trace_id
SET trace_id = 'abc123def456';
SET span_id = 'span789';

-- 4. 查询追踪信息
SELECT
    application_name,
    query,
    query_start,
    state,
    wait_event_type,
    wait_event
FROM pg_stat_activity
WHERE application_name LIKE '%order-service%'
ORDER BY query_start DESC;
```
