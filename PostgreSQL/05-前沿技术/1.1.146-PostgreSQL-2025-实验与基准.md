# PostgreSQL 17/18 å®éªŒä¸åŸºå‡†

> **æ–‡æ¡£ç‰ˆæœ¬**: v2.0
> **æœ€åæ›´æ–°**: 2025-11-11
> **ç‰ˆæœ¬è¦†ç›–**: PostgreSQL 17 (2024-09-26) | PostgreSQL 18 (2025-09-25) â­
> **æ–‡æ¡£çŠ¶æ€**: âœ… å·²æ›´æ–°è‡³ PostgreSQL 18
> **ğŸ“‹ ç›¸å…³æ–‡æ¡£**:
>
> - [AI æ—¶ä»£ä¸“é¢˜](../ai_view.md) â­â­â­ (v3.0, 2025-11-11)
> - [å‘é‡æ£€ç´¢æ€§èƒ½è°ƒä¼˜æŒ‡å—](./05.05-å‘é‡æ£€ç´¢æ€§èƒ½è°ƒä¼˜æŒ‡å—.md) (PG 18+ â­)

[English](../../en-US/1-database-systems/1.1-postgresql/1.1.146-postgresql-2025-experiments-and-benchmarks.md)

## 1. ç›®æ ‡ä¸èŒƒå›´

- è¯„ä¼° PostgreSQL 17/18 æ–°ç‰¹æ€§ï¼ˆAI åŸç”Ÿã€å‘é‡å¢å¼ºã€æµå¤„ç†ã€å¤šæ¨¡æ€ã€äº‘åŸç”Ÿï¼‰çš„æ€§èƒ½ä¸ç¨³å®šæ€§ã€‚
- æä¾›æ ‡å‡†åŒ–çš„åŸºå‡†è„šæœ¬ã€å¯å¤ç°å®éªŒæ­¥éª¤ä¸æŒ‡æ ‡æ¨¡æ¿ã€‚
- **PostgreSQL 18 é‡ç‚¹**: å¼‚æ­¥ I/O å­ç³»ç»Ÿã€è™šæ‹Ÿç”Ÿæˆåˆ—ã€pgvector 2.0 æ€§èƒ½æµ‹è¯• â­

## 2. ç¯å¢ƒé…ç½®

- ç¡¬ä»¶ï¼š32C/128Gï¼ŒNVMe SSDï¼›å¯é€‰ GPUï¼ˆA10 æˆ– MI210ï¼‰ã€‚
- ç³»ç»Ÿï¼šLinux Kernel >= 5.15ï¼›å®¹å™¨/K8s ç¯å¢ƒå¯é€‰ã€‚
- æ•°æ®é›†ï¼šå…¬å¼€æ•°æ®é›† + åˆæˆæ•°æ®ï¼ˆæ–‡æœ¬/å›¾åƒ/éŸ³é¢‘å‘é‡ï¼‰ã€‚

## 3. åŸºå‡†è®¾è®¡

### 3.1 å‘é‡æ£€ç´¢

- æ•°æ®è§„æ¨¡ï¼š1e6ã€1e7ã€5e7 å‘é‡ï¼ˆ768 ç»´ï¼‰
- æŒ‡æ ‡ï¼šQPSã€P95/P99ã€å¬å›@kã€ç´¢å¼•æ„å»ºæ—¶é—´ã€ç´¢å¼•å­˜å‚¨å ç”¨
- å˜é‡ï¼šHNSW/IVF å‚æ•°ã€SIMD/GPU å¼€å…³ã€æ‰¹é‡å¤§å°

### 3.2 AI åŸç”Ÿæ¨ç†

- åœºæ™¯ï¼šæƒ…æ„Ÿåˆ†æ/å®ä½“æŠ½å–/åŒ¹é…
- æŒ‡æ ‡ï¼šå»¶è¿Ÿåˆ†å¸ƒï¼ˆP50/95/99ï¼‰ã€ååã€ç¼“å­˜å‘½ä¸­ã€GPU åˆ©ç”¨ç‡
- å˜é‡ï¼šæ¨¡å‹å¤§å°ã€æ‰¹å°ºå¯¸ã€GPU æ± ç­–ç•¥ã€å¹¶å‘è¿æ¥

### 3.3 åŸç”Ÿæµå¤„ç†

- åœºæ™¯ï¼š1k/5k/20k events/s çš„æ»šåŠ¨çª—å£ç»Ÿè®¡
- æŒ‡æ ‡ï¼šç«¯åˆ°ç«¯å»¶è¿Ÿã€ä¸¢å¤±ç‡ã€Exactly-Once è¦†ç›–ç‡ã€çŠ¶æ€å¤§å°
- å˜é‡ï¼šçª—å£å¤§å°ã€å¹¶è¡Œåº¦ã€Checkpoint å‘¨æœŸ

### 3.4 å¤šæ¨¡æ€æ£€ç´¢

- åœºæ™¯ï¼šæ–‡æœ¬â†’ç»Ÿä¸€å‘é‡æ£€ç´¢
- æŒ‡æ ‡ï¼šå¬å›@kã€å»¶è¿Ÿã€èåˆæƒé‡æ•æ„Ÿæ€§
- å˜é‡ï¼šèåˆå‡½æ•°ã€ç»´åº¦å‹ç¼©ã€å‘é‡é‡åŒ–

## 4. æ•°æ®å‡†å¤‡è„šæœ¬

```sql
-- ç”Ÿæˆå‘é‡æ•°æ®ï¼ˆç¤ºä¾‹ï¼‰
CREATE TABLE IF NOT EXISTS items (
  id BIGSERIAL PRIMARY KEY,
  title TEXT,
  embedding VECTOR(768)
);

INSERT INTO items (title, embedding)
SELECT
  md5(random()::text),
  vector_rand(768)
FROM generate_series(1, 1000000);
```

```python
# load_images.py - ç”Ÿæˆå›¾åƒ/éŸ³é¢‘åµŒå…¥çš„å ä½ç¤ºä¾‹
import os, json, random
import numpy as np
import psycopg2

DIM_TEXT, DIM_IMG, DIM_AUD = 768, 512, 256

def rand_vec(dim):
    v = np.random.randn(dim).astype(np.float32)
    v /= (np.linalg.norm(v) + 1e-8)
    return v

conn = psycopg2.connect(os.environ.get("PG_URL","postgres://postgres:postgres@localhost:5432/postgres"))
cur = conn.cursor()
cur.execute("""
CREATE TABLE IF NOT EXISTS multimodal_content (
  id BIGSERIAL PRIMARY KEY,
  text_content TEXT,
  text_embedding VECTOR(768),
  image_path TEXT,
  image_embedding VECTOR(512),
  audio_path TEXT,
  audio_embedding VECTOR(256),
  unified_embedding VECTOR(1024)
);
""")

for i in range(100000):
    txt = f"sample-{i}"
    te = list(rand_vec(DIM_TEXT))
    ie = list(rand_vec(DIM_IMG))
    ae = list(rand_vec(DIM_AUD))
    ue = list(np.concatenate([te[:512], ie[:256], ae[:256]] + [np.zeros(0)]))
    cur.execute(
        "INSERT INTO multimodal_content (text_content, text_embedding, image_path, image_embedding, audio_path, audio_embedding, unified_embedding) VALUES (%s, %s, %s, %s, %s, %s, %s)",
        (txt, te, f"/img/{i}.jpg", ie, f"/aud/{i}.wav", ae, ue)
    )
    if i % 1000 == 0:
        conn.commit()

conn.commit()
cur.close()
conn.close()
```

## 5. åŸºå‡†è„šæœ¬

```sql
-- å‘é‡ç´¢å¼•åŸºå‡†
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_items_emb_hnsw
ON items USING hnsw (embedding vector_cosine_ops)
WITH (m=16, ef_construction=200, ef_search=100);

-- æŸ¥è¯¢æ¨¡æ¿
PREPARE qv(VECTOR(768), INT) AS
SELECT id, 1 - (embedding <=> $1) AS score
FROM items
ORDER BY embedding <=> $1
LIMIT $2;
```

```python
# bench_vector.py - å‘é‡æ£€ç´¢å‹æµ‹
import os, time, json, random
import numpy as np
import psycopg2

NQ = int(os.environ.get("NQ","1000"))
K = int(os.environ.get("K","10"))

def rand_vec(dim=768):
    v = np.random.randn(dim).astype(np.float32)
    v /= (np.linalg.norm(v) + 1e-8)
    return v

conn = psycopg2.connect(os.environ.get("PG_URL","postgres://postgres:postgres@localhost:5432/postgres"))
cur = conn.cursor()

lat = []
for _ in range(NQ):
    q = list(rand_vec())
    t0 = time.time()
    cur.execute("EXECUTE qv(%s,%s)", (q, K))
    _ = cur.fetchall()
    lat.append((time.time()-t0)*1000)

print(json.dumps({
    "nq": NQ,
    "k": K,
    "p50": float(np.percentile(lat,50)),
    "p95": float(np.percentile(lat,95)),
    "p99": float(np.percentile(lat,99)),
    "avg": float(np.mean(lat))
}, ensure_ascii=False))
```

## 6. æŒ‡æ ‡æ¨¡æ¿

- æ€§èƒ½ï¼šQPSã€P50/95/99ã€TPSã€CPU/GPU åˆ©ç”¨ç‡ã€IOPSã€å¸¦å®½
- è´¨é‡ï¼šå¬å›@kã€å‡†ç¡®ç‡ã€NDCG
- å¯é ï¼šå¯ç”¨æ€§ã€ä¸¢å¤±ç‡ã€æ¢å¤æ—¶é—´
- æˆæœ¬ï¼š$/QPSã€$/TB/æœˆã€èƒ½æ•ˆï¼ˆQPS/Wï¼‰

```markdown
| åœºæ™¯ | å‚æ•° | QPS | P95(ms) | P99(ms) | å¬å›@10 | å¤‡æ³¨ |
|------|------|-----|---------|---------|---------|------|
| å‘é‡æ£€ç´¢ | m=16,ef=100 |  |  |  |  |  |
| æ¨ç† | batch=8 |  |  |  |  |  |
| æµå¤„ç† | win=1m |  |  |  |  |  |
```

## 7. æŠ¥å‘Šç”Ÿæˆ

- è¾“å‡º JSON/CSV + å¯è§†åŒ–ï¼ˆJupyter/Plotlyï¼‰ã€‚
- ç»Ÿä¸€å‘½åï¼š`bench_{date}_{scenario}_{params}.json`ã€‚

## 8. å¤ç°å®éªŒæµç¨‹

1) å‡†å¤‡ç¯å¢ƒ â†’ 2) åŠ è½½æ•°æ® â†’ 3) æ„å»ºç´¢å¼• â†’ 4) è¿è¡ŒåŸºå‡† â†’ 5) é‡‡é›†æŒ‡æ ‡ â†’ 6) å‡ºå…·æŠ¥å‘Š â†’ 7) å›å½’å¯¹æ¯”ã€‚

> å»ºè®®åŠ å…¥å¤œé—´å›å½’åŸºå‡†ï¼Œç›‘æ§æ€§èƒ½æ¼‚ç§»ã€‚

## 9. ç»“æœæ±‡æ€»ä¸å¯è§†åŒ–

- ç»“æœæ±‡æ€»ï¼ˆCSVï¼‰ï¼š

```bash
python benchmarks/aggregate_results.py results/all.csv bench_stream.json bench_infer.json
```

- å¯è§†åŒ–ï¼ˆPlotlyï¼‰ï¼š

```bash
python benchmarks/plot_results.py bench_stream.json bench_infer.json
```

- ä¾èµ–å®‰è£…ï¼š

```bash
python -m pip install -r requirements.txt
```

- è¾“å‡ºäº§ç‰©ï¼š
  - `results/all.csv`ï¼šæ±‡æ€»åçš„æŒ‡æ ‡è¡¨
  - ç”Ÿæˆåå¯åœ¨ä»“åº“æ ¹ç›®å½•è®¿é—®ï¼š
    - [p50_ms.html](../../../p50_ms.html)
    - [p95_ms.html](../../../p95_ms.html)
    - [p99_ms.html](../../../p99_ms.html)
    - [avg_ms.html](../../../avg_ms.html)
    - [throughput_qps.html](../../../throughput_qps.html)

## 10. é™„ï¼šè„šæœ¬ä¸ä½¿ç”¨

- ç›®å½•ï¼š`benchmarks/`

### 10.1 æµå¤„ç†å‹æµ‹

```bash
export PG_URL=postgres://postgres:postgres@localhost:5432/postgres
python benchmarks/bench_stream.py > bench_stream.json
```

è¾“å‡ºå­—æ®µï¼š`event_rate,duration_s,window_sec,p50_ms,p95_ms,p99_ms,avg_ms`

### 10.2 AI æ¨ç†å‹æµ‹

```bash
export PG_URL=postgres://postgres:postgres@localhost:5432/postgres
MODEL=sentiment_analyzer NQ=2000 BATCH=4 python benchmarks/bench_inference.py > bench_infer.json
```

è¾“å‡ºå­—æ®µï¼š`model,nq,batch,throughput_qps,p50_ms,p95_ms,p99_ms,avg_ms`
