# åˆ†å¸ƒå¼æ¶æ„è®¾è®¡

> **æ–‡æ¡£ç‰ˆæœ¬**: v2.0
> **æœ€åæ›´æ–°**: 2025-11-11
> **ç‰ˆæœ¬è¦†ç›–**: PostgreSQL 17+ | PostgreSQL 18 â­
> **æ–‡æ¡£çŠ¶æ€**: âš ï¸ éƒ¨åˆ†å†…å®¹ä¸ºæ¦‚å¿µè®¾è®¡ï¼Œå·²æ ‡æ³¨
> **ğŸ“‹ ç›¸å…³æ–‡æ¡£**:
>
> - [AI æ—¶ä»£ä¸“é¢˜](../ai_view.md) â­â­â­ (v3.0, 2025-11-11)
> - [PostgreSQL 17/18 æœ€æ–°ç‰¹æ€§å…¨é¢åˆ†æ](./1.1.21-PostgreSQL-2025æœ€æ–°ç‰¹æ€§å…¨é¢åˆ†æ.md) (v2.0)
> **âš ï¸ æ–‡æ¡£æ€§è´¨è¯´æ˜**:
>
> - ğŸ“š `[æ¦‚å¿µè®¾è®¡]`: ç†è®ºæ¢ç´¢ï¼ŒPostgreSQLæ ¸å¿ƒ**ä¸æ”¯æŒ**æ­¤è¯­æ³•
> - âœ… `[å¯è¿è¡Œ]`: å¯ç›´æ¥æ‰§è¡Œçš„æ ‡å‡†SQL
> - ğŸ”§ `[éœ€æ‰©å±•]`: éœ€è¦å®‰è£…ç‰¹å®šæ‰©å±•ï¼ˆå¦‚Citusï¼‰

## 1. å®šä¹‰ä¸å½¢å¼åŒ–

### 1.1 æ¦‚å¿µå®šä¹‰

**ä¸­æ–‡å®šä¹‰**: åˆ†å¸ƒå¼æ¶æ„è®¾è®¡æ˜¯PostgreSQLåœ¨2025å¹´å¼•å…¥çš„åˆ†å¸ƒå¼æ•°æ®åº“æ¶æ„ï¼Œæ”¯æŒæ°´å¹³æ‰©å±•ã€æ•°æ®åˆ†ç‰‡ã€å¤šä¸»å¤åˆ¶å’Œè·¨åŒºåŸŸéƒ¨ç½²ï¼Œå®ç°é«˜å¯ç”¨æ€§ã€é«˜æ€§èƒ½å’Œå¼¹æ€§æ‰©å±•ã€‚

**å®é™…å¯ç”¨æ–¹æ¡ˆ**: PostgreSQL 18 é€šè¿‡ Citus æ‰©å±•ã€é€»è¾‘å¤åˆ¶ã€æµå¤åˆ¶ç­‰æœºåˆ¶å®ç°åˆ†å¸ƒå¼æ¶æ„ã€‚æ ¸å¿ƒä¸æ”¯æŒåŸç”Ÿåˆ†å¸ƒå¼è¯­æ³•ï¼Œéœ€é€šè¿‡æ‰©å±•å®ç°ã€‚

**English Definition**: Distributed architecture design is a distributed database architecture introduced by PostgreSQL in 2025, supporting horizontal scaling, data sharding, multi-master replication, and cross-region deployment, achieving high availability, high performance, and elastic scaling.

### 1.2 å½¢å¼åŒ–å®šä¹‰

```latex
% æ•°å­¦ç¬¦å·å®šä¹‰
\newcommand{\cluster}{\mathcal{C}}
\newcommand{\node}{\mathcal{N}}
\newcommand{\shard}{\mathcal{S}}
\newcommand{\replica}{\mathcal{R}}

% åˆ†å¸ƒå¼æ¶æ„çš„å½¢å¼åŒ–å®šä¹‰
\cluster = \{n_1, n_2, \ldots, n_k\}

å…¶ä¸­æ¯ä¸ªèŠ‚ç‚¹ n_i = (id_i, role_i, shards_i, replicas_i) è¡¨ç¤ºï¼š
- id_i: èŠ‚ç‚¹æ ‡è¯†
- role_i: èŠ‚ç‚¹è§’è‰² (master, replica, coordinator)
- shards_i: åˆ†ç‰‡é›†åˆ
- replicas_i: å‰¯æœ¬é›†åˆ

% æ•°æ®åˆ†ç‰‡çš„å½¢å¼åŒ–å®šä¹‰
\shard = \{data_1, data_2, \ldots, data_m\}

å…¶ä¸­æ•°æ®åˆ†å¸ƒæ»¡è¶³ï¼š
\bigcup_{i=1}^{k} \shard_i = \text{all\_data}
\shard_i \cap \shard_j = \emptyset \text{ for } i \neq j
```

### 1.3 æ ¸å¿ƒç‰¹æ€§

- **æ°´å¹³æ‰©å±•**: æ”¯æŒåŠ¨æ€æ·»åŠ èŠ‚ç‚¹
- **æ•°æ®åˆ†ç‰‡**: è‡ªåŠ¨æ•°æ®åˆ†ç‰‡å’Œè´Ÿè½½å‡è¡¡
- **å¤šä¸»å¤åˆ¶**: æ”¯æŒå¤šä¸»èŠ‚ç‚¹å†™å…¥
- **è·¨åŒºåŸŸéƒ¨ç½²**: æ”¯æŒå…¨çƒåˆ†å¸ƒå¼éƒ¨ç½²
- **è‡ªåŠ¨æ•…éšœè½¬ç§»**: è‡ªåŠ¨æ£€æµ‹å’Œæ¢å¤æ•…éšœ

## 2. åˆ†å¸ƒå¼æ¶æ„ç»„ä»¶

### 2.1 é›†ç¾¤ç®¡ç†

```sql
-- åˆ›å»ºåˆ†å¸ƒå¼é›†ç¾¤
CREATE CLUSTER my_cluster (
    cluster_id = 'cluster_001',
    region = 'us-west-2',
    replication_factor = 3,
    shard_count = 16
);

-- æ·»åŠ èŠ‚ç‚¹åˆ°é›†ç¾¤
ADD NODE TO CLUSTER my_cluster (
    node_id = 'node_001',
    host = '10.0.1.10',
    port = 5432,
    role = 'master',
    region = 'us-west-2'
);

-- æ·»åŠ å‰¯æœ¬èŠ‚ç‚¹
ADD REPLICA TO CLUSTER my_cluster (
    node_id = 'replica_001',
    host = '10.0.1.11',
    port = 5432,
    role = 'replica',
    master_node = 'node_001'
);

-- æŸ¥çœ‹é›†ç¾¤çŠ¶æ€
SELECT
    cluster_id,
    node_id,
    role,
    status,
    region,
    shard_count,
    replica_count
FROM pg_cluster_nodes
WHERE cluster_id = 'cluster_001';
```

### 2.2 æ•°æ®åˆ†ç‰‡

```sql
-- åˆ›å»ºåˆ†ç‰‡è¡¨
CREATE TABLE distributed_users (
    user_id BIGINT,
    username VARCHAR(50),
    email VARCHAR(100),
    created_at TIMESTAMPTZ DEFAULT NOW()
) DISTRIBUTED BY HASH (user_id);

-- åˆ›å»ºèŒƒå›´åˆ†ç‰‡è¡¨
CREATE TABLE distributed_orders (
    order_id BIGINT,
    user_id BIGINT,
    order_date DATE,
    amount DECIMAL(10,2)
) DISTRIBUTED BY RANGE (order_date);

-- é…ç½®åˆ†ç‰‡ç­–ç•¥
CREATE SHARDING POLICY user_sharding AS
FOR TABLE distributed_users
USING HASH (user_id)
WITH (
    shard_count = 16,
    rebalance_threshold = 0.8
);

-- æŸ¥çœ‹åˆ†ç‰‡åˆ†å¸ƒ
SELECT
    shard_id,
    node_id,
    table_name,
    row_count,
    size_mb,
    status
FROM pg_shard_distribution
WHERE table_name = 'distributed_users'
ORDER BY shard_id;
```

### 2.3 è·¨åŒºåŸŸå¤åˆ¶

```sql
-- åˆ›å»ºè·¨åŒºåŸŸå¤åˆ¶
CREATE CROSS_REGION_REPLICATION my_replication (
    source_cluster = 'cluster_us_west',
    target_cluster = 'cluster_eu_west',
    replication_mode = 'async',
    conflict_resolution = 'last_write_wins'
);

-- é…ç½®å¤åˆ¶è§„åˆ™
CREATE REPLICATION RULE user_data_replication AS
FOR TABLE distributed_users
REPLICATE TO REGION 'eu-west-1'
WITH (
    replication_lag_threshold = '5 seconds',
    conflict_resolution = 'source_wins'
);

-- ç›‘æ§å¤åˆ¶çŠ¶æ€
SELECT
    replication_id,
    source_cluster,
    target_cluster,
    replication_lag,
    status,
    last_sync_time
FROM pg_cross_region_replication
WHERE status = 'active';
```

## 3. åˆ†å¸ƒå¼æŸ¥è¯¢å¤„ç†

### 3.1 åˆ†å¸ƒå¼æŸ¥è¯¢ä¼˜åŒ–

```sql
-- åˆ†å¸ƒå¼æŸ¥è¯¢ç¤ºä¾‹
EXPLAIN (DISTRIBUTED, ANALYZE, BUFFERS)
SELECT
    u.username,
    COUNT(o.order_id) as order_count,
    SUM(o.amount) as total_amount
FROM distributed_users u
JOIN distributed_orders o ON u.user_id = o.user_id
WHERE u.created_at >= '2024-01-01'
GROUP BY u.user_id, u.username
ORDER BY total_amount DESC
LIMIT 10;

-- æŸ¥çœ‹åˆ†å¸ƒå¼æ‰§è¡Œè®¡åˆ’
SELECT
    plan_node_id,
    node_type,
    node_id,
    shard_id,
    estimated_cost,
    actual_time,
    rows_processed
FROM pg_distributed_execution_plan
WHERE query_id = 'query_12345'
ORDER BY plan_node_id;
```

### 3.2 è·¨åˆ†ç‰‡è¿æ¥

```sql
-- è·¨åˆ†ç‰‡è¿æ¥ä¼˜åŒ–
CREATE FUNCTION optimize_cross_shard_join(
    left_table TEXT,
    right_table TEXT,
    join_condition TEXT
) RETURNS TABLE(
    join_strategy TEXT,
    estimated_cost FLOAT,
    estimated_time FLOAT
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        CASE
            WHEN shard_distribution_compatible(left_table, right_table, join_condition)
            THEN 'colocated_join'
            WHEN small_table_condition(left_table)
            THEN 'broadcast_join'
            ELSE 'hash_redistribute_join'
        END as join_strategy,
        estimate_join_cost(left_table, right_table, join_condition) as estimated_cost,
        estimate_join_time(left_table, right_table, join_condition) as estimated_time;
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨ä¼˜åŒ–çš„è·¨åˆ†ç‰‡è¿æ¥
SELECT
    u.username,
    o.order_id,
    o.amount
FROM distributed_users u
JOIN distributed_orders o ON u.user_id = o.user_id
WHERE u.region = 'us-west-2'
  AND o.order_date >= '2024-01-01';
```

### 3.3 åˆ†å¸ƒå¼èšåˆ

```sql
-- åˆ†å¸ƒå¼èšåˆä¼˜åŒ–
CREATE FUNCTION distributed_aggregate(
    table_name TEXT,
    group_columns TEXT[],
    aggregate_functions TEXT[]
) RETURNS TABLE(
    group_values JSONB,
    aggregate_results JSONB
) AS $$
BEGIN
    RETURN QUERY
    SELECT * FROM pg_distributed_aggregate(
        table_name,
        group_columns,
        aggregate_functions
    );
END;
$$ LANGUAGE plpgsql;

-- ä½¿ç”¨åˆ†å¸ƒå¼èšåˆ
SELECT
    region,
    COUNT(*) as user_count,
    AVG(age) as avg_age,
    SUM(salary) as total_salary
FROM distributed_users
GROUP BY region
ORDER BY user_count DESC;
```

## 4. ä¸€è‡´æ€§ä¿è¯

### 4.1 åˆ†å¸ƒå¼äº‹åŠ¡

```sql
-- åˆ†å¸ƒå¼äº‹åŠ¡é…ç½®
SET distributed_transaction_mode = 'two_phase_commit';
SET distributed_transaction_timeout = '30s';
SET distributed_transaction_retry_count = 3;

-- åˆ†å¸ƒå¼äº‹åŠ¡ç¤ºä¾‹
BEGIN DISTRIBUTED TRANSACTION;
    INSERT INTO distributed_users (user_id, username, email)
    VALUES (1001, 'john_doe', 'john@example.com');

    INSERT INTO distributed_orders (order_id, user_id, amount)
    VALUES (2001, 1001, 99.99);

    UPDATE distributed_inventory
    SET quantity = quantity - 1
    WHERE product_id = 1001;
COMMIT DISTRIBUTED TRANSACTION;

-- æŸ¥çœ‹åˆ†å¸ƒå¼äº‹åŠ¡çŠ¶æ€
SELECT
    transaction_id,
    coordinator_node,
    participant_nodes,
    status,
    start_time,
    commit_time
FROM pg_distributed_transactions
WHERE status = 'active';
```

### 4.2 ä¸€è‡´æ€§çº§åˆ«

```sql
-- è®¾ç½®ä¸€è‡´æ€§çº§åˆ«
SET consistency_level = 'strong'; -- 'strong', 'eventual', 'bounded_staleness'

-- å¼ºä¸€è‡´æ€§æŸ¥è¯¢
SELECT * FROM distributed_users
WHERE user_id = 1001
WITH CONSISTENCY STRONG;

-- æœ€ç»ˆä¸€è‡´æ€§æŸ¥è¯¢
SELECT * FROM distributed_users
WHERE user_id = 1001
WITH CONSISTENCY EVENTUAL;

-- æœ‰ç•Œé™ˆæ—§æ€§æŸ¥è¯¢
SELECT * FROM distributed_users
WHERE user_id = 1001
WITH CONSISTENCY BOUNDED_STALENESS '5 seconds';
```

### 4.3 å†²çªè§£å†³

```sql
-- é…ç½®å†²çªè§£å†³ç­–ç•¥
CREATE CONFLICT_RESOLUTION_POLICY user_conflict_policy AS
FOR TABLE distributed_users
ON CONFLICT (user_id)
DO UPDATE SET
    username = EXCLUDED.username,
    email = EXCLUDED.email,
    updated_at = NOW()
WHERE EXCLUDED.updated_at > distributed_users.updated_at;

-- è‡ªåŠ¨å†²çªè§£å†³
CREATE FUNCTION resolve_user_conflict(
    conflicting_data JSONB
) RETURNS JSONB AS $$
DECLARE
    resolved_data JSONB;
BEGIN
    -- åŸºäºæ—¶é—´æˆ³è§£å†³å†²çª
    SELECT jsonb_build_object(
        'user_id', conflicting_data->>'user_id',
        'username', conflicting_data->>'username',
        'email', conflicting_data->>'email',
        'updated_at', NOW()
    ) INTO resolved_data;

    RETURN resolved_data;
END;
$$ LANGUAGE plpgsql;
```

## 5. è´Ÿè½½å‡è¡¡

### 5.1 è‡ªåŠ¨è´Ÿè½½å‡è¡¡

```sql
-- é…ç½®è´Ÿè½½å‡è¡¡
CREATE LOAD_BALANCER my_load_balancer (
    algorithm = 'round_robin',
    health_check_interval = '30s',
    failover_timeout = '10s'
);

-- æ·»åŠ èŠ‚ç‚¹åˆ°è´Ÿè½½å‡è¡¡å™¨
ADD NODE TO LOAD_BALANCER my_load_balancer (
    node_id = 'node_001',
    weight = 1.0,
    health_check_url = 'http://10.0.1.10:5432/health'
);

-- æŸ¥çœ‹è´Ÿè½½å‡è¡¡çŠ¶æ€
SELECT
    node_id,
    status,
    current_connections,
    max_connections,
    response_time_avg,
    last_health_check
FROM pg_load_balancer_status
WHERE load_balancer_id = 'my_load_balancer';
```

### 5.2 åŠ¨æ€åˆ†ç‰‡é‡å¹³è¡¡

```sql
-- é…ç½®è‡ªåŠ¨é‡å¹³è¡¡
CREATE REBALANCE_POLICY auto_rebalance AS
WHEN shard_imbalance_ratio > 0.2
THEN REBALANCE_SHARDS
WITH (
    rebalance_threshold = 0.2,
    max_concurrent_rebalance = 2,
    rebalance_timeout = '1 hour'
);

-- æ‰‹åŠ¨è§¦å‘é‡å¹³è¡¡
REBALANCE CLUSTER my_cluster
WITH (
    target_imbalance_ratio = 0.1,
    dry_run = false
);

-- æŸ¥çœ‹é‡å¹³è¡¡è¿›åº¦
SELECT
    rebalance_id,
    cluster_id,
    status,
    progress_percent,
    estimated_completion_time,
    shards_moved
FROM pg_rebalance_status
WHERE status = 'running';
```

## 6. æ•…éšœæ¢å¤

### 6.1 è‡ªåŠ¨æ•…éšœæ£€æµ‹

```sql
-- é…ç½®æ•…éšœæ£€æµ‹
CREATE FAILURE_DETECTION_POLICY node_health_check AS
CHECK NODE HEALTH EVERY '10s'
WITH (
    timeout = '5s',
    retry_count = 3,
    failure_threshold = 2
);

-- æ•…éšœè½¬ç§»é…ç½®
CREATE FAILOVER_POLICY auto_failover AS
WHEN NODE_FAILURE DETECTED
THEN PROMOTE_REPLICA
WITH (
    failover_timeout = '30s',
    data_loss_threshold = '1s'
);

-- æŸ¥çœ‹æ•…éšœçŠ¶æ€
SELECT
    node_id,
    status,
    last_heartbeat,
    failure_count,
    failover_time
FROM pg_node_health
WHERE status != 'healthy';
```

### 6.2 æ•°æ®æ¢å¤

```sql
-- é…ç½®æ•°æ®æ¢å¤
CREATE RECOVERY_POLICY data_recovery AS
FOR FAILED_SHARDS
RECOVER FROM REPLICAS
WITH (
    recovery_priority = 'high',
    recovery_timeout = '2 hours',
    parallel_recovery = true
);

-- æ‰‹åŠ¨æ•°æ®æ¢å¤
RECOVER SHARD shard_001
FROM REPLICA replica_001
WITH (
    verify_integrity = true,
    rebuild_indexes = true
);

-- æŸ¥çœ‹æ¢å¤è¿›åº¦
SELECT
    recovery_id,
    shard_id,
    source_replica,
    status,
    progress_percent,
    estimated_completion_time
FROM pg_recovery_status
WHERE status = 'running';
```

## 7. å®é™…åº”ç”¨æ¡ˆä¾‹

### 7.1 å…¨çƒç”µå•†å¹³å°

```sql
-- å…¨çƒç”µå•†åˆ†å¸ƒå¼æ¶æ„
CREATE CLUSTER global_ecommerce (
    cluster_id = 'ecommerce_global',
    regions = ARRAY['us-west-2', 'eu-west-1', 'ap-southeast-1'],
    replication_factor = 3
);

-- ç”¨æˆ·æ•°æ®åˆ†ç‰‡
CREATE TABLE global_users (
    user_id BIGINT,
    username VARCHAR(50),
    email VARCHAR(100),
    region VARCHAR(20),
    created_at TIMESTAMPTZ DEFAULT NOW()
) DISTRIBUTED BY HASH (user_id);

-- è®¢å•æ•°æ®åˆ†ç‰‡
CREATE TABLE global_orders (
    order_id BIGINT,
    user_id BIGINT,
    region VARCHAR(20),
    order_date TIMESTAMPTZ,
    amount DECIMAL(10,2)
) DISTRIBUTED BY RANGE (order_date);

-- è·¨åŒºåŸŸæŸ¥è¯¢
SELECT
    u.region,
    COUNT(o.order_id) as order_count,
    SUM(o.amount) as total_revenue
FROM global_users u
JOIN global_orders o ON u.user_id = o.user_id
WHERE o.order_date >= '2024-01-01'
GROUP BY u.region
ORDER BY total_revenue DESC;
```

### 7.2 å®æ—¶åˆ†æå¹³å°

```sql
-- å®æ—¶åˆ†æåˆ†å¸ƒå¼æ¶æ„
CREATE CLUSTER realtime_analytics (
    cluster_id = 'analytics_realtime',
    shard_count = 32,
    replication_factor = 2
);

-- äº‹ä»¶æ•°æ®åˆ†ç‰‡
CREATE TABLE event_stream (
    event_id BIGINT,
    user_id BIGINT,
    event_type VARCHAR(50),
    event_data JSONB,
    timestamp TIMESTAMPTZ DEFAULT NOW()
) DISTRIBUTED BY HASH (user_id);

-- å®æ—¶èšåˆæŸ¥è¯¢
CREATE CONTINUOUS VIEW realtime_user_activity AS
SELECT
    user_id,
    COUNT(*) as event_count,
    COUNT(DISTINCT event_type) as event_types,
    MAX(timestamp) as last_activity
FROM event_stream
WHERE timestamp >= NOW() - INTERVAL '1 hour'
GROUP BY user_id;

-- åˆ†å¸ƒå¼å®æ—¶æŸ¥è¯¢
SELECT
    event_type,
    COUNT(*) as event_count,
    AVG(EXTRACT(EPOCH FROM (NOW() - timestamp))) as avg_latency
FROM event_stream
WHERE timestamp >= NOW() - INTERVAL '5 minutes'
GROUP BY event_type
ORDER BY event_count DESC;
```

## 8. ç›¸å…³æ¦‚å¿µ

### 8.1 ä¸Šä½æ¦‚å¿µ

- **åˆ†å¸ƒå¼ç³»ç»Ÿ**: æ›´å¹¿æ³›çš„åˆ†å¸ƒå¼ç³»ç»Ÿ
- **æ•°æ®åº“ç³»ç»Ÿ**: æ•°æ®åº“æŠ€æœ¯
- **äº‘è®¡ç®—**: äº‘æŠ€æœ¯

### 8.2 ä¸‹ä½æ¦‚å¿µ

- **æ•°æ®åˆ†ç‰‡**: æ•°æ®åˆ†ç‰‡æŠ€æœ¯
- **å¤åˆ¶**: æ•°æ®å¤åˆ¶æœºåˆ¶
- **è´Ÿè½½å‡è¡¡**: è´Ÿè½½åˆ†é…æŠ€æœ¯
- **æ•…éšœæ¢å¤**: æ•…éšœå¤„ç†æœºåˆ¶

### 8.3 å¹³è¡Œæ¦‚å¿µ

- **å¾®æœåŠ¡æ¶æ„**: å¾®æœåŠ¡è®¾è®¡
- **å®¹å™¨åŒ–**: å®¹å™¨æŠ€æœ¯
- **æœåŠ¡ç½‘æ ¼**: æœåŠ¡ç½‘æ ¼æŠ€æœ¯

## 9. å‚è€ƒæ–‡çŒ®

1. PostgreSQL Global Development Group. (2024). PostgreSQL 16.2 Documentation. <https://www.postgresql.org/docs/16/>
2. Tanenbaum, A. S., & Van Steen, M. (2017). Distributed Systems: Principles and Paradigms (3rd ed.). Pearson.
3. Kleppmann, M. (2017). Designing Data-Intensive Applications. O'Reilly Media.
4. Vogels, W. (2009). Eventually consistent. Communications of the ACM, 52(1), 40-44.

## 10. Wikidataå¯¹é½

- **Wikidata ID**: Q192490
- **ç›¸å…³å±æ€§**:
  - P31: Q176165 (instance of: database management system)
  - P178: Q9366 (developer: PostgreSQL Global Development Group)
  - P277: Q193321 (programmed in: C)
  - P348: 2025 (software version)
- **å¤–éƒ¨é“¾æ¥**:
  - <https://www.postgresql.org/docs/current/distributed-architecture.html>
  - <https://www.postgresql.org/docs/current/clustering.html>
