# SQL性能优化决策树

> **创建日期**: 2025-12-04
> **难度**: ⭐⭐⭐⭐⭐

---

## 决策树总览

```text
SQL性能问题诊断与优化决策树
══════════════════════════════════════════════════════════════════════════════

                              查询慢？
                                 │
                ┌────────────────┼────────────────┐
                │                │                │
           执行时间慢？       返回数据慢？      偶尔慢？
                │                │                │
        ┌───────┴───────┐        │          ┌─────┴─────┐
        │               │        │          │           │
    查询计划差？    数据量大？  网络延迟？ 锁等待？   缓存miss？
        │               │        │          │           │
        ↓               ↓        ↓          ↓           ↓
    [优化1]         [优化2]    [优化3]    [优化4]     [优化5]
```

---

## 优化路径1：查询计划优化

### 诊断步骤

```sql
-- Step 1: 获取EXPLAIN ANALYZE
EXPLAIN ANALYZE
SELECT * FROM orders o
JOIN users u ON o.user_id = u.id
WHERE o.created_at > '2025-01-01';

-- Step 2: 识别问题节点
-- 关键指标：
-- • Sequential Scan → 缺少索引
-- • Nested Loop → JOIN顺序不对
-- • High rows estimated vs actual → 统计信息过时
```

### 决策树

```text
查询计划问题分类
═══════════════════════════════════════════════════════════════

问题: Sequential Scan on large table
    │
    ├─ WHERE条件在索引列？
    │   ├─ YES → 索引未被使用
    │   │         └─ 原因？
    │   │             ├─ 函数包裹列 → WHERE DATE(created_at) = ...
    │   │             │   解决: 改为范围查询
    │   │             │         WHERE created_at >= '2025-01-01'
    │   │             │           AND created_at < '2025-01-02'
    │   │             │
    │   │             ├─ 类型不匹配 → WHERE id = '123' (id是INTEGER)
    │   │             │   解决: WHERE id = 123
    │   │             │
    │   │             ├─ OR条件 → WHERE a = 1 OR b = 2
    │   │             │   解决: 拆分为两个查询 + UNION
    │   │             │
    │   │             └─ LIKE前置通配符 → WHERE email LIKE '%@gmail.com'
    │   │                 解决: 全文索引或pg_trgm索引
    │   │
    │   └─ NO → 创建索引
    │             CREATE INDEX idx_orders_created ON orders(created_at);
    │
    └─ 表很小(<1000行)？
        └─ YES → Sequential Scan更快，无需优化

问题: Nested Loop Join slow
    │
    ├─ JOIN条件有索引？
    │   ├─ NO → 创建索引
    │   │       CREATE INDEX idx_orders_user_id ON orders(user_id);
    │   │
    │   └─ YES → JOIN顺序问题
    │             └─ 小表在外，大表在内
    │                 解决: 使用STRAIGHT_JOIN(MySQL) 或
    │                       SET join_collapse_limit(PostgreSQL)
    │
    └─ 考虑Hash Join？
        └─ SET enable_nestloop = OFF; (测试用)

问题: 统计信息过时
    │
    └─ 执行ANALYZE
        PostgreSQL: ANALYZE table_name;
        MySQL: ANALYZE TABLE table_name;
        SQLite: ANALYZE;
```

---

## 优化路径2：数据量优化

### 决策树

```text
数据量大问题处理
═══════════════════════════════════════════════════════════════

返回行数 > 10,000？
    │
    ├─ 是否需要全部数据？
    │   ├─ NO → 添加LIMIT
    │   │       SELECT ... LIMIT 100;
    │   │
    │   └─ YES → 分批查询
    │             方法1: 游标（适合只读）
    │             方法2: Keyset分页（适合有序）
    │               SELECT * FROM orders
    │               WHERE id > last_id
    │               ORDER BY id
    │               LIMIT 1000;
    │
    └─ JOIN导致行数爆炸？
        └─ 检查JOIN条件
            ├─ 笛卡尔积？
            │   解决: 添加ON条件
            │
            └─ 一对多关系？
                解决: 考虑EXISTS代替JOIN
                  SELECT * FROM users u
                  WHERE EXISTS (
                    SELECT 1 FROM orders o
                    WHERE o.user_id = u.id
                  );

数据表本身很大(>100GB)？
    │
    ├─ 按时间范围查询？
    │   └─ 使用分区表
    │       PostgreSQL:
    │         CREATE TABLE orders_2025_01 PARTITION OF orders
    │         FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
    │
    ├─ 历史数据不常访问？
    │   └─ 归档旧数据
    │       • 移到历史表
    │       • 压缩存储
    │
    └─ 冷热数据混合？
        └─ 冷热分离架构
            • 热数据: PostgreSQL
            • 冷数据: Parquet + S3
```

---

## 优化路径3：网络与IO优化

### 决策树

```text
网络/IO瓶颈优化
═══════════════════════════════════════════════════════════════

查询执行快，但客户端收到慢？
    │
    ├─ 网络延迟高？
    │   ├─ 跨地域访问？
    │   │   解决:
    │   │     • 使用CDN
    │   │     • 读写分离 + 就近路由
    │   │     • 缓存层（Redis）
    │   │
    │   └─ 单次传输数据量大？
    │         └─ 只SELECT需要的列
    │             BAD:  SELECT *
    │             GOOD: SELECT id, name
    │
    ├─ 磁盘IO高？
    │   ├─ 缓存命中率低？
    │   │   PostgreSQL:
    │   │     SELECT
    │   │       sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read))
    │   │       as cache_hit_ratio
    │   │     FROM pg_statio_user_tables;
    │   │
    │   │   解决:
    │   │     • 增加shared_buffers
    │   │     • 使用覆盖索引（避免回表）
    │   │
    │   └─ 随机IO多？
    │         └─ 索引扫描导致
    │             解决: 考虑Sequential Scan（大范围查询）
    │                   SET random_page_cost = 1.1; (SSD)
    │
    └─ 结果集序列化慢？
        └─ 使用二进制协议
            • PostgreSQL: cursor + COPY
            • MySQL: --max-allowed-packet
```

---

## 优化路径4：并发与锁优化

### 决策树

```text
并发与锁问题优化
═══════════════════════════════════════════════════════════════

查询偶尔变慢？
    │
    └─ 锁等待？
        PostgreSQL:
          SELECT * FROM pg_locks
          WHERE NOT granted;

        MySQL:
          SHOW ENGINE INNODB STATUS;

        问题分类:
        │
        ├─ 表锁（Table Lock）
        │   └─ DDL操作（ALTER TABLE）？
        │       解决:
        │         • 业务低峰期执行
        │         • PostgreSQL: CREATE INDEX CONCURRENTLY
        │         • MySQL: ALGORITHM=INPLACE
        │
        ├─ 行锁（Row Lock）
        │   ├─ 长事务持有锁？
        │   │   解决:
        │   │     • 减小事务范围
        │   │     • 拆分大事务
        │   │     • 监控并kill长事务
        │   │
        │   └─ 死锁（Deadlock）？
        │         原因: 两个事务互相等待
        │         解决:
        │           • 统一锁顺序
        │           • 使用SELECT FOR UPDATE NOWAIT
        │           • 减小事务粒度
        │
        └─ MVCC膨胀（PostgreSQL特有）
            └─ 死元组过多？
                检测:
                  SELECT n_dead_tup, n_live_tup
                  FROM pg_stat_user_tables
                  WHERE n_dead_tup > 10000;

                解决:
                  • 手动VACUUM
                  • 调整autovacuum参数
                  • 避免长事务

读写冲突？
    │
    ├─ PostgreSQL: 使用MVCC，读不阻塞写
    │   问题较少，除非:
    │     • FOR UPDATE锁
    │     • 显式LOCK TABLE
    │
    └─ MySQL: 间隙锁（Gap Lock）
        场景: REPEATABLE READ + 范围查询
        解决:
          • 改用READ COMMITTED
          • 使用精确等值查询
```

---

## 优化路径5：缓存优化

### 决策树

```text
缓存策略优化
═══════════════════════════════════════════════════════════════

查询结果可缓存？
    │
    ├─ 数据更新频率？
    │   ├─ 几乎不变（配置数据）
    │   │   → 应用层缓存（永久）
    │   │       const CONFIG = loadOnce();
    │   │
    │   ├─ 低频更新（分钟级）
    │   │   → Redis缓存（TTL 5分钟）
    │   │       SETEX cache_key 300 value
    │   │
    │   └─ 高频更新（秒级）
    │         → 数据库查询缓存
    │             MySQL: query_cache (已废弃)
    │             PostgreSQL: 使用物化视图
    │               CREATE MATERIALIZED VIEW mv_stats AS ...
    │               REFRESH MATERIALIZED VIEW CONCURRENTLY mv_stats;
    │
    └─ 缓存粒度？
        ├─ 整个查询结果
        │   → Redis Hash/String
        │       HSET user:123 name "Alice" email "..."
        │
        ├─ 聚合统计
        │   → Redis自增计数
        │       INCR user:123:login_count
        │
        └─ 查询结果集
            → Redis Sorted Set（排行榜）
                ZADD leaderboard 9500 "user:123"

缓存失效策略？
    │
    ├─ Write-Through（写穿）
    │   • 写数据库同时写缓存
    │   • 优点: 缓存总是最新
    │   • 缺点: 写入变慢
    │
    ├─ Write-Behind（写回）
    │   • 先写缓存，异步写数据库
    │   • 优点: 写入快
    │   • 缺点: 可能丢失数据
    │
    └─ Cache-Aside（旁路）
        • 读: 缓存miss → 查数据库 → 写缓存
        • 写: 更新数据库 → 删除缓存
        • 优点: 实现简单
        • 缺点: 短暂不一致
```

---

## 综合优化案例

### 案例：电商订单查询优化

```sql
-- 原始查询（慢：2.3秒）
SELECT
    o.id,
    o.order_no,
    u.username,
    u.email,
    p.product_name,
    oi.quantity,
    oi.price
FROM orders o
JOIN users u ON o.user_id = u.id
JOIN order_items oi ON oi.order_id = o.id
JOIN products p ON oi.product_id = p.id
WHERE o.created_at > '2025-01-01'
    AND o.status = 'completed'
ORDER BY o.created_at DESC;

-- 诊断
EXPLAIN ANALYZE ...

-- 问题识别:
-- 1. Sequential Scan on orders (500万行)
-- 2. Nested Loop Join (orders × order_items)
-- 3. 返回10万行

-- 优化方案

-- 优化1: 创建复合索引
CREATE INDEX idx_orders_status_created
ON orders(status, created_at DESC);
-- 效果: Sequential Scan → Index Scan

-- 优化2: 覆盖索引（避免回表）
CREATE INDEX idx_order_items_covering
ON order_items(order_id, product_id, quantity, price);
-- 效果: 减少IO

-- 优化3: 只查询需要的列
-- 不需要email？删除 u.email

-- 优化4: 分页
SELECT ...
LIMIT 100 OFFSET 0;
-- 效果: 减少网络传输

-- 优化5: 物化视图（按日聚合）
CREATE MATERIALIZED VIEW daily_completed_orders AS
SELECT
    DATE(created_at) as order_date,
    id, order_no, user_id, ...
FROM orders
WHERE status = 'completed';

CREATE INDEX ON daily_completed_orders(order_date);

-- 查询改为
SELECT * FROM daily_completed_orders
WHERE order_date >= '2025-01-01'
ORDER BY order_date DESC
LIMIT 100;

-- 最终结果: 2.3秒 → 0.05秒 (提升46倍)
```

---

**文档版本**: v1.0.0
**最后更新**: 2025-12-04
