# 分布式事务算法实现

> **创建日期**：2025-12-04
> **难度**：⭐⭐⭐⭐⭐
> **前置知识**：分布式系统、一致性协议

---

## 两阶段提交（2PC）

### 算法实现

```python
class TwoPhaseCommitCoordinator:
    def __init__(self, participants):
        self.participants = participants  # 数据库连接列表
        self.transaction_id = generate_uuid()

    def execute_distributed_transaction(self, operations):
        """执行分布式事务"""
        # Phase 1: Prepare
        print("Phase 1: Prepare")
        prepared = []

        for i, (conn, op) in enumerate(zip(self.participants, operations)):
            try:
                # 执行操作
                conn.execute("BEGIN")
                conn.execute(op['sql'], op['params'])

                # 准备提交
                conn.execute(f"PREPARE TRANSACTION '{self.transaction_id}_{i}'")
                prepared.append((conn, i))
                print(f"  参与者{i}: PREPARED")
            except Exception as e:
                print(f"  参与者{i}: FAILED - {e}")
                # Prepare失败，回滚所有已准备的事务
                self.abort_all(prepared)
                return False

        # Phase 2: Commit
        print("Phase 2: Commit")
        committed = []

        for conn, i in prepared:
            try:
                conn.execute(f"COMMIT PREPARED '{self.transaction_id}_{i}'")
                committed.append((conn, i))
                print(f"  参与者{i}: COMMITTED")
            except Exception as e:
                print(f"  参与者{i}: COMMIT FAILED - {e}")
                # 这里很危险！部分提交了
                # 需要人工介入或自动重试
                return False

        print("分布式事务成功")
        return True

    def abort_all(self, prepared):
        """回滚所有已准备的事务"""
        for conn, i in prepared:
            try:
                conn.execute(f"ROLLBACK PREPARED '{self.transaction_id}_{i}'")
            except:
                pass

# 使用示例
db1 = psycopg2.connect("postgresql://db1/accounts")
db2 = psycopg2.connect("postgresql://db2/accounts")

coordinator = TwoPhaseCommitCoordinator([db1, db2])

# 跨数据库转账
success = coordinator.execute_distributed_transaction([
    {
        'sql': "UPDATE accounts SET balance = balance - %s WHERE account_id = %s",
        'params': (100, 1001)
    },
    {
        'sql': "UPDATE accounts SET balance = balance + %s WHERE account_id = %s",
        'params': (100, 2001)
    }
])
```

### 2PC问题与优化

```text
两阶段提交问题
══════════════════════════════════════════════════════════════════════════════

问题1：阻塞（Blocking）
• 协调者崩溃后，参与者一直等待
• 解决：超时机制+3PC

问题2：单点故障
• 协调者宕机导致整个系统无法提交
• 解决：协调者主备+Paxos/Raft

问题3：性能开销
• 两轮网络通信
• 持有锁时间长
• 解决：Saga模式（最终一致性）

性能对比（跨2个数据库）：
┌──────────────────┬──────────┬────────────────────┐
│ 方案             │ 延迟     │ 吞吐量             │
├──────────────────┼──────────┼────────────────────┤
│ 本地事务         │ 1ms      │ 10000 TPS          │
│ 2PC              │ 10-50ms  │ 100-500 TPS        │
│ Saga（异步）     │ 5ms      │ 2000-5000 TPS      │
└──────────────────┴──────────┴────────────────────┘
```

---

## Saga模式实现

```python
# Saga模式：补偿事务

class SagaOrchestrator:
    def __init__(self):
        self.steps = []
        self.compensations = []

    def add_step(self, forward_action, compensation_action):
        """添加Saga步骤"""
        self.steps.append(forward_action)
        self.compensations.append(compensation_action)

    def execute(self):
        """执行Saga"""
        executed = []

        try:
            # 顺序执行所有步骤
            for i, step in enumerate(self.steps):
                print(f"执行步骤{i+1}/{len(self.steps)}")
                result = step()
                executed.append(i)

                if not result['success']:
                    raise Exception(f"步骤{i+1}失败: {result['error']}")

            print("Saga成功完成")
            return True

        except Exception as e:
            print(f"Saga失败: {e}，开始补偿")

            # 逆序执行补偿操作
            for i in reversed(executed):
                try:
                    print(f"补偿步骤{i+1}")
                    self.compensations[i]()
                except Exception as comp_error:
                    print(f"补偿失败: {comp_error}")
                    # 记录到日志，人工介入

            return False

# 示例：跨服务下单

saga = SagaOrchestrator()

# 步骤1：创建订单
saga.add_step(
    forward_action=lambda: order_service.create_order(order_data),
    compensation_action=lambda: order_service.cancel_order(order_id)
)

# 步骤2：扣减库存
saga.add_step(
    forward_action=lambda: inventory_service.deduct_stock(product_id, quantity),
    compensation_action=lambda: inventory_service.restore_stock(product_id, quantity)
)

# 步骤3：扣款
saga.add_step(
    forward_action=lambda: payment_service.charge(user_id, amount),
    compensation_action=lambda: payment_service.refund(user_id, amount)
)

# 步骤4：发送通知
saga.add_step(
    forward_action=lambda: notification_service.send_email(user_id, "订单确认"),
    compensation_action=lambda: notification_service.send_email(user_id, "订单取消")
)

# 执行
success = saga.execute()
```

---

## 分布式锁实现

### Redis分布式锁

```python
import redis
import uuid
import time

class RedisDistributedLock:
    def __init__(self, redis_client, lock_name, expire_time=10):
        self.redis = redis_client
        self.lock_name = f"lock:{lock_name}"
        self.expire_time = expire_time
        self.token = str(uuid.uuid4())

    def acquire(self, blocking=True, timeout=None):
        """获取锁"""
        start_time = time.time()

        while True:
            # SET NX EX：原子操作
            if self.redis.set(self.lock_name, self.token, nx=True, ex=self.expire_time):
                return True  # 获取成功

            if not blocking:
                return False

            if timeout and (time.time() - start_time) >= timeout:
                return False

            time.sleep(0.01)  # 10ms后重试

    def release(self):
        """释放锁（Lua脚本保证原子性）"""
        lua_script = """
        if redis.call("get", KEYS[1]) == ARGV[1] then
            return redis.call("del", KEYS[1])
        else
            return 0
        end
        """
        self.redis.eval(lua_script, 1, self.lock_name, self.token)

    def __enter__(self):
        self.acquire()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.release()

# 使用
redis_client = redis.Redis()

with RedisDistributedLock(redis_client, "order:1001"):
    # 临界区：确保只有一个进程处理订单1001
    process_order(1001)
```

### 基于PostgreSQL的分布式锁

```sql
-- 使用PostgreSQL Advisory Lock作为分布式锁

CREATE TABLE distributed_locks (
    lock_name VARCHAR(100) PRIMARY KEY,
    token UUID NOT NULL,
    acquired_at TIMESTAMPTZ NOT NULL,
    expires_at TIMESTAMPTZ NOT NULL,
    holder_info JSONB
);

CREATE INDEX idx_locks_expires ON distributed_locks(expires_at);

-- 获取锁
CREATE OR REPLACE FUNCTION acquire_lock(
    p_lock_name VARCHAR(100),
    p_token UUID,
    p_expire_seconds INTEGER DEFAULT 30
) RETURNS BOOLEAN AS $$
BEGIN
    -- 清理过期锁
    DELETE FROM distributed_locks
    WHERE expires_at < CURRENT_TIMESTAMP;

    -- 尝试获取锁
    BEGIN
        INSERT INTO distributed_locks (lock_name, token, acquired_at, expires_at)
        VALUES (
            p_lock_name,
            p_token,
            CURRENT_TIMESTAMP,
            CURRENT_TIMESTAMP + (p_expire_seconds || ' seconds')::INTERVAL
        );
        RETURN TRUE;
    EXCEPTION WHEN unique_violation THEN
        RETURN FALSE;  -- 锁已被占用
    END;
END;
$$ LANGUAGE plpgsql;

-- 释放锁
CREATE OR REPLACE FUNCTION release_lock(
    p_lock_name VARCHAR(100),
    p_token UUID
) RETURNS BOOLEAN AS $$
DECLARE
    v_deleted INTEGER;
BEGIN
    DELETE FROM distributed_locks
    WHERE lock_name = p_lock_name AND token = p_token;

    GET DIAGNOSTICS v_deleted = ROW_COUNT;
    RETURN v_deleted > 0;
END;
$$ LANGUAGE plpgsql;

-- Python使用
import uuid

class PostgreSQLDistributedLock:
    def __init__(self, conn, lock_name, expire_seconds=30):
        self.conn = conn
        self.lock_name = lock_name
        self.token = uuid.uuid4()
        self.expire_seconds = expire_seconds

    def __enter__(self):
        cursor = self.conn.execute(
            "SELECT acquire_lock(%s, %s, %s)",
            (self.lock_name, self.token, self.expire_seconds)
        )
        acquired = cursor.fetchone()[0]
        if not acquired:
            raise Exception(f"无法获取锁: {self.lock_name}")
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.conn.execute(
            "SELECT release_lock(%s, %s)",
            (self.lock_name, self.token)
        )

# 使用
conn = psycopg2.connect("...")

with PostgreSQLDistributedLock(conn, "process_order_1001"):
    # 临界区
    process_order(1001)
```

---

**文档版本**: v1.0.0
**最后更新**: 2025-12-04
