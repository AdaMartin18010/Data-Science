# SQL执行模型与查询编译

> **创建日期**: 2025-12-04
> **难度**: ⭐⭐⭐⭐⭐

---

## SQL执行流程

```text
SQL查询执行的五个阶段
══════════════════════════════════════════════════════════════════════════════

1. 解析（Parsing）
   └─ 词法分析 → 语法分析 → 生成AST

2. 绑定（Binding）
   └─ 名称解析 → 类型检查 → 语义验证

3. 优化（Optimization）
   └─ 逻辑优化 → 物理优化 → 代价估算

4. 执行（Execution）
   └─ 迭代器模型 / 向量化 / 编译执行

5. 结果返回（Result）
   └─ 投影 → 格式化 → 传输

示例流程：
SELECT name FROM users WHERE age > 18
    ↓ Parse
AST: {SELECT, [name], FROM, users, WHERE, {age, >, 18}}
    ↓ Bind
Resolve: users表存在，name和age列存在，类型正确
    ↓ Optimize
Plan: SeqScan(users) → Filter(age>18) → Project(name)
    ↓ Execute
迭代器执行，返回结果
```

---

## 执行模型

### Volcano迭代器模型

```text
Volcano模型（经典）
═══════════════════════════════════════════════════════════════

查询：SELECT name, SUM(salary) FROM employees GROUP BY name

执行计划树：
                ┌─────────────┐
                │   Project   │ (name, sum)
                └──────┬──────┘
                       │
                ┌──────▼──────┐
                │   HashAgg   │ (GROUP BY name)
                └──────┬──────┘
                       │
                ┌──────▼──────┐
                │   SeqScan   │ (employees)
                └─────────────┘

迭代器接口：
• open(): 初始化
• next(): 返回下一个元组（如果有）
• close(): 清理资源

执行流程（拉取模型）：
1. Project.open()
   └─ HashAgg.open()
      └─ SeqScan.open()

2. Project.next()
   └─ HashAgg.next() [首次]
      ├─ 循环: SeqScan.next() 直到EOF
      │  └─ 累积到哈希表
      └─ 返回第一个分组结果

3. Project.next() [第二次]
   └─ HashAgg.next()
      └─ 返回下一个分组结果

优点：
• 实现简单
• 代码模块化
• Pipeline友好

缺点：
• 虚函数调用开销大（每行一次）
• CPU缓存不友好
• 分支预测失败多
```

### 向量化执行

```text
向量化模型（现代）
═══════════════════════════════════════════════════════════════

与Volcano的区别：
• Volcano: next()返回一个元组
• Vectorized: next()返回一批元组（向量）

查询：SELECT a + b FROM table WHERE c > 10

Volcano执行（每行循环）：
for each row:
    if row.c > 10:
        result = row.a + row.b
        emit(result)

向量化执行（SIMD友好）：
batch = scan_next_batch(1000)  # 1000行
mask = batch.c > 10            # SIMD比较
result = batch.a[mask] + batch.b[mask]  # SIMD加法
emit(result)

性能提升：
• 10-100倍（取决于查询类型）
• CPU指令级并行（SIMD）
• 更少的函数调用
• 更好的缓存利用

代表数据库：
• MonetDB（先驱）
• ClickHouse
• DuckDB
• Apache Arrow
```

---

## 查询优化器

### 逻辑优化

```sql
-- 原始查询
SELECT * FROM orders o
JOIN users u ON o.user_id = u.id
WHERE u.country = 'USA'
  AND o.total > 1000;

-- 逻辑优化规则

-- 规则1：谓词下推（Predicate Pushdown）
-- 将WHERE条件尽早应用

-- 优化前：
JOIN(orders, users) → FILTER(country='USA' AND total>1000)

-- 优化后：
JOIN(
    FILTER(orders, total>1000),
    FILTER(users, country='USA')
)

-- 规则2：投影下推（Projection Pushdown）
-- 只读取需要的列

-- 优化前：
SELECT o.id, u.name
FROM orders o JOIN users u ...

-- 优化后：
SELECT orders.id, users.name  -- 扫描时只读这两列

-- 规则3：JOIN顺序优化
-- 小表在外，大表在内

-- 如果 users表(1万行) << orders表(100万行)
-- 优化前：orders JOIN users
-- 优化后：users JOIN orders

-- 规则4：子查询扁平化
-- 将子查询转换为JOIN

-- 优化前：
SELECT * FROM users
WHERE id IN (SELECT user_id FROM orders WHERE total > 1000);

-- 优化后：
SELECT DISTINCT u.*
FROM users u
JOIN orders o ON u.id = o.user_id
WHERE o.total > 1000;
```

### 代价估算

```text
代价模型
═══════════════════════════════════════════════════════════════

Cost = CPU_cost + IO_cost

CPU_cost = rows * CPU_tuple_cost
IO_cost = pages * IO_page_cost

示例：SeqScan vs IndexScan

表：users (100万行，1000页)
查询：WHERE age = 25 （选择性：1%，返回1万行）

-- SeqScan（全表扫描）
IO_cost = 1000 * 1.0 = 1000
CPU_cost = 1000000 * 0.01 = 10000
Total = 11000

-- IndexScan（索引扫描）
Index_IO = log(1000000) = 20页 (B-Tree深度)
Data_IO = 10000页 (回表)
IO_cost = 20 + 10000 = 10020
CPU_cost = 10000 * 0.01 = 100
Total = 10120

结论：IndexScan更快（虽然差距不大）

-- 如果选择性更高（age = 25，只返回10行）
IndexScan:
IO_cost = 20 + 10 = 30
CPU_cost = 10 * 0.01 = 0.1
Total = 30.1

SeqScan:
Total = 11000

结论：IndexScan快367倍！
```

---

## PostgreSQL执行引擎

### EXPLAIN分析

```sql
-- 示例查询
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT u.name, COUNT(*) as order_count
FROM users u
JOIN orders o ON u.id = o.user_id
WHERE o.created_at > '2025-01-01'
GROUP BY u.id, u.name;

-- 输出（简化）
HashAggregate  (cost=25.00..27.00 rows=200 width=40) (actual time=1.234..1.456 rows=150 loops=1)
  Group Key: u.id, u.name
  Batches: 1  Memory Usage: 24kB
  Buffers: shared hit=8
  ->  Hash Join  (cost=5.00..20.00 rows=1000 width=32) (actual time=0.123..0.789 rows=800 loops=1)
        Hash Cond: (o.user_id = u.id)
        Buffers: shared hit=8
        ->  Seq Scan on orders o  (cost=0.00..12.00 rows=800 width=8) (actual time=0.010..0.456 rows=800 loops=1)
              Filter: (created_at > '2025-01-01'::date)
              Rows Removed by Filter: 200
              Buffers: shared hit=5
        ->  Hash  (cost=3.00..3.00 rows=150 width=36) (actual time=0.089..0.090 rows=150 loops=1)
              Buckets: 1024  Batches: 1  Memory Usage: 12kB
              Buffers: shared hit=3
              ->  Seq Scan on users u  (cost=0.00..3.00 rows=150 width=36) (actual time=0.005..0.045 rows=150 loops=1)
                    Buffers: shared hit=3

Planning Time: 0.234 ms
Execution Time: 1.567 ms

关键指标解读：
• cost=开始..结束：估算代价
• actual time=开始..结束：实际时间（ms）
• rows=估算行数
• actual rows=实际行数
• loops=循环次数
• Buffers: shared hit=缓存命中页数
```

---

## 编译执行（JIT）

```text
传统解释执行 vs JIT编译
═══════════════════════════════════════════════════════════════

传统Volcano模型（解释执行）：
for (;;) {
    Tuple *tuple = child->next();  // 虚函数调用
    if (tuple == NULL) break;

    // 表达式求值（解释执行）
    Value result = eval_expr(tuple, expr);  // 分支多

    if (result.is_true()) {
        emit(tuple);
    }
}

JIT编译执行（PostgreSQL 11+）：
// 生成LLVM IR
define void @filter_func(i8* %tuple) {
    %age_ptr = getelementptr i8, i8* %tuple, i32 8
    %age = load i32, i32* %age_ptr
    %cmp = icmp sgt i32 %age, 18
    br i1 %cmp, label %emit, label %skip
emit:
    call void @emit_tuple(i8* %tuple)
    br label %skip
skip:
    ret void
}

// 编译为机器码
cmp DWORD PTR [rdi+8], 18
jle .skip
call emit_tuple
.skip:
ret

优势：
• 无虚函数调用开销
• 无分支预测失败
• SIMD指令优化
• 内联表达式求值

性能提升：30-50%（表达式密集查询）

启用JIT（PostgreSQL）：
SET jit = on;
SET jit_above_cost = 100000;  -- 代价>100000才JIT
```

---

## 并行执行

```sql
-- PostgreSQL并行查询

-- 配置
SET max_parallel_workers_per_gather = 4;
SET parallel_setup_cost = 1000;
SET parallel_tuple_cost = 0.1;

-- 查询
EXPLAIN ANALYZE
SELECT COUNT(*) FROM large_table WHERE value > 1000;

-- 执行计划
Finalize Aggregate  (cost=10000..10001 rows=1 width=8) (actual time=123.456..123.457 rows=1 loops=1)
  ->  Gather  (cost=10000..10000 rows=4 width=8) (actual time=123.123..125.234 rows=5 loops=1)
        Workers Planned: 4
        Workers Launched: 4
        ->  Partial Aggregate  (cost=9000..9000 rows=1 width=8) (actual time=120.123..120.124 rows=1 loops=5)
              ->  Parallel Seq Scan on large_table  (cost=0.00..8000 rows=250000 width=0) (actual time=0.012..89.456 rows=200000 loops=5)
                    Filter: (value > 1000)

-- 工作流程：
1. Coordinator启动4个Worker进程
2. 每个Worker扫描表的一部分（Parallel Seq Scan）
3. 每个Worker计算部分聚合（Partial Aggregate）
4. Coordinator收集结果（Gather）
5. Coordinator计算最终聚合（Finalize Aggregate）

并行效率 = (串行时间 / 并行时间) / Worker数
理想：100%
实际：60-80%（通信开销）
```

---

**文档版本**: v1.0.0
**最后更新**: 2025-12-04
