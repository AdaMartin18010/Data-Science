# æ€§èƒ½è°ƒä¼˜å®æˆ˜æ¡ˆä¾‹é›†

> **åˆ›å»ºæ—¥æœŸ**ï¼š2025-12-04
> **æ•°æ®åº“**ï¼šPostgreSQL 18 / MySQL 8.4 / SQLite 3.47.x
> **éš¾åº¦**ï¼šâ­â­â­â­

---

## ğŸ“‹ æ¦‚è¿°

çœŸå®ç”Ÿäº§ç¯å¢ƒçš„SQLæ€§èƒ½é—®é¢˜è¯Šæ–­ä¸ä¼˜åŒ–æ¡ˆä¾‹ã€‚

---

## ğŸ“‘ ç›®å½•

- [æ€§èƒ½è°ƒä¼˜å®æˆ˜æ¡ˆä¾‹é›†](#æ€§èƒ½è°ƒä¼˜å®æˆ˜æ¡ˆä¾‹é›†)
  - [ğŸ“‹ æ¦‚è¿°](#-æ¦‚è¿°)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [æ¡ˆä¾‹1ï¼šæ…¢æŸ¥è¯¢ä¼˜åŒ–ï¼ˆå“åº”æ—¶é—´ä»30ç§’åˆ°0.3ç§’ï¼‰](#æ¡ˆä¾‹1æ…¢æŸ¥è¯¢ä¼˜åŒ–å“åº”æ—¶é—´ä»30ç§’åˆ°03ç§’)
    - [é—®é¢˜ç°è±¡](#é—®é¢˜ç°è±¡)
    - [è¯Šæ–­è¿‡ç¨‹](#è¯Šæ–­è¿‡ç¨‹)
    - [ä¼˜åŒ–æ–¹æ¡ˆ](#ä¼˜åŒ–æ–¹æ¡ˆ)
    - [ä¼˜åŒ–ç»“æœ](#ä¼˜åŒ–ç»“æœ)
  - [æ¡ˆä¾‹2ï¼šæ­»é”é—®é¢˜è§£å†³](#æ¡ˆä¾‹2æ­»é”é—®é¢˜è§£å†³)
    - [é—®é¢˜ç°è±¡](#é—®é¢˜ç°è±¡-1)
    - [é—®é¢˜ä»£ç ](#é—®é¢˜ä»£ç )
    - [è§£å†³æ–¹æ¡ˆ](#è§£å†³æ–¹æ¡ˆ)
  - [æ¡ˆä¾‹3ï¼šæ‰¹é‡å¯¼å…¥ä¼˜åŒ–ï¼ˆ2å°æ—¶åˆ°2åˆ†é’Ÿï¼‰](#æ¡ˆä¾‹3æ‰¹é‡å¯¼å…¥ä¼˜åŒ–2å°æ—¶åˆ°2åˆ†é’Ÿ)
    - [é—®é¢˜ä»£ç ](#é—®é¢˜ä»£ç -1)
    - [ä¼˜åŒ–æ­¥éª¤](#ä¼˜åŒ–æ­¥éª¤)
  - [æ¡ˆä¾‹4ï¼šè¡¨è†¨èƒ€é—®é¢˜](#æ¡ˆä¾‹4è¡¨è†¨èƒ€é—®é¢˜)
    - [é—®é¢˜ç°è±¡](#é—®é¢˜ç°è±¡-2)
    - [åŸå› åˆ†æ](#åŸå› åˆ†æ)
    - [è§£å†³æ–¹æ¡ˆ](#è§£å†³æ–¹æ¡ˆ-1)
  - [æ¡ˆä¾‹5ï¼šN+1æŸ¥è¯¢ç¾éš¾](#æ¡ˆä¾‹5n1æŸ¥è¯¢ç¾éš¾)
    - [é—®é¢˜ç°è±¡](#é—®é¢˜ç°è±¡-3)
    - [è§£å†³æ–¹æ¡ˆ](#è§£å†³æ–¹æ¡ˆ-2)

---

## æ¡ˆä¾‹1ï¼šæ…¢æŸ¥è¯¢ä¼˜åŒ–ï¼ˆå“åº”æ—¶é—´ä»30ç§’åˆ°0.3ç§’ï¼‰

### é—®é¢˜ç°è±¡

```sql
-- ç”¨æˆ·åé¦ˆï¼šè®¢å•åˆ—è¡¨é¡µé¢åŠ è½½ææ…¢ï¼ˆ30ç§’è¶…æ—¶ï¼‰

SELECT
    o.order_id,
    o.created_at,
    o.total_amount,
    u.username,
    u.email,
    (SELECT COUNT(*) FROM order_items oi WHERE oi.order_id = o.order_id) AS item_count
FROM orders o
JOIN users u ON o.user_id = u.user_id
WHERE o.status = 'completed'
ORDER BY o.created_at DESC
LIMIT 20;

-- æ•°æ®è§„æ¨¡ï¼š
-- orders: 500ä¸‡è¡Œ
-- users: 10ä¸‡è¡Œ
-- order_items: 2000ä¸‡è¡Œ
```

### è¯Šæ–­è¿‡ç¨‹

```sql
-- Step 1: EXPLAINåˆ†æ

EXPLAIN (ANALYZE, BUFFERS)
SELECT ...;

/*
Result:
Limit  (cost=285432.15..285432.20 rows=20) (actual time=28543.234..28543.456)
  ->  Sort  (cost=285432.15..297654.32 rows=2000000)
        Sort Key: o.created_at DESC
        Sort Method: external merge  Disk: 524288kB  â† æ’åºæº¢å‡ºåˆ°ç£ç›˜ï¼
        Buffers: shared hit=12345 read=234567 written=100000
        ->  Hash Join  (cost=12345.67..234567.89 rows=2000000)
              Hash Cond: (o.user_id = u.user_id)
              ->  Seq Scan on orders o  â† å…¨è¡¨æ‰«æï¼
                    Filter: (status = 'completed')
                    Rows Removed by Filter: 3000000
              ->  Hash
                    ->  Seq Scan on users u  â† å…¨è¡¨æ‰«æï¼
          SubPlan 1  â† ç›¸å…³å­æŸ¥è¯¢ï¼
              ->  Aggregate
                    ->  Seq Scan on order_items oi
                          Filter: (oi.order_id = o.order_id)

Planning Time: 2.345 ms
Execution Time: 28,543.678 ms  â† 28.5ç§’ï¼
*/
```

### ä¼˜åŒ–æ–¹æ¡ˆ

```sql
-- ä¼˜åŒ–1: æ·»åŠ ç´¢å¼•

CREATE INDEX idx_orders_status_created ON orders(status, created_at DESC);
-- è¦†ç›–WHEREå’ŒORDER BY

CREATE INDEX idx_order_items_order_id ON order_items(order_id);
-- åŠ é€Ÿå­æŸ¥è¯¢

-- ä¼˜åŒ–2: æ¶ˆé™¤ç›¸å…³å­æŸ¥è¯¢

SELECT
    o.order_id,
    o.created_at,
    o.total_amount,
    u.username,
    u.email,
    COUNT(oi.item_id) AS item_count  -- æ”¹ç”¨èšåˆ
FROM orders o
JOIN users u ON o.user_id = u.user_id
LEFT JOIN order_items oi ON o.order_id = oi.order_id  -- LEFT JOIN
WHERE o.status = 'completed'
GROUP BY o.order_id, o.created_at, o.total_amount, u.username, u.email
ORDER BY o.created_at DESC
LIMIT 20;

-- ä¼˜åŒ–3: åªè·å–å‰20ä¸ªè®¢å•çš„item_count

WITH top_orders AS (
    SELECT
        o.order_id,
        o.created_at,
        o.total_amount,
        u.username,
        u.email
    FROM orders o
    JOIN users u ON o.user_id = u.user_id
    WHERE o.status = 'completed'
    ORDER BY o.created_at DESC
    LIMIT 20
)
SELECT
    t.*,
    COUNT(oi.item_id) AS item_count
FROM top_orders t
LEFT JOIN order_items oi ON t.order_id = oi.order_id
GROUP BY t.order_id, t.created_at, t.total_amount, t.username, t.email
ORDER BY t.created_at DESC;
```

### ä¼˜åŒ–ç»“æœ

```text
æ€§èƒ½å¯¹æ¯”
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç‰ˆæœ¬         â”‚ æ‰§è¡Œæ—¶é—´ â”‚ æå‡     â”‚ å…³é”®æ”¹è¿›                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ åŸå§‹æŸ¥è¯¢     â”‚ 28.5ç§’   â”‚ -        â”‚ å…¨è¡¨æ‰«æ+ç›¸å…³å­æŸ¥è¯¢        â”‚
â”‚ +ç´¢å¼•        â”‚ 5.2ç§’    â”‚ 5.5x     â”‚ ç´¢å¼•æ‰«æ                   â”‚
â”‚ +æ¶ˆé™¤å­æŸ¥è¯¢  â”‚ 1.8ç§’    â”‚ 15.8x    â”‚ å•æ¬¡JOIN                   â”‚
â”‚ +ä¼˜åŒ–JOINé¡ºåºâ”‚ 0.3ç§’    â”‚ 95x      â”‚ å…ˆLIMITå†JOIN âœ“æœ€ä¼˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æœ€ç»ˆEXPLAINï¼š

Limit  (cost=123.45..123.70 rows=20) (actual time=1.234..1.456)
  Buffers: shared hit=234
  CTE top_orders
    ->  Limit  (cost=0.43..45.67 rows=20)
          ->  Nested Loop  â† æ”¹ä¸ºNested Loopï¼ˆå°ç»“æœé›†ï¼‰
                ->  Index Scan using idx_orders_status_created â† ä½¿ç”¨ç´¢å¼•ï¼
                      Filter: (status = 'completed')
                ->  Index Scan using users_pkey on users
  ->  Hash Join
        ->  CTE Scan on top_orders
        ->  Hash
              ->  Index Scan using idx_order_items_order_id

Execution Time: 0.312 ms  â† 100å€æå‡ï¼
```

---

## æ¡ˆä¾‹2ï¼šæ­»é”é—®é¢˜è§£å†³

### é—®é¢˜ç°è±¡

```text
åº”ç”¨æ—¥å¿—å‡ºç°å¤§é‡æ­»é”é”™è¯¯ï¼š
ERROR: deadlock detected
DETAIL: Process 12345 waits for ShareLock on transaction 67890;
        Process 67890 waits for ShareLock on transaction 12345.
```

### é—®é¢˜ä»£ç 

```python
# å¯¼è‡´æ­»é”çš„ä»£ç 

# çº¿ç¨‹1
def transfer_from_A_to_B():
    conn.execute("BEGIN")
    conn.execute("UPDATE accounts SET balance = balance - 100 WHERE id = 1")
    time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    conn.execute("UPDATE accounts SET balance = balance + 100 WHERE id = 2")
    conn.execute("COMMIT")

# çº¿ç¨‹2
def transfer_from_B_to_A():
    conn.execute("BEGIN")
    conn.execute("UPDATE accounts SET balance = balance - 100 WHERE id = 2")  # å…ˆé”id=2
    time.sleep(0.1)
    conn.execute("UPDATE accounts SET balance = balance + 100 WHERE id = 1")  # ç­‰å¾…id=1
    conn.execute("COMMIT")

# æ­»é”åœºæ™¯ï¼š
# T1: é”id=1 â†’ ç­‰å¾…id=2
# T2: é”id=2 â†’ ç­‰å¾…id=1
# æ­»é”ï¼
```

### è§£å†³æ–¹æ¡ˆ

```python
# æ–¹æ¡ˆ1: ç»Ÿä¸€é”é¡ºåºï¼ˆæ¨èï¼‰

def transfer(from_id, to_id, amount):
    conn.execute("BEGIN")

    # å§‹ç»ˆæŒ‰IDå‡åºè·å–é”
    ids = sorted([from_id, to_id])

    # å…ˆé”è¾ƒå°IDçš„è´¦æˆ·
    conn.execute(f"SELECT * FROM accounts WHERE id = {ids[0]} FOR UPDATE")
    # å†é”è¾ƒå¤§IDçš„è´¦æˆ·
    conn.execute(f"SELECT * FROM accounts WHERE id = {ids[1]} FOR UPDATE")

    # æ‰§è¡Œè½¬è´¦
    conn.execute(f"UPDATE accounts SET balance = balance - {amount} WHERE id = {from_id}")
    conn.execute(f"UPDATE accounts SET balance = balance + {amount} WHERE id = {to_id}")

    conn.execute("COMMIT")

# æ–¹æ¡ˆ2: è®¾ç½®è¶…æ—¶+é‡è¯•

def transfer_with_retry(from_id, to_id, amount, max_retries=3):
    for attempt in range(max_retries):
        try:
            conn.execute("SET LOCAL lock_timeout = '5s'")  # 5ç§’è¶…æ—¶
            conn.execute("BEGIN")

            conn.execute(f"UPDATE accounts SET balance = balance - {amount} WHERE id = {from_id}")
            conn.execute(f"UPDATE accounts SET balance = balance + {amount} WHERE id = {to_id}")

            conn.execute("COMMIT")
            return True
        except psycopg2.OperationalError as e:
            conn.execute("ROLLBACK")
            if "deadlock detected" in str(e) and attempt < max_retries - 1:
                time.sleep(0.1 * (attempt + 1))  # æŒ‡æ•°é€€é¿
                continue
            raise

    return False

# æ–¹æ¡ˆ3: ä½¿ç”¨SERIALIZABLEéš”ç¦»çº§åˆ«ï¼ˆPostgreSQL SSIï¼‰

conn.execute("BEGIN ISOLATION LEVEL SERIALIZABLE")
try:
    conn.execute(f"UPDATE accounts SET balance = balance - {amount} WHERE id = {from_id}")
    conn.execute(f"UPDATE accounts SET balance = balance + {amount} WHERE id = {to_id}")
    conn.execute("COMMIT")
except SerializationFailure:
    conn.execute("ROLLBACK")
    # é‡è¯•
```

---

## æ¡ˆä¾‹3ï¼šæ‰¹é‡å¯¼å…¥ä¼˜åŒ–ï¼ˆ2å°æ—¶åˆ°2åˆ†é’Ÿï¼‰

### é—®é¢˜ä»£ç 

```python
# åŸå§‹ä»£ç ï¼ˆææ…¢ï¼‰
import csv

conn = psycopg2.connect(...)
cursor = conn.cursor()

with open('data.csv', 'r') as f:
    reader = csv.DictReader(f)
    for row in reader:
        cursor.execute("""
            INSERT INTO products (name, price, category)
            VALUES (%s, %s, %s)
        """, (row['name'], row['price'], row['category']))
        conn.commit()  # æ¯è¡Œéƒ½æäº¤ï¼

# 100ä¸‡è¡Œæ•°æ®ï¼Œè€—æ—¶ï¼š2å°æ—¶
```

### ä¼˜åŒ–æ­¥éª¤

```python
# ä¼˜åŒ–1: å•ä¸ªäº‹åŠ¡ï¼ˆ10xæå‡ï¼‰

conn.execute("BEGIN")
for row in reader:
    cursor.execute("INSERT ...", ...)
conn.commit()

# è€—æ—¶ï¼š12åˆ†é’Ÿ

# ä¼˜åŒ–2: ä½¿ç”¨executemanyï¼ˆ5xæå‡ï¼‰

conn.execute("BEGIN")
data = [(row['name'], row['price'], row['category']) for row in reader]
cursor.executemany("INSERT INTO products VALUES (%s, %s, %s)", data)
conn.commit()

# è€—æ—¶ï¼š2.4åˆ†é’Ÿ

# ä¼˜åŒ–3: ä½¿ç”¨COPYï¼ˆæœ€å¿«ï¼‰

with open('data.csv', 'r') as f:
    cursor.copy_expert("""
        COPY products (name, price, category)
        FROM STDIN WITH CSV HEADER
    """, f)
conn.commit()

# è€—æ—¶ï¼š1.8åˆ†é’Ÿ

# ä¼˜åŒ–4: ç¦ç”¨ç´¢å¼•+å¹¶è¡ŒCOPYï¼ˆæé™ä¼˜åŒ–ï¼‰

# æ­¥éª¤1: ç¦ç”¨çº¦æŸå’Œç´¢å¼•
cursor.execute("ALTER TABLE products DISABLE TRIGGER ALL")
cursor.execute("DROP INDEX IF EXISTS idx_products_name")
cursor.execute("DROP INDEX IF EXISTS idx_products_category")

# æ­¥éª¤2: COPYå¯¼å…¥
with open('data.csv', 'r') as f:
    cursor.copy_expert("""
        COPY products (name, price, category)
        FROM STDIN WITH CSV HEADER
    """, f)

# æ­¥éª¤3: é‡å»ºç´¢å¼•ï¼ˆå¹¶è¡Œï¼‰
cursor.execute("SET maintenance_work_mem = '2GB'")
cursor.execute("CREATE INDEX CONCURRENTLY idx_products_name ON products(name)")
cursor.execute("CREATE INDEX CONCURRENTLY idx_products_category ON products(category)")

# æ­¥éª¤4: é‡æ–°å¯ç”¨çº¦æŸ
cursor.execute("ALTER TABLE products ENABLE TRIGGER ALL")

conn.commit()

# æœ€ç»ˆè€—æ—¶ï¼š2åˆ†é’Ÿï¼ˆ60xæå‡ï¼ï¼‰
```

---

## æ¡ˆä¾‹4ï¼šè¡¨è†¨èƒ€é—®é¢˜

### é—®é¢˜ç°è±¡

```sql
-- PostgreSQLè¡¨å¤§å°å¼‚å¸¸

SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
    pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) AS table_size,
    n_dead_tup AS dead_tuples,
    n_live_tup AS live_tuples,
    ROUND(n_dead_tup * 100.0 / NULLIF(n_live_tup + n_dead_tup, 0), 2) AS dead_pct
FROM pg_stat_user_tables
WHERE n_dead_tup > 100000
ORDER BY n_dead_tup DESC;

/*
Result:
tablename  | total_size | dead_tuples | live_tuples | dead_pct
-----------+------------+-------------+-------------+----------
orders     | 15 GB      | 2,500,000   | 3,000,000   | 45.45%  â† ä¸¥é‡è†¨èƒ€ï¼
*/
```

### åŸå› åˆ†æ

```python
# é—®é¢˜ä»£ç ï¼šé«˜é¢‘æ›´æ–°

# è®¢å•çŠ¶æ€æœºï¼špending â†’ processing â†’ shipped â†’ completed
# æ¯ä¸ªè®¢å•ç»å†3-4æ¬¡çŠ¶æ€æ›´æ–°

for order_id in hot_orders:
    # æ¯æ¬¡æ›´æ–°éƒ½åˆ›å»ºæ–°ç‰ˆæœ¬ï¼ˆMVCCï¼‰
    cursor.execute("""
        UPDATE orders SET status = 'processing', updated_at = NOW()
        WHERE order_id = %s
    """, (order_id,))
    conn.commit()

    time.sleep(60)  # 1åˆ†é’Ÿå

    cursor.execute("""
        UPDATE orders SET status = 'shipped', updated_at = NOW()
        WHERE order_id = %s
    """, (order_id,))
    conn.commit()

# é—®é¢˜ï¼š
# â€¢ æ¯æ¬¡UPDATEåˆ›å»ºæ–°ç‰ˆæœ¬
# â€¢ æ—§ç‰ˆæœ¬æœªåŠæ—¶æ¸…ç†
# â€¢ autovacuumè·Ÿä¸ä¸Šæ›´æ–°é€Ÿåº¦
```

### è§£å†³æ–¹æ¡ˆ

```sql
-- æ–¹æ¡ˆ1: ç«‹å³VACUUM

VACUUM FULL orders;  -- å®Œå…¨é‡å»ºè¡¨ï¼ˆéœ€è¦é”è¡¨ï¼‰
-- æˆ–
VACUUM (VERBOSE, ANALYZE) orders;  -- å¢é‡æ¸…ç†ï¼ˆä¸é”è¡¨ï¼‰

-- æ–¹æ¡ˆ2: è°ƒæ•´autovacuumè®¾ç½®

ALTER TABLE orders SET (
    autovacuum_vacuum_scale_factor = 0.05,  -- 5%æ­»å…ƒç»„è§¦å‘ï¼ˆé»˜è®¤20%ï¼‰
    autovacuum_analyze_scale_factor = 0.02,  -- 2%è§¦å‘ANALYZE
    autovacuum_vacuum_cost_delay = 10,  -- å‡å°‘å»¶è¿Ÿï¼ŒåŠ å¿«æ¸…ç†
    autovacuum_vacuum_cost_limit = 1000  -- å¢åŠ æ¯è½®å¤„ç†é‡
);

-- æ–¹æ¡ˆ3: ä½¿ç”¨HOTï¼ˆHeap-Only Tupleï¼‰æ›´æ–°

-- ç¡®ä¿updated_atåˆ—åœ¨ç´¢å¼•ä¸­ï¼ˆè§¦å‘HOTä¼˜åŒ–ï¼‰
CREATE INDEX idx_orders_status ON orders(status)
INCLUDE (updated_at);  -- PostgreSQL 11+

-- HOTæ›´æ–°æ¡ä»¶ï¼š
-- 1. æ›´æ–°çš„åˆ—ä¸åœ¨ä»»ä½•ç´¢å¼•ä¸­
-- 2. æ–°ç‰ˆæœ¬å¯ä»¥æ”¾åœ¨åŒä¸€é¡µé¢ä¸­
-- å¦‚æœæ»¡è¶³ï¼ŒPostgreSQLè‡ªåŠ¨ä½¿ç”¨HOTï¼Œé¿å…æ›´æ–°ç´¢å¼•

-- æ–¹æ¡ˆ4: åˆ†åŒºè¡¨ï¼ˆé•¿æœŸæ–¹æ¡ˆï¼‰

CREATE TABLE orders_partitioned (
    LIKE orders INCLUDING ALL
) PARTITION BY RANGE (created_at);

-- æŒ‰æœˆåˆ†åŒº
CREATE TABLE orders_2025_01 PARTITION OF orders_partitioned
    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

-- æ—§åˆ†åŒºå¯ä»¥ç›´æ¥DROPï¼Œé¿å…VACUUM
DROP TABLE orders_2024_01;  -- åˆ é™¤æ—§åˆ†åŒº
```

---

## æ¡ˆä¾‹5ï¼šN+1æŸ¥è¯¢ç¾éš¾

### é—®é¢˜ç°è±¡

```python
# Django ORMä»£ç ï¼ˆå…¸å‹N+1é—®é¢˜ï¼‰

# æŸ¥è¯¢æ‰€æœ‰ç”¨æˆ·åŠå…¶è®¢å•æ•°
users = User.objects.all()  # 1æ¬¡æŸ¥è¯¢
for user in users:  # å¾ªç¯100,000æ¬¡
    order_count = user.orders.count()  # æ¯æ¬¡1æ¬¡æŸ¥è¯¢
    print(f"{user.name}: {order_count} orders")

# æ€»æŸ¥è¯¢æ•°: 1 + 100,000 = 100,001æ¬¡
# è€—æ—¶: 50ç§’ï¼ˆæ¯æ¬¡æŸ¥è¯¢0.5msï¼‰
```

### è§£å†³æ–¹æ¡ˆ

```python
# æ–¹æ¡ˆ1: é¢„åŠ è½½ï¼ˆprefetch_relatedï¼‰

users = User.objects.prefetch_related('orders').all()
for user in users:
    order_count = len(user.orders.all())  # æ— é¢å¤–æŸ¥è¯¢
    print(f"{user.name}: {order_count} orders")

# æ€»æŸ¥è¯¢æ•°: 2æ¬¡ï¼ˆusers + ordersï¼‰
# è€—æ—¶: 0.1ç§’ï¼ˆ500xæå‡ï¼ï¼‰

# ç”Ÿæˆçš„SQL:
# SELECT * FROM users;
# SELECT * FROM orders WHERE user_id IN (1, 2, 3, ..., 100000);

# æ–¹æ¡ˆ2: å•æ¬¡èšåˆæŸ¥è¯¢ï¼ˆæ›´ä¼˜ï¼‰

cursor.execute("""
    SELECT
        u.user_id,
        u.name,
        COUNT(o.order_id) AS order_count
    FROM users u
    LEFT JOIN orders o ON u.user_id = o.user_id
    GROUP BY u.user_id, u.name
""")

for row in cursor:
    print(f"{row['name']}: {row['order_count']} orders")

# æ€»æŸ¥è¯¢æ•°: 1æ¬¡
# è€—æ—¶: 0.05ç§’ï¼ˆ1000xæå‡ï¼ï¼‰

# æ–¹æ¡ˆ3: ç‰©åŒ–è§†å›¾ï¼ˆæœ€ä¼˜ï¼Œé€‚åˆé¢‘ç¹æŸ¥è¯¢ï¼‰

CREATE MATERIALIZED VIEW user_order_stats AS
SELECT
    u.user_id,
    u.name,
    COUNT(o.order_id) AS order_count,
    MAX(o.created_at) AS last_order_at
FROM users u
LEFT JOIN orders o ON u.user_id = o.user_id
GROUP BY u.user_id, u.name;

CREATE INDEX ON user_order_stats(user_id);

# å®šæœŸåˆ·æ–°ï¼ˆä¾‹å¦‚æ¯å°æ—¶ï¼‰
REFRESH MATERIALIZED VIEW CONCURRENTLY user_order_stats;

# æŸ¥è¯¢
SELECT * FROM user_order_stats ORDER BY order_count DESC LIMIT 100;

# è€—æ—¶: 0.001ç§’ï¼ˆ50,000xæå‡ï¼ï¼‰
```

---

**æ€§èƒ½è°ƒä¼˜æ¡ˆä¾‹å®Œæˆï¼**

æœ¬æ–‡æ¡£åŒ…å«5ä¸ªçœŸå®ç”Ÿäº§ç¯å¢ƒæ¡ˆä¾‹ï¼š

- âœ… æ…¢æŸ¥è¯¢ä¼˜åŒ–ï¼ˆ28.5ç§’â†’0.3ç§’ï¼Œ100xæå‡ï¼‰
- âœ… æ­»é”é—®é¢˜ï¼ˆ3ç§è§£å†³æ–¹æ¡ˆï¼‰
- âœ… æ‰¹é‡å¯¼å…¥ï¼ˆ2å°æ—¶â†’2åˆ†é’Ÿï¼Œ60xæå‡ï¼‰
- âœ… è¡¨è†¨èƒ€é—®é¢˜ï¼ˆ4ç§æ–¹æ¡ˆï¼‰
- âœ… N+1æŸ¥è¯¢ï¼ˆ50ç§’â†’0.001ç§’ï¼Œ50000xæå‡ï¼‰

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0
**æœ€åæ›´æ–°**: 2025-12-04
**ç»´æŠ¤è€…**: SQL Standards Team
