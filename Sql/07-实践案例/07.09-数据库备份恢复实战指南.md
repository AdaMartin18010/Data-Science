# æ•°æ®åº“å¤‡ä»½æ¢å¤å®æˆ˜æŒ‡å—

> **åˆ›å»ºæ—¥æœŸ**ï¼š2025-12-04
> **æ•°æ®åº“**ï¼šPostgreSQL 18 / MySQL 8.4 / SQLite 3.47.x
> **éš¾åº¦**ï¼šâ­â­â­â­

---

## ğŸ“‹ æ¦‚è¿°

ç”Ÿäº§ç¯å¢ƒæ•°æ®åº“å¤‡ä»½æ¢å¤çš„å®Œæ•´æ–¹æ¡ˆï¼ŒåŒ…æ‹¬å¤‡ä»½ç­–ç•¥ã€è‡ªåŠ¨åŒ–è„šæœ¬å’Œç¾éš¾æ¢å¤ã€‚

---

## ğŸ“‘ ç›®å½•

- [æ•°æ®åº“å¤‡ä»½æ¢å¤å®æˆ˜æŒ‡å—](#æ•°æ®åº“å¤‡ä»½æ¢å¤å®æˆ˜æŒ‡å—)
  - [ğŸ“‹ æ¦‚è¿°](#-æ¦‚è¿°)
  - [ğŸ“‘ ç›®å½•](#-ç›®å½•)
  - [ä¸€ã€å¤‡ä»½ç­–ç•¥](#ä¸€å¤‡ä»½ç­–ç•¥)
    - [1.1 3-2-1å¤‡ä»½åŸåˆ™](#11-3-2-1å¤‡ä»½åŸåˆ™)
    - [1.2 RTOå’ŒRPO](#12-rtoå’Œrpo)
  - [äºŒã€PostgreSQLå¤‡ä»½æ–¹æ¡ˆ](#äºŒpostgresqlå¤‡ä»½æ–¹æ¡ˆ)
    - [2.1 é€»è¾‘å¤‡ä»½ï¼ˆpg\_dumpï¼‰](#21-é€»è¾‘å¤‡ä»½pg_dump)
    - [2.2 ç‰©ç†å¤‡ä»½ï¼ˆpg\_basebackupï¼‰](#22-ç‰©ç†å¤‡ä»½pg_basebackup)
    - [2.3 WALå½’æ¡£ï¼ˆPITRï¼‰](#23-walå½’æ¡£pitr)
  - [ä¸‰ã€SQLiteå¤‡ä»½æ–¹æ¡ˆ](#ä¸‰sqliteå¤‡ä»½æ–¹æ¡ˆ)
    - [3.1 æ–‡ä»¶æ‹·è´å¤‡ä»½](#31-æ–‡ä»¶æ‹·è´å¤‡ä»½)
    - [3.2 åœ¨çº¿å¤‡ä»½ï¼ˆWALæ¨¡å¼ï¼‰](#32-åœ¨çº¿å¤‡ä»½walæ¨¡å¼)
    - [3.3 å¢é‡å¤‡ä»½](#33-å¢é‡å¤‡ä»½)
  - [å››ã€è‡ªåŠ¨åŒ–å¤‡ä»½è„šæœ¬](#å››è‡ªåŠ¨åŒ–å¤‡ä»½è„šæœ¬)
  - [äº”ã€æ¢å¤æ¼”ç»ƒ](#äº”æ¢å¤æ¼”ç»ƒ)
    - [5.1 å®Œå…¨æ¢å¤](#51-å®Œå…¨æ¢å¤)
    - [5.2 æ—¶é—´ç‚¹æ¢å¤ï¼ˆPITRï¼‰](#52-æ—¶é—´ç‚¹æ¢å¤pitr)
    - [5.3 éƒ¨åˆ†æ¢å¤](#53-éƒ¨åˆ†æ¢å¤)

---

## ä¸€ã€å¤‡ä»½ç­–ç•¥

### 1.1 3-2-1å¤‡ä»½åŸåˆ™

```text
3-2-1å¤‡ä»½åŸåˆ™
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

3: è‡³å°‘3ä»½æ•°æ®å‰¯æœ¬
â”œâ”€â”€ 1ä»½ç”Ÿäº§æ•°æ®ï¼ˆä¸»åº“ï¼‰
â”œâ”€â”€ 1ä»½æœ¬åœ°å¤‡ä»½ï¼ˆåŒæœºæˆ¿ï¼‰
â””â”€â”€ 1ä»½å¼‚åœ°å¤‡ä»½ï¼ˆä¸åŒæœºæˆ¿/äº‘å­˜å‚¨ï¼‰

2: ä½¿ç”¨2ç§ä¸åŒå­˜å‚¨ä»‹è´¨
â”œâ”€â”€ æœ¬åœ°SSD/HDD
â””â”€â”€ äº‘å­˜å‚¨ï¼ˆS3/OSSï¼‰æˆ–ç£å¸¦

1: è‡³å°‘1ä»½ç¦»çº¿å¤‡ä»½
â””â”€â”€ ç‰©ç†éš”ç¦»ï¼Œé˜²æ­¢å‹’ç´¢è½¯ä»¶

å®æ–½æ–¹æ¡ˆï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ä¸»æ•°æ®åº“ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰                                            â”‚
â”‚ PostgreSQL on Server1                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       â”‚       â”‚               â”‚
        â–¼       â–¼       â–¼               â–¼
    æœ¬åœ°å¤‡ä»½  çƒ­å¤‡   WALå½’æ¡£        å¼‚åœ°å¤‡ä»½
    (æ¯æ—¥)   (å®æ—¶)  (è¿ç»­)         (æ¯æ—¥)
    Server2  Replica S3 Bucket     äº‘å­˜å‚¨
```

### 1.2 RTOå’ŒRPO

```text
æ¢å¤ç›®æ ‡è®¾å®š
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

RTOï¼ˆRecovery Time Objectiveï¼‰ï¼šå…è®¸çš„æœ€å¤§åœæœºæ—¶é—´
RPOï¼ˆRecovery Point Objectiveï¼‰ï¼šå…è®¸çš„æœ€å¤§æ•°æ®ä¸¢å¤±æ—¶é—´

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç³»ç»Ÿçº§åˆ«     â”‚ RTOç›®æ ‡    â”‚ RPOç›®æ ‡    â”‚ æ¨èæ–¹æ¡ˆ                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å…³é”®ä¸šåŠ¡     â”‚ < 5åˆ†é’Ÿ    â”‚ 0ï¼ˆé›¶ä¸¢å¤±ï¼‰â”‚ åŒæ­¥å¤åˆ¶+è‡ªåŠ¨æ•…éšœè½¬ç§»    â”‚
â”‚ é‡è¦ä¸šåŠ¡     â”‚ < 1å°æ—¶    â”‚ < 15åˆ†é’Ÿ   â”‚ å¼‚æ­¥å¤åˆ¶+WALå½’æ¡£         â”‚
â”‚ ä¸€èˆ¬ä¸šåŠ¡     â”‚ < 4å°æ—¶    â”‚ < 1å°æ—¶    â”‚ æ¯å°æ—¶å¤‡ä»½               â”‚
â”‚ å¼€å‘æµ‹è¯•     â”‚ < 24å°æ—¶   â”‚ < 24å°æ—¶   â”‚ æ¯æ—¥å¤‡ä»½                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## äºŒã€PostgreSQLå¤‡ä»½æ–¹æ¡ˆ

### 2.1 é€»è¾‘å¤‡ä»½ï¼ˆpg_dumpï¼‰

```bash
#!/bin/bash
# PostgreSQLé€»è¾‘å¤‡ä»½è„šæœ¬

# é…ç½®
DB_HOST="localhost"
DB_PORT="5432"
DB_NAME="mydb"
DB_USER="postgres"
BACKUP_DIR="/backup/postgres"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/${DB_NAME}_${DATE}.sql.gz"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# æ‰§è¡Œå¤‡ä»½ï¼ˆå‹ç¼©ï¼‰
pg_dump \
    -h $DB_HOST \
    -p $DB_PORT \
    -U $DB_USER \
    -d $DB_NAME \
    --format=custom \
    --compress=9 \
    --verbose \
    --file=$BACKUP_FILE.custom

# æˆ–è€…çº¯SQLæ ¼å¼ï¼ˆæ›´é€šç”¨ï¼‰
pg_dump \
    -h $DB_HOST \
    -U $DB_USER \
    -d $DB_NAME \
    --format=plain \
    | gzip > $BACKUP_FILE

# å¤‡ä»½å•ä¸ªè¡¨
pg_dump -t users -t orders \
    -h $DB_HOST \
    -U $DB_USER \
    -d $DB_NAME \
    | gzip > ${BACKUP_DIR}/tables_${DATE}.sql.gz

# å¤‡ä»½schema only
pg_dump --schema-only \
    -h $DB_HOST \
    -U $DB_USER \
    -d $DB_NAME \
    > ${BACKUP_DIR}/schema_${DATE}.sql

# éªŒè¯å¤‡ä»½
if [ $? -eq 0 ]; then
    echo "å¤‡ä»½æˆåŠŸ: $BACKUP_FILE"

    # ä¸Šä¼ åˆ°S3
    aws s3 cp $BACKUP_FILE s3://my-backups/postgres/

    # æ¸…ç†30å¤©å‰çš„æœ¬åœ°å¤‡ä»½
    find $BACKUP_DIR -name "*.sql.gz" -mtime +30 -delete
else
    echo "å¤‡ä»½å¤±è´¥ï¼" >&2
    exit 1
fi
```

**æ¢å¤**ï¼š

```bash
# æ¢å¤customæ ¼å¼å¤‡ä»½
pg_restore \
    -h localhost \
    -U postgres \
    -d mydb_restored \
    --verbose \
    /backup/postgres/mydb_20251204.sql.gz.custom

# æ¢å¤çº¯SQLæ ¼å¼
gunzip -c /backup/postgres/mydb_20251204.sql.gz | psql -U postgres -d mydb_restored

# æ¢å¤å•ä¸ªè¡¨
pg_restore -t users \
    -h localhost \
    -U postgres \
    -d mydb \
    /backup/postgres/backup.custom
```

### 2.2 ç‰©ç†å¤‡ä»½ï¼ˆpg_basebackupï¼‰

```bash
# PostgreSQLç‰©ç†å¤‡ä»½ï¼ˆæ–‡ä»¶çº§ï¼‰

# åŸºç¡€å¤‡ä»½
pg_basebackup \
    -h localhost \
    -U replication_user \
    -D /backup/base \
    --format=tar \
    --gzip \
    --progress \
    --checkpoint=fast \
    --wal-method=stream  # åŒæ—¶å¤‡ä»½WAL

# å¢é‡å¤‡ä»½ï¼ˆPostgreSQL 17+ï¼‰
pg_basebackup \
    -D /backup/incremental \
    --incremental=/backup/base/backup_manifest \
    --format=plain
```

### 2.3 WALå½’æ¡£ï¼ˆPITRï¼‰

```sql
-- PostgreSQL WALå½’æ¡£é…ç½®ï¼ˆpostgresql.confï¼‰

wal_level = replica
archive_mode = on
archive_command = 'test ! -f /archive/%f && cp %p /archive/%f'
archive_timeout = 300  -- 5åˆ†é’Ÿå¼ºåˆ¶å½’æ¡£

-- æˆ–ä¸Šä¼ åˆ°S3
archive_command = 'aws s3 cp %p s3://my-wal-archive/%f'

-- æ¢å¤é…ç½®ï¼ˆrecovery.confæˆ–postgresql.auto.confï¼‰
restore_command = 'cp /archive/%f %p'
recovery_target_time = '2025-12-04 10:30:00'  -- æ¢å¤åˆ°æŒ‡å®šæ—¶é—´ç‚¹
```

---

## ä¸‰ã€SQLiteå¤‡ä»½æ–¹æ¡ˆ

### 3.1 æ–‡ä»¶æ‹·è´å¤‡ä»½

```bash
#!/bin/bash
# SQLiteæ–‡ä»¶å¤‡ä»½è„šæœ¬

DB_FILE="/app/data/app.db"
BACKUP_DIR="/backup/sqlite"
DATE=$(date +%Y%m%d_%H%M%S)

# æ–¹æ³•1: ç›´æ¥æ‹·è´ï¼ˆéœ€è¦åœæ­¢å†™å…¥ï¼‰
# ä¸æ¨èï¼šå¯èƒ½æ‹·è´åˆ°ä¸ä¸€è‡´çŠ¶æ€

# æ–¹æ³•2: SQLite backup APIï¼ˆæ¨èï¼‰
sqlite3 $DB_FILE ".backup ${BACKUP_DIR}/app_${DATE}.db"

# æ–¹æ³•3: å¯¼å‡ºSQL
sqlite3 $DB_FILE .dump | gzip > ${BACKUP_DIR}/app_${DATE}.sql.gz

# éªŒè¯å¤‡ä»½
sqlite3 ${BACKUP_DIR}/app_${DATE}.db "PRAGMA integrity_check"

# å‹ç¼©å¤‡ä»½
gzip ${BACKUP_DIR}/app_${DATE}.db

# ä¸Šä¼ åˆ°äº‘
rclone copy ${BACKUP_DIR}/app_${DATE}.db.gz remote:backups/sqlite/
```

### 3.2 åœ¨çº¿å¤‡ä»½ï¼ˆWALæ¨¡å¼ï¼‰

```python
# SQLiteåœ¨çº¿å¤‡ä»½ï¼ˆPythonå®ç°ï¼‰

import sqlite3
import shutil
from datetime import datetime

def online_backup(source_db, backup_db):
    """åœ¨çº¿å¤‡ä»½ï¼ˆä¸é˜»å¡è¯»å†™ï¼‰"""
    # è¿æ¥æºæ•°æ®åº“
    source = sqlite3.connect(source_db)

    # ç¡®ä¿WALæ¨¡å¼
    source.execute("PRAGMA journal_mode=WAL")

    # æ‰§è¡Œbackup API
    backup = sqlite3.connect(backup_db)

    with backup:
        source.backup(backup)

    backup.close()
    source.close()

    print(f"å¤‡ä»½å®Œæˆ: {backup_db}")
    return backup_db

def incremental_backup_wal(db_file, backup_dir):
    """å¤‡ä»½WALæ–‡ä»¶ï¼ˆå¢é‡ï¼‰"""
    wal_file = f"{db_file}-wal"
    shm_file = f"{db_file}-shm"

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    # è§¦å‘checkpointï¼ˆå°†WALåˆå¹¶åˆ°ä¸»æ–‡ä»¶ï¼‰
    conn = sqlite3.connect(db_file)
    conn.execute("PRAGMA wal_checkpoint(PASSIVE)")

    # å¤‡ä»½ä¸»æ–‡ä»¶
    shutil.copy2(db_file, f"{backup_dir}/db_{timestamp}.db")

    # å¤‡ä»½WALï¼ˆå¦‚æœè¿˜æœ‰æœªcheckpointçš„æ•°æ®ï¼‰
    if os.path.exists(wal_file):
        shutil.copy2(wal_file, f"{backup_dir}/wal_{timestamp}.wal")

    conn.close()

# å®šæ—¶å¤‡ä»½
import schedule

def backup_job():
    online_backup('/app/data/app.db', f'/backup/app_{datetime.now().strftime("%Y%m%d_%H%M%S")}.db')

# æ¯6å°æ—¶å¤‡ä»½ä¸€æ¬¡
schedule.every(6).hours.do(backup_job)

# æ¯å¤©å‡Œæ™¨2ç‚¹å®Œæ•´å¤‡ä»½
schedule.every().day.at("02:00").do(lambda:
    online_backup('/app/data/app.db', f'/backup/daily/app_{datetime.now().strftime("%Y%m%d")}.db')
)

while True:
    schedule.run_pending()
    time.sleep(60)
```

### 3.3 å¢é‡å¤‡ä»½

```python
# SQLiteå¢é‡å¤‡ä»½æ–¹æ¡ˆ

import sqlite3
import hashlib

class IncrementalBackup:
    def __init__(self, db_file):
        self.db_file = db_file
        self.conn = sqlite3.connect(db_file)

    def get_table_checksum(self, table_name):
        """è®¡ç®—è¡¨çš„æ ¡éªŒå’Œ"""
        cursor = self.conn.execute(f"SELECT * FROM {table_name} ORDER BY rowid")
        checksum = hashlib.md5()

        for row in cursor:
            checksum.update(str(row).encode())

        return checksum.hexdigest()

    def export_changed_tables(self, last_checksums, backup_file):
        """å¯¼å‡ºå˜åŒ–çš„è¡¨"""
        cursor = self.conn.execute(
            "SELECT name FROM sqlite_master WHERE type='table'"
        )
        tables = [row[0] for row in cursor]

        changed_tables = []
        current_checksums = {}

        for table in tables:
            current_checksum = self.get_table_checksum(table)
            current_checksums[table] = current_checksum

            if table not in last_checksums or last_checksums[table] != current_checksum:
                changed_tables.append(table)

        if changed_tables:
            # å¯¼å‡ºå˜åŒ–çš„è¡¨
            backup_conn = sqlite3.connect(backup_file)

            for table in changed_tables:
                # è·å–è¡¨ç»“æ„
                schema = self.conn.execute(
                    f"SELECT sql FROM sqlite_master WHERE type='table' AND name='{table}'"
                ).fetchone()[0]

                backup_conn.execute(schema)

                # å¤åˆ¶æ•°æ®
                rows = self.conn.execute(f"SELECT * FROM {table}").fetchall()
                placeholders = ','.join(['?'] * len(rows[0])) if rows else ''
                if rows:
                    backup_conn.executemany(
                        f"INSERT INTO {table} VALUES ({placeholders})",
                        rows
                    )

            backup_conn.commit()
            backup_conn.close()

            print(f"å¢é‡å¤‡ä»½å®Œæˆï¼Œå˜åŒ–è¡¨: {changed_tables}")

        return current_checksums

# ä½¿ç”¨
backup = IncrementalBackup('/app/data/app.db')
checksums = {}

# ç¬¬ä¸€æ¬¡ï¼šå…¨é‡å¤‡ä»½
checksums = backup.export_changed_tables({}, '/backup/full.db')

# åç»­ï¼šå¢é‡å¤‡ä»½
checksums = backup.export_changed_tables(checksums, f'/backup/incr_{datetime.now()}.db')
```

---

## å››ã€è‡ªåŠ¨åŒ–å¤‡ä»½è„šæœ¬

```python
# å®Œæ•´çš„è‡ªåŠ¨åŒ–å¤‡ä»½ç³»ç»Ÿ

import os
import subprocess
import boto3
from datetime import datetime, timedelta
import logging

class BackupManager:
    def __init__(self, config):
        self.config = config
        self.s3 = boto3.client('s3')
        self.logger = logging.getLogger(__name__)

    def backup_postgres(self):
        """PostgreSQLå¤‡ä»½"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_file = f"/backup/pg_{timestamp}.custom"

        try:
            # æ‰§è¡Œpg_dump
            subprocess.run([
                'pg_dump',
                '-h', self.config['pg_host'],
                '-U', self.config['pg_user'],
                '-d', self.config['pg_database'],
                '-Fc',  # Custom format
                '-f', backup_file
            ], check=True, timeout=3600)

            # éªŒè¯å¤‡ä»½
            result = subprocess.run([
                'pg_restore',
                '--list',
                backup_file
            ], capture_output=True, text=True)

            if result.returncode == 0:
                self.logger.info(f"å¤‡ä»½éªŒè¯æˆåŠŸ: {backup_file}")

                # ä¸Šä¼ åˆ°S3
                self.upload_to_s3(backup_file, 'postgres')

                # æ¸…ç†æœ¬åœ°æ—§å¤‡ä»½
                self.cleanup_old_backups('/backup', days=7)

                return True
            else:
                self.logger.error("å¤‡ä»½éªŒè¯å¤±è´¥")
                return False

        except subprocess.TimeoutExpired:
            self.logger.error("å¤‡ä»½è¶…æ—¶")
            return False
        except Exception as e:
            self.logger.error(f"å¤‡ä»½å¤±è´¥: {e}")
            return False

    def backup_sqlite(self):
        """SQLiteå¤‡ä»½"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        for db_name, db_path in self.config['sqlite_dbs'].items():
            backup_file = f"/backup/sqlite_{db_name}_{timestamp}.db"

            conn = sqlite3.connect(db_path)
            backup_conn = sqlite3.connect(backup_file)

            with backup_conn:
                conn.backup(backup_conn)

            backup_conn.close()
            conn.close()

            # å‹ç¼©
            subprocess.run(['gzip', backup_file])

            # ä¸Šä¼ 
            self.upload_to_s3(f"{backup_file}.gz", 'sqlite')

    def upload_to_s3(self, file_path, db_type):
        """ä¸Šä¼ å¤‡ä»½åˆ°S3"""
        bucket = self.config['s3_bucket']
        key = f"{db_type}/{os.path.basename(file_path)}"

        try:
            self.s3.upload_file(
                file_path,
                bucket,
                key,
                ExtraArgs={
                    'StorageClass': 'STANDARD_IA'  # ä¸é¢‘ç¹è®¿é—®å­˜å‚¨ç±»
                }
            )
            self.logger.info(f"å·²ä¸Šä¼ åˆ°S3: s3://{bucket}/{key}")
        except Exception as e:
            self.logger.error(f"S3ä¸Šä¼ å¤±è´¥: {e}")

    def cleanup_old_backups(self, backup_dir, days=30):
        """æ¸…ç†æ—§å¤‡ä»½"""
        cutoff = datetime.now() - timedelta(days=days)

        for file in os.listdir(backup_dir):
            file_path = os.path.join(backup_dir, file)
            if os.path.isfile(file_path):
                file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                if file_time < cutoff:
                    os.remove(file_path)
                    self.logger.info(f"åˆ é™¤æ—§å¤‡ä»½: {file_path}")

    def run_daily_backup(self):
        """æ¯æ—¥å¤‡ä»½ä»»åŠ¡"""
        self.logger.info("å¼€å§‹æ¯æ—¥å¤‡ä»½...")

        success = True

        # PostgreSQLå¤‡ä»½
        if not self.backup_postgres():
            success = False

        # SQLiteå¤‡ä»½
        try:
            self.backup_sqlite()
        except Exception as e:
            self.logger.error(f"SQLiteå¤‡ä»½å¤±è´¥: {e}")
            success = False

        if success:
            self.logger.info("æ¯æ—¥å¤‡ä»½å®Œæˆ")
        else:
            self.logger.error("å¤‡ä»½å­˜åœ¨å¤±è´¥")
            # å‘é€å‘Šè­¦é‚®ä»¶/Slacké€šçŸ¥
            self.send_alert("å¤‡ä»½å¤±è´¥")

        return success

# é…ç½®
config = {
    'pg_host': 'localhost',
    'pg_user': 'postgres',
    'pg_database': 'production',
    'sqlite_dbs': {
        'cache': '/app/cache.db',
        'sessions': '/app/sessions.db'
    },
    's3_bucket': 'my-database-backups'
}

# è¿è¡Œ
manager = BackupManager(config)

# å®šæ—¶ä»»åŠ¡ï¼ˆcrontabï¼‰
# 0 2 * * * /usr/bin/python3 /scripts/backup.py
if __name__ == '__main__':
    manager.run_daily_backup()
```

---

## äº”ã€æ¢å¤æ¼”ç»ƒ

### 5.1 å®Œå…¨æ¢å¤

```bash
# PostgreSQLå®Œå…¨æ¢å¤

# Step 1: åˆ›å»ºæ–°æ•°æ®åº“
createdb -U postgres mydb_restored

# Step 2: æ¢å¤å¤‡ä»½
pg_restore \
    -h localhost \
    -U postgres \
    -d mydb_restored \
    --verbose \
    --jobs=4 \  # å¹¶è¡Œæ¢å¤ï¼ˆ4ä¸ªè¿›ç¨‹ï¼‰
    /backup/mydb_20251204.custom

# Step 3: éªŒè¯æ•°æ®
psql -U postgres -d mydb_restored -c "SELECT COUNT(*) FROM users;"
psql -U postgres -d mydb_restored -c "SELECT COUNT(*) FROM orders;"

# Step 4: åˆ‡æ¢åº”ç”¨è¿æ¥
# æ›´æ–°åº”ç”¨é…ç½®ï¼ŒæŒ‡å‘mydb_restored
```

### 5.2 æ—¶é—´ç‚¹æ¢å¤ï¼ˆPITRï¼‰

```bash
# PostgreSQLæ—¶é—´ç‚¹æ¢å¤

# åœºæ™¯ï¼š2025-12-04 10:30è¯¯åˆ é™¤æ•°æ®ï¼Œéœ€è¦æ¢å¤åˆ°10:25

# Step 1: åœæ­¢PostgreSQL
systemctl stop postgresql

# Step 2: æ¸…ç©ºæ•°æ®ç›®å½•
rm -rf /var/lib/postgresql/data/*

# Step 3: æ¢å¤åŸºç¡€å¤‡ä»½
tar -xzf /backup/base/base.tar.gz -C /var/lib/postgresql/data/

# Step 4: é…ç½®æ¢å¤ç›®æ ‡
cat > /var/lib/postgresql/data/recovery.signal << EOF
restore_command = 'cp /archive/%f %p'
recovery_target_time = '2025-12-04 10:25:00'
recovery_target_action = 'promote'
EOF

# Step 5: å¯åŠ¨PostgreSQLï¼ˆè‡ªåŠ¨åº”ç”¨WALï¼‰
systemctl start postgresql

# Step 6: éªŒè¯æ¢å¤ç‚¹
psql -U postgres -c "SELECT NOW();"
psql -U postgres -c "SELECT COUNT(*) FROM deleted_table;"

# Step 7: æå‡ä¸ºä¸»åº“ï¼ˆå¦‚æœæ»¡æ„ï¼‰
psql -U postgres -c "SELECT pg_wal_replay_resume();"
```

### 5.3 éƒ¨åˆ†æ¢å¤

```bash
# æ¢å¤å•ä¸ªè¡¨ï¼ˆä¸å½±å“å…¶ä»–æ•°æ®ï¼‰

# Step 1: ä»å¤‡ä»½æå–å•ä¸ªè¡¨
pg_restore \
    -t users \
    -h localhost \
    -U postgres \
    -d temp_db \
    /backup/full_backup.custom

# Step 2: å¯¼å‡ºä¸ºSQL
pg_dump -t users temp_db > users_restore.sql

# Step 3: æ¢å¤åˆ°ç”Ÿäº§åº“ï¼ˆä½¿ç”¨æ–°è¡¨åï¼Œé¿å…å†²çªï¼‰
sed 's/users/users_restored/g' users_restore.sql | psql -U postgres -d production

# Step 4: æ‰‹åŠ¨éªŒè¯å’Œåˆå¹¶æ•°æ®
psql -U postgres -d production << SQL
    -- å¯¹æ¯”æ•°æ®
    SELECT COUNT(*) FROM users;
    SELECT COUNT(*) FROM users_restored;

    -- åˆå¹¶æ•°æ®ï¼ˆä¾‹å¦‚æ¢å¤è¯¯åˆ é™¤çš„è¡Œï¼‰
    INSERT INTO users
    SELECT * FROM users_restored
    WHERE user_id NOT IN (SELECT user_id FROM users);

    -- æ¸…ç†
    DROP TABLE users_restored;
SQL
```

---

**å¤‡ä»½æ¢å¤æŒ‡å—å®Œæˆï¼**

æœ¬æ–‡æ¡£æä¾›ï¼š

- âœ… 3-2-1å¤‡ä»½åŸåˆ™
- âœ… RTO/RPOç›®æ ‡è®¾å®š
- âœ… PostgreSQL 3ç§å¤‡ä»½æ–¹æ¡ˆï¼ˆé€»è¾‘/ç‰©ç†/WALå½’æ¡£ï¼‰
- âœ… SQLite 3ç§å¤‡ä»½æ–¹æ¡ˆï¼ˆæ–‡ä»¶/åœ¨çº¿/å¢é‡ï¼‰
- âœ… å®Œæ•´è‡ªåŠ¨åŒ–å¤‡ä»½è„šæœ¬ï¼ˆPythonï¼‰
- âœ… 3ç§æ¢å¤åœºæ™¯ï¼ˆå®Œå…¨/PITR/éƒ¨åˆ†ï¼‰

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0
**æœ€åæ›´æ–°**: 2025-12-04
**ç»´æŠ¤è€…**: SQL Standards Team
