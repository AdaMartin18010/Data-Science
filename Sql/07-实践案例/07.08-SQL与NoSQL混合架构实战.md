# SQL与NoSQL混合架构实战

> **创建日期**：2025-12-04
> **技术栈**：PostgreSQL 18 + Redis + MongoDB + Elasticsearch
> **难度**：⭐⭐⭐⭐⭐

---

## 📋 概述

在现代应用中，SQL和NoSQL各有优势。本文档展示如何在一个系统中有效整合两者。

---

## 📑 目录

- [SQL与NoSQL混合架构实战](#sql与nosql混合架构实战)
  - [📋 概述](#-概述)
  - [📑 目录](#-目录)
  - [一、架构设计原则](#一架构设计原则)
    - [1.1 技术选型矩阵](#11-技术选型矩阵)
    - [1.2 数据分层策略](#12-数据分层策略)
  - [二、PostgreSQL + Redis模式](#二postgresql--redis模式)
    - [2.1 Redis作为缓存层](#21-redis作为缓存层)
    - [2.2 Redis作为消息队列](#22-redis作为消息队列)
  - [三、PostgreSQL + MongoDB模式](#三postgresql--mongodb模式)
    - [3.1 结构化+非结构化数据](#31-结构化非结构化数据)
    - [3.2 事件溯源模式](#32-事件溯源模式)
  - [四、PostgreSQL + Elasticsearch模式](#四postgresql--elasticsearch模式)
    - [4.1 全文搜索架构](#41-全文搜索架构)
  - [五、完整案例：电商搜索系统](#五完整案例电商搜索系统)

---

## 一、架构设计原则

### 1.1 技术选型矩阵

```text
SQL vs NoSQL技术选型矩阵
══════════════════════════════════════════════════════════════════════════════

┌────────────────────┬──────────────┬────────────────────────────────┐
│ 数据特征           │ 推荐技术     │ 原因                           │
├────────────────────┼──────────────┼────────────────────────────────┤
│ 结构化+关系复杂    │ PostgreSQL   │ ACID+外键+JOIN                 │
│ 高并发读写         │ PostgreSQL   │ MVCC优势                       │
│ 事务一致性要求高   │ PostgreSQL   │ ACID保证                       │
│ 复杂查询分析       │ PostgreSQL   │ 窗口函数+CTE                   │
├────────────────────┼──────────────┼────────────────────────────────┤
│ 高频读取缓存       │ Redis        │ 内存速度，10万QPS              │
│ 会话存储           │ Redis        │ TTL自动过期                    │
│ 实时计数器         │ Redis        │ INCR原子操作                   │
│ 消息队列           │ Redis        │ Pub/Sub, Streams               │
├────────────────────┼──────────────┼────────────────────────────────┤
│ 文档存储           │ MongoDB      │ 灵活Schema                     │
│ 日志存储           │ MongoDB      │ 快速写入                       │
│ 嵌套数据           │ MongoDB      │ 原生支持嵌套                   │
├────────────────────┼──────────────┼────────────────────────────────┤
│ 全文搜索           │ Elasticsearch│ 倒排索引，相关性排序           │
│ 日志分析           │ Elasticsearch│ ELK stack                      │
│ 复杂聚合           │ Elasticsearch│ Aggregation框架                │
└────────────────────┴──────────────┴────────────────────────────────┘

混合使用原则：
• 主数据存储用SQL（PostgreSQL）
• 缓存加速用Redis
• 非结构化数据用MongoDB
• 搜索用Elasticsearch
• 保持单一真相源（Single Source of Truth）
```

### 1.2 数据分层策略

```text
四层数据架构
══════════════════════════════════════════════════════════════════════════════

┌─────────────────────────────────────────────────────────────────────────┐
│ L1: 应用内存缓存（进程内）                                              │
│ • 技术: Dict / LRU Cache                                                │
│ • TTL: 秒级                                                             │
│ • 用途: 极热点数据                                                      │
└─────────────────────────────────────────────────────────────────────────┘
                                   ↓ Miss
┌─────────────────────────────────────────────────────────────────────────┐
│ L2: 分布式缓存（Redis）                                                 │
│ • 技术: Redis Cluster                                                   │
│ • TTL: 分钟到小时级                                                     │
│ • 用途: 热数据、会话、计数器                                            │
└─────────────────────────────────────────────────────────────────────────┘
                                   ↓ Miss
┌─────────────────────────────────────────────────────────────────────────┐
│ L3: 主数据库（PostgreSQL）                                              │
│ • 技术: PostgreSQL 18 + 读副本                                          │
│ • 持久化: 永久                                                          │
│ • 用途: 事务数据、关系数据                                              │
└─────────────────────────────────────────────────────────────────────────┘
                                   ↓ 补充
┌─────────────────────────────────────────────────────────────────────────┐
│ L4: 专用存储                                                            │
│ • 文档: MongoDB（非结构化数据）                                         │
│ • 搜索: Elasticsearch（全文搜索）                                       │
│ • 时序: TimescaleDB（时间序列）                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 二、PostgreSQL + Redis模式

### 2.1 Redis作为缓存层

```python
# Cache-Aside模式（旁路缓存）

import redis
import psycopg2
import json

class HybridCache:
    def __init__(self):
        self.redis = redis.Redis(host='localhost', port=6379, decode_responses=True)
        self.pg = psycopg2.connect("postgresql://...")

    def get_user(self, user_id):
        """获取用户（多级缓存）"""
        cache_key = f"user:{user_id}"

        # 1. 查Redis
        cached = self.redis.get(cache_key)
        if cached:
            return json.loads(cached)

        # 2. 查PostgreSQL
        cursor = self.pg.cursor()
        cursor.execute("SELECT * FROM users WHERE user_id = %s", (user_id,))
        user = cursor.fetchone()

        if user:
            # 3. 写回Redis（TTL=1小时）
            self.redis.setex(
                cache_key,
                3600,
                json.dumps(dict(user))
            )

        return user

    def update_user(self, user_id, data):
        """更新用户（写穿透）"""
        cursor = self.pg.cursor()

        # 1. 更新PostgreSQL
        cursor.execute("""
            UPDATE users SET name = %s, updated_at = NOW()
            WHERE user_id = %s
        """, (data['name'], user_id))
        self.pg.commit()

        # 2. 失效Redis缓存
        self.redis.delete(f"user:{user_id}")

        # 或者：更新Redis缓存（Write-Through）
        # self.redis.setex(f"user:{user_id}", 3600, json.dumps(data))

# 批量缓存预热
def warm_up_cache():
    """预热热点数据"""
    cursor = pg.cursor()
    cursor.execute("""
        SELECT user_id, name, email
        FROM users
        WHERE last_active > NOW() - INTERVAL '24 hours'
        LIMIT 10000
    """)

    pipe = redis.pipeline()
    for row in cursor:
        pipe.setex(
            f"user:{row[0]}",
            3600,
            json.dumps({'name': row[1], 'email': row[2]})
        )
    pipe.execute()  # 批量执行
```

### 2.2 Redis作为消息队列

```python
# PostgreSQL + Redis Stream消息队列

import redis

class OrderProcessor:
    def __init__(self):
        self.redis = redis.Redis()
        self.pg = psycopg2.connect("...")
        self.stream_name = "orders:pending"

    def create_order(self, order_data):
        """创建订单（异步处理）"""
        cursor = self.pg.cursor()

        # 1. 插入订单到PostgreSQL
        cursor.execute("""
            INSERT INTO orders (user_id, total_amount, status)
            VALUES (%s, %s, 'pending')
            RETURNING order_id
        """, (order_data['user_id'], order_data['total']))
        order_id = cursor.fetchone()[0]
        self.pg.commit()

        # 2. 发送到Redis Stream（异步处理）
        self.redis.xadd(
            self.stream_name,
            {
                'order_id': order_id,
                'action': 'process',
                'data': json.dumps(order_data)
            }
        )

        return order_id

    def process_orders(self):
        """消费者：处理订单队列"""
        consumer_group = "order_processors"
        consumer_name = "worker1"

        # 创建消费者组
        try:
            self.redis.xgroup_create(
                self.stream_name,
                consumer_group,
                id='0',
                mkstream=True
            )
        except redis.ResponseError:
            pass  # 组已存在

        while True:
            # 读取消息
            messages = self.redis.xreadgroup(
                consumer_group,
                consumer_name,
                {self.stream_name: '>'},
                count=10,
                block=1000  # 1秒超时
            )

            for stream, msgs in messages:
                for msg_id, msg_data in msgs:
                    try:
                        order_id = int(msg_data['order_id'])

                        # 处理订单（更新PostgreSQL）
                        cursor = self.pg.cursor()
                        cursor.execute("""
                            UPDATE orders
                            SET status = 'processing',
                                processed_at = NOW()
                            WHERE order_id = %s
                        """, (order_id,))
                        self.pg.commit()

                        # 确认消息已处理
                        self.redis.xack(self.stream_name, consumer_group, msg_id)

                    except Exception as e:
                        print(f"处理失败: {e}")
                        # 消息会自动重试
```

---

## 三、PostgreSQL + MongoDB模式

### 3.1 结构化+非结构化数据

```python
# 混合数据存储

from pymongo import MongoClient
import psycopg2

class HybridDataStore:
    def __init__(self):
        self.pg = psycopg2.connect("...")
        self.mongo = MongoClient()['mydb']

    def save_user(self, user_data):
        """保存用户"""
        # PostgreSQL：结构化核心数据
        cursor = self.pg.cursor()
        cursor.execute("""
            INSERT INTO users (name, email, created_at)
            VALUES (%s, %s, NOW())
            RETURNING user_id
        """, (user_data['name'], user_data['email']))
        user_id = cursor.fetchone()[0]
        self.pg.commit()

        # MongoDB：非结构化扩展数据（用户行为、偏好等）
        self.mongo.user_profiles.insert_one({
            'user_id': user_id,
            'preferences': user_data.get('preferences', {}),
            'activity_log': [],
            'tags': user_data.get('tags', []),
            'metadata': user_data.get('metadata', {})
        })

        return user_id

    def get_user_complete(self, user_id):
        """获取完整用户数据"""
        # PostgreSQL：核心数据
        cursor = self.pg.cursor()
        cursor.execute("SELECT * FROM users WHERE user_id = %s", (user_id,))
        user_row = cursor.fetchone()

        if not user_row:
            return None

        user = dict(zip([desc[0] for desc in cursor.description], user_row))

        # MongoDB：扩展数据
        profile = self.mongo.user_profiles.find_one({'user_id': user_id})
        if profile:
            user['preferences'] = profile.get('preferences', {})
            user['tags'] = profile.get('tags', [])
            user['recent_activity'] = profile.get('activity_log', [])[-10:]  # 最近10条

        return user

    def track_activity(self, user_id, activity):
        """追踪用户行为（MongoDB）"""
        self.mongo.user_profiles.update_one(
            {'user_id': user_id},
            {
                '$push': {
                    'activity_log': {
                        '$each': [activity],
                        '$slice': -1000  # 只保留最近1000条
                    }
                }
            }
        )

# 使用场景：
# • PostgreSQL存储用户基本信息、订单、交易（需要事务）
# • MongoDB存储用户行为日志、推荐偏好（灵活schema）
```

### 3.2 事件溯源模式

```python
# 事件溯源：PostgreSQL存储聚合，MongoDB存储事件

class EventSourcedOrder:
    def __init__(self):
        self.pg = psycopg2.connect("...")
        self.mongo = MongoClient()['events']

    def create_order(self, order_data):
        """创建订单（事件溯源）"""
        order_id = generate_id()

        # MongoDB：存储事件
        self.mongo.order_events.insert_one({
            'event_id': generate_id(),
            'order_id': order_id,
            'event_type': 'OrderCreated',
            'data': order_data,
            'timestamp': datetime.now(),
            'version': 1
        })

        # PostgreSQL：存储聚合状态（物化视图）
        cursor = self.pg.cursor()
        cursor.execute("""
            INSERT INTO orders (order_id, user_id, total, status)
            VALUES (%s, %s, %s, 'created')
        """, (order_id, order_data['user_id'], order_data['total']))
        self.pg.commit()

        return order_id

    def update_order_status(self, order_id, new_status):
        """更新订单状态（事件）"""
        # 1. 追加事件到MongoDB
        self.mongo.order_events.insert_one({
            'event_id': generate_id(),
            'order_id': order_id,
            'event_type': 'StatusChanged',
            'data': {'status': new_status},
            'timestamp': datetime.now()
        })

        # 2. 更新PostgreSQL聚合
        cursor = self.pg.cursor()
        cursor.execute("""
            UPDATE orders SET status = %s, updated_at = NOW()
            WHERE order_id = %s
        """, (new_status, order_id))
        self.pg.commit()

    def rebuild_order_state(self, order_id):
        """从事件重建订单状态（用于审计或修复）"""
        events = self.mongo.order_events.find(
            {'order_id': order_id}
        ).sort('timestamp', 1)

        state = {}
        for event in events:
            if event['event_type'] == 'OrderCreated':
                state = event['data']
            elif event['event_type'] == 'StatusChanged':
                state['status'] = event['data']['status']
            elif event['event_type'] == 'ItemAdded':
                if 'items' not in state:
                    state['items'] = []
                state['items'].append(event['data']['item'])

        return state

# 优势：
# • 完整审计日志（MongoDB events）
# • 可以重建任意时间点的状态
# • 高性能查询（PostgreSQL聚合视图）
```

---

## 四、PostgreSQL + Elasticsearch模式

### 4.1 全文搜索架构

```python
# PostgreSQL作为主库，Elasticsearch作为搜索引擎

from elasticsearch import Elasticsearch
import psycopg2

class SearchService:
    def __init__(self):
        self.pg = psycopg2.connect("...")
        self.es = Elasticsearch(['http://localhost:9200'])

    def index_product(self, product_id):
        """索引商品到Elasticsearch"""
        # 从PostgreSQL获取数据
        cursor = self.pg.cursor()
        cursor.execute("""
            SELECT product_id, name, description, category, price, tags
            FROM products
            WHERE product_id = %s
        """, (product_id,))

        row = cursor.fetchone()
        if not row:
            return

        # 构造文档
        doc = {
            'product_id': row[0],
            'name': row[1],
            'description': row[2],
            'category': row[3],
            'price': row[4],
            'tags': row[5],  # PostgreSQL数组
            'indexed_at': datetime.now()
        }

        # 索引到Elasticsearch
        self.es.index(
            index='products',
            id=product_id,
            document=doc
        )

    def search_products(self, query, filters=None):
        """搜索商品"""
        # Elasticsearch查询
        search_body = {
            'query': {
                'bool': {
                    'must': [
                        {
                            'multi_match': {
                                'query': query,
                                'fields': ['name^2', 'description'],  # name权重x2
                                'fuzziness': 'AUTO'  # 模糊匹配
                            }
                        }
                    ],
                    'filter': []
                }
            },
            'size': 20,
            'from': 0
        }

        # 添加过滤条件
        if filters:
            if 'category' in filters:
                search_body['query']['bool']['filter'].append({
                    'term': {'category': filters['category']}
                })
            if 'price_range' in filters:
                search_body['query']['bool']['filter'].append({
                    'range': {
                        'price': {
                            'gte': filters['price_range'][0],
                            'lte': filters['price_range'][1]
                        }
                    }
                })

        # 执行搜索
        result = self.es.search(index='products', body=search_body)

        # 提取product_ids
        product_ids = [hit['_source']['product_id'] for hit in result['hits']['hits']]

        # 从PostgreSQL获取完整数据（包含实时库存等）
        if product_ids:
            cursor = self.pg.cursor()
            cursor.execute("""
                SELECT product_id, name, price, stock
                FROM products
                WHERE product_id = ANY(%s)
                ORDER BY array_position(%s, product_id)
            """, (product_ids, product_ids))

            products = cursor.fetchall()
            return products

        return []

    def sync_all_products(self):
        """全量同步到Elasticsearch"""
        cursor = self.pg.cursor('products_cursor')  # 服务端游标
        cursor.execute("SELECT product_id FROM products")

        bulk_data = []
        for row in cursor:
            product_id = row[0]
            # 批量索引（每1000个提交一次）
            bulk_data.append({'index': {'_index': 'products', '_id': product_id}})
            bulk_data.append(self.get_product_doc(product_id))

            if len(bulk_data) >= 2000:  # 1000个文档
                self.es.bulk(body=bulk_data)
                bulk_data = []

        if bulk_data:
            self.es.bulk(body=bulk_data)

# 实时同步：PostgreSQL触发器
CREATE OR REPLACE FUNCTION notify_product_change()
RETURNS TRIGGER AS $$
BEGIN
    PERFORM pg_notify('product_changes',
        json_build_object(
            'product_id', NEW.product_id,
            'operation', TG_OP
        )::text
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER product_change_trigger
AFTER INSERT OR UPDATE ON products
FOR EACH ROW
EXECUTE FUNCTION notify_product_change();

# Python监听器
import select

conn = psycopg2.connect("...", async_=True)
conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)
cursor = conn.cursor()
cursor.execute("LISTEN product_changes;")

while True:
    select.select([conn], [], [], 5)
    conn.poll()
    while conn.notifies:
        notify = conn.notifies.pop(0)
        data = json.loads(notify.payload)
        # 更新Elasticsearch
        search_service.index_product(data['product_id'])
```

---

## 五、完整案例：电商搜索系统

```text
电商搜索系统架构
══════════════════════════════════════════════════════════════════════════════

用户请求: "蓝牙耳机"
    │
    ▼
┌─────────────────────────────────────────────────────────────────┐
│ 1. Elasticsearch全文搜索                                        │
│    • 分词：蓝牙 + 耳机                                          │
│    • 倒排索引查找                                               │
│    • 相关性排序                                                 │
│    • 返回：Top 100 product_ids                                  │
└─────────────────────────────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────────────────────────────┐
│ 2. Redis缓存查询                                                │
│    • 批量查询：MGET product:1001 product:1002 ...              │
│    • 命中率：70%                                                │
│    • 未命中的ID传给下一层                                       │
└─────────────────────────────────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────────────────────────────────┐
│ 3. PostgreSQL补充查询                                           │
│    • SELECT * FROM products WHERE id IN (...)                   │
│    • 获取实时库存、价格                                         │
│    • 写回Redis缓存                                              │
└─────────────────────────────────────────────────────────────────┘
    │
    ▼
返回结果给用户（总耗时<100ms）
```

---

**混合架构实战完成！**

本文档提供：

- ✅ SQL vs NoSQL技术选型矩阵
- ✅ 四层数据架构设计
- ✅ PostgreSQL + Redis缓存模式（完整Python实现）
- ✅ PostgreSQL + MongoDB文档存储模式
- ✅ PostgreSQL + Elasticsearch搜索模式
- ✅ 实时数据同步方案（LISTEN/NOTIFY）
- ✅ 电商搜索系统完整架构

---

**文档版本**: v1.0.0
**最后更新**: 2025-12-04
**维护者**: SQL Standards Team
