# 微服务数据分片案例

> **案例类型**：微服务架构实战案例
> **应用场景**：微服务、数据分片、分布式系统
> **技术特点**：数据分片、服务隔离、一致性保证

---

## 📑 目录

- [微服务数据分片案例](#微服务数据分片案例)
  - [📑 目录](#-目录)
  - [1. 场景描述](#1-场景描述)
    - [1.1 业务背景](#11-业务背景)
    - [1.2 系统规模](#12-系统规模)
  - [2. 技术挑战](#2-技术挑战)
    - [2.1 数据分片](#21-数据分片)
    - [2.2 服务隔离](#22-服务隔离)
    - [2.3 跨服务查询](#23-跨服务查询)
  - [3. 解决方案](#3-解决方案)
    - [3.1 分片策略](#31-分片策略)
    - [3.2 路由机制](#32-路由机制)
    - [3.3 数据一致性](#33-数据一致性)
  - [4. 实现细节](#4-实现细节)
    - [4.1 Python实现](#41-python实现)
    - [4.2 分片管理](#42-分片管理)
  - [5. 性能优化](#5-性能优化)
  - [6. 优化效果](#6-优化效果)
  - [7. 最佳实践](#7-最佳实践)
  - [8. 🔗 相关资源](#8--相关资源)

---

## 1. 场景描述

### 1.1 业务背景

某微服务系统需要将数据分片到多个SQLite数据库：

- **服务数量**：10+ 个微服务
- **数据分片**：按用户ID分片
- **数据量**：每个分片 1000万+ 条记录
- **查询要求**：单分片查询 < 50ms
- **一致性要求**：最终一致性

### 1.2 系统规模

- **分片数量**：100+ 个分片
- **单分片大小**：50GB+
- **总数据量**：5TB+
- **查询QPS**：10,000+ 查询/秒
- **写入TPS**：5,000+ 写入/秒

---

## 2. 技术挑战

### 2.1 数据分片

**挑战**：

- 数据分片策略
- 分片路由
- 分片平衡

**解决方案**：

- 一致性哈希分片
- 分片路由表
- 动态分片调整

### 2.2 服务隔离

**挑战**：

- 服务间数据隔离
- 跨服务查询
- 数据同步

**解决方案**：

- 每个服务独立数据库
- API网关聚合
- 事件驱动同步

### 2.3 跨服务查询

**挑战**：

- 跨分片查询
- 聚合查询
- 性能优化

**解决方案**：

- 并行查询
- 结果聚合
- 缓存优化

---

## 3. 解决方案

### 3.1 分片策略

```python
import hashlib
import sqlite3
from pathlib import Path

class ShardManager:
    def __init__(self, shard_count: int = 100, base_dir: str = './shards'):
        self.shard_count = shard_count
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(parents=True, exist_ok=True)
        self.shards = {}
        self.initialize_shards()

    def initialize_shards(self):
        """初始化分片"""
        for i in range(self.shard_count):
            shard_path = self.base_dir / f"shard_{i:03d}.db"
            conn = sqlite3.connect(str(shard_path))
            self.setup_shard_schema(conn)
            self.shards[i] = {
                'path': shard_path,
                'conn': conn
            }

    def setup_shard_schema(self, conn):
        """设置分片Schema"""
        cursor = conn.cursor()
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS users (
                id INTEGER PRIMARY KEY,
                user_id INTEGER NOT NULL,
                name TEXT NOT NULL,
                email TEXT,
                shard_id INTEGER NOT NULL,
                created_at INTEGER NOT NULL
            )
        """)
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_users_user_id ON users(user_id)")
        conn.commit()

    def get_shard_id(self, user_id: int) -> int:
        """根据用户ID获取分片ID"""
        # 一致性哈希
        hash_value = int(hashlib.md5(str(user_id).encode()).hexdigest(), 16)
        return hash_value % self.shard_count

    def get_shard_connection(self, user_id: int) -> sqlite3.Connection:
        """获取分片连接"""
        shard_id = self.get_shard_id(user_id)
        return self.shards[shard_id]['conn']

    def insert_user(self, user_id: int, name: str, email: str):
        """插入用户（自动路由到分片）"""
        shard_id = self.get_shard_id(user_id)
        conn = self.shards[shard_id]['conn']
        cursor = conn.cursor()

        cursor.execute("""
            INSERT INTO users (user_id, name, email, shard_id, created_at)
            VALUES (?, ?, ?, ?, strftime('%s', 'now'))
        """, (user_id, name, email, shard_id))

        conn.commit()

    def get_user(self, user_id: int):
        """获取用户（自动路由到分片）"""
        shard_id = self.get_shard_id(user_id)
        conn = self.shards[shard_id]['conn']
        cursor = conn.cursor()

        cursor.execute("SELECT * FROM users WHERE user_id = ?", (user_id,))
        return cursor.fetchone()

    def query_all_shards(self, query: str, params: tuple = ()):
        """查询所有分片（并行）"""
        import concurrent.futures
        results = []

        def query_shard(shard_id):
            conn = self.shards[shard_id]['conn']
            cursor = conn.cursor()
            cursor.execute(query, params)
            return cursor.fetchall()

        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            futures = {
                executor.submit(query_shard, shard_id): shard_id
                for shard_id in self.shards.keys()
            }

            for future in concurrent.futures.as_completed(futures):
                try:
                    result = future.result()
                    results.extend(result)
                except Exception as e:
                    print(f"分片查询失败: {e}")

        return results
```

### 3.2 路由机制

```python
class ShardRouter:
    def __init__(self, shard_manager: ShardManager):
        self.shard_manager = shard_manager
        self.routing_cache = {}

    def route_query(self, query: str, params: tuple = ()):
        """路由查询"""
        # 解析查询获取user_id
        user_id = self.extract_user_id(params)

        if user_id:
            # 单分片查询
            return self.single_shard_query(user_id, query, params)
        else:
            # 跨分片查询
            return self.multi_shard_query(query, params)

    def extract_user_id(self, params: tuple) -> int:
        """从参数中提取user_id"""
        # 简化处理，实际需要SQL解析
        if params and len(params) > 0:
            return params[0] if isinstance(params[0], int) else None
        return None

    def single_shard_query(self, user_id: int, query: str, params: tuple):
        """单分片查询"""
        conn = self.shard_manager.get_shard_connection(user_id)
        cursor = conn.cursor()
        cursor.execute(query, params)
        return cursor.fetchall()

    def multi_shard_query(self, query: str, params: tuple):
        """跨分片查询"""
        return self.shard_manager.query_all_shards(query, params)
```

### 3.3 数据一致性

```python
class ConsistencyManager:
    def __init__(self, shard_manager: ShardManager):
        self.shard_manager = shard_manager

    def distributed_transaction(self, operations: List[Dict]):
        """分布式事务（两阶段提交简化版）"""
        # 准备阶段
        prepared = []
        for op in operations:
            shard_id = self.shard_manager.get_shard_id(op['user_id'])
            conn = self.shard_manager.shards[shard_id]['conn']

            try:
                cursor = conn.cursor()
                cursor.execute("BEGIN TRANSACTION")
                # 执行操作
                cursor.execute(op['query'], op['params'])
                prepared.append((shard_id, conn))
            except Exception as e:
                # 回滚所有已准备的操作
                for sid, c in prepared:
                    c.rollback()
                raise e

        # 提交阶段
        for shard_id, conn in prepared:
            try:
                conn.commit()
            except Exception as e:
                # 回滚所有
                for sid, c in prepared:
                    c.rollback()
                raise e
```

---

## 4. 实现细节

### 4.1 Python实现

```python
class MicroserviceSharding:
    def __init__(self, service_name: str, shard_count: int = 100):
        self.service_name = service_name
        self.shard_manager = ShardManager(shard_count, f'./{service_name}/shards')
        self.router = ShardRouter(self.shard_manager)

    def execute_query(self, query: str, params: tuple = ()):
        """执行查询（自动路由）"""
        return self.router.route_query(query, params)

    def insert_data(self, table: str, data: Dict):
        """插入数据"""
        user_id = data.get('user_id')
        if not user_id:
            raise ValueError("需要user_id进行分片路由")

        shard_id = self.shard_manager.get_shard_id(user_id)
        conn = self.shard_manager.get_shard_connection(user_id)
        cursor = conn.cursor()

        columns = ', '.join(data.keys())
        placeholders = ', '.join(['?'] * len(data))
        values = list(data.values())

        cursor.execute(f"INSERT INTO {table} ({columns}) VALUES ({placeholders})", values)
        conn.commit()
```

### 4.2 分片管理

```python
class ShardBalancer:
    def __init__(self, shard_manager: ShardManager):
        self.shard_manager = shard_manager

    def analyze_shard_sizes(self) -> Dict[int, int]:
        """分析分片大小"""
        sizes = {}
        for shard_id, shard_info in self.shard_manager.shards.items():
            file_size = shard_info['path'].stat().st_size
            sizes[shard_id] = file_size

        return sizes

    def rebalance_shards(self, threshold_mb: int = 1000):
        """重新平衡分片"""
        sizes = self.analyze_shard_sizes()
        avg_size = sum(sizes.values()) / len(sizes)
        threshold = threshold_mb * 1024 * 1024

        # 找出需要迁移的分片
        overloaded = [sid for sid, size in sizes.items() if size > avg_size + threshold]
        underloaded = [sid for sid, size in sizes.items() if size < avg_size - threshold]

        # 执行数据迁移
        for src_shard in overloaded:
            if underloaded:
                dst_shard = underloaded.pop(0)
                self.migrate_data(src_shard, dst_shard)

    def migrate_data(self, src_shard_id: int, dst_shard_id: int):
        """迁移数据"""
        # 简化实现，实际需要更复杂的迁移逻辑
        print(f"从分片 {src_shard_id} 迁移数据到分片 {dst_shard_id}")
```

---

## 5. 性能优化

- **分片路由缓存**：减少路由计算
- **连接池**：每个分片使用连接池
- **并行查询**：跨分片查询并行执行
- **索引优化**：每个分片独立索引

---

## 6. 优化效果

- **查询性能**：单分片查询 < 50ms
- **写入性能**：支持 5,000+ TPS
- **扩展性**：支持动态添加分片
- **负载均衡**：分片大小差异 < 10%

---

## 7. 最佳实践

1. **分片策略**
   - 一致性哈希
   - 分片数量为2的幂
   - 预留分片容量

2. **路由优化**
   - 缓存路由结果
   - 批量路由
   - 路由表预加载

3. **数据管理**
   - 定期分片平衡
   - 监控分片大小
   - 自动化迁移

---

## 8. 🔗 相关资源

- [多线程并发模式](../08-编程实践/08.12-SQLite多线程并发模式最佳实践.md) - 并发处理
- [性能优化](../03-性能优化/) - 性能优化策略
- [连接管理](../08-编程实践/08.01-连接管理.md) - 连接管理

---

**最后更新**: 2025-12-05
**维护者**: Data-Science Team
