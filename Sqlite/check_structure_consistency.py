#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æŸ¥ Sqlite æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰ Markdown æ–‡ä»¶çš„ç»“æ„ä¸€è‡´æ€§
åŸºäº Analysis æ–‡ä»¶å¤¹çš„æ£€æŸ¥è„šæœ¬
"""

import os
import re
from pathlib import Path
from collections import defaultdict
from typing import List, Dict, Tuple, Optional

class StructureChecker:
    def __init__(self, root_dir: str):
        self.root_dir = Path(root_dir)
        self.issues = []
        self.file_stats = {}
        
    def find_markdown_files(self) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰ Markdown æ–‡ä»¶"""
        md_files = []
        for root, dirs, files in os.walk(self.root_dir):
            # è·³è¿‡ä¸€äº›ä¸éœ€è¦æ£€æŸ¥çš„ç›®å½•
            if any(skip in root for skip in ['.git', '__pycache__', 'node_modules', '.structure_backup']):
                continue
            # æ’é™¤å¤‡ä»½ç›®å½•
            if '.structure_backup' in dirs:
                dirs.remove('.structure_backup')
            for file in files:
                if file.endswith('.md') and not file.startswith('structure_') and file != 'check_structure_consistency.py' and file != 'fix_structure_consistency.py':
                    md_files.append(Path(root) / file)
        return sorted(md_files)
    
    def extract_headings(self, content: str) -> List[Tuple[int, str, int]]:
        """æå–æ‰€æœ‰æ ‡é¢˜ï¼Œè¿”å› (çº§åˆ«, æ ‡é¢˜æ–‡æœ¬, è¡Œå·)"""
        headings = []
        lines = content.split('\n')
        for i, line in enumerate(lines, 1):
            # åŒ¹é… Markdown æ ‡é¢˜
            match = re.match(r'^(#{1,6})\s+(.+)$', line.strip())
            if match:
                level = len(match.group(1))
                text = match.group(2).strip()
                headings.append((level, text, i))
        return headings
    
    def check_toc(self, content: str) -> Optional[Dict]:
        """æ£€æŸ¥æ˜¯å¦æœ‰ç›®å½•ï¼ˆTOCï¼‰"""
        toc_patterns = [
            r'^##?\s*ç›®å½•\s*$',
            r'^##?\s*Table of Contents\s*$',
            r'^##?\s*TOC\s*$',
            r'^##?\s*å†…å®¹\s*$',
            r'^##?\s*Contents\s*$',
        ]
        
        lines = content.split('\n')
        toc_found = False
        toc_start = None
        toc_end = None
        
        for i, line in enumerate(lines):
            for pattern in toc_patterns:
                if re.match(pattern, line, re.IGNORECASE):
                    toc_found = True
                    toc_start = i + 1
                    break
            if toc_found:
                # æŸ¥æ‰¾ç›®å½•ç»“æŸä½ç½®ï¼ˆä¸‹ä¸€ä¸ªäºŒçº§æ ‡é¢˜ï¼‰
                for j in range(i + 1, min(i + 100, len(lines))):
                    if re.match(r'^##\s+', lines[j]):
                        toc_end = j
                        break
                if toc_end is None:
                    toc_end = min(i + 100, len(lines))
                break
        
        return {
            'found': toc_found,
            'start': toc_start,
            'end': toc_end
        } if toc_found else None
    
    def check_numbering_consistency(self, headings: List[Tuple[int, str, int]]) -> List[str]:
        """æ£€æŸ¥æ ‡é¢˜ç¼–å·ä¸€è‡´æ€§"""
        issues = []
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼–å·
        has_numbering = False
        no_numbering = False
        
        for level, text, line_num in headings:
            # è·³è¿‡H1ï¼ˆæ–‡ä»¶æ ‡é¢˜ï¼‰
            if level == 1:
                continue
            # æ£€æŸ¥æ˜¯å¦æœ‰æ•°å­—ç¼–å·ï¼ˆå¦‚ "1. æ ‡é¢˜" æˆ– "1.1 æ ‡é¢˜"ï¼‰æˆ–ä¸­æ–‡ç¼–å·ï¼ˆä¸€ã€äºŒã€ä¸‰ï¼‰
            numbered_pattern = r'^(\d+(\.\d+)*|[\u4e00\u4e8c\u4e09\u56db\u4e94\u516d\u4e03\u516b\u4e5d\u5341]+)[\s\.ã€]'
            if re.match(numbered_pattern, text):
                has_numbering = True
            else:
                # æ’é™¤emojiå’Œç‰¹æ®Šç¬¦å·å¼€å¤´çš„æ ‡é¢˜
                if not re.match(r'^[ğŸ“–ğŸ—ï¸ğŸ”¬ğŸ’¡ğŸš€ğŸ“šğŸ¯âš™ï¸ğŸ”§âœ…âŒâš ï¸ğŸ’»ğŸŒğŸ”’ğŸ“ŠğŸ¨ğŸ”ğŸ’¾ğŸŒğŸ”ğŸ“ˆğŸ“‰ğŸ“ğŸ’¼ğŸ†ğŸŒŸâœ¨ğŸªğŸ­ğŸ¬ğŸ²ğŸ°ğŸ±ğŸ³ğŸ´ğŸµğŸ¶ğŸ¸ğŸ¹ğŸºğŸ»ğŸ¥ğŸ¤ğŸ§ğŸ“‹ğŸ“‘]', text):
                    no_numbering = True
        
        # å¦‚æœåŒæ—¶å­˜åœ¨ç¼–å·å’Œæœªç¼–å·çš„æ ‡é¢˜ï¼Œè®°å½•é—®é¢˜
        if has_numbering and no_numbering:
            issues.append("æ–‡ä»¶ä¸­åŒæ—¶å­˜åœ¨ç¼–å·å’Œæœªç¼–å·çš„æ ‡é¢˜")
        elif has_numbering:
            # æ£€æŸ¥ç¼–å·æ˜¯å¦è¿ç»­
            issues.extend(self._check_numbering_sequence(headings))
        
        return issues
    
    def _check_numbering_sequence(self, headings: List[Tuple[int, str, int]]) -> List[str]:
        """æ£€æŸ¥ç¼–å·åºåˆ—æ˜¯å¦è¿ç»­"""
        issues = []
        level_numbers = {2: 0, 3: 0, 4: 0, 5: 0, 6: 0}
        prev_level = 1
        
        for level, text, line_num in headings:
            # è·³è¿‡H1ï¼ˆæ–‡ä»¶æ ‡é¢˜ï¼‰
            if level == 1:
                continue
            
            # æ£€æŸ¥æ•°å­—ç¼–å·æˆ–ä¸­æ–‡ç¼–å·
            match = re.match(r'^(\d+(?:\.\d+)*|[\u4e00\u4e8c\u4e09\u56db\u4e94\u516d\u4e03\u516b\u4e5d\u5341]+)[\s\.ã€]', text)
            if match:
                number_str = match.group(1)
                
                # å¦‚æœæ˜¯ä¸­æ–‡ç¼–å·ï¼Œè½¬æ¢ä¸ºæ•°å­—
                chinese_to_num = {'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5, 'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'å': 10}
                if number_str in chinese_to_num:
                    numbers = [chinese_to_num[number_str]]
                else:
                    numbers = [int(n) for n in number_str.split('.')]
                
                # å¦‚æœå±‚çº§ä¸‹é™ï¼Œé‡ç½®æ›´æ·±å±‚çº§çš„ç¼–å·
                if level <= prev_level:
                    for l in range(level + 1, 7):
                        level_numbers[l] = 0
                
                # æ£€æŸ¥ç¼–å·æ˜¯å¦æ­£ç¡®ï¼ˆç®€åŒ–æ£€æŸ¥ï¼Œä¸»è¦æ£€æŸ¥H2å±‚çº§ï¼‰
                if level == 2:
                    level_numbers[2] += 1
                    if numbers[0] != level_numbers[2]:
                        # å…è®¸ä¸­æ–‡ç¼–å·ï¼Œä¸å¼ºåˆ¶æ£€æŸ¥
                        if not any(c in number_str for c in chinese_to_num.keys()):
                            issues.append(
                                f"è¡Œ {line_num}: H2æ ‡é¢˜ç¼–å·ä¸è¿ç»­ã€‚"
                                f"æœŸæœ› {level_numbers[2]}ï¼Œå®é™… {numbers[0]}"
                            )
                            level_numbers[2] = numbers[0]
                
                prev_level = level
            else:
                # æœªç¼–å·çš„æ ‡é¢˜ï¼Œé‡ç½®è¯¥å±‚çº§åŠæ›´æ·±å±‚çº§çš„æœŸæœ›å€¼
                for l in range(level, 7):
                    level_numbers[l] = 0
                prev_level = level
        
        return issues
    
    def check_heading_structure(self, headings: List[Tuple[int, str, int]]) -> List[str]:
        """æ£€æŸ¥æ ‡é¢˜ç»“æ„ï¼ˆå±‚çº§æ˜¯å¦åˆç†ï¼‰"""
        issues = []
        
        if not headings:
            return issues
        
        prev_level = headings[0][0]
        
        for i, (level, text, line_num) in enumerate(headings[1:], 1):
            # æ£€æŸ¥å±‚çº§è·³è·ƒï¼ˆä¸èƒ½è·³è¿‡å±‚çº§ï¼Œå¦‚ä» h2 ç›´æ¥åˆ° h4ï¼‰
            if level > prev_level + 1:
                issues.append(
                    f"è¡Œ {line_num}: æ ‡é¢˜å±‚çº§è·³è·ƒè¿‡å¤§ã€‚"
                    f"ä» h{prev_level} è·³åˆ° h{level}"
                )
            prev_level = level
        
        return issues
    
    def analyze_file(self, file_path: Path) -> Dict:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            return {
                'error': str(e),
                'headings': [],
                'toc': None,
                'issues': [f"æ— æ³•è¯»å–æ–‡ä»¶: {e}"]
            }
        
        headings = self.extract_headings(content)
        toc = self.check_toc(content)
        
        issues = []
        issues.extend(self.check_numbering_consistency(headings))
        issues.extend(self.check_heading_structure(headings))
        
        return {
            'headings': headings,
            'toc': toc,
            'issues': issues,
            'has_numbering': any(re.match(r'^(\d+(\.\d+)*|[\u4e00\u4e8c\u4e09\u56db\u4e94\u516d\u4e03\u516b\u4e5d\u5341]+)[\s\.ã€]', h[1]) for h in headings if h[0] > 1),
            'heading_count': len(headings)
        }
    
    def check_all_files(self):
        """æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶"""
        md_files = self.find_markdown_files()
        print(f"æ‰¾åˆ° {len(md_files)} ä¸ª Markdown æ–‡ä»¶\n")
        
        total_issues = 0
        files_with_issues = 0
        numbering_stats = {'numbered': 0, 'unnumbered': 0, 'mixed': 0}
        toc_stats = {'with_toc': 0, 'without_toc': 0}
        
        for file_path in md_files:
            rel_path = file_path.relative_to(self.root_dir)
            result = self.analyze_file(file_path)
            
            self.file_stats[str(rel_path)] = result
            
            if result.get('issues'):
                files_with_issues += 1
                total_issues += len(result['issues'])
                self.issues.append({
                    'file': str(rel_path),
                    'issues': result['issues']
                })
            
            # ç»Ÿè®¡ç¼–å·æƒ…å†µ
            if result.get('has_numbering'):
                if any(not re.match(r'^(\d+(\.\d+)*|[\u4e00\u4e8c\u4e09\u56db\u4e94\u516d\u4e03\u516b\u4e5d\u5341]+)[\s\.ã€]', h[1]) for h in result.get('headings', []) if h[0] > 1):
                    numbering_stats['mixed'] += 1
                else:
                    numbering_stats['numbered'] += 1
            else:
                numbering_stats['unnumbered'] += 1
            
            # ç»Ÿè®¡ç›®å½•æƒ…å†µ
            if result.get('toc') and result['toc'].get('found'):
                toc_stats['with_toc'] += 1
            else:
                toc_stats['without_toc'] += 1
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print("=" * 80)
        print("ç»“æ„æ£€æŸ¥ç»Ÿè®¡")
        print("=" * 80)
        print(f"\næ€»æ–‡ä»¶æ•°: {len(md_files)}")
        print(f"æœ‰é—®é¢˜çš„æ–‡ä»¶: {files_with_issues}")
        print(f"æ€»é—®é¢˜æ•°: {total_issues}")
        
        print(f"\næ ‡é¢˜ç¼–å·ç»Ÿè®¡:")
        print(f"  - å…¨éƒ¨ç¼–å·: {numbering_stats['numbered']}")
        print(f"  - å…¨éƒ¨æœªç¼–å·: {numbering_stats['unnumbered']}")
        print(f"  - æ··åˆç¼–å·: {numbering_stats['mixed']}")
        
        print(f"\nç›®å½•ç»Ÿè®¡:")
        print(f"  - æœ‰ç›®å½•: {toc_stats['with_toc']}")
        print(f"  - æ— ç›®å½•: {toc_stats['without_toc']}")
        
        # æ‰“å°é—®é¢˜è¯¦æƒ…
        if self.issues:
            print("\n" + "=" * 80)
            print("é—®é¢˜è¯¦æƒ…ï¼ˆå‰20ä¸ªï¼‰")
            print("=" * 80)
            for item in self.issues[:20]:
                print(f"\næ–‡ä»¶: {item['file']}")
                for issue in item['issues']:
                    print(f"  - {issue}")
            if len(self.issues) > 20:
                print(f"\n... è¿˜æœ‰ {len(self.issues) - 20} ä¸ªæ–‡ä»¶æœ‰é—®é¢˜")
        
        return {
            'total_files': len(md_files),
            'files_with_issues': files_with_issues,
            'total_issues': total_issues,
            'numbering_stats': numbering_stats,
            'toc_stats': toc_stats,
            'issues': self.issues
        }

def main():
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = Path(__file__).parent
    checker = StructureChecker(script_dir)
    results = checker.check_all_files()
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    import json
    output_file = script_dir / 'structure_check_report.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")

if __name__ == '__main__':
    main()
