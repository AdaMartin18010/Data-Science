#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ—å¼ç‰©åŒ–è§†å›¾ç¤ºä¾‹

ä¸ºåˆ†ææŸ¥è¯¢åˆ›å»ºåˆ—å­˜å‚¨ç»“æ„ï¼Œæ¨¡æ‹Ÿåˆ—å­˜å‚¨çš„ä¼˜åŠ¿ï¼š
- åªæ‰«æéœ€è¦çš„åˆ—ï¼ŒI/Oå‡å°‘
- é€‚åˆèšåˆæŸ¥è¯¢ã€ç»Ÿè®¡æŸ¥è¯¢
- å®šæœŸåˆ·æ–°ï¼Œä¿æŒæ•°æ®ä¸€è‡´æ€§
"""

import sqlite3
import time
import os

class ColumnarMaterializedView:
    """åˆ—å¼ç‰©åŒ–è§†å›¾ï¼šä¸ºåˆ†ææŸ¥è¯¢åˆ›å»ºåˆ—å­˜å‚¨ç»“æ„"""
    
    def __init__(self, conn, source_table, columns):
        self.conn = conn
        self.source_table = source_table
        self.columns = columns
        self.column_tables = {}
        
    def create_column_tables(self):
        """ä¸ºæ¯åˆ—åˆ›å»ºå•ç‹¬çš„è¡¨ï¼ˆæ¨¡æ‹Ÿåˆ—å­˜å‚¨ï¼‰"""
        cursor = self.conn.cursor()
        
        for col in self.columns:
            col_table = f"{self.source_table}_{col}_column"
            self.column_tables[col] = col_table
            
            cursor.execute(f"""
                CREATE TABLE IF NOT EXISTS {col_table} (
                    row_id INTEGER PRIMARY KEY,
                    value TEXT,
                    INDEX idx_value (value)
                )
            """)
        
        self.conn.commit()
        print(f"âœ… åˆ›å»ºäº† {len(self.columns)} ä¸ªåˆ—è¡¨")
        
    def populate_columns(self):
        """ä»åŸå§‹è¡¨å¡«å……åˆ—è¡¨ï¼ˆå®šæœŸåˆ·æ–°ï¼‰"""
        cursor = self.conn.cursor()
        
        # æ¸…ç©ºç°æœ‰æ•°æ®
        for col_table in self.column_tables.values():
            cursor.execute(f"DELETE FROM {col_table}")
        
        # è·å–æ‰€æœ‰è¡Œ
        columns_str = ', '.join(self.columns)
        cursor.execute(f"SELECT rowid, {columns_str} FROM {self.source_table}")
        rows = cursor.fetchall()
        
        # æŒ‰åˆ—å­˜å‚¨
        for col_idx, col in enumerate(self.columns):
            col_table = self.column_tables[col]
            col_values = [(row[0], str(row[col_idx + 1])) for row in rows]
            
            cursor.executemany(
                f"INSERT INTO {col_table} (row_id, value) VALUES (?, ?)",
                col_values
            )
        
        self.conn.commit()
        print(f"âœ… åˆ—å¼ç‰©åŒ–è§†å›¾å·²æ›´æ–°ï¼Œå…± {len(rows)} è¡Œ")
        
    def query_aggregate(self, column, aggregate_func='COUNT', condition=None):
        """ä½¿ç”¨åˆ—å­˜å‚¨è¿›è¡ŒèšåˆæŸ¥è¯¢"""
        col_table = self.column_tables[column]
        cursor = self.conn.cursor()
        
        if aggregate_func == 'COUNT':
            if condition:
                query = f"SELECT COUNT(*) FROM {col_table} WHERE {condition}"
            else:
                query = f"SELECT COUNT(*) FROM {col_table}"
        elif aggregate_func == 'COUNT_DISTINCT':
            query = f"SELECT COUNT(DISTINCT value) FROM {col_table}"
            if condition:
                query = f"SELECT COUNT(DISTINCT value) FROM {col_table} WHERE {condition}"
        else:
            raise ValueError(f"Unsupported aggregate function: {aggregate_func}")
        
        result = cursor.execute(query).fetchone()
        return result[0] if result else 0
    
    def query_group_by(self, column):
        """ä½¿ç”¨åˆ—å­˜å‚¨è¿›è¡Œåˆ†ç»„æŸ¥è¯¢"""
        col_table = self.column_tables[column]
        cursor = self.conn.cursor()
        
        query = f"""
            SELECT value, COUNT(*) as count
            FROM {col_table}
            GROUP BY value
            ORDER BY count DESC
        """
        
        return cursor.execute(query).fetchall()

def create_sample_data(conn):
    """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
    cursor = conn.cursor()
    
    # åˆ›å»ºæ—¥å¿—è¡¨
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS logs (
            id INTEGER PRIMARY KEY,
            user_id INTEGER,
            action TEXT,
            timestamp INTEGER,
            duration INTEGER
        )
    """)
    
    # æ’å…¥æµ‹è¯•æ•°æ®
    import random
    actions = ['login', 'logout', 'view', 'edit', 'delete', 'search', 'download']
    
    data = []
    base_time = int(time.time())
    for i in range(100000):
        data.append((
            random.randint(1, 1000),  # user_id
            random.choice(actions),   # action
            base_time - random.randint(0, 86400 * 7),  # timestamp
            random.randint(10, 5000)  # duration
        ))
    
    cursor.executemany("""
        INSERT INTO logs (user_id, action, timestamp, duration)
        VALUES (?, ?, ?, ?)
    """, data)
    
    conn.commit()
    print(f"âœ… åˆ›å»ºäº† {len(data)} æ¡æ—¥å¿—æ•°æ®")

def compare_query_performance(conn, view):
    """å¯¹æ¯”æŸ¥è¯¢æ€§èƒ½"""
    cursor = conn.cursor()
    
    print("\n" + "="*60)
    print("æŸ¥è¯¢æ€§èƒ½å¯¹æ¯”ï¼ˆåˆ—å­˜å‚¨ vs è¡Œå­˜å‚¨ï¼‰")
    print("="*60)
    
    # æŸ¥è¯¢1ï¼šCOUNTèšåˆ
    print("\næŸ¥è¯¢1ï¼šCOUNTèšåˆ - SELECT COUNT(*) FROM logs WHERE action = 'login'")
    
    start = time.time()
    cursor.execute("SELECT COUNT(*) FROM logs WHERE action = 'login'")
    result1 = cursor.fetchone()[0]
    time1 = time.time() - start
    print(f"  è¡Œå­˜å‚¨æŸ¥è¯¢: {time1*1000:.2f}ms, ç»“æœ: {result1}")
    
    start = time.time()
    result2 = view.query_aggregate('action', 'COUNT', "value = 'login'")
    time2 = time.time() - start
    print(f"  åˆ—å­˜å‚¨æŸ¥è¯¢: {time2*1000:.2f}ms, ç»“æœ: {result2}")
    print(f"  æ€§èƒ½æå‡: {time1/time2:.2f}x")
    
    # æŸ¥è¯¢2ï¼šCOUNT DISTINCT
    print("\næŸ¥è¯¢2ï¼šCOUNT DISTINCT - SELECT COUNT(DISTINCT user_id) FROM logs")
    
    start = time.time()
    cursor.execute("SELECT COUNT(DISTINCT user_id) FROM logs")
    result3 = cursor.fetchone()[0]
    time3 = time.time() - start
    print(f"  è¡Œå­˜å‚¨æŸ¥è¯¢: {time3*1000:.2f}ms, ç»“æœ: {result3}")
    
    start = time.time()
    result4 = view.query_aggregate('user_id', 'COUNT_DISTINCT')
    time4 = time.time() - start
    print(f"  åˆ—å­˜å‚¨æŸ¥è¯¢: {time4*1000:.2f}ms, ç»“æœ: {result4}")
    print(f"  æ€§èƒ½æå‡: {time3/time4:.2f}x")
    
    # æŸ¥è¯¢3ï¼šGROUP BYèšåˆ
    print("\næŸ¥è¯¢3ï¼šGROUP BYèšåˆ - SELECT action, COUNT(*) FROM logs GROUP BY action")
    
    start = time.time()
    cursor.execute("SELECT action, COUNT(*) FROM logs GROUP BY action ORDER BY COUNT(*) DESC")
    results5 = cursor.fetchall()
    time5 = time.time() - start
    print(f"  è¡Œå­˜å‚¨æŸ¥è¯¢: {time5*1000:.2f}ms, è¿”å› {len(results5)} ç»„")
    
    start = time.time()
    results6 = view.query_group_by('action')
    time6 = time.time() - start
    print(f"  åˆ—å­˜å‚¨æŸ¥è¯¢: {time6*1000:.2f}ms, è¿”å› {len(results6)} ç»„")
    print(f"  æ€§èƒ½æå‡: {time5/time6:.2f}x")
    
    # æ˜¾ç¤ºåˆ†ç»„ç»“æœ
    print("\n  åˆ†ç»„ç»“æœï¼ˆå‰5ç»„ï¼‰:")
    for value, count in results6[:5]:
        print(f"    {value}: {count}")

def main():
    """ä¸»å‡½æ•°"""
    db_path = 'columnar_view_example.db'
    
    # åˆ é™¤æ—§æ•°æ®åº“
    if os.path.exists(db_path):
        os.remove(db_path)
    
    conn = sqlite3.connect(db_path)
    
    print("="*60)
    print("åˆ—å¼ç‰©åŒ–è§†å›¾ç¤ºä¾‹")
    print("="*60)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    print("\n1. åˆ›å»ºç¤ºä¾‹æ•°æ®...")
    create_sample_data(conn)
    
    # åˆ›å»ºåˆ—å¼ç‰©åŒ–è§†å›¾
    print("\n2. åˆ›å»ºåˆ—å¼ç‰©åŒ–è§†å›¾...")
    view = ColumnarMaterializedView(conn, 'logs', ['user_id', 'action', 'timestamp', 'duration'])
    view.create_column_tables()
    view.populate_columns()
    
    # å¯¹æ¯”æŸ¥è¯¢æ€§èƒ½
    print("\n3. å¯¹æ¯”æŸ¥è¯¢æ€§èƒ½...")
    compare_query_performance(conn, view)
    
    print("\n" + "="*60)
    print("ç¤ºä¾‹å®Œæˆï¼")
    print("="*60)
    print(f"\næ•°æ®åº“æ–‡ä»¶: {db_path}")
    print("\nğŸ’¡ æ€»ç»“ï¼š")
    print("  - åˆ—å­˜å‚¨é€‚åˆèšåˆæŸ¥è¯¢ã€ç»Ÿè®¡æŸ¥è¯¢")
    print("  - åªæ‰«æéœ€è¦çš„åˆ—ï¼ŒI/Oå‡å°‘ï¼Œæ€§èƒ½æå‡")
    print("  - éœ€è¦å®šæœŸåˆ·æ–°ç‰©åŒ–è§†å›¾ï¼Œä¿æŒæ•°æ®ä¸€è‡´æ€§")
    print("  - é€‚åˆè¯»å¤šå†™å°‘çš„åˆ†æåœºæ™¯")
    
    conn.close()

if __name__ == '__main__':
    main()
