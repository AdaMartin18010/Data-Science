#!/usr/bin/env python3
"""
æ‰¹é‡è¿ç§»ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•é«˜æ•ˆè¿ç§»å¤§æ‰¹é‡æ•°æ®

åŠŸèƒ½ï¼š
- æ‰¹é‡æ•°æ®è¿ç§»
- è¿›åº¦ç›‘æ§
- æ€§èƒ½ä¼˜åŒ–
- é”™è¯¯å¤„ç†
"""

import sqlite3
import psycopg2
from psycopg2.extras import execute_batch
import time
from datetime import datetime


def create_large_sqlite_example():
    """åˆ›å»ºåŒ…å«å¤§é‡æ•°æ®çš„SQLiteç¤ºä¾‹æ•°æ®åº“"""
    print("ğŸ“ åˆ›å»ºSQLiteç¤ºä¾‹æ•°æ®åº“ï¼ˆå¤§é‡æ•°æ®ï¼‰...")
    
    conn = sqlite3.connect('example_large.db')
    cursor = conn.cursor()
    
    # åˆ›å»ºè¡¨
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS products (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            price REAL NOT NULL,
            stock INTEGER NOT NULL,
            category TEXT,
            created_at INTEGER DEFAULT (strftime('%s', 'now'))
        )
    """)
    
    # æ‰¹é‡æ’å…¥æ•°æ®
    print("  æ’å…¥ç¤ºä¾‹æ•°æ®...")
    batch_size = 1000
    total_rows = 10000
    
    categories = ['Electronics', 'Clothing', 'Food', 'Books', 'Toys']
    
    for i in range(0, total_rows, batch_size):
        batch = []
        for j in range(batch_size):
            if i + j >= total_rows:
                break
            batch.append((
                f'Product {i+j+1}',
                10.0 + (i+j) % 1000,
                100 - (i+j) % 50,
                categories[(i+j) % len(categories)],
                int(time.time()) - (i+j)
            ))
        
        cursor.executemany(
            "INSERT INTO products (name, price, stock, category, created_at) VALUES (?, ?, ?, ?, ?)",
            batch
        )
        
        if (i // batch_size + 1) % 10 == 0:
            print(f"    å·²æ’å…¥ {min(i+batch_size, total_rows)}/{total_rows} è¡Œ")
    
    conn.commit()
    
    cursor.execute("SELECT COUNT(*) FROM products")
    count = cursor.fetchone()[0]
    print(f"  âœ… åˆ›å»ºå®Œæˆ: {count} è¡Œæ•°æ®\n")
    
    conn.close()
    return 'example_large.db'


def migrate_with_progress(sqlite_db: str, pg_conn_string: str, batch_size: int = 1000):
    """æ‰¹é‡è¿ç§»å¹¶æ˜¾ç¤ºè¿›åº¦"""
    print("ğŸš€ å¼€å§‹æ‰¹é‡è¿ç§»...")
    
    sqlite_conn = sqlite3.connect(sqlite_db)
    sqlite_conn.row_factory = sqlite3.Row
    sqlite_cursor = sqlite_conn.cursor()
    
    pg_conn = psycopg2.connect(pg_conn_string)
    pg_cursor = pg_conn.cursor()
    
    try:
        # åˆ›å»ºPostgreSQLè¡¨
        print("  ğŸ“‹ åˆ›å»ºPostgreSQLè¡¨...")
        pg_cursor.execute("""
            CREATE TABLE IF NOT EXISTS products (
                id SERIAL PRIMARY KEY,
                name VARCHAR(255) NOT NULL,
                price NUMERIC(10,2) NOT NULL,
                stock INTEGER NOT NULL,
                category VARCHAR(100),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        pg_conn.commit()
        print("  âœ… è¡¨åˆ›å»ºå®Œæˆ")
        
        # è·å–æ€»è¡Œæ•°
        sqlite_cursor.execute("SELECT COUNT(*) FROM products")
        total_rows = sqlite_cursor.fetchone()[0]
        
        print(f"\n  ğŸ“Š å¼€å§‹è¿ç§» {total_rows} è¡Œæ•°æ® (æ‰¹é‡å¤§å°: {batch_size})")
        print("  " + "-"*50)
        
        start_time = time.time()
        rows_migrated = 0
        offset = 0
        
        while offset < total_rows:
            # è¯»å–ä¸€æ‰¹æ•°æ®
            sqlite_cursor.execute(
                "SELECT * FROM products LIMIT ? OFFSET ?",
                (batch_size, offset)
            )
            rows = sqlite_cursor.fetchall()
            
            if not rows:
                break
            
            # è½¬æ¢æ•°æ®
            data = []
            for row in rows:
                created_at = datetime.fromtimestamp(row['created_at']) if row['created_at'] else None
                data.append((
                    row['name'],
                    row['price'],
                    row['stock'],
                    row['category'],
                    created_at
                ))
            
            # æ‰¹é‡æ’å…¥
            try:
                execute_batch(
                    pg_cursor,
                    "INSERT INTO products (name, price, stock, category, created_at) VALUES (%s, %s, %s, %s, %s)",
                    data,
                    page_size=batch_size
                )
                pg_conn.commit()
                
                rows_migrated += len(data)
                offset += batch_size
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (rows_migrated / total_rows) * 100
                elapsed = time.time() - start_time
                speed = rows_migrated / elapsed if elapsed > 0 else 0
                eta = (total_rows - rows_migrated) / speed if speed > 0 else 0
                
                print(f"\r  [{progress:6.2f}%] {rows_migrated:6}/{total_rows} è¡Œ | "
                      f"é€Ÿåº¦: {speed:6.0f} è¡Œ/ç§’ | ETA: {eta:4.0f} ç§’", end='', flush=True)
            
            except Exception as e:
                pg_conn.rollback()
                print(f"\n  âŒ æ‰¹é‡æ’å…¥å¤±è´¥: {e}")
                raise
        
        elapsed_time = time.time() - start_time
        print(f"\n\n  âœ… è¿ç§»å®Œæˆ!")
        print(f"     æ€»è¡Œæ•°: {rows_migrated}")
        print(f"     è€—æ—¶: {elapsed_time:.2f} ç§’")
        print(f"     å¹³å‡é€Ÿåº¦: {rows_migrated/elapsed_time:.0f} è¡Œ/ç§’")
        
        # éªŒè¯æ•°æ®
        print("\n  ğŸ” éªŒè¯æ•°æ®...")
        sqlite_cursor.execute("SELECT COUNT(*) FROM products")
        sqlite_count = sqlite_cursor.fetchone()[0]
        
        pg_cursor.execute("SELECT COUNT(*) FROM products")
        pg_count = pg_cursor.fetchone()[0]
        
        if sqlite_count == pg_count:
            print(f"  âœ… æ•°æ®éªŒè¯é€šè¿‡: {pg_count} è¡Œ")
        else:
            print(f"  âŒ æ•°æ®éªŒè¯å¤±è´¥: SQLite={sqlite_count}, PostgreSQL={pg_count}")
        
    finally:
        sqlite_conn.close()
        pg_conn.close()
    
    print("\nâœ… æ‰¹é‡è¿ç§»å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    import os
    
    pg_conn_string = os.getenv(
        'POSTGRESQL_CONNECTION',
        'postgresql://postgres:postgres@localhost:5432/testdb'
    )
    
    print("="*60)
    print("SQLite åˆ° PostgreSQL æ‰¹é‡è¿ç§»ç¤ºä¾‹")
    print("="*60)
    print()
    
    sqlite_db = create_large_sqlite_example()
    
    try:
        migrate_with_progress(sqlite_db, pg_conn_string, batch_size=1000)
    except psycopg2.OperationalError as e:
        print(f"\nâŒ PostgreSQLè¿æ¥é”™è¯¯: {e}")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    cleanup = input("\næ˜¯å¦åˆ é™¤SQLiteç¤ºä¾‹æ•°æ®åº“? (y/N): ")
    if cleanup.lower() == 'y':
        import os
        if os.path.exists(sqlite_db):
            os.remove(sqlite_db)
            print(f"âœ… å·²åˆ é™¤ {sqlite_db}")


if __name__ == '__main__':
    main()
