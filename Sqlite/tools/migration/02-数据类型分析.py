#!/usr/bin/env python3
"""
SQLiteæ•°æ®ç±»å‹åˆ†æå·¥å…·

åŠŸèƒ½ï¼š
- åˆ†æSQLiteæ•°æ®ç±»å‹ä½¿ç”¨æƒ…å†µ
- ç”ŸæˆPostgreSQLç±»å‹æ˜ å°„å»ºè®®
- è¯†åˆ«ç±»å‹è½¬æ¢é£é™©
- åˆ†æå®é™…å­˜å‚¨ç±»å‹

ä½¿ç”¨æ–¹æ³•ï¼š
    python 02-æ•°æ®ç±»å‹åˆ†æ.py database.db [--table TABLE_NAME] [--output report.json]
"""

import sqlite3
import json
import sys
import argparse
from typing import Dict, List, Any, Set
from collections import defaultdict


class DataTypeAnalyzer:
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path)
        self.conn.row_factory = sqlite3.Row
        self.report = {
            'database': db_path,
            'tables': [],
            'type_mapping': {},
            'risks': [],
            'recommendations': []
        }
    
    def analyze(self, table_name: str = None):
        """æ‰§è¡Œæ•°æ®ç±»å‹åˆ†æ"""
        print("ğŸ” å¼€å§‹æ•°æ®ç±»å‹åˆ†æ...")
        
        # è·å–æ‰€æœ‰è¡¨
        cursor = self.conn.cursor()
        if table_name:
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table_name,))
        else:
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        
        tables = [row[0] for row in cursor.fetchall()]
        
        if not tables:
            print("âŒ æœªæ‰¾åˆ°è¡¨")
            return self.report
        
        # åˆ†ææ¯ä¸ªè¡¨
        for table in tables:
            self._analyze_table(table)
        
        # ç”Ÿæˆç±»å‹æ˜ å°„å»ºè®®
        self._generate_type_mapping()
        
        # è¯†åˆ«é£é™©
        self._identify_risks()
        
        print("âœ… åˆ†æå®Œæˆ")
        return self.report
    
    def _analyze_table(self, table_name: str):
        """åˆ†æå•ä¸ªè¡¨çš„æ•°æ®ç±»å‹"""
        cursor = self.conn.cursor()
        
        table_info = {
            'name': table_name,
            'columns': [],
            'row_count': 0,
            'sample_data': {}
        }
        
        # è·å–è¡¨ç»“æ„
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns = cursor.fetchall()
        
        # è·å–è¡Œæ•°
        cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
        table_info['row_count'] = cursor.fetchone()[0]
        
        # åˆ†ææ¯åˆ—
        for col in columns:
            col_name = col[1]
            declared_type = col[2] or ''
            not_null = col[3]
            default_value = col[4]
            primary_key = col[5]
            
            col_info = {
                'name': col_name,
                'declared_type': declared_type,
                'type_affinity': self._get_type_affinity(declared_type),
                'not_null': bool(not_null),
                'default_value': default_value,
                'primary_key': bool(primary_key),
                'actual_types': {},
                'sample_values': []
            }
            
            # åˆ†æå®é™…å­˜å‚¨ç±»å‹
            if table_info['row_count'] > 0:
                self._analyze_actual_types(cursor, table_name, col_name, col_info)
            
            table_info['columns'].append(col_info)
        
        self.report['tables'].append(table_info)
        print(f"  ğŸ“‹ åˆ†æè¡¨: {table_name} ({table_info['row_count']} è¡Œ)")
    
    def _get_type_affinity(self, declared_type: str) -> str:
        """è·å–ç±»å‹äº²å’Œæ€§"""
        if not declared_type:
            return 'NUMERIC'
        
        declared_type_upper = declared_type.upper()
        
        if 'INT' in declared_type_upper:
            return 'INTEGER'
        elif 'CHAR' in declared_type_upper or 'CLOB' in declared_type_upper or 'TEXT' in declared_type_upper:
            return 'TEXT'
        elif 'BLOB' in declared_type_upper or not declared_type_upper:
            return 'BLOB'
        elif 'REAL' in declared_type_upper or 'FLOA' in declared_type_upper or 'DOUB' in declared_type_upper:
            return 'REAL'
        else:
            return 'NUMERIC'
    
    def _analyze_actual_types(self, cursor, table_name: str, col_name: str, col_info: Dict):
        """åˆ†æå®é™…å­˜å‚¨ç±»å‹"""
        # é‡‡æ ·åˆ†æï¼ˆæœ€å¤š1000è¡Œï¼‰
        cursor.execute(f"SELECT {col_name} FROM {table_name} LIMIT 1000")
        rows = cursor.fetchall()
        
        type_counts = defaultdict(int)
        sample_values = []
        
        for row in rows:
            value = row[0]
            
            if value is None:
                type_counts['NULL'] += 1
            elif isinstance(value, int):
                type_counts['INTEGER'] += 1
                if len(sample_values) < 5:
                    sample_values.append(value)
            elif isinstance(value, float):
                type_counts['REAL'] += 1
                if len(sample_values) < 5:
                    sample_values.append(value)
            elif isinstance(value, str):
                type_counts['TEXT'] += 1
                if len(sample_values) < 5:
                    sample_values.append(value[:50])  # æˆªæ–­é•¿æ–‡æœ¬
            elif isinstance(value, bytes):
                type_counts['BLOB'] += 1
                if len(sample_values) < 5:
                    sample_values.append(f"<BLOB {len(value)} bytes>")
        
        col_info['actual_types'] = dict(type_counts)
        col_info['sample_values'] = sample_values
        
        # æ£€æŸ¥ç±»å‹ä¸€è‡´æ€§
        if len(type_counts) > 1 and 'NULL' not in type_counts:
            col_info['type_inconsistent'] = True
        elif len(type_counts) > 2:
            col_info['type_inconsistent'] = True
    
    def _generate_type_mapping(self):
        """ç”ŸæˆPostgreSQLç±»å‹æ˜ å°„å»ºè®®"""
        type_mapping = {}
        
        for table in self.report['tables']:
            for col in table['columns']:
                col_name = f"{table['name']}.{col['name']}"
                affinity = col['type_affinity']
                actual_types = col.get('actual_types', {})
                
                # åŸºäºå®é™…ç±»å‹ç”Ÿæˆæ˜ å°„å»ºè®®
                if not actual_types or 'NULL' in actual_types and len(actual_types) == 1:
                    # å…¨NULLåˆ—
                    mapping = {
                        'recommended_type': 'TEXT',
                        'reason': 'åˆ—å…¨ä¸ºNULLï¼Œå»ºè®®ä½¿ç”¨TEXT',
                        'confidence': 'low'
                    }
                elif 'INTEGER' in actual_types and len(actual_types) == 1:
                    # çº¯æ•´æ•°
                    # æ£€æŸ¥èŒƒå›´
                    max_value = max([v for v in col.get('sample_values', []) if isinstance(v, int)], default=0)
                    if max_value > 2147483647:
                        mapping = {
                            'recommended_type': 'BIGINT',
                            'reason': 'å€¼è¶…å‡ºINTEGERèŒƒå›´',
                            'confidence': 'high'
                        }
                    else:
                        mapping = {
                            'recommended_type': 'INTEGER',
                            'reason': 'æ•´æ•°ç±»å‹',
                            'confidence': 'high'
                        }
                elif 'REAL' in actual_types and len(actual_types) == 1:
                    # çº¯æµ®ç‚¹æ•°
                    mapping = {
                        'recommended_type': 'DOUBLE PRECISION',
                        'reason': 'æµ®ç‚¹æ•°ç±»å‹',
                        'confidence': 'high'
                    }
                elif 'TEXT' in actual_types and len(actual_types) == 1:
                    # çº¯æ–‡æœ¬
                    # æ£€æŸ¥é•¿åº¦
                    max_length = max([len(str(v)) for v in col.get('sample_values', [])], default=0)
                    if max_length > 255:
                        mapping = {
                            'recommended_type': 'TEXT',
                            'reason': f'æ–‡æœ¬é•¿åº¦è¶…è¿‡255ï¼ˆæœ€å¤§{max_length}ï¼‰',
                            'confidence': 'high'
                        }
                    else:
                        mapping = {
                            'recommended_type': f'VARCHAR({max(255, max_length + 10)})',
                            'reason': f'æ–‡æœ¬ç±»å‹ï¼Œå»ºè®®é•¿åº¦{max(255, max_length + 10)}',
                            'confidence': 'medium'
                        }
                elif 'BLOB' in actual_types:
                    mapping = {
                        'recommended_type': 'BYTEA',
                        'reason': 'äºŒè¿›åˆ¶æ•°æ®',
                        'confidence': 'high'
                    }
                else:
                    # æ··åˆç±»å‹
                    mapping = {
                        'recommended_type': 'TEXT',
                        'reason': 'æ··åˆç±»å‹ï¼Œå»ºè®®è½¬æ¢ä¸ºTEXT',
                        'confidence': 'low'
                    }
                
                type_mapping[col_name] = mapping
                col['pg_type_mapping'] = mapping
        
        self.report['type_mapping'] = type_mapping
    
    def _identify_risks(self):
        """è¯†åˆ«ç±»å‹è½¬æ¢é£é™©"""
        risks = []
        
        for table in self.report['tables']:
            for col in table['columns']:
                # æ£€æŸ¥ç±»å‹ä¸ä¸€è‡´
                if col.get('type_inconsistent'):
                    risks.append({
                        'table': table['name'],
                        'column': col['name'],
                        'type': 'type_inconsistent',
                        'severity': 'medium',
                        'message': f"åˆ— {col['name']} å­˜å‚¨äº†å¤šç§ç±»å‹çš„æ•°æ®",
                        'actual_types': col.get('actual_types', {})
                    })
                
                # æ£€æŸ¥NUMERICäº²å’Œæ€§
                if col['type_affinity'] == 'NUMERIC' and col.get('actual_types'):
                    if len(col['actual_types']) > 2:
                        risks.append({
                            'table': table['name'],
                            'column': col['name'],
                            'type': 'numeric_affinity',
                            'severity': 'high',
                            'message': f"åˆ— {col['name']} ä½¿ç”¨NUMERICäº²å’Œæ€§ï¼Œå­˜å‚¨äº†å¤šç§ç±»å‹",
                            'actual_types': col.get('actual_types', {})
                        })
                
                # æ£€æŸ¥INTEGERèŒƒå›´
                if col['type_affinity'] == 'INTEGER':
                    sample_ints = [v for v in col.get('sample_values', []) if isinstance(v, int)]
                    if sample_ints:
                        max_val = max(sample_ints)
                        if max_val > 2147483647:
                            risks.append({
                                'table': table['name'],
                                'column': col['name'],
                                'type': 'integer_range',
                                'severity': 'high',
                                'message': f"åˆ— {col['name']} çš„å€¼ {max_val} è¶…å‡ºINTEGERèŒƒå›´",
                                'max_value': max_val
                            })
        
        self.report['risks'] = risks
    
    def print_report(self):
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“Š æ•°æ®ç±»å‹åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        for table in self.report['tables']:
            print(f"\nğŸ“‹ è¡¨: {table['name']}")
            print(f"  è¡Œæ•°: {table['row_count']}")
            
            for col in table['columns']:
                print(f"\n  ğŸ”¹ åˆ—: {col['name']}")
                print(f"    å£°æ˜ç±»å‹: {col['declared_type'] or '(æ— )'}")
                print(f"    ç±»å‹äº²å’Œæ€§: {col['type_affinity']}")
                
                if col.get('actual_types'):
                    print(f"    å®é™…ç±»å‹åˆ†å¸ƒ:")
                    for type_name, count in col['actual_types'].items():
                        print(f"      - {type_name}: {count}")
                
                if col.get('pg_type_mapping'):
                    mapping = col['pg_type_mapping']
                    print(f"    PostgreSQLå»ºè®®: {mapping['recommended_type']}")
                    print(f"      åŸå› : {mapping['reason']}")
                    print(f"      ç½®ä¿¡åº¦: {mapping['confidence']}")
        
        if self.report['risks']:
            print(f"\nâš ï¸  é£é™©ç‚¹ ({len(self.report['risks'])}):")
            for risk in self.report['risks']:
                print(f"  - [{risk['severity'].upper()}] {risk['message']}")
        
        print("\n" + "="*60)
    
    def save_report(self, output_path: str):
        """ä¿å­˜æŠ¥å‘Šåˆ°JSONæ–‡ä»¶"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.report, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")


def main():
    parser = argparse.ArgumentParser(description='SQLiteæ•°æ®ç±»å‹åˆ†æå·¥å…·')
    parser.add_argument('database', help='SQLiteæ•°æ®åº“æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--table', '-t', help='æŒ‡å®šè¦åˆ†æçš„è¡¨åï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--output', '-o', help='è¾“å‡ºJSONæŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    try:
        analyzer = DataTypeAnalyzer(args.database)
        report = analyzer.analyze(args.table)
        analyzer.print_report()
        
        if args.output:
            analyzer.save_report(args.output)
    
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®åº“æ–‡ä»¶ {args.database}")
        sys.exit(1)
    except sqlite3.Error as e:
        print(f"âŒ SQLiteé”™è¯¯: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
