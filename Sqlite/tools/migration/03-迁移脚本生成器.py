#!/usr/bin/env python3
"""
SQLiteåˆ°PostgreSQLè¿ç§»è„šæœ¬ç”Ÿæˆå™¨

åŠŸèƒ½ï¼š
- è‡ªåŠ¨ç”ŸæˆPostgreSQL DDL
- ç”Ÿæˆæ•°æ®è¿ç§»è„šæœ¬
- ç”Ÿæˆç´¢å¼•å’Œçº¦æŸè„šæœ¬
- æ”¯æŒç±»å‹æ˜ å°„é…ç½®

ä½¿ç”¨æ–¹æ³•ï¼š
    python 03-è¿ç§»è„šæœ¬ç”Ÿæˆå™¨.py database.db --output migration.sql [--config config.json]
"""

import sqlite3
import json
import sys
import argparse
from typing import Dict, List, Any, Optional


class MigrationScriptGenerator:
    def __init__(self, db_path: str, type_mapping: Optional[Dict] = None):
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path)
        self.conn.row_factory = sqlite3.Row
        self.type_mapping = type_mapping or {}
        self.scripts = {
            'ddl': [],
            'data_migration': [],
            'indexes': [],
            'constraints': [],
            'comments': []
        }
    
    def generate(self):
        """ç”Ÿæˆæ‰€æœ‰è¿ç§»è„šæœ¬"""
        print("ğŸ”§ å¼€å§‹ç”Ÿæˆè¿ç§»è„šæœ¬...")
        
        # è·å–æ‰€æœ‰è¡¨
        cursor = self.conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' ORDER BY name")
        tables = [row[0] for row in cursor.fetchall()]
        
        # ç”Ÿæˆè¡¨ç»“æ„
        for table_name in tables:
            self._generate_table_ddl(table_name)
            self._generate_data_migration(table_name)
            self._generate_indexes(table_name)
            self._generate_constraints(table_name)
        
        print("âœ… è„šæœ¬ç”Ÿæˆå®Œæˆ")
        return self.scripts
    
    def _generate_table_ddl(self, table_name: str):
        """ç”Ÿæˆè¡¨DDL"""
        cursor = self.conn.cursor()
        
        # è·å–è¡¨ä¿¡æ¯
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns = cursor.fetchall()
        
        # è·å–CREATE TABLEè¯­å¥
        cursor.execute(f"SELECT sql FROM sqlite_master WHERE type='table' AND name='{table_name}'")
        create_sql = cursor.fetchone()[0]
        
        # ç”ŸæˆPostgreSQL DDL
        pg_ddl = f"CREATE TABLE {table_name} (\n"
        
        col_definitions = []
        primary_keys = []
        
        for col in columns:
            col_name = col[1]
            col_type = col[2] or ''
            not_null = col[3]
            default_value = col[4]
            primary_key = col[5]
            
            # ç±»å‹æ˜ å°„
            pg_type = self._map_type(col_type, table_name, col_name)
            
            # åˆ—å®šä¹‰
            col_def = f"    {col_name} {pg_type}"
            
            # NOT NULL
            if not_null or primary_key:
                col_def += " NOT NULL"
            
            # DEFAULT
            if default_value is not None:
                pg_default = self._map_default(default_value, pg_type)
                col_def += f" DEFAULT {pg_default}"
            
            # SERIAL for primary key
            if primary_key and 'INTEGER' in col_type.upper():
                col_def = col_def.replace('INTEGER', 'SERIAL').replace(' BIGINT', ' BIGSERIAL')
            
            col_definitions.append(col_def)
            
            if primary_key:
                primary_keys.append(col_name)
        
        pg_ddl += ",\n".join(col_definitions)
        
        # ä¸»é”®çº¦æŸ
        if primary_keys:
            pg_ddl += f",\n    PRIMARY KEY ({', '.join(primary_keys)})"
        
        pg_ddl += "\n);"
        
        self.scripts['ddl'].append({
            'table': table_name,
            'sql': pg_ddl
        })
        
        print(f"  ğŸ“‹ ç”Ÿæˆè¡¨DDL: {table_name}")
    
    def _map_type(self, sqlite_type: str, table_name: str, col_name: str) -> str:
        """æ˜ å°„SQLiteç±»å‹åˆ°PostgreSQLç±»å‹"""
        # æ£€æŸ¥è‡ªå®šä¹‰æ˜ å°„
        key = f"{table_name}.{col_name}"
        if key in self.type_mapping:
            return self.type_mapping[key]
        
        if not sqlite_type:
            return 'TEXT'
        
        sqlite_type_upper = sqlite_type.upper()
        
        # åŸºæœ¬ç±»å‹æ˜ å°„
        if 'INT' in sqlite_type_upper:
            return 'INTEGER'
        elif 'CHAR' in sqlite_type_upper or 'TEXT' in sqlite_type_upper or 'CLOB' in sqlite_type_upper:
            return 'TEXT'
        elif 'BLOB' in sqlite_type_upper:
            return 'BYTEA'
        elif 'REAL' in sqlite_type_upper or 'FLOA' in sqlite_type_upper or 'DOUB' in sqlite_type_upper:
            return 'DOUBLE PRECISION'
        elif 'NUMERIC' in sqlite_type_upper or 'DECIMAL' in sqlite_type_upper:
            return 'NUMERIC'
        else:
            return 'TEXT'
    
    def _map_default(self, default_value: Any, pg_type: str) -> str:
        """æ˜ å°„é»˜è®¤å€¼"""
        if isinstance(default_value, str):
            # æ£€æŸ¥æ˜¯å¦æ˜¯å‡½æ•°è°ƒç”¨
            if default_value.upper().startswith(('CURRENT_', 'NOW()', 'DATETIME', 'DATE')):
                if 'TIMESTAMP' in pg_type.upper():
                    return 'CURRENT_TIMESTAMP'
                elif 'DATE' in pg_type.upper():
                    return 'CURRENT_DATE'
                else:
                    return f"'{default_value}'"
            else:
                return f"'{default_value}'"
        elif isinstance(default_value, (int, float)):
            return str(default_value)
        else:
            return f"'{default_value}'"
    
    def _generate_data_migration(self, table_name: str):
        """ç”Ÿæˆæ•°æ®è¿ç§»è„šæœ¬"""
        cursor = self.conn.cursor()
        
        # è·å–åˆ—ä¿¡æ¯
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns = [col[1] for col in cursor.fetchall()]
        
        # ç”ŸæˆCOPYå‘½ä»¤ï¼ˆæ¨èæ–¹å¼ï¼‰
        copy_sql = f"""
-- æ•°æ®è¿ç§»: {table_name}
-- ä½¿ç”¨COPYå‘½ä»¤ï¼ˆæœ€å¿«ï¼‰
COPY {table_name} ({', '.join(columns)}) FROM STDIN WITH CSV;
"""
        
        # æˆ–è€…ç”ŸæˆINSERTè¯­å¥ï¼ˆå¤‡ç”¨æ–¹å¼ï¼‰
        placeholders = ', '.join(['%s'] * len(columns))
        insert_sql = f"""
-- å¤‡ç”¨æ–¹å¼: ä½¿ç”¨INSERTè¯­å¥
-- INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({placeholders});
"""
        
        self.scripts['data_migration'].append({
            'table': table_name,
            'copy_sql': copy_sql,
            'insert_sql': insert_sql
        })
    
    def _generate_indexes(self, table_name: str):
        """ç”Ÿæˆç´¢å¼•è„šæœ¬"""
        cursor = self.conn.cursor()
        
        cursor.execute(f"SELECT name, sql FROM sqlite_master WHERE type='index' AND tbl_name='{table_name}'")
        indexes = cursor.fetchall()
        
        for idx_name, idx_sql in indexes:
            if idx_sql:
                # è½¬æ¢SQLiteç´¢å¼•è¯­æ³•åˆ°PostgreSQL
                pg_sql = idx_sql.replace('CREATE INDEX', 'CREATE INDEX IF NOT EXISTS')
                pg_sql = pg_sql.replace('CREATE UNIQUE INDEX', 'CREATE UNIQUE INDEX IF NOT EXISTS')
                
                # ç§»é™¤SQLiteç‰¹å®šè¯­æ³•
                pg_sql = pg_sql.replace('ON "', 'ON ').replace('"', '')
                
                self.scripts['indexes'].append({
                    'table': table_name,
                    'name': idx_name,
                    'sql': pg_sql
                })
    
    def _generate_constraints(self, table_name: str):
        """ç”Ÿæˆçº¦æŸè„šæœ¬"""
        cursor = self.conn.cursor()
        
        # å¤–é”®çº¦æŸ
        cursor.execute(f"PRAGMA foreign_key_list({table_name})")
        foreign_keys = cursor.fetchall()
        
        for fk in foreign_keys:
            fk_sql = f"""
ALTER TABLE {table_name}
    ADD CONSTRAINT fk_{table_name}_{fk[3]}
    FOREIGN KEY ({fk[3]}) REFERENCES {fk[2]}({fk[4]});
"""
            self.scripts['constraints'].append({
                'table': table_name,
                'type': 'foreign_key',
                'sql': fk_sql
            })
    
    def save_scripts(self, output_path: str):
        """ä¿å­˜è„šæœ¬åˆ°æ–‡ä»¶"""
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("-- SQLite to PostgreSQL Migration Script\n")
            f.write(f"-- Generated from: {self.db_path}\n")
            f.write("-- \n")
            f.write("-- Usage:\n")
            f.write("--   1. Review and adjust type mappings\n")
            f.write("--   2. Execute DDL scripts to create tables\n")
            f.write("--   3. Migrate data using COPY or INSERT\n")
            f.write("--   4. Create indexes\n")
            f.write("--   5. Add constraints\n")
            f.write("\n")
            f.write("BEGIN;\n\n")
            
            # DDL
            f.write("-- ============================================\n")
            f.write("-- Table Definitions (DDL)\n")
            f.write("-- ============================================\n\n")
            for ddl in self.scripts['ddl']:
                f.write(f"-- Table: {ddl['table']}\n")
                f.write(ddl['sql'])
                f.write("\n\n")
            
            # Data Migration
            f.write("-- ============================================\n")
            f.write("-- Data Migration\n")
            f.write("-- ============================================\n\n")
            for migration in self.scripts['data_migration']:
                f.write(migration['copy_sql'])
                f.write(migration['insert_sql'])
                f.write("\n")
            
            # Indexes
            f.write("-- ============================================\n")
            f.write("-- Indexes\n")
            f.write("-- ============================================\n\n")
            for idx in self.scripts['indexes']:
                f.write(f"-- Index: {idx['name']} on {idx['table']}\n")
                f.write(idx['sql'])
                f.write("\n\n")
            
            # Constraints
            f.write("-- ============================================\n")
            f.write("-- Constraints\n")
            f.write("-- ============================================\n\n")
            for constraint in self.scripts['constraints']:
                f.write(constraint['sql'])
                f.write("\n")
            
            f.write("COMMIT;\n")
        
        print(f"ğŸ’¾ è„šæœ¬å·²ä¿å­˜åˆ°: {output_path}")


def load_config(config_path: str) -> Dict:
    """åŠ è½½ç±»å‹æ˜ å°„é…ç½®"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            return config.get('type_mapping', {})
    except FileNotFoundError:
        print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return {}
    except json.JSONDecodeError:
        print(f"âš ï¸  é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {config_path}")
        return {}


def main():
    parser = argparse.ArgumentParser(description='SQLiteåˆ°PostgreSQLè¿ç§»è„šæœ¬ç”Ÿæˆå™¨')
    parser.add_argument('database', help='SQLiteæ•°æ®åº“æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', required=True, help='è¾“å‡ºSQLè„šæœ¬æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--config', '-c', help='ç±»å‹æ˜ å°„é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰')
    
    args = parser.parse_args()
    
    try:
        # åŠ è½½é…ç½®
        type_mapping = {}
        if args.config:
            type_mapping = load_config(args.config)
        
        # ç”Ÿæˆè„šæœ¬
        generator = MigrationScriptGenerator(args.database, type_mapping)
        scripts = generator.generate()
        generator.save_scripts(args.output)
        
        print(f"\nâœ… æˆåŠŸç”Ÿæˆè¿ç§»è„šæœ¬")
        print(f"   - DDL: {len(scripts['ddl'])} ä¸ªè¡¨")
        print(f"   - ç´¢å¼•: {len(scripts['indexes'])} ä¸ª")
        print(f"   - çº¦æŸ: {len(scripts['constraints'])} ä¸ª")
    
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®åº“æ–‡ä»¶ {args.database}")
        sys.exit(1)
    except sqlite3.Error as e:
        print(f"âŒ SQLiteé”™è¯¯: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
