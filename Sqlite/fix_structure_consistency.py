#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨åŒ–ä¿®å¤ Sqlite æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰ Markdown æ–‡ä»¶çš„ç»“æ„ä¸€è‡´æ€§é—®é¢˜
æ”¯æŒä¸­æ–‡ç¼–å·å’Œ emoji æ ¼å¼
"""

import os
import re
from pathlib import Path
from typing import List, Tuple, Dict
import shutil
from datetime import datetime

class StructureFixer:
    def __init__(self, root_dir: str, backup: bool = True, keep_chinese_numbering: bool = True, keep_emoji: bool = True):
        self.root_dir = Path(root_dir)
        self.backup = backup
        self.keep_chinese_numbering = keep_chinese_numbering
        self.keep_emoji = keep_emoji
        self.fixed_files = []
        self.errors = []
        
        # ä¸­æ–‡æ•°å­—æ˜ å°„
        self.chinese_to_num = {'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5, 'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'å': 10}
        self.num_to_chinese = {v: k for k, v in self.chinese_to_num.items()}
        
    def find_markdown_files(self) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰ Markdown æ–‡ä»¶"""
        md_files = []
        for root, dirs, files in os.walk(self.root_dir):
            if any(skip in root for skip in ['.git', '__pycache__', 'node_modules', '.structure_backup']):
                continue
            if '.structure_backup' in dirs:
                dirs.remove('.structure_backup')
            for file in files:
                if file.endswith('.md') and not file.startswith('structure_') and file != 'check_structure_consistency.py' and file != 'fix_structure_consistency.py':
                    md_files.append(Path(root) / file)
        return sorted(md_files)
    
    def backup_file(self, file_path: Path):
        """å¤‡ä»½æ–‡ä»¶"""
        if self.backup:
            backup_dir = self.root_dir / '.structure_backup' / file_path.relative_to(self.root_dir).parent
            backup_dir.mkdir(parents=True, exist_ok=True)
            backup_path = backup_dir / file_path.name
            shutil.copy2(file_path, backup_path)
    
    def extract_headings(self, content: str) -> List[Tuple[int, str, int]]:
        """æå–æ‰€æœ‰æ ‡é¢˜"""
        headings = []
        lines = content.split('\n')
        for i, line in enumerate(lines, 1):
            match = re.match(r'^(#{1,6})\s+(.+)$', line.strip())
            if match:
                level = len(match.group(1))
                text = match.group(2).strip()
                headings.append((level, text, i))
        return headings
    
    def remove_emoji_from_heading(self, text: str) -> str:
        """ç§»é™¤æ ‡é¢˜å¼€å¤´çš„emojiï¼ˆå¦‚æœkeep_emojiä¸ºFalseï¼‰"""
        if self.keep_emoji:
            return text
        emoji_pattern = r'^[ğŸ“–ğŸ—ï¸ğŸ”¬ğŸ’¡ğŸš€ğŸ“šğŸ¯âš™ï¸ğŸ”§âœ…âŒâš ï¸ğŸ’»ğŸŒğŸ”’ğŸ“ŠğŸ¨ğŸ”ğŸ’¾ğŸŒğŸ”ğŸ“ˆğŸ“‰ğŸ“ğŸ’¼ğŸ†ğŸŒŸâœ¨ğŸªğŸ­ğŸ¬ğŸ²ğŸ°ğŸ±ğŸ³ğŸ´ğŸµğŸ¶ğŸ¸ğŸ¹ğŸºğŸ»ğŸ¥ğŸ¤ğŸ§ğŸ“‹ğŸ“‘]\s*'
        text = re.sub(emoji_pattern, '', text)
        return text.strip()
    
    def normalize_heading_numbering(self, headings: List[Tuple[int, str, int]], content: str) -> str:
        """æ ‡å‡†åŒ–æ ‡é¢˜ç¼–å·"""
        lines = content.split('\n')
        new_lines = lines.copy()
        
        level_numbers = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0}
        prev_level = 1
        use_chinese = False  # æ£€æµ‹æ˜¯å¦ä½¿ç”¨ä¸­æ–‡ç¼–å·
        
        # å…ˆæ£€æµ‹æ˜¯å¦ä½¿ç”¨ä¸­æ–‡ç¼–å·
        for level, text, _ in headings:
            if level > 1:
                if re.match(r'^[\u4e00\u4e8c\u4e09\u56db\u4e94\u516d\u4e03\u516b\u4e5d\u5341]+[\s\.ã€]', text):
                    use_chinese = True
                    break
        
        for level, text, line_num in headings:
            if level == 1:
                cleaned_text = self.remove_emoji_from_heading(text)
                new_lines[line_num - 1] = f"# {cleaned_text}"
                continue
            
            cleaned_text = self.remove_emoji_from_heading(text)
            
            # ç§»é™¤ç°æœ‰ç¼–å·ï¼ˆæ•°å­—æˆ–ä¸­æ–‡ï¼‰
            cleaned_text = re.sub(r'^(\d+(\.\d+)*|[\u4e00\u4e8c\u4e09\u56db\u4e94\u516d\u4e03\u516b\u4e5d\u5341]+)[\s\.ã€]+', '', cleaned_text)
            cleaned_text = cleaned_text.strip()
            
            if level <= prev_level:
                for l in range(level + 1, 7):
                    level_numbers[l] = 0
            
            level_numbers[level] += 1
            
            # ç”Ÿæˆç¼–å·
            if level == 2:
                if self.keep_chinese_numbering and use_chinese:
                    number = self.num_to_chinese.get(level_numbers[2], str(level_numbers[2]))
                    separator = 'ã€' if use_chinese else '.'
                else:
                    number = str(level_numbers[2])
                    separator = '.'
            elif level == 3:
                if self.keep_chinese_numbering and use_chinese:
                    num2 = self.num_to_chinese.get(level_numbers[2], str(level_numbers[2]))
                    num3 = str(level_numbers[3])
                    number = f"{num2}.{num3}"
                    separator = '.'
                else:
                    number = f"{level_numbers[2]}.{level_numbers[3]}"
                    separator = '.'
            elif level == 4:
                number = f"{level_numbers[2]}.{level_numbers[3]}.{level_numbers[4]}"
                separator = '.'
            else:
                number = ""
                separator = ""
            
            hashes = '#' * level
            if number:
                new_lines[line_num - 1] = f"{hashes} {number}{separator} {cleaned_text}"
            else:
                new_lines[line_num - 1] = f"{hashes} {cleaned_text}"
            
            prev_level = level
        
        return '\n'.join(new_lines)
    
    def fix_heading_level_jumps(self, content: str) -> str:
        """ä¿®å¤æ ‡é¢˜å±‚çº§è·³è·ƒ"""
        lines = content.split('\n')
        new_lines = []
        prev_level = 1
        
        for i, line in enumerate(lines):
            match = re.match(r'^(#{1,6})\s+(.+)$', line.strip())
            if match:
                level = len(match.group(1))
                text = match.group(2).strip()
                
                if level > prev_level + 1:
                    new_level = min(level, prev_level + 1)
                    hashes = '#' * new_level
                    new_lines.append(f"{hashes} {text}")
                    prev_level = new_level
                else:
                    new_lines.append(line)
                    if level > 0:
                        prev_level = level
            else:
                new_lines.append(line)
        
        return '\n'.join(new_lines)
    
    def fix_file(self, file_path: Path) -> Tuple[bool, List[str]]:
        """ä¿®å¤å•ä¸ªæ–‡ä»¶"""
        try:
            self.backup_file(file_path)
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            issues_fixed = []
            headings = self.extract_headings(content)
            
            if not headings:
                return False, ["æ–‡ä»¶æ²¡æœ‰æ ‡é¢˜"]
            
            needs_fix = False
            
            # æ£€æŸ¥æ··åˆç¼–å·
            numbered_count = 0
            unnumbered_count = 0
            for h in headings:
                if h[0] > 1:
                    text = h[1]
                    if re.match(r'^(\d+(\.\d+)*|[\u4e00\u4e8c\u4e09\u56db\u4e94\u516d\u4e03\u516b\u4e5d\u5341]+)[\s\.ã€]', text):
                        numbered_count += 1
                    elif not re.match(r'^[ğŸ“–ğŸ—ï¸ğŸ”¬ğŸ’¡ğŸš€ğŸ“šğŸ¯âš™ï¸ğŸ”§âœ…âŒâš ï¸ğŸ’»ğŸŒğŸ”’ğŸ“ŠğŸ¨ğŸ”ğŸ’¾ğŸŒğŸ”ğŸ“ˆğŸ“‰ğŸ“ğŸ’¼ğŸ†ğŸŒŸâœ¨ğŸªğŸ­ğŸ¬ğŸ²ğŸ°ğŸ±ğŸ³ğŸ´ğŸµğŸ¶ğŸ¸ğŸ¹ğŸºğŸ»ğŸ¥ğŸ¤ğŸ§ğŸ“‹ğŸ“‘]', text):
                        unnumbered_count += 1
            
            if numbered_count > 0 and unnumbered_count > 0:
                needs_fix = True
                issues_fixed.append("ä¿®å¤æ··åˆç¼–å·")
            
            # æ£€æŸ¥å±‚çº§è·³è·ƒ
            prev_level = headings[0][0]
            for level, text, line_num in headings[1:]:
                if level > prev_level + 1:
                    needs_fix = True
                    issues_fixed.append(f"ä¿®å¤å±‚çº§è·³è·ƒï¼ˆè¡Œ{line_num}ï¼‰")
                    break
                if level > 0:
                    prev_level = level
            
            # æ£€æŸ¥emojiï¼ˆå¦‚æœkeep_emojiä¸ºFalseï¼‰
            if not self.keep_emoji:
                has_emoji = any(re.match(r'^[ğŸ“–ğŸ—ï¸ğŸ”¬ğŸ’¡ğŸš€ğŸ“šğŸ¯âš™ï¸ğŸ”§âœ…âŒâš ï¸ğŸ’»ğŸŒğŸ”’ğŸ“ŠğŸ¨ğŸ”ğŸ’¾ğŸŒğŸ”ğŸ“ˆğŸ“‰ğŸ“ğŸ’¼ğŸ†ğŸŒŸâœ¨ğŸªğŸ­ğŸ¬ğŸ²ğŸ°ğŸ±ğŸ³ğŸ´ğŸµğŸ¶ğŸ¸ğŸ¹ğŸºğŸ»ğŸ¥ğŸ¤ğŸ§ğŸ“‹ğŸ“‘]', h[1]) for h in headings)
                if has_emoji:
                    needs_fix = True
                    issues_fixed.append("ç§»é™¤æ ‡é¢˜ä¸­çš„emoji")
            
            if not needs_fix:
                return False, []
            
            # æ‰§è¡Œä¿®å¤
            content = self.fix_heading_level_jumps(content)
            headings = self.extract_headings(content)
            content = self.normalize_heading_numbering(headings, content)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            return True, issues_fixed
            
        except Exception as e:
            return False, [f"é”™è¯¯: {str(e)}"]
    
    def fix_all_files(self):
        """ä¿®å¤æ‰€æœ‰æ–‡ä»¶"""
        md_files = self.find_markdown_files()
        print(f"æ‰¾åˆ° {len(md_files)} ä¸ª Markdown æ–‡ä»¶\n")
        
        if self.backup:
            backup_dir = self.root_dir / '.structure_backup'
            backup_dir.mkdir(exist_ok=True)
            print(f"å¤‡ä»½ç›®å½•: {backup_dir}\n")
        
        fixed_count = 0
        error_count = 0
        
        for i, file_path in enumerate(md_files, 1):
            rel_path = file_path.relative_to(self.root_dir)
            print(f"[{i}/{len(md_files)}] å¤„ç†: {rel_path}")
            
            success, issues = self.fix_file(file_path)
            
            if success:
                fixed_count += 1
                self.fixed_files.append({
                    'file': str(rel_path),
                    'issues': issues
                })
                print(f"  âœ“ å·²ä¿®å¤: {', '.join(issues)}")
            elif issues:
                error_count += 1
                self.errors.append({
                    'file': str(rel_path),
                    'error': issues[0]
                })
                print(f"  âœ— é”™è¯¯: {issues[0]}")
            else:
                print(f"  - æ— éœ€ä¿®å¤")
        
        print(f"\n{'='*80}")
        print(f"ä¿®å¤å®Œæˆ!")
        print(f"  æ€»æ–‡ä»¶æ•°: {len(md_files)}")
        print(f"  å·²ä¿®å¤: {fixed_count}")
        print(f"  é”™è¯¯: {error_count}")
        print(f"  æ— éœ€ä¿®å¤: {len(md_files) - fixed_count - error_count}")
        
        return {
            'total': len(md_files),
            'fixed': fixed_count,
            'errors': error_count,
            'fixed_files': self.fixed_files,
            'errors': self.errors
        }

def main():
    script_dir = Path(__file__).parent
    # ä¿ç•™ä¸­æ–‡ç¼–å·å’Œemoji
    fixer = StructureFixer(script_dir, backup=True, keep_chinese_numbering=True, keep_emoji=True)
    
    print("="*80)
    print("Sqlite æ–‡ä»¶å¤¹ç»“æ„ä¸€è‡´æ€§ä¿®å¤å·¥å…·")
    print("="*80)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    results = fixer.fix_all_files()
    
    import json
    report_file = script_dir / 'structure_fix_report.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nä¿®å¤æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == '__main__':
    main()
